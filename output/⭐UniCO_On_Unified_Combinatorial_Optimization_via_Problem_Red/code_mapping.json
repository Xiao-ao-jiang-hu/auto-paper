{
  "file_path": "MatDIFFNet/src/env.py, MatDIFFNet/src/model.py, MatDIFFNet/src/solver.py, MatDIFFNet_jittor/src/model.py, MatDIFFNet_jittor/src/solver.py, MatPOENet/ATSPEnv.py, MatPOENet/ATSPModel.py, MatPOENet/ATSPTrainer.py, MatPOENet_jittor/ATSPModel.py",
  "function_name": "MatDIFFNetEnv, MatDIFFNetModel, MatDIFFNetSolver, MatDIFFNetModel, MatDIFFNetSolver, ATSPEnv, ATSPModel, ATSPTrainer, ATSPModel",
  "code_snippet": "\n\n# ==========================================\n# File: MatDIFFNet/src/env.py\n# Function/Context: MatDIFFNetEnv\n# ==========================================\nimport torch\nimport numpy as np\nimport torch.utils.data\nfrom torch import Tensor\nfrom typing import Union\nfrom sortedcollections import OrderedSet\nfrom scipy.spatial.distance import cdist\nfrom torch.utils.data import DataLoader as GraphDataLoader\nfrom ml4co_kit import BaseEnv, to_numpy, to_tensor, check_dim\nfrom ml4co_kit import ATSPSolver, ATSPDataGenerator, TSPSolver\n\nclass MatDIFFNetEnv(BaseEnv):\n    def __init__(\n        self,\n        data_type: list = [\"TSP\", \"ATSP\", \"SAT\", \"HCP\", \"VC\"],\n        nodes_num: int = None,\n        mode: str = None,\n        train_data_size: int = 128000,\n        train_batch_size: int = 1,\n        test_batch_size: int = 1,\n        val_samples: int = 1280,\n        num_workers: int = 4,\n        # TSP (Uniform)\n        tsp_train_path: str = None,\n        tsp_val_path: str = None,\n        tsp_test_path: str = None,\n        # ATSP (Uniform)\n        atsp_train_path: str = None,\n        atsp_val_path: str = None,\n        atsp_test_path: str = None,\n        # ATSP (SAT)\n        sat_clauses_num: list = [3, 4, 5, 6, 7],\n        sat_vars_num: list = [6, 5, 5, 4, 3],\n        # ATSP (HCP)\n        hcp_nodes_num: int = 50,\n        # ATSP (VC)\n        vc_e_scale: tuple = (10, 13),\n        vc_k_scale: tuple = (3, 8),\n        vc_n_scale: tuple = (8, 18),\n        # Device\n        device: str = \"cpu\"\n    ):\n        super(MatDIFFNetEnv, self).__init__(\n            name=\"MatDIFFNetEnv\",\n            mode=mode,\n            train_batch_size=train_batch_size,\n            val_batch_size=val_samples,\n            test_batch_size=test_batch_size,\n            num_workers=num_workers,\n            device=device\n        )\n        \n        # Basic\n        self.nodes_num = nodes_num\n        self.train_data_size = train_data_size\n        self.data_type = data_type\n        self.val_samples = val_samples\n\n        # ML4CO-Kit Solvers\n        self.tmp_tsp_solver = TSPSolver()\n        self.tmp_atsp_solver = ATSPSolver()\n        \n        # TSP (Uniform)\n        self.tsp_train_path = tsp_train_path\n        self.tsp_val_path = tsp_val_path\n        self.tsp_test_path = tsp_test_path\n        self.tsp_points_train = None\n        self.tsp_ref_tours_train = None\n        self.tsp_start_idx_train = 0\n        self.tsp_points_val = None\n        self.tsp_ref_tours_val = None\n        \n        # ATSP (Uniform)\n        self.atsp_train_path = atsp_train_path\n        self.atsp_val_path = atsp_val_path\n        self.atsp_test_path = atsp_test_path\n        self.atsp_dists_train = None\n        self.atsp_ref_tours_train = None\n        self.atsp_start_idx_train = 0\n        self.atsp_dists_val = None\n        self.atsp_ref_tours_val = None\n        \n        # ATSP (SAT)\n        self.sat_clauses_num = sat_clauses_num\n        self.sat_vars_num = sat_vars_num\n        assert len(self.sat_clauses_num) == len(self.sat_vars_num)\n        \n        # ATSP (HCP)\n        self.hcp_nodes_num = hcp_nodes_num\n        \n        # ATSP (VC)\n        self.vc_e_scale = vc_e_scale\n        self.vc_k_scale = vc_k_scale\n        self.vc_n_scale = vc_n_scale\n\n        # load data\n        self.load_data()\n        \n    def load_data(self):\n        if self.mode == \"train\":\n            # train dataset\n            self.train_dataset = FakeDataset(data_size=self.train_data_size)\n            \n            if \"TSP\" in self.data_type:\n                self.tmp_tsp_solver.from_txt(self.tsp_train_path, show_time=True, ref=True)\n                self.tsp_points_train = self.tmp_tsp_solver.points\n                self.tsp_ref_tours_train = self.tmp_tsp_solver.ref_tours\n                \n            if \"ATSP\" in self.data_type:\n                self.tmp_atsp_solver.from_txt(self.atsp_train_path, show_time=True, ref=True)\n                self.atsp_dists_train = self.tmp_atsp_solver.dists\n                self.atsp_ref_tours_train = self.tmp_atsp_solver.ref_tours\n                    \n            # val dataset\n            self.val_dataset = FakeDataset(data_size=self.val_samples)\n\n            if \"TSP\" in self.data_type:\n                self.tmp_tsp_solver.from_txt(self.tsp_val_path, show_time=True, ref=True)\n                self.tsp_points_val = self.tmp_tsp_solver.points\n                self.tsp_ref_tours_val = self.tmp_tsp_solver.ref_tours \n\n            if \"ATSP\" in self.data_type:\n                self.tmp_atsp_solver.from_txt(self.atsp_val_path, show_time=True, ref=True)\n                self.atsp_dists_val = self.tmp_atsp_solver.dists\n                self.atsp_ref_tours_val = self.tmp_atsp_solver.ref_tours\n\n        elif self.mode == \"test\":\n            # test dataset\n            self.test_dataset = FakeDataset(data_size=1280)\n        else:\n            # solve mode / none mode\n            pass\n    \n    def train_dataloader(self):\n        train_dataloader=GraphDataLoader(\n            self.train_dataset, \n            batch_size=self.train_batch_size, \n            shuffle=True,\n            num_workers=self.num_workers, \n            pin_memory=True,\n            persistent_workers=True, \n            drop_last=True\n        )\n        return train_dataloader\n\n    def val_dataloader(self):\n        val_dataloader=GraphDataLoader(\n            self.val_dataset, \n            batch_size=self.val_batch_size, \n            shuffle=False\n        )\n        return val_dataloader\n    \n    def test_dataloader(self):\n        # force the test batch size to be 1\n        self.test_batch_size = 1\n        test_dataloader=GraphDataLoader(\n            self.test_dataset,\n            batch_size=self.test_batch_size, \n        )\n        return test_dataloader\n    \n    def _process_data(self, dists: Tensor, ref_tour: Tensor) -> Tensor:\n        # check dim\n        check_dim(dists, 2)\n        check_dim(ref_tour, 1)\n        \n        # to numpy\n        dists = to_numpy(dists)\n        ref_tour = to_numpy(ref_tour)\n        \n        # adj matrix\n        nodes_num = dists.shape[0]\n        adj_matrix = np.zeros((nodes_num, nodes_num))\n        for i in range(ref_tour.shape[0] - 1):\n            adj_matrix[ref_tour[i], ref_tour[i + 1]] = 1\n        \n        # to tensor\n        adj_matrix = to_tensor(adj_matrix)\n        return adj_matrix\n\n    def process_data(self, dists: Tensor, ref_tours: Tensor) -> Tensor:\n        # check dim\n        check_dim(dists, 3)\n        check_dim(ref_tours, 2)\n        \n        # process data\n        nodes_num = dists[0].shape[-1]\n        adj_matrix_list = list() \n        for idx in range(dists.shape[0]):\n            adj_matrix = self._process_data(dists[idx], ref_tours[idx])\n            adj_matrix_list.append(adj_matrix)\n        \n        # torch.cat\n        adj_matrix = torch.cat(adj_matrix_list, dim=0).to(self.device)\n        adj_matrix = adj_matrix.reshape(-1, nodes_num, nodes_num)\n        return adj_matrix\n        \n    def generate_data(self, batch_size: int) -> Union[Tensor, Tensor]:\n        idx = np.random.randint(low=0, high=len(self.data_type), size=(1,))[0]\n        data_type = self.data_type[idx]\n        if data_type == \"TSP\":\n            dists, ref_tours = self.generate_data_tsp(batch_size)\n        elif data_type == \"ATSP\":\n            dists, ref_tours = self.generate_data_atsp(batch_size)\n        elif data_type == \"SAT\":\n            dists, ref_tours = self.generate_data_sat(batch_size)\n        elif data_type == \"HCP\":\n            dists, ref_tours = self.generate_data_hcp(batch_size)\n        elif data_type == \"VC\":\n            dists, ref_tours = self.generate_data_vc(batch_size)\n        dists = to_tensor(dists).to(self.device)\n        ref_tours = to_tensor(ref_tours).to(self.device)\n        return dists, ref_tours\n    \n    def generate_data_tsp(self, batch_size: int) -> Union[np.ndarray, np.ndarray]:\n        idx = self.tsp_start_idx_train\n        start_idx = idx * batch_size\n        end_idx = start_idx + batch_size\n        points: np.ndarray = self.tsp_points_train[start_idx : end_idx]\n        ref_tours = self.tsp_ref_tours_train[start_idx : end_idx]\n        if end_idx + batch_size < len(self.tsp_points_train):\n            self.tsp_start_idx_train += 1\n        else:\n            self.tsp_start_idx_train = 0\n        dists = np.array([cdist(points[idx], points[idx]) for idx in range(points.shape[0])])\n        self.nodes_num = dists.shape[-1]\n        return dists, ref_tours\n    \n    def generate_data_atsp(self, batch_size: int) -> Union[np.ndarray, np.ndarray]:\n        idx = self.atsp_start_idx_train\n        start_idx = idx * batch_size\n        end_idx = start_idx + batch_size\n        dists: np.ndarray = self.atsp_dists_train[start_idx : end_idx]\n        ref_tours = self.atsp_ref_tours_train[start_idx : end_idx]\n        if end_idx + batch_size < len(self.atsp_dists_train):\n            self.atsp_start_idx_train += 1\n        else:\n            self.atsp_start_idx_train = 0\n        self.nodes_num = dists.shape[-1]\n        return dists, ref_tours\n    \n    def generate_data_sat(self, batch_size: int) -> Union[np.ndarray, np.ndarray]:\n        rand_i = np.random.randint(0, len(self.sat_clauses_num))\n        sat_vars_nums = self.sat_vars_num[rand_i]\n        sat_clauses_nums = self.sat_clauses_num[rand_i]\n        tmp_astp_generator = ATSPDataGenerator(\n            num_threads=batch_size,\n            data_type=\"sat\",\n            sat_vars_nums=sat_vars_nums,\n            sat_clauses_nums=sat_clauses_nums\n        )\n        self.nodes_num = tmp_astp_generator.nodes_num\n        return tmp_astp_generator._generate_sat()\n    \n    def generate_data_hcp(self, batch_size: int) -> Union[np.ndarray, np.ndarray]:\n        tmp_astp_generator = ATSPDataGenerator(\n            nodes_num=self.hcp_nodes_num,\n            num_threads=batch_size,\n            data_type=\"hcp\",\n        )\n        self.nodes_num = tmp_astp_generator.nodes_num\n        return tmp_astp_generator._generate_hcp()\n\n    def generate_data_vc(self, batch_size: int) -> Union[np.ndarray, np.ndarray]:\n        E = np.random.randint(self.vc_e_scale[0], self.vc_e_scale[1])\n        K = np.random.randint(self.vc_k_scale[0], self.vc_k_scale[1])\n        N = np.random.randint(self.vc_n_scale[0], self.vc_n_scale[1])\n        dists = list()\n        ref_tours = list()\n        for _ in range(batch_size):\n            dist, ref_tour = gen_vertex_cover(E, K, N, calc_gt=True)\n            dists.append(dist)\n            ref_tours.append(ref_tour)\n        return np.array(dists), np.array(ref_tours)\n\n    def get_val_data(self) -> dict:\n        val_data_dict = dict()\n        for k in self.data_type:\n            if k == \"TSP\":\n                points = self.tsp_points_val\n                tsp_dists_val = np.array([cdist(points[idx], points[idx]) for idx in range(self.val_samples)])\n                val_data_dict[\"TSP\"] = (tsp_dists_val[:self.val_samples], self.tsp_ref_tours_val[:self.val_samples])\n            if k == \"ATSP\":\n                val_data_dict[\"ATSP\"] = (self.atsp_dists_val[:self.val_samples], self.atsp_ref_tours_val[:self.val_samples])\n            if k == \"SAT\":\n                val_data_dict[\"SAT\"] = self.generate_data_sat(self.val_samples)\n            if k == \"HCP\":\n                val_data_dict[\"HCP\"] = self.generate_data_hcp(self.val_samples)\n            if k == \"VC\":\n                val_data_dict[\"VC\"] = self.generate_data_hcp(self.val_samples)\n        return val_data_dict\n\ndef gen_vertex_cover(num_edges, k, ori_N, calc_gt=False):\n    '''\n    num_edges: Number of edges in VC G\n    k: Number of nodes as vertex cover\n    ori_N: num_nodes in original VC graph G\n\n    if self.env_params['node_cnt'] == 50:\n        E = np.random.randint(10, 13) -> num_edges\n        k = np.random.randint(3, 8)   -> k\n        N = np.random.randint(8, 18)  -> ori_N\n    elif self.env_params['node_cnt'] == 100:\n        E = np.random.randint(21, 24)\n        k = np.random.randint(6, 14)\n        N = np.random.randint(14, 30)\n    '''\n    N = 4 * num_edges + k # num_nodes in the HCP graph G'\n    dist = np.ones((N, N))\n    vertex_cover = OrderedSet(np.random.choice(ori_N, size=k, replace=False)) # select k nodes as vertex cover\n    adj_list = [OrderedSet() for _ in range(ori_N)]\n    cover_ofs = 4 * num_edges\n    start_idx = {} # starting index of nodes in G'\n    gt_tour = []\n    link_edges = []\n    while True:\n        valid = True\n        for _ in range(num_edges):\n            while True:\n                if calc_gt:\n                    u = vertex_cover[np.random.randint(k)]\n                else:\n                    u = np.random.randint(ori_N)\n                v = np.random.randint(ori_N)\n                if u == v:\n                    continue\n                if v not in adj_list[u]:\n                    adj_list[u].add(v)\n                    adj_list[v].add(u)\n                    break\n        for u in vertex_cover:\n            if not adj_list[u]:\n                valid = False\n                break\n        if valid:\n            break\n        else:\n            adj_list = [OrderedSet() for _ in range(ori_N)]\n            continue\n    new_node_idx = 0\n    for i in range(ori_N):\n        for j in range(len(adj_list[i])):\n            u, v = i, adj_list[i][j]\n            start_idx[(u, v)] = new_node_idx + j * 2\n        new_node_idx += (2 * len(adj_list[i]))\n    for u in range(ori_N):\n        for i in range(len(adj_list[u])):\n            v = adj_list[u][i]\n            v_idx = start_idx[(v, u)]\n            u_idx = start_idx[(u, v)]\n            dist[u_idx, u_idx + 1] = 0\n            dist[u_idx, v_idx] = 0\n            dist[v_idx, u_idx] = 0\n            dist[u_idx + 1, v_idx + 1] = 0\n            dist[v_idx + 1, u_idx + 1] = 0\n            if i == 0:\n                for j in range(k):\n                    cover_node = cover_ofs + j\n                    dist[cover_node, u_idx] = 0\n                    link_edges.append((cover_node, u_idx))\n            if i == len(adj_list[u]) - 1:\n                for j in range(k):\n                    cover_node = cover_ofs + j\n                    dist[u_idx + 1, cover_node] = 0\n                    link_edges.append((u_idx + 1, cover_node))\n            else:\n                dist[u_idx + 1, u_idx + 2] = 0\n    cover_node = cover_ofs\n    if calc_gt:\n        for u in vertex_cover:\n            gt_tour.append(cover_node)\n            for i in range(len(adj_list[u])):                    \n                v = adj_list[u][i]\n                v_idx = start_idx[(v, u)]\n                u_idx = start_idx[(u, v)]\n                if v in vertex_cover:\n                    gt_tour.extend([u_idx, u_idx + 1])\n                else:\n                    gt_tour.extend([u_idx, v_idx, v_idx + 1, u_idx + 1])\n            cover_node += 1\n        assert len(gt_tour) == N, f'{len(gt_tour)} != {N}'\n        gt_tour.append(gt_tour[0])\n        assert sorted(gt_tour[:-1]) == [i for i in range(N)], sorted(gt_tour[:-1])\n    return dist, gt_tour\n\n# ==========================================\n# File: MatDIFFNet/src/model.py\n# Function/Context: MatDIFFNetModel\n# ==========================================\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch import nn, Tensor\nfrom typing import Any, Union, Tuple\nfrom ml4co_kit import BaseModel, ATSPSolver, to_numpy\nfrom .env import MatDIFFNetEnv\nfrom .gnn_encoder import GNNEncoder\nfrom .decoder import MatDIFFNetDecoder\nfrom .diffusion_utils import CategoricalDiffusion, InferenceSchedule\n\n\ndef get_coords_by_dists(dists: Tensor) -> Union[Tensor, Tensor]:\n    batch_size, nodes_num, _ = dists.shape\n    coords = torch.arange(2*nodes_num) + 1 / (2*nodes_num)\n    coords = coords.reshape(1, nodes_num, 2)\n    coords = coords.expand(batch_size, nodes_num, 2)\n    coords_source = coords[:, :, 0]\n    coords_target = coords[:, :, 1]\n    return coords_source, coords_target\n\n\nclass MatDIFFNetModel(BaseModel):\n    def __init__(\n        self,\n        env: MatDIFFNetEnv,\n        encoder: GNNEncoder,\n        decoder: MatDIFFNetDecoder,\n        lr_scheduler: str = \"cosine-decay\",\n        learning_rate: float = 2e-4,\n        weight_decay: float = 1e-4,\n        # diffusion\n        diffusion_schedule: str = \"linear\",\n        inference_schedule: str = \"cosine\",\n        diffusion_steps: int = 1000,\n        inference_diffusion_steps: int = 50,\n        parallel_sampling: int = 1,\n        sequential_sampling: int = 1,\n    ):      \n        # super\n        super(MatDIFFNetModel, self).__init__(\n            env=env,\n            model=encoder,\n            lr_scheduler=lr_scheduler,\n            learning_rate=learning_rate,\n            weight_decay=weight_decay\n        )\n        self.env: MatDIFFNetEnv\n        self.model: GNNEncoder\n        self.decoder = decoder\n\n        # diffusion\n        self.diffusion_schedule = diffusion_schedule\n        self.inference_schedule = inference_schedule\n        self.diffusion_steps = diffusion_steps\n        self.inference_diffusion_steps = inference_diffusion_steps\n        self.diffusion = CategoricalDiffusion(\n            T=self.diffusion_steps, schedule=self.diffusion_schedule\n        )\n        self.parallel_sampling = parallel_sampling\n        self.sequential_sampling = sequential_sampling\n            \n        # record solved tours\n        self.solved_tours_list = list()\n    \n    def categorical_posterior(\n        self, target_t: int, t: int, x0_pred_prob: Tensor, xt: Tensor\n    ) -> Tensor:\n        diffusion = self.diffusion\n\n        if target_t is None:\n            target_t = t - 1\n        else:\n            target_t = torch.from_numpy(target_t).view(1)\n\n        if target_t > 0:\n            Q_t = np.linalg.inv(diffusion.Q_bar[target_t]) @ diffusion.Q_bar[t]\n            Q_t = torch.from_numpy(Q_t).float().to(x0_pred_prob.device)\n        else:\n            Q_t = torch.eye(2).float().to(x0_pred_prob.device)\n        Q_bar_t_source = (\n            torch.from_numpy(diffusion.Q_bar[t]).float().to(x0_pred_prob.device)\n        )\n        Q_bar_t_target = (\n            torch.from_numpy(diffusion.Q_bar[target_t]).float().to(x0_pred_prob.device)\n        )\n\n        xt = F.one_hot(xt.long(), num_classes=2).float()\n        xt = xt.reshape(x0_pred_prob.shape)\n\n        x_t_target_prob_part_1 = torch.matmul(xt, Q_t.permute((1, 0)).contiguous())\n        x_t_target_prob_part_2 = Q_bar_t_target[0]\n        x_t_target_prob_part_3 = (Q_bar_t_source[0] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_target_prob = (\n            x_t_target_prob_part_1 * x_t_target_prob_part_2\n        ) / x_t_target_prob_part_3\n\n        sum_x_t_target_prob = x_t_target_prob[..., 1] * x0_pred_prob[..., 0]\n        x_t_target_prob_part_2_new = Q_bar_t_target[1]\n        x_t_target_prob_part_3_new = (Q_bar_t_source[1] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_source_prob_new = (\n            x_t_target_prob_part_1 * x_t_target_prob_part_2_new\n        ) / x_t_target_prob_part_3_new\n\n        sum_x_t_target_prob += x_t_source_prob_new[..., 1] * x0_pred_prob[..., 1]\n\n        if target_t > 0:\n            xt = torch.bernoulli(sum_x_t_target_prob.clamp(0, 1))\n        else:\n            xt = sum_x_t_target_prob.clamp(min=0)\n\n        return xt\n\n    def guided_categorical_posterior(\n        self,\n        target_t: int,\n        t: int,\n        x0_pred_prob: Tensor,\n        xt: Tensor,\n        grad=None,\n    ) -> Tensor:\n        # xt: b, n, n\n        if grad is None:\n            grad = xt.grad\n        with torch.no_grad():\n            diffusion = self.diffusion\n        if target_t is None:\n            target_t = t - 1\n        else:\n            target_t = torch.from_numpy(target_t).view(1)\n\n        if target_t > 0:\n            Q_t = np.linalg.inv(diffusion.Q_bar[target_t]) @ diffusion.Q_bar[t]\n            Q_t = (\n                torch.from_numpy(Q_t).float().to(x0_pred_prob.device)\n            )  # [2, 2], transition matrix\n        else:\n            Q_t = torch.eye(2).float().to(x0_pred_prob.device)\n        Q_bar_t_source = (\n            torch.from_numpy(diffusion.Q_bar[t]).float().to(x0_pred_prob.device)\n        )\n        Q_bar_t_target = (\n            torch.from_numpy(diffusion.Q_bar[target_t]).float().to(x0_pred_prob.device)\n        )\n\n        xt_grad_zero, xt_grad_one = torch.zeros(xt.shape, device=xt.device).unsqueeze(\n            -1\n        ).repeat(1, 1, 1, 2), torch.zeros(xt.shape, device=xt.device).unsqueeze(\n            -1\n        ).repeat(\n            1, 1, 1, 2\n        )\n        xt_grad_zero[..., 0] = (1 - xt) * grad\n        xt_grad_zero[..., 1] = -xt_grad_zero[..., 0]\n        xt_grad_one[..., 1] = xt * grad\n        xt_grad_one[..., 0] = -xt_grad_one[..., 1]\n        xt_grad = xt_grad_zero + xt_grad_one\n\n        xt = F.one_hot(xt.long(), num_classes=2).float()\n        xt = xt.reshape(x0_pred_prob.shape)  # [b, n, n, 2]\n\n        # q(xt−1|xt,x0=0)pθ(x0=0|xt)\n        x_t_target_prob_part_1 = torch.matmul(xt, Q_t.permute((1, 0)).contiguous())\n        x_t_target_prob_part_2 = Q_bar_t_target[0]\n        x_t_target_prob_part_3 = (Q_bar_t_source[0] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_target_prob = (\n            x_t_target_prob_part_1 * x_t_target_prob_part_2\n        ) / x_t_target_prob_part_3  # [b, n, n, 2]\n\n        sum_x_t_target_prob = x_t_target_prob[..., 1] * x0_pred_prob[..., 0]\n\n        # q(xt−1|xt,x0=1)pθ(x0=1|xt)\n        x_t_target_prob_part_2_new = Q_bar_t_target[1]\n        x_t_target_prob_part_3_new = (Q_bar_t_source[1] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_source_prob_new = (\n            x_t_target_prob_part_1 * x_t_target_prob_part_2_new\n        ) / x_t_target_prob_part_3_new\n\n        sum_x_t_target_prob += x_t_source_prob_new[..., 1] * x0_pred_prob[..., 1]\n\n        p_theta = torch.cat(\n            (1 - sum_x_t_target_prob.unsqueeze(-1), sum_x_t_target_prob.unsqueeze(-1)),\n            dim=-1,\n        )\n        p_phi = torch.exp(-xt_grad)\n        posterior = (p_theta * p_phi) / torch.sum(\n            (p_theta * p_phi), dim=-1, keepdim=True\n        )\n\n        if target_t > 0:\n            xt = torch.bernoulli(posterior[..., 1].clamp(0, 1))\n        else:\n            xt = posterior[..., 1].clamp(min=0)\n            \n        return xt\n\n    def categorical_denoise_step(\n        self,\n        dists: Tensor,\n        xt: Tensor,\n        t: Tensor,\n        device: str,\n        edge_index: Tensor = None,\n        target_t: Tensor = None,\n    ):\n        with torch.no_grad():\n            t = torch.from_numpy(t).view(1)\n            xt: Tensor\n            if xt.ndim == 2:\n                xt = xt.unsqueeze(dim=0)\n            xt = xt.to(self.device)\n\n            xt_scale = (xt * 2 - 1).float()\n            xt_scale = xt_scale * (1.0 + 0.05 * torch.rand_like(xt_scale))\n\n            # get nodes\n            x1, x2 = get_coords_by_dists(dists)\n            x1 = x1.float().to(self.device)\n            x2 = x2.float().to(self.device)\n        \n            x0_pred = self.model.forward(\n                x1=x1,\n                x2=x2,\n                dists=dists.float().to(device),\n                graph=xt_scale.float().to(device),\n                edge_index=edge_index.long().to(device) if edge_index is not None else None,\n                timesteps=t.float().to(device),\n            )\n\n            x0_pred_prob = (\n                x0_pred.permute((0, 2, 3, 1)).contiguous().softmax(dim=-1)\n            )\n            \n            x0_pred_prob = x0_pred_prob.to(self.device)\n            xt = self.categorical_posterior(target_t, t, x0_pred_prob, xt)\n            return xt\n\n    @torch.enable_grad() \n    @torch.inference_mode(False)\n    def guided_categorical_denoise_step(\n        self, \n        dists: Tensor, \n        xt: Tensor, \n        t: Tensor, \n        device: str, \n        edge_index: Tensor=None, \n        target_t: Tensor=None\n    ):\n        xt = xt.float()  # b, n, n\n        xt.requires_grad = True\n        t = torch.from_numpy(t).view(1)\n        if edge_index is not None: edge_index = edge_index.clone()\n\n        # [b, 2, n, n]\n        # with torch.inference_mode(False):\n        ###############################################\n        # scale to [-1, 1]\n        xt_scale = (xt * 2 - 1)\n        xt_scale = xt_scale * (1.0 + 0.05 * torch.rand_like(xt_scale))\n        # xt_scale = xt\n        ###############################################\n\n        # print(dists.shape, xt.shape)\n        x0_pred = self.forward(\n            dists.float().to(device),\n            xt_scale.to(device),\n            edge_index.long().to(device) if edge_index is not None else None,\n            t.float().to(device),\n        )\n\n        x0_pred_prob = x0_pred.permute((0, 2, 3, 1)).contiguous().softmax(dim=-1)\n        cost_est = (dists * x0_pred_prob[..., 1]).sum()\n        cost_est.requires_grad_(True)\n        cost_est.backward()\n        \n        assert xt.grad is not None\n\n        xt.grad = nn.functional.normalize(xt.grad, p=2, dim=-1)\n        xt = self.guided_categorical_posterior(target_t, t, x0_pred_prob, xt)\n\n        return xt.detach()\n      \n    def solve_encode(self, dists: Tensor) -> Tensor:        \n        device = dists.device\n        heatmap_list = list()\n\n        # dists & edge_index\n        dists = dists.repeat(self.parallel_sampling, 1, 1)\n\n        # heatmap\n        batch_size = dists.shape[0]\n        for _ in range(self.sequential_sampling):\n            # diffusion xt\n            xt = torch.randn(batch_size, self.env.nodes_num, self.env.nodes_num)\n            if self.parallel_sampling > 1:\n                xt = xt.repeat(self.parallel_sampling, 1, 1)\n                xt = torch.randn_like(xt)\n            xt = (xt > 0).long().to(device)\n\n            # time schedule\n            time_schedule = InferenceSchedule(\n                inference_schedule=self.inference_schedule,\n                T=self.diffusion.T,\n                inference_T=self.inference_diffusion_steps,\n            )\n\n            # Diffusion iterations\n            for i in range(self.inference_diffusion_steps):\n                t1, t2 = time_schedule(i)\n                t1 = np.array([t1]).astype(int)\n                t2 = np.array([t2]).astype(int)\n                # [B, N, N], heatmap score\n                xt = self.categorical_denoise_step(\n                    dists, xt, t1, device, edge_index=None, target_t=t2\n                )\n\n            heatmap_list.append(xt)\n            \n        heatmap = torch.cat(heatmap_list, dim=0)\n        heatmap = heatmap.reshape(-1, self.env.nodes_num, self.env.nodes_num)\n        return heatmap\n\n    def train_test_encode(\n        self, dists: Tensor, adj_matrix: Tensor = None,\n    ) -> Tuple[Tensor, Tensor]:\n        # xt\n        adj_matrix_onehot: Tensor = F.one_hot(adj_matrix.long(), num_classes=2)\n        adj_matrix_onehot = adj_matrix_onehot.float()\n        t = np.random.randint(1, self.diffusion.T + 1, dists.shape[0]).astype(int)\n        xt = self.diffusion.sample(adj_matrix_onehot, t)    \n        xt = xt * 2 - 1\n        xt = xt * (1.0 + 0.05 * torch.rand_like(xt))\n\n        # t\n        t = torch.from_numpy(t).float().view(adj_matrix.shape[0])\n\n        # get nodes\n        x1, x2 = get_coords_by_dists(dists)\n        x1 = x1.float().to(self.device)\n        x2 = x2.float().to(self.device)\n        \n        # x0_pred\n        x0_pred = self.model.forward(\n            x1=x1,\n            x2=x2,\n            dists=dists.float().to(self.device),\n            graph=xt.float().to(self.device),\n            edge_index=None,\n            timesteps=t.float().to(self.device)\n        )\n\n        # loss\n        loss = nn.CrossEntropyLoss()(x0_pred, adj_matrix.long())\n\n        if self.env.mode == \"train\":\n            return None, loss\n        else:\n            heatmap = self.solve_encode(dists)\n            return heatmap, loss\n\n    def encode(\n        self, dists: Tensor, adj_matrix: Tensor = None\n    ) -> Union[Tuple[Tensor, Tensor], Tensor]:\n        if self.env.mode == \"solve\":\n            return self.solve_encode(dists)\n        else:\n            return self.train_test_encode(dists, adj_matrix)\n            \n    def shared_step(self, batch: Any, batch_idx: int, phase: str):\n        # env mode\n        self.env.mode = phase\n\n        if phase == \"train\":\n            # batch data is fake, just get batch length\n            batch_size = len(batch)\n            del batch\n        \n            # use env to get data\n            dists, ref_tours = self.env.generate_data(batch_size)\n            \n            # process data\n            adj_matrix = self.env.process_data(dists, ref_tours)\n            \n            # real share encoding step & calculate loss\n            heatmap, loss = self.encode(dists=dists, adj_matrix=adj_matrix)\n            metrics = {f\"{phase}/loss\": loss}\n        \n        else:\n            # get val data from env\n            val_data_dict = self.env.get_val_data()\n            \n            all_loss = 0\n            metrics = dict()\n            # validation for TSP, ATSP, SAT, HCP\n            for k, v in val_data_dict.items():\n                # get data   \n                dists, ref_tours = v\n                dists = torch.from_numpy(dists).to(self.device)\n                ref_tours = torch.from_numpy(ref_tours).to(self.device)\n\n                # process data\n                self.env.nodes_num = dists.shape[-1]\n                self.decoder.nodes_num = self.env.nodes_num\n                adj_matrix = self.env.process_data(dists, ref_tours)\n\n                # real share encoding step & calculate loss\n                heatmap, loss = self.encode(dists=dists, adj_matrix=adj_matrix)\n                \n                all_loss += loss.item()\n                \n                # decoding\n                solved_tours = self.decoder.decode(heatmap=heatmap, dists=dists)\n\n                # calculate gap\n                tmp_solver = ATSPSolver()\n                tmp_solver.from_data(\n                    dists=to_numpy(dists), tours=to_numpy(ref_tours), ref=True\n                )\n                solved_tours = solved_tours.reshape(-1, self.env.nodes_num + 1)\n                tmp_solver.from_data(tours=solved_tours, ref=False)\n\n                # Gap or Length\n                if k == \"TSP\":\n                    _, _, gap, _ = tmp_solver.evaluate(calculate_gap=True)\n                    metrics[f\"{phase}/{k}_gap\"] = gap\n                else:\n                    _, length, _, _ = tmp_solver.evaluate(calculate_gap=False)\n                    metrics[f\"{phase}/{k}_length\"] = length\n            \n            metrics[f\"{phase}/loss\"] = all_loss / len(val_data_dict)\n        \n        return metrics\n\n# ==========================================\n# File: MatDIFFNet/src/solver.py\n# Function/Context: MatDIFFNetSolver\n# ==========================================\nimport torch\nimport numpy as np\nfrom typing import List\nfrom torch import Tensor\nfrom ml4co_kit import (\n    ATSPEvaluator, ATSPSolver, to_tensor, \n    iterative_execution, SOLVER_TYPE\n)\nfrom .model import MatDIFFNetModel\n\n\nclass MatDIFFNetSolver(ATSPSolver):\n    def __init__(\n        self, \n        model: MatDIFFNetModel, \n        seed: int = 1234,\n        pretrained_path: str = None\n    ):\n        # basic\n        super(MatDIFFNetSolver, self).__init__(solver_type=SOLVER_TYPE.ML4ATSP, scale=1)\n        np.random.seed(seed=seed)\n        torch.manual_seed(seed=seed)\n        self.model = model\n        \n        # pretrain & device & mode\n        if pretrained_path is not None:\n            self.model.load_state_dict(torch.load(pretrained_path, map_location=\"cpu\"))\n        self.model.to(self.model.env.device).eval()\n        self.model.env.mode = \"solve\"\n        \n        # solved cache\n        self.solved_tours = list()\n        self.dists = list()\n        \n    def solve(self, dists: List[np.ndarray], show_time: bool = False) -> np.ndarray:\n        self.dists = dists\n        self.solved_tours = list()\n        for idx in iterative_execution(range, len(dists), self.solve_msg, show_time):\n            self.solved_tours.append(self._solve(dists[idx]))\n\n    def _solve(self, dist: np.ndarray) -> np.ndarray:\n        # encode\n        dist = to_tensor(dist).to(self.model.env.device).unsqueeze(0)\n        self.model.env.nodes_num = dist.shape[-1]\n        heatmap: Tensor = self.model.encode(dists=dist)\n        \n        # decode\n        self.model.decoder.nodes_num = heatmap.shape[-1]\n        return self.model.decoder.decode(heatmap=heatmap, dists=dist)\n        \n    def evaluate(self):\n        costs = list()\n        for dist, solved_tour in zip(self.dists, self.solved_tours): \n            evaluator = ATSPEvaluator(dist)\n            costs.append(evaluator.evaluate(route=solved_tour))\n\n        costs = np.array(costs)\n        costs_avg = np.mean(costs)\n        print(costs_avg)\n\n# ==========================================\n# File: MatDIFFNet_jittor/src/model.py\n# Function/Context: MatDIFFNetModel\n# ==========================================\nimport os\nimport jittor as jt\nimport numpy as np\nfrom jittor import nn, Var\nfrom typing import Any, Union, Tuple\nfrom ml4co_kit import ATSPSolver\nfrom tqdm import trange\nfrom .env import MatDIFFNetEnv\nfrom .gnn_encoder import GNNEncoder\nfrom .decoder import MatDIFFNetDecoder\nfrom .diffusion_utils import CategoricalDiffusion, InferenceSchedule\n\n\ndef get_coords_by_dists(dists: Var) -> Tuple[Var, Var]:\n    batch_size, nodes_num, _ = dists.shape\n    coords = jt.arange(2*nodes_num) + 1 / (2*nodes_num)\n    coords = coords.reshape(1, nodes_num, 2)\n    coords = coords.expand(batch_size, nodes_num, 2)\n    coords_source = coords[:, :, 0]\n    coords_target = coords[:, :, 1]\n    return coords_source, coords_target\n\nclass MatDIFFNetModel(object):\n    def __init__(\n        self,\n        env: MatDIFFNetEnv,\n        encoder: GNNEncoder,\n        decoder: MatDIFFNetDecoder,\n        lr_scheduler: str = \"cosine-decay\",\n        learning_rate: float = 2e-4,\n        weight_decay: float = 1e-4,\n        max_epochs: int = 100,\n        val_evry_n_epochs: int = 1,\n        ckpt_save_dir: str = \"your/save/dir\",\n        # diffusion\n        diffusion_schedule: str = \"linear\",\n        inference_schedule: str = \"cosine\",\n        diffusion_steps: int = 1000,\n        inference_diffusion_steps: int = 50,\n        parallel_sampling: int = 1,\n        sequential_sampling: int = 1,\n        # cuda\n        use_cuda: bool = True,\n        # pretrained weight\n        pretrained_path: str = None\n    ):      \n        self.env: MatDIFFNetEnv = env\n        self.model: GNNEncoder = encoder\n        self.decoder = decoder\n\n        self.max_epochs = max_epochs\n        self.val_evry_n_epochs = val_evry_n_epochs\n        self.best_avg_obj_val = 1e6\n        os.makedirs(ckpt_save_dir, exist_ok=True)\n        self.ckpt_save_path = os.path.join(ckpt_save_dir, \"checkpoint-{}-{}.pkl\")\n\n        jt.flags.use_cuda = use_cuda # set device for jittor globally\n\n        if lr_scheduler == \"constant\":\n            self.optimizer = jt.optim.AdamW(\n                self.model.parameters(), \n                lr=learning_rate, \n                weight_decay=weight_decay\n            )\n        elif lr_scheduler == \"cosine-decay\":\n            self.optimizer = jt.optim.AdamW(\n                self.model.parameters(), \n                lr=learning_rate, \n                weight_decay=weight_decay\n            )\n            self.lr_scheduler = jt.lr_scheduler.CosineAnnealingLR(\n                self.optimizer,\n                T_max=self.env.train_data_size // self.env.train_batch_size * self.max_epochs,\n                eta_min=0.0,\n            )\n        \n        # load pretrained weight\n        if pretrained_path is not None:\n            self.model.load(pretrained_path)\n            print(f\"Pretrained weights loaded: {pretrained_path}.\")\n\n        # diffusion\n        self.diffusion_schedule = diffusion_schedule\n        self.inference_schedule = inference_schedule\n        self.diffusion_steps = diffusion_steps\n        self.inference_diffusion_steps = inference_diffusion_steps\n        self.diffusion = CategoricalDiffusion(\n            T=self.diffusion_steps, schedule=self.diffusion_schedule\n        )\n        self.parallel_sampling = parallel_sampling\n        self.sequential_sampling = sequential_sampling\n            \n        # record solved tours\n        self.solved_tours_list = list()\n    \n    def categorical_posterior(\n        self, target_t: int, t: int, x0_pred_prob: Var, xt: Var\n    ) -> Var:\n        diffusion = self.diffusion\n\n        if target_t is None:\n            target_t = t - 1\n        else:\n            target_t = jt.Var(target_t).view(1)\n\n        if target_t > 0:\n            Q_t = np.linalg.inv(diffusion.Q_bar[target_t]) @ diffusion.Q_bar[t]\n            Q_t = jt.float32(Q_t)\n        else:\n            Q_t = jt.init.eye(2, jt.float32)\n        Q_bar_t_source = (\n            jt.float32(diffusion.Q_bar[t])\n        )\n        Q_bar_t_target = (\n            jt.float32(diffusion.Q_bar[target_t])\n        )\n\n        xt = nn.one_hot(xt.long(), num_classes=2).float()\n        xt = xt.reshape(x0_pred_prob.shape)\n\n        x_t_target_prob_part_1 = jt.matmul(xt, Q_t.permute((1, 0)).contiguous())\n        x_t_target_prob_part_2 = Q_bar_t_target[0]\n        x_t_target_prob_part_3 = (Q_bar_t_source[0] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_target_prob = (\n            x_t_target_prob_part_1 * x_t_target_prob_part_2\n        ) / x_t_target_prob_part_3\n\n        sum_x_t_target_prob = x_t_target_prob[..., 1] * x0_pred_prob[..., 0]\n        x_t_target_prob_part_2_new = Q_bar_t_target[1]\n        x_t_target_prob_part_3_new = (Q_bar_t_source[1] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_source_prob_new = (\n            x_t_target_prob_part_1 * x_t_target_prob_part_2_new\n        ) / x_t_target_prob_part_3_new\n\n        sum_x_t_target_prob += x_t_source_prob_new[..., 1] * x0_pred_prob[..., 1]\n\n        if target_t > 0:\n            xt = jt.bernoulli(jt.clamp(sum_x_t_target_prob, 0, 1))\n        else:\n            xt = sum_x_t_target_prob.clamp(min_v=0)\n\n        return xt\n\n    def guided_categorical_posterior(\n        self,\n        target_t: int,\n        t: int,\n        x0_pred_prob: Var,\n        xt: Var,\n        grad=None,\n    ) -> Var:\n        # xt: b, n, n\n        if grad is None:\n            grad = xt.grad\n        with jt.no_grad():\n            diffusion = self.diffusion\n        if target_t is None:\n            target_t = t - 1\n        else:\n            target_t = jt.Var(target_t).view(1)\n\n        if target_t > 0:\n            Q_t = np.linalg.inv(diffusion.Q_bar[target_t]) @ diffusion.Q_bar[t]\n            Q_t = (\n                jt.float32(Q_t)\n            )  # [2, 2], transition matrix\n        else:\n            Q_t = jt.init.eye(2, \"float32\")\n        Q_bar_t_source = (\n            jt.float32(diffusion.Q_bar[t])\n        )\n        Q_bar_t_target = (\n            jt.float32(diffusion.Q_bar[target_t])\n        )\n\n        xt_grad_zero, xt_grad_one = jt.zeros(xt.shape).unsqueeze(-1).repeat(1, 1, 1, 2), \\\n                                    jt.zeros(xt.shape).unsqueeze(-1).repeat(1, 1, 1, 2)\n        xt_grad_zero[..., 0] = (1 - xt) * grad\n        xt_grad_zero[..., 1] = -xt_grad_zero[..., 0]\n        xt_grad_one[..., 1] = xt * grad\n        xt_grad_one[..., 0] = -xt_grad_one[..., 1]\n        xt_grad = xt_grad_zero + xt_grad_one\n\n        xt = nn.one_hot(xt.long(), num_classes=2).float()\n        xt = xt.reshape(x0_pred_prob.shape)  # [b, n, n, 2]\n\n        # q(xt−1|xt,x0=0)pθ(x0=0|xt)\n        x_t_target_prob_part_1 = jt.matmul(xt, Q_t.permute((1, 0)).contiguous())\n        x_t_target_prob_part_2 = Q_bar_t_target[0]\n        x_t_target_prob_part_3 = (Q_bar_t_source[0] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_target_prob = (\n            x_t_target_prob_part_1 * x_t_target_prob_part_2\n        ) / x_t_target_prob_part_3  # [b, n, n, 2]\n\n        sum_x_t_target_prob = x_t_target_prob[..., 1] * x0_pred_prob[..., 0]\n\n        # q(xt−1|xt,x0=1)pθ(x0=1|xt)\n        x_t_target_prob_part_2_new = Q_bar_t_target[1]\n        x_t_target_prob_part_3_new = (Q_bar_t_source[1] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_source_prob_new = (\n            x_t_target_prob_part_1 * x_t_target_prob_part_2_new\n        ) / x_t_target_prob_part_3_new\n\n        sum_x_t_target_prob += x_t_source_prob_new[..., 1] * x0_pred_prob[..., 1]\n\n        p_theta = jt.cat(\n            (1 - sum_x_t_target_prob.unsqueeze(-1), sum_x_t_target_prob.unsqueeze(-1)),\n            dim=-1,\n        )\n        p_phi = jt.exp(-xt_grad)\n        posterior = (p_theta * p_phi) / jt.sum(\n            (p_theta * p_phi), dim=-1, keepdim=True\n        )\n\n        if target_t > 0:\n            xt = jt.bernoulli(jt.clamp(posterior[..., 1], 0, 1))\n        else:\n            xt = jt.clamp(posterior[..., 1], min_v=0)\n            \n        return xt\n\n    def categorical_denoise_step(\n        self,\n        dists: Var,\n        xt: Var,\n        t: Var,\n        edge_index: Var = None,\n        target_t: Var = None,\n    ):\n        with jt.no_grad():\n            t = jt.Var(t).view(1)\n            xt: Var\n            if xt.ndim == 2:\n                xt = xt.unsqueeze(dim=0)\n\n            xt_scale = (xt * 2 - 1).float()\n            xt_scale = xt_scale * (1.0 + 0.05 * jt.rand_like(xt_scale))\n\n            # get nodes\n            x1, x2 = get_coords_by_dists(dists)\n            x1 = x1.float()\n            x2 = x2.float()\n            \n            x0_pred = self.model.execute(\n                x1=x1,\n                x2=x2,\n                dists=dists.float(),\n                graph=xt_scale.float(),\n                edge_index=edge_index.long() if edge_index is not None else None,\n                timesteps=t.float(),\n            )\n\n            x0_pred_prob = (\n                x0_pred.permute((0, 2, 3, 1)).contiguous().softmax(dim=-1)\n            )\n            \n            x0_pred_prob = x0_pred_prob\n            xt = self.categorical_posterior(target_t, t, x0_pred_prob, xt)\n            return xt\n  \n    def solve_encode(self, dists: Var) -> Var:        \n        heatmap_list = list()\n\n        # dists & edge_index\n        dists = dists.repeat(self.parallel_sampling, 1, 1)\n\n        # heatmap\n        batch_size = dists.shape[0]\n        for _ in range(self.sequential_sampling):\n            # diffusion xt\n            xt = jt.randn(batch_size, self.env.nodes_num, self.env.nodes_num)\n            if self.parallel_sampling > 1:\n                xt = xt.repeat(self.parallel_sampling, 1, 1)\n                xt = jt.randn_like(xt)\n            xt = (xt > 0).long()\n\n            # time schedule\n            time_schedule = InferenceSchedule(\n                inference_schedule=self.inference_schedule,\n                T=self.diffusion.T,\n                inference_T=self.inference_diffusion_steps,\n            )\n\n            # Diffusion iterations\n            for i in range(self.inference_diffusion_steps):\n                t1, t2 = time_schedule(i)\n                t1 = np.array([t1]).astype(int)\n                t2 = np.array([t2]).astype(int)\n                # [B, N, N], heatmap score\n                xt = self.categorical_denoise_step(\n                    dists, xt, t1, edge_index=None, target_t=t2\n                )\n\n            heatmap_list.append(xt)\n            \n        heatmap = jt.concat(heatmap_list, dim=0)\n        heatmap = heatmap.reshape(-1, self.env.nodes_num, self.env.nodes_num)\n        return heatmap\n\n    def train_test_encode(\n        self, dists: Var, adj_matrix: Var = None,\n    ) -> Tuple[Var, Var]:\n        # xt\n        adj_matrix_onehot: Var = nn.one_hot(adj_matrix.long(), num_classes=2)\n        adj_matrix_onehot = adj_matrix_onehot.float()\n        t = np.random.randint(1, self.diffusion.T + 1, dists.shape[0]).astype(int)\n        xt = self.diffusion.sample(adj_matrix_onehot, t)    \n        xt = xt * 2 - 1\n        xt = xt * (1.0 + 0.05 * jt.rand_like(xt))\n\n        # t\n        t = jt.float32(t).view(adj_matrix.shape[0])\n\n        # get nodes\n        x1, x2 = get_coords_by_dists(dists)\n        x1 = x1.float()\n        x2 = x2.float()\n        \n        # x0_pred\n        x0_pred = self.model.execute(\n            x1=x1,\n            x2=x2,\n            dists=dists.float(),\n            graph=xt.float(),\n            edge_index=None,\n            timesteps=t.float()\n        )\n\n        # loss\n        loss = nn.CrossEntropyLoss()(x0_pred, adj_matrix.long())\n\n        if self.env.mode == \"train\":\n            return None, loss\n        else:\n            heatmap = self.solve_encode(dists)\n            return heatmap, loss\n\n    def encode(\n        self, dists: Var, adj_matrix: Var = None\n    ) -> Union[Tuple[Var, Var], Var]:\n        if self.env.mode == \"solve\":\n            return self.solve_encode(dists)\n        else:\n            return self.train_test_encode(dists, adj_matrix)\n            \n    def model_train(self):\n        num_batches_per_epoch = self.env.train_data_size // self.env.train_batch_size\n        tr = trange(self.max_epochs)\n        for epoch in tr:  \n            for batch_idx in range(num_batches_per_epoch):\n                # use env to get data\n                dists, ref_tours = self.env.generate_data(self.env.train_batch_size)\n                adj_matrix = self.env.process_data(dists, ref_tours)\n\n                # generate heatmap & calculate loss to update model parameters\n                heatmap, loss = self.encode(dists=dists, adj_matrix=adj_matrix)\n                self.lr_scheduler.step()\n                self.optimizer.zero_grad()\n                self.optimizer.backward(loss)\n                self.optimizer.step()\n                tr.set_description(f\"Epoch {epoch} ({batch_idx}/{num_batches_per_epoch}), loss={loss:.4f}\")\n\n            # validation\n            if epoch % self.val_evry_n_epochs == 0:\n                print(\"Valiadtion...\")\n                avg_obj_val = self.model_eval()\n                if avg_obj_val < self.best_avg_obj_val:\n                    self.best_avg_obj_val = avg_obj_val\n                    self.model.save(self.ckpt_save_path.format(epoch, f\"{avg_obj_val:.4f}\"))\n                    print(f\"Avg. obj: {avg_obj_val}, saved new best!\")\n                else:\n                    print(f\"Avg. obj: {avg_obj_val}\")\n\n    def model_eval(self):    \n        # get val data from env\n        val_data_dict = self.env.get_val_data()\n        \n        # all_loss = 0\n        all_obj = 0\n        # validation for TSP, ATSP, SAT, HCP\n        for k, v in val_data_dict.items():\n            # get data   \n            dists, ref_tours = v\n            dists = jt.Var(dists)\n            ref_tours = jt.Var(ref_tours)\n\n            # process data\n            self.env.nodes_num = dists.shape[-1]\n            self.decoder.nodes_num = self.env.nodes_num\n            adj_matrix = self.env.process_data(dists, ref_tours)\n\n            # real share encoding step & calculate loss\n            heatmap = self.solve_encode(dists=dists)\n                        \n            # decoding\n            solved_tours = self.decoder.decode(heatmap=heatmap, dists=dists)\n\n            # calculate gap\n            tmp_solver = ATSPSolver()\n            tmp_solver.from_data(\n                dists=dists.numpy(), tours=ref_tours.numpy(), ref=True\n            )\n            solved_tours = solved_tours.reshape(-1, self.env.nodes_num + 1)\n            tmp_solver.from_data(tours=solved_tours, ref=False)\n\n            # Gap or Length\n            if k == \"TSP\":\n                costs_avg, _, gap, _ = tmp_solver.evaluate(calculate_gap=True)\n                # metrics.update({f\"tsp_obj\": costs_avg})\n                all_obj += costs_avg\n                print(f\"[TSP] obj: {costs_avg:.4f}, gap: {gap:.4f}%\")\n            if k == \"ATSP\":\n                costs_avg, _, gap, _ = tmp_solver.evaluate(calculate_gap=True)\n                all_obj += costs_avg\n                # metrics.update({f\"atsp_obj\": costs_avg})\n                print(f\"[ATSP] obj: {costs_avg:.4f}, gap: {gap:.4f}%\")\n            if k == \"SAT\":\n                costs_avg = tmp_solver.evaluate()\n                all_obj += costs_avg\n                # metrics.upd\n\n# ==========================================\n# File: MatDIFFNet_jittor/src/solver.py\n# Function/Context: MatDIFFNetSolver\n# ==========================================\nimport jittor as jt\nimport numpy as np\nfrom typing import List\nfrom jittor import Var\nfrom ml4co_kit import (\n    ATSPEvaluator, ATSPSolver, \n    iterative_execution, SOLVER_TYPE\n)\nfrom .model import MatDIFFNetModel\n\n\nclass MatDIFFNetSolver(ATSPSolver):\n    def __init__(\n        self, \n        model: MatDIFFNetModel, \n        seed: int = 1234,\n        pretrained_path: str = None\n    ):\n        # basic\n        super(MatDIFFNetSolver, self).__init__(solver_type=SOLVER_TYPE.ML4ATSP, scale=1)\n        jt.misc.set_global_seed(seed)\n        self.model = model\n        \n        # pretrain & device & mode\n        if pretrained_path is not None:\n            self.model.model.load(pretrained_path)\n        self.model.model.eval()\n        self.model.env.mode = \"solve\"\n        \n        # solved cache\n        self.solved_tours = list()\n        self.dists = list()\n        \n    def solve(self, dists: List[np.ndarray], show_time: bool = False) -> np.ndarray:\n        self.dists = dists\n        self.solved_tours = list()\n        for idx in iterative_execution(range, len(dists), self.solve_msg, show_time):\n            self.solved_tours.append(self._solve(dists[idx]))\n\n    def _solve(self, dist: np.ndarray) -> np.ndarray:\n        # encode\n        dist = jt.Var(dist).unsqueeze(0)\n        self.model.env.nodes_num = dist.shape[-1]\n        heatmap: Var = self.model.encode(dists=dist)\n        \n        # decode\n        self.model.decoder.nodes_num = heatmap.shape[-1]\n        return self.model.decoder.decode(heatmap=heatmap, dists=dist)\n        \n    def evaluate(self):\n        costs = list()\n        for dist, solved_tour in zip(self.dists, self.solved_tours): \n            evaluator = ATSPEvaluator(dist)\n            costs.append(evaluator.evaluate(route=solved_tour))\n\n        costs = np.array(costs)\n        costs_avg = np.mean(costs)\n        print(costs_avg)\n\n# ==========================================\n# File: MatPOENet/ATSPEnv.py\n# Function/Context: ATSPEnv\n# ==========================================\nimport sys\nsys.path.append(\"../\")\n\nfrom dataclasses import dataclass\nimport torch\nimport numpy as np\nfrom utils.ATSProblemDef import get_random_problems\nfrom utils.base_methods import *\nfrom utils.generate_data import *\nfrom utils.positional_encoding import *\n\n\n@dataclass\nclass Reset_State:\n    problems: torch.Tensor\n    # shape: (batch, node, node)\n\n\n@dataclass\nclass Step_State:\n    BATCH_IDX: torch.Tensor\n    POMO_IDX: torch.Tensor\n    # shape: (batch, pomo)\n    current_node: torch.Tensor = None\n    # shape: (batch, pomo)\n    ninf_mask: torch.Tensor = None\n    # shape: (batch, pomo, node)\n\n\nclass ATSPEnv:\n    def __init__(self, **env_params):\n\n        # Const @INIT\n        ####################################\n        self.env_params = env_params\n        self.node_cnt = env_params['node_cnt']\n\n        # Const @Load_Problem\n        ####################################\n        self.batch_size = None\n        self.BATCH_IDX = None\n        self.POMO_IDX = None\n        # IDX.shape: (batch, pomo)\n        self.problems = None\n        # shape: (batch, node, node)\n\n        # Dynamic\n        ####################################\n        self.selected_count = None\n        self.current_node = None\n        # shape: (batch, pomo)\n        self.selected_node_list = None\n        # shape: (batch, pomo, 0~)\n\n        # STEP-State\n        ####################################\n        self.step_state = None\n\n        # multiple scales\n        self.min_scale = env_params[\"min_scale\"]\n        self.max_scale = env_params[\"max_scale\"]\n\n        self.pos_emb_dim = self.env_params[\"pos_embedding_dim\"]\n\n        self.problem_type_idx = 0\n\n    def load_problems_from_pool(self, batch_size):\n        self.batch_size = batch_size\n        n_problem = len(self.env_params[\"problem_pool\"])\n        self.problem_type_idx = np.random.randint(n_problem)\n        problem_type = self.env_params[\"problem_pool\"][self.problem_type_idx]\n        if problem_type == \"atsp_triangle\":\n            self.node_cnt = np.random.randint(\n                self.env_params[\"min_scale\"], \n                self.env_params[\"max_scale\"])\n            problem_gen_params = self.env_params['problem_gen_params']\n            problems = get_random_problems(batch_size, self.node_cnt).cpu().numpy()\n        elif problem_type == \"tsp_euc\":\n            self.node_cnt = np.random.randint(\n                self.env_params[\"min_scale\"], \n                self.env_params[\"max_scale\"])\n            problems = [gen_Euclidean(self.node_cnt, 2) for _ in range(self.batch_size)]\n        elif problem_type == \"hcp\":\n            self.node_cnt = np.random.randint(\n                self.env_params[\"min_scale\"], \n                self.env_params[\"max_scale\"])\n            problems = [gen_hcp(self.node_cnt, np.random.rand() * 0.2 + 0.1) for _ in range(self.batch_size)]\n        elif problem_type == \"3sat\":\n            self.node_cnt = self.env_params[\"node_cnt\"]\n            if self.node_cnt == 20:\n                num_clauses = [3, 2, 2]\n                num_vars = [3, 4, 5]\n            elif self.node_cnt == 50:\n                num_clauses = [3, 4, 5, 6, 7]\n                num_vars = [6, 5, 5, 4, 3]\n            elif self.node_cnt == 100:\n                num_clauses = [9, 8, 7, 6, 5]\n                num_vars = [5, 6, 7, 8, 9]\n            rand_idx = np.random.randint(0, len(num_clauses))\n            self.node_cnt = 2 * num_clauses[rand_idx] * num_vars[rand_idx] + num_clauses[rand_idx]\n            problems = [gen_3sat(num_clauses[rand_idx], num_vars[rand_idx]) for _ in range(self.batch_size)]\n        else:\n            raise NotImplementedError(\"Problem type {} is not implemented.\".format(problem_type))\n        self.BATCH_IDX = torch.arange(self.batch_size)[:, None].expand(self.batch_size, self.node_cnt)\n        self.POMO_IDX = torch.arange(self.node_cnt)[None, :].expand(self.batch_size, self.node_cnt)\n        # positional encoding\n        self.pos_emb = make_positional_encoding_cosh_recur(self.pos_emb_dim, self.node_cnt, scaler=100)\n        self.pos_emb = self.pos_emb.unsqueeze(0).repeat(self.batch_size, 1, 1)\n        # initial tours\n        solver = BaseSolver(self.node_cnt)\n        if self.env_params[\"init_solver\"] == None:\n            pass\n        elif self.env_params[\"init_solver\"] == \"nn\":\n            f_solver = solver.solve_nearest_neighbor \n        elif self.env_params[\"init_solver\"] == \"lkh\":\n            f_solver = solver.solve_lkh\n        elif self.env_params[\"init_solver\"] == \"rand\":\n            f_solver = solver.solve_rand_perm\n        elif self.env_params[\"init_solver\"] == \"fi\":\n            f_solver = solver.solve_farthest_insertion\n        else:\n            raise NotImplementedError(\"Solver {} is not implemented.\".format(self.env_params[\"init_solver\"]))\n        if self.env_params[\"init_solver\"]:\n            for i in range(self.batch_size):\n                f_solver(problems[i])\n                init_tour = np.array(solver.get_path(), dtype=np.int64)\n                problems[i] = problems[i][init_tour, :][:, init_tour]\n        # problems\n        self.problems = torch.Tensor(np.array(problems))\n\n    def load_problems_manual(self, problems):\n        # problems.shape: (batch, node, node)\n\n        self.batch_size = problems.size(0)\n        self.node_cnt = problems.size(1)\n        self.BATCH_IDX = torch.arange(self.batch_size)[:, None].expand(self.batch_size, self.node_cnt)\n        self.POMO_IDX = torch.arange(self.node_cnt)[None, :].expand(self.batch_size, self.node_cnt)\n\n        self.pos_emb = make_positional_encoding_cosh_recur(self.pos_emb_dim, self.node_cnt, scaler=100)\n        # self.pos_emb = make_positional_encoding_zero(self.pos_emb_dim, self.node_cnt)\n        self.pos_emb = self.pos_emb.unsqueeze(0).repeat(self.batch_size, 1, 1)\n        # initial tours\n        solver = BaseSolver(self.node_cnt)\n        if self.env_params[\"init_solver\"] == None:\n            pass\n        elif self.env_params[\"init_solver\"] == \"nn\":\n            f_solver = solver.solve_nearest_neighbor\n        elif self.env_params[\"init_solver\"] == \"lkh\":\n            f_solver = solver.solve_lkh\n        elif self.env_params[\"init_solver\"] == \"fi\":\n            f_solver = solver.solve_farthest_insertion\n        else:\n            raise NotImplementedError(\"Solver {} is not implemented.\".format(self.env_params[\"init_solver\"]))\n        if self.env_params[\"init_solver\"]:\n            for i in range(self.batch_size):\n                f_solver(problems[i])\n                init_tour = np.array(solver.get_path(), dtype=np.int64)\n                problems[i] = problems[i][init_tour, :][:, init_tour]\n        # problems\n        self.problems = problems\n        # shape: (batch, node, node)\n\n    def reset(self):\n        self.selected_count = 0\n        self.current_node = None\n        # shape: (batch, pomo)\n        self.selected_node_list = torch.empty((self.batch_size, self.node_cnt, 0), dtype=torch.long)\n        # shape: (batch, pomo, 0~)\n\n        self._create_step_state()\n\n        reward = None\n        done = False\n        return Reset_State(problems=self.problems), reward, done\n\n    def _create_step_state(self):\n        self.step_state = Step_State(BATCH_IDX=self.BATCH_IDX, POMO_IDX=self.POMO_IDX)\n        self.step_state.ninf_mask = torch.zeros((self.batch_size, self.node_cnt, self.node_cnt))\n        # shape: (batch, pomo, node)\n\n    def pre_step(self):\n        reward = None\n        done = False\n        return self.step_state, reward, done\n\n    def step(self, node_idx):\n        # node_idx.shape: (batch, pomo)\n\n        self.selected_count += 1\n        self.current_node = node_idx\n        # shape: (batch, pomo)\n        self.selected_node_list = torch.cat((self.selected_node_list, self.current_node[:, :, None]), dim=2)\n        # shape: (batch, pomo, 0~node)\n\n        self._update_step_state()\n        \n        # returning values\n        done = (self.selected_count == self.node_cnt)\n        if done:\n            reward = -self._get_total_distance()  # Note the MINUS Sign ==> We MAXIMIZE reward\n            # shape: (batch, pomo)\n        else:    \n            reward = None\n        return self.step_state, reward, done\n\n    def _update_step_state(self):\n        self.step_state.current_node = self.current_node\n        # shape: (batch, pomo)\n        self.step_state.ninf_mask[self.BATCH_IDX, self.POMO_IDX, self.current_node] = float('-inf')\n        # shape: (batch, pomo, node)\n\n    def _get_total_distance(self):\n\n        node_from = self.selected_node_list\n        # shape: (batch, pomo, node)\n        node_to = self.selected_node_list.roll(dims=2, shifts=-1)\n        # shape: (batch, pomo, node)\n        batch_index = self.BATCH_IDX[:, :, None].expand(self.batch_size, self.node_cnt, self.node_cnt)\n        # shape: (batch, pomo, node)\n\n        selected_cost = self.problems[batch_index, node_from, node_to]\n        # shape: (batch, pomo, node)\n        total_distance = selected_cost.sum(2)\n        # shape: (batch, pomo)\n\n        return total_distance\n\n# ==========================================\n# File: MatPOENet/ATSPModel.py\n# Function/Context: ATSPModel\n# ==========================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom ATSPModel_LIB import *\nimport sys\nsys.path.append(\"../../../\")\nfrom utils.positional_encoding import *\n\nclass ATSPModel(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        self.model_params = model_params\n        self.encoder = ATSP_Encoder(**model_params)\n        self.decoder = ATSP_Decoder(**model_params)\n        self.encoded_row = None\n        self.encoded_col = None\n\n    def pre_forward_pe(self, reset_state, pos_emb):\n        problems = reset_state.problems\n        self.encoded_row, self.encoded_col = self.encoder(\n            torch.zeros_like(pos_emb), pos_emb, problems)\n        self.decoder.set_kv(self.encoded_col)\n\n    def forward(self, state):\n        batch_size = state.BATCH_IDX.size(0)\n        pomo_size = state.BATCH_IDX.size(1)\n\n        if state.current_node is None:\n            selected = torch.arange(pomo_size)[None, :].expand(batch_size, pomo_size)\n            prob = torch.ones(size=(batch_size, pomo_size))\n            encoded_first_row = _get_encoding(self.encoded_row, selected)\n            self.decoder.set_q1(encoded_first_row)\n        else:\n            encoded_current_row = _get_encoding(self.encoded_row, state.current_node)\n            all_job_probs = self.decoder(encoded_current_row, ninf_mask=state.ninf_mask)\n\n            if self.training or self.model_params['eval_type'] == 'softmax':\n                while True:\n                    with torch.no_grad():\n                        selected = all_job_probs.reshape(batch_size * pomo_size, -1).multinomial(1) \\\n                            .squeeze(dim=1).reshape(batch_size, pomo_size)\n                    prob = all_job_probs[state.BATCH_IDX, state.POMO_IDX, selected] \\\n                        .reshape(batch_size, pomo_size)\n                    if (prob != 0).all():\n                        break\n            else:\n                selected = all_job_probs.argmax(dim=2)\n                prob = None\n        return selected, prob\n\ndef _get_encoding(encoded_nodes, node_index_to_pick):\n    batch_size = node_index_to_pick.size(0)\n    pomo_size = node_index_to_pick.size(1)\n    embedding_dim = encoded_nodes.size(2)\n    gathering_index = node_index_to_pick[:, :, None].expand(batch_size, pomo_size, embedding_dim)\n    picked_nodes = encoded_nodes.gather(dim=1, index=gathering_index)\n    return picked_nodes\n\nclass ATSP_Encoder(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        encoder_layer_num = model_params['encoder_layer_num']\n        self.layers = nn.ModuleList([EncoderLayer(**model_params) for _ in range(encoder_layer_num)])\n\n    def forward(self, row_emb, col_emb, cost_mat):\n        for layer in self.layers:\n            row_emb, col_emb = layer(row_emb, col_emb, cost_mat)\n        return row_emb, col_emb\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        self.row_encoding_block = EncodingBlock(**model_params)\n        self.col_encoding_block = EncodingBlock(**model_params)\n\n    def forward(self, row_emb, col_emb, cost_mat):\n        row_emb_out = self.row_encoding_block(row_emb, col_emb, cost_mat)\n        col_emb_out = self.col_encoding_block(col_emb, row_emb, cost_mat.transpose(1, 2))\n        return row_emb_out, col_emb_out\n\nclass EncodingBlock(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        self.model_params = model_params\n        embedding_dim = self.model_params['embedding_dim']\n        head_num = self.model_params['head_num']\n        qkv_dim = self.model_params['qkv_dim']\n        self.Wq = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wk = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wv = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.mixed_score_MHA = MixedScore_MultiHeadAttention(**model_params)\n        self.multi_head_combine = nn.Linear(head_num * qkv_dim, embedding_dim)\n        self.add_n_normalization_1 = AddAndInstanceNormalization(**model_params)\n        self.feed_forward = FeedForward(**model_params)\n        self.add_n_normalization_2 = AddAndInstanceNormalization(**model_params)\n\n    def forward(self, row_emb, col_emb, cost_mat):\n        head_num = self.model_params['head_num']\n        q = reshape_by_heads(self.Wq(row_emb), head_num=head_num)\n        k = reshape_by_heads(self.Wk(col_emb), head_num=head_num)\n        v = reshape_by_heads(self.Wv(col_emb), head_num=head_num)\n        out_concat = self.mixed_score_MHA(q, k, v, cost_mat)\n        multi_head_out = self.multi_head_combine(out_concat)\n        out1 = self.add_n_normalization_1(row_emb, multi_head_out)\n        out2 = self.feed_forward(out1)\n        out3 = self.add_n_normalization_2(out1, out2)\n        return out3\n\nclass ATSP_Decoder(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        self.model_params = model_params\n        embedding_dim = self.model_params['embedding_dim']\n        head_num = self.model_params['head_num']\n        qkv_dim = self.model_params['qkv_dim']\n        self.Wq_0 = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wq_1 = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wk = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wv = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.multi_head_combine = nn.Linear(head_num * qkv_dim, embedding_dim)\n        self.k = None\n        self.v = None\n        self.single_head_key = None\n        self.q1 = None\n\n    def set_kv(self, encoded_jobs):\n        head_num = self.model_params['head_num']\n        self.k = reshape_by_heads(self.Wk(encoded_jobs), head_num=head_num)\n        self.v = reshape_by_heads(self.Wv(encoded_jobs), head_num=head_num)\n        self.single_head_key = encoded_jobs.transpose(1, 2)\n\n    def set_q1(self, encoded_q1):\n        head_num = self.model_params['head_num']\n        self.q1 = reshape_by_heads(self.Wq_1(encoded_q1), head_num=head_num)\n\n    def forward(self, encoded_q0, ninf_mask):\n        head_num = self.model_params['head_num']\n        q0 = reshape_by_heads(self.Wq_0(encoded_q0), head_num=head_num)\n        q = self.q1 + q0\n        out_concat = self._multi_head_attention(q, self.k, self.v, rank3_ninf_mask=ninf_mask)\n        mh_atten_out = self.multi_head_combine(out_concat)\n        score = torch.matmul(mh_atten_out, self.single_head_key)\n        sqrt_embedding_dim = self.model_params['sqrt_embedding_dim']\n        logit_clipping = self.model_params['logit_clipping']\n        score_scaled = score / sqrt_embedding_dim\n        score_clipped = logit_clipping * torch.tanh(score_scaled)\n        score_masked = score_clipped + ninf_mask\n        probs = F.softmax(score_masked, dim=2)\n        return probs\n\n    def _multi_head_attention(self, q, k, v, rank2_ninf_mask=None, rank3_ninf_mask=None):\n        batch_s = q.size(0)\n        n = q.size(2)\n        node_cnt = k.size(2)\n        head_num = self.model_params['head_num']\n        qkv_dim = self.model_params['qkv_dim']\n        sqrt_qkv_dim = self.model_params['sqrt_qkv_dim']\n        score = torch.matmul(q, k.transpose(2, 3))\n        score_scaled = score / sqrt_qkv_dim\n        if rank2_ninf_mask is not None:\n            score_scaled = score_scaled + rank2_ninf_mask[:, None, None, :].expand(batch_s, head_num, n, node_cnt)\n        if rank3_ninf_mask is not None:\n            score_scaled = score_scaled + rank3_ninf_mask[:, None, :, :].expand(batch_s, head_num, n, node_cnt)\n        weights = nn.Softmax(dim=3)(score_scaled)\n        out = torch.matmul(weights, v)\n        out_transposed = out.transpose(1, 2)\n        out_concat = out_transposed.reshape(batch_s, n, head_num * qkv_dim)\n        return out_concat\n\ndef reshape_by_heads(qkv, head_num):\n    batch_s = qkv.size(0)\n    n = qkv.size(1)\n    q_reshaped = qkv.reshape(batch_s, n, head_num, -1)\n    q_transposed = q_reshaped.transpose(1, 2)\n    return q_transposed\n\n# ==========================================\n# File: MatPOENet/ATSPTrainer.py\n# Function/Context: ATSPTrainer\n# ==========================================\nimport torch\nfrom logging import getLogger\n\nfrom ATSPEnv import ATSPEnv as Env\nfrom ATSPModel import ATSPModel as Model\n\nfrom torch.optim import Adam as Optimizer\nfrom torch.optim.lr_scheduler import MultiStepLR as Scheduler\n\nfrom utils.utils import *\nfrom utils.ATSProblemDef import load_single_problem_from_file\nfrom tqdm import tqdm\n\nclass ATSPTrainer:\n    def __init__(self,\n                 env_params,\n                 model_params,\n                 optimizer_params,\n                 trainer_params):\n\n        # save arguments\n        self.env_params = env_params\n        self.model_params = model_params\n        self.optimizer_params = optimizer_params\n        self.trainer_params = trainer_params\n\n        # result folder, logger\n        self.logger = getLogger(name='trainer')\n        self.result_folder = get_result_folder()\n        self.result_log = LogData()\n        self.best_score = 1e10\n        self.best_cls_scores = None\n\n        # cuda\n        USE_CUDA = self.trainer_params['use_cuda']\n        if USE_CUDA:\n            cuda_device_num = self.trainer_params['cuda_device_num']\n            torch.cuda.set_device(cuda_device_num)\n            device = torch.device('cuda', cuda_device_num)\n            torch.set_default_tensor_type('torch.cuda.FloatTensor')\n        else:\n            device = torch.device('cpu')\n            torch.set_default_tensor_type('torch.FloatTensor')\n\n        # Main Components\n        self.model = Model(**self.model_params)\n        self.env = Env(**self.env_params)\n        self.optimizer = Optimizer(self.model.parameters(), **self.optimizer_params['optimizer'])\n        self.scheduler = Scheduler(self.optimizer, **self.optimizer_params['scheduler'])\n\n        # Restore\n        self.start_epoch = 1\n        model_load = trainer_params['model_load']\n        if model_load['enable']:\n            checkpoint_fullname = '{path}/checkpoint-{epoch}.pt'.format(**model_load)\n            checkpoint = torch.load(checkpoint_fullname, map_location=device)\n            self.model.load_state_dict(checkpoint['model_state_dict'])\n            self.start_epoch = 1 + model_load['epoch']\n            self.result_log.set_raw_data(checkpoint['result_log'])\n            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n            self.scheduler.last_epoch = model_load['epoch']-1\n            self.logger.info('Saved Model Loaded !!')\n\n        # utility\n        self.time_estimator = TimeEstimator()\n\n    def run(self):\n        self.time_estimator.reset(self.start_epoch)\n        val_interval = self.trainer_params['val_interval']\n        n_nodes = self.env_params['min_scale']\n        val_dir = self.trainer_params['val_dir'].format(n_nodes)\n        for epoch in range(self.start_epoch, self.trainer_params['epochs']+1):\n            self.logger.info('=================================================================')\n\n            # LR Decay\n            self.scheduler.step()\n\n            # Train\n            train_score, train_loss = self._train_one_epoch(epoch)\n            self.result_log.append('train_score', epoch, train_score)\n            self.result_log.append('train_loss', epoch, train_loss)\n\n            # Validation TODO\n            # if epoch % val_interval == 0:\n            #     cls = ['atsp', 'tsp2d', 'hcp', '3sat']\n            #     val_score, val_score_aug, cls_scores = self._validation(dir=val_dir)\n            #     self.result_log.append('val_score', epoch, val_score)\n            #     self.result_log.append('val_score_aug', epoch, val_score_aug)\n            #     self.result_log.append('val_score_atsp', epoch, cls_scores[0].item())\n            #     self.result_log.append('val_score_euc', epoch, cls_scores[1].item())\n            #     self.result_log.append('val_score_hcp', epoch, cls_scores[2].item())\n            #     self.result_log.append('val_score_3sat', epoch, cls_scores[3].item())\n            #     self.logger.info(f'val_score: {val_score:.4f}, val_score_aug: {val_score_aug:.4f}')\n            #     for i in range(4):\n            #         self.logger.info(f'{cls[i]}: {cls_scores[i]:.4f}')\n\n            ############################\n            # Logs & Checkpoint\n            ############################\n            elapsed_time_str, remain_time_str = self.time_estimator.get_est_string(epoch, self.trainer_params['epochs'])\n            self.logger.info(\"Epoch {:3d}/{:3d}: Time Est.: Elapsed[{}], Remain[{}]\".format(\n                epoch, self.trainer_params['epochs'], elapsed_time_str, remain_time_str))\n\n            all_done = (epoch == self.trainer_params['epochs'])\n            model_save_interval = self.trainer_params['logging']['model_save_interval']\n            img_save_interval = self.trainer_params['logging']['img_save_interval']\n\n            if epoch > 1:  # save latest images, every epoch\n                self.logger.info(\"Saving log_image\")\n                image_prefix = '{}/latest'.format(self.result_folder)\n                util_save_log_image_with_label(image_prefix, self.trainer_params['logging']['log_image_params_1'],\n                                    self.result_log, labels=['train_score'])\n                util_save_log_image_with_label(image_prefix, self.trainer_params['logging']['log_image_params_2'],\n                                    self.result_log, labels=['train_loss'])\n                # if epoch % val_interval == 0:\n                #     util_save_log_image_with_label(image_prefix, self.trainer_params['logging']['log_image_params_1'],\n                #                         self.result_log, labels=['val_score'])\n                #     for cls in ['atsp', 'euc', 'hcp', '3sat']:\n                #         util_save_log_image_with_label(image_prefix, self.trainer_params['logging']['log_image_params_1'],\n                #                             self.result_log, labels=[f'val_score_{cls}'])\n\n            if epoch % model_save_interval == 0:\n                self.logger.info(\"Saving trained_model\")\n                checkpoint_dict = {\n                    'epoch': epoch,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'scheduler_state_dict': self.scheduler.state_dict(),\n                    'result_log': self.result_log.get_raw_data()\n                }\n                torch.save(checkpoint_dict,\n                    f'{self.result_folder}/checkpoint-{epoch}.pt')\n\n            if all_done:\n                self.logger.info(\" *** Training Done *** \")\n                self.logger.info(\"Now, printing log array...\")\n                util_print_log_array(self.logger, self.result_log)\n\n    def _train_one_epoch(self, epoch):\n\n        score_AM = AverageMeter()\n        loss_AM = AverageMeter()\n\n        train_num_episode = self.trainer_params['train_episodes']\n        episode = 0\n        loop_cnt = 0\n        while episode < train_num_episode:\n\n            remaining = train_num_episode - episode\n            batch_size = min(self.trainer_params['train_batch_size'], remaining)\n\n            avg_score, avg_loss = self._train_one_batch(batch_size)\n            score_AM.update(avg_score, batch_size)\n            loss_AM.update(avg_loss, batch_size)\n\n            episode += batch_size\n\n            # Log First 10 Batch, only at the first epoch\n            if epoch == self.start_epoch:\n                loop_cnt += 1\n                if loop_cnt <= 10:\n                    self.logger.info('Epoch {:3d}: Train {:3d}/{:3d}({:1.1f}%)  Score: {:.4f},  Loss: {:.4f}'\n                                     .format(epoch, episode, train_num_episode, 100. * episode / train_num_episode,\n                                             score_AM.avg, loss_AM.avg))\n\n        # Log Once, for each epoch\n        self.logger.info('Epoch {:3d}: Train ({:3.0f}%)  Score: {:.4f},  Loss: {:.4f}'\n                         .format(epoch, 100. * episode / train_num_episode,\n                                 score_AM.avg, loss_AM.avg))\n\n        return score_AM.avg, loss_AM.avg\n\n    def _validation(self, n_instances=2000, dir='../data/val_set/20_2000'):\n        no_aug_scores, aug_scores = 0, 0\n        cls_scores = torch.zeros((4,)) # atsp, hcp, euc, 3sat\n        problems= []\n        # load all validation instances\n        for i in range(n_instances):\n            filename = os.path.join(dir, f'{i}.atsp')\n            problem = load_single_problem_from_file(filename)\n            problems.append(problem.cpu().numpy().tolist())\n\n        batch_size = 100\n        aug_factor = 8\n        # batch_size = aug_factor * batch_size\n        num_batches = n_instances // batch_size # 20\n        for batch_idx in tqdm(range(num_batches)):\n            zero_cnt = {'no_aug':0, 'aug':0} # for decisive problems\n            batched_problems = problems[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n            # print(batched_problems)\n            # types = ['atsp', 'euc', 'hcp', '3sat']\n            batched_problems = torch.tensor(batched_problems)\n            batched_problems = batched_problems.repeat(aug_factor, 1, 1)\n            self.model.eval()\n            with torch.no_grad():\n                self.env.load_problems_manual(batched_problems)\n                reset_state, _, _ = self.env.reset()\n                self.model.pre_forward_pe(reset_state, self.env.pos_emb)\n\n                # POMO Rollout\n                ###############################################\n                state, reward, done = self.env.pre_step()\n                while not done:\n                    selected, _ = self.model(state)\n                    # shape: (batch, pomo)\n                    state, reward, done = self.env.step(selected)\n\n                # Return\n                ###############################################\n                aug_reward = reward.reshape(aug_factor, batch_size, self.env.node_cnt)\n                # shape: (augmentation, batch, pomo)\n\n                max_pomo_reward, _ = aug_reward.max(dim=2)  # get best results from pomo\n                # shape: (augmentation, batch)\n                no_aug_score = -max_pomo_reward[0, :].float().mean()  # negative sign to make positive value\n\n                max_aug_pomo_reward, _ = max_pomo_reward.max(dim=0)  # get best results from augmentation\n                # shape: (batch,)\n                aug_score = -max_aug_pomo_reward.float().mean()  # negative sign to make positive value\n\n                aug_zero = (-max_aug_pomo_reward.float() < 1e-3).sum()\n                no_aug_zero = (-max_pomo_reward[0, :].float() < 1e-3).sum()\n                zero_cnt['aug'] += int(aug_zero)\n                zero_cnt['no_aug'] += int(no_aug_zero)\n\n                no_aug_scores += no_aug_score.item()\n                aug_scores += aug_score.item()\n                cls_scores[batch_idx // 5] += no_aug_score\n            \n        return no_aug_scores / num_batches, aug_scores / num_batches, cls_scores / (num_batches / 4)\n\n    def _train_one_batch(self, batch_size):\n\n        # Prep\n        ###############################################\n        self.model.train()\n\n        self.env.load_problems_from_pool(batch_size)\n        reset_state, _, _ = self.env.reset()\n\n        self.model.pre_forward_pe(reset_state, self.env.pos_emb)\n\n        prob_list = torch.zeros(size=(batch_size, self.env.node_cnt, 0))\n        # shape: (batch, pomo, 0~)\n\n        # POMO Rollout\n        ###############################################\n        state, reward, done = self.env.pre_step()\n        while not done:\n            selected, prob = self.model(state)\n            # shape: (batch, pomo)\n            state, reward, done = self.env.step(selected)\n\n            prob_list = torch.cat((prob_list, prob[:, :, None]), dim=2)\n\n        # Loss\n        ###############################################\n        advantage = reward - reward.float().mean(dim=1, keepdims=True)\n        # shape: (batch, pomo)\n        log_prob = prob_list.log().sum(dim=2)\n        # size = (batch, pomo)\n        loss = -advantage * log_prob  # Minus Sign: To Increase REWARD\n        # shape: (batch, pomo)\n        loss_mean = loss.mean()\n\n        # Score\n        ###############################################\n        max_pomo_reward, _ = reward.max(dim=1)  # get best results from pomo\n        score_mean = -max_pomo_reward.float().mean()  # negative sign to make positive value\n\n        # Step & Return\n        ###############################################\n        self.model.zero_grad()\n        loss_mean.backward()\n        self.optimizer.step()\n        return score_mean.item(), loss_mean.item()\n\n# ==========================================\n# File: MatPOENet_jittor/ATSPModel.py\n# Function/Context: ATSPModel\n# ==========================================\nimport jittor as jt\nimport jittor.nn as nn\nfrom ATSPModel_LIB import *\nimport sys\nsys.path.append(\"../../../\")\n\nfrom utils_jittor.positional_encoding import *\n\nclass ATSPModel(nn.Module):\n\n    def __init__(self, **model_params):\n        super().__init__()\n        self.model_params = model_params\n        self.encoder = ATSP_Encoder(**model_params)\n        self.decoder = ATSP_Decoder(**model_params)\n        self._encoded_row = None\n        self._encoded_col = None\n        # shape: (batch, node, embedding)\n\n    def pre_forward_pe(self, reset_state, pos_emb):\n        problems = reset_state.problems\n        self._encoded_row, self._encoded_col = self.encoder(jt.zeros_like(pos_emb), pos_emb, problems)\n        self.decoder.set_kv(self._encoded_col)\n\n    def execute(self, state):\n\n        batch_size = state.BATCH_IDX.size(0)\n        pomo_size = state.BATCH_IDX.size(1)\n\n        if state.current_node is None:\n            selected = jt.arange(pomo_size)[None, :].expand(batch_size, pomo_size)\n            prob = jt.ones((batch_size, pomo_size))\n            # shape: (batch, 1, embedding)\n            encoded_first_row = _get_encoding(self._encoded_row, selected)\n            # shape: (batch, pomo, embedding)\n            self.decoder.set_q1(encoded_first_row)\n\n        else:\n            encoded_current_row = _get_encoding(self._encoded_row, state.current_node)\n            # shape: (batch, pomo, embedding)\n            all_job_probs = self.decoder(encoded_current_row, ninf_mask=state.ninf_mask)\n            # shape: (batch, pomo, job)\n\n            if self.training or self.model_params['eval_type'] == 'softmax':\n                while True:  # to fix pyjt.multinomial bug on selecting 0 probability elements\n                    with jt.no_grad():\n                        selected = jt.multinomial(weights=all_job_probs.reshape(batch_size * pomo_size, -1), num_samples=1) \\\n                            .squeeze(dim=1).reshape(batch_size, pomo_size)\n                        # shape: (batch, pomo)\n\n                    prob = all_job_probs[state.BATCH_IDX, state.POMO_IDX, selected] \\\n                        .reshape(batch_size, pomo_size)\n                    # shape: (batch, pomo)\n\n                    if (prob != 0).all():\n                        break\n            else:\n                selected = all_job_probs.argmax(dim=2)\n                # shape: (batch, pomo)\n                prob = None\n\n        return selected, prob\n\n\ndef _get_encoding(encoded_nodes, node_index_to_pick):\n    # encoded_nodes.shape: (batch, problem, embedding)\n    # node_index_to_pick.shape: (batch, pomo)\n    batch_size = node_index_to_pick.size(0)\n    pomo_size = node_index_to_pick.size(1)\n    embedding_dim = encoded_nodes.size(2)\n\n    gathering_index = node_index_to_pick[:, :, None].expand(batch_size, pomo_size, embedding_dim)\n    # shape: (batch, pomo, embedding)\n\n    picked_nodes = encoded_nodes.gather(dim=1, index=gathering_index)\n    # shape: (batch, pomo, embedding)\n\n    return picked_nodes\n\nclass PEEncodingBlock(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        self.model_params = model_params\n        pos_embedding_dim = self.model_params['pos_embedding_dim']\n        embedding_dim = self.model_params['embedding_dim']\n        head_num = self.model_params['head_num']\n        qkv_dim = self.model_params['qkv_dim']\n\n        self.Wq = nn.Linear(pos_embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wk = nn.Linear(pos_embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wv = nn.Linear(pos_embedding_dim, head_num * qkv_dim, bias=False)\n        self.mixed_score_MHA = MixedScore_MultiHeadAttention(**model_params)\n        self.multi_head_combine = nn.Linear(head_num * qkv_dim, pos_embedding_dim)\n\n        self.add_n_normalization_1 = PEAddAndInstanceNormalization(**model_params)\n        self.feed_forward = PEFeedForward(**model_params)\n        self.add_n_normalization_2 = AddAndInstanceNormalization(**model_params)\n\n    def execute(self, row_emb, col_emb, cost_mat):\n        head_num = self.model_params['head_num']\n\n        q = reshape_by_heads(self.Wq(row_emb), head_num=head_num)\n        # q shape: (batch, head_num, row_cnt, qkv_dim)\n        k = reshape_by_heads(self.Wk(col_emb), head_num=head_num)\n        v = reshape_by_heads(self.Wv(col_emb), head_num=head_num)\n        # kv shape: (batch, head_num, col_cnt, qkv_dim)\n\n        out_concat = self.mixed_score_MHA(q, k, v, cost_mat)\n        # shape: (batch, row_cnt, head_num*qkv_dim)\n\n        multi_head_out = self.multi_head_combine(out_concat)\n        # shape: (batch, row_cnt, embedding)\n\n        out1 = self.add_n_normalization_1(row_emb, multi_head_out)\n        out2 = self.feed_forward(out1)\n        # out3 = self.add_n_normalization_2(out1, out2)\n\n        # return out3\n        return out2\n        # shape: (batch, row_cnt, embedding)\n\n########################################\n# ENCODER\n########################################\nclass ATSP_Encoder(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        encoder_layer_num = model_params['encoder_layer_num']\n        self.layers = nn.ModuleList([EncoderLayer(**model_params) for _ in range(encoder_layer_num)])\n\n    def execute(self, row_emb, col_emb, cost_mat):\n        # col_emb.shape: (batch, col_cnt, embedding)\n        # row_emb.shape: (batch, row_cnt, embedding)\n        # cost_mat.shape: (batch, row_cnt, col_cnt)\n\n        for layer in self.layers:\n            row_emb, col_emb = layer(row_emb, col_emb, cost_mat)\n\n        return row_emb, col_emb\n\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        self.row_encoding_block = EncodingBlock(**model_params)\n        self.col_encoding_block = EncodingBlock(**model_params)\n\n    def execute(self, row_emb, col_emb, cost_mat):\n        # row_emb.shape: (batch, row_cnt, embedding)\n        # col_emb.shape: (batch, col_cnt, embedding)\n        # cost_mat.shape: (batch, row_cnt, col_cnt)\n        row_emb_out = self.row_encoding_block(row_emb, col_emb, cost_mat)\n        col_emb_out = self.col_encoding_block(col_emb, row_emb, cost_mat.transpose(1, 2))\n\n        return row_emb_out, col_emb_out\n\n\nclass EncodingBlock(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        self.model_params = model_params\n        embedding_dim = self.model_params['embedding_dim']\n        head_num = self.model_params['head_num']\n        qkv_dim = self.model_params['qkv_dim']\n\n        self.Wq = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wk = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wv = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.mixed_score_MHA = MixedScore_MultiHeadAttention(**model_params)\n        self.multi_head_combine = nn.Linear(head_num * qkv_dim, embedding_dim)\n\n        self.add_n_normalization_1 = AddAndInstanceNormalization(**model_params)\n        self.feed_forward = FeedForward(**model_params)\n        self.add_n_normalization_2 = AddAndInstanceNormalization(**model_params)\n\n    def execute(self, row_emb, col_emb, cost_mat):\n        # NOTE: row and col can be exchanged, if cost_mat.transpose(1,2) is used\n        # input1.shape: (batch, row_cnt, embedding)\n        # input2.shape: (batch, col_cnt, embedding)\n        # cost_mat.shape: (batch, row_cnt, col_cnt)\n        head_num = self.model_params['head_num']\n\n        q = reshape_by_heads(self.Wq(row_emb), head_num=head_num)\n        # q shape: (batch, head_num, row_cnt, qkv_dim)\n        k = reshape_by_heads(self.Wk(col_emb), head_num=head_num)\n        v = reshape_by_heads(self.Wv(col_emb), head_num=head_num)\n        # kv shape: (batch, head_num, col_cnt, qkv_dim)\n\n        out_concat = self.mixed_score_MHA(q, k, v, cost_mat)\n        # shape: (batch, row_cnt, head_num*qkv_dim)\n\n        multi_head_out = self.multi_head_combine(out_concat)\n        # shape: (batch, row_cnt, embedding)\n\n        out1 = self.add_n_normalization_1(row_emb, multi_head_out)\n        out2 = self.feed_forward(out1)\n        out3 = self.add_n_normalization_2(out1, out2)\n\n        return out3\n        # shape: (batch, row_cnt, embedding)\n\n\n########################################\n# Decoder\n########################################\n\nclass ATSP_Decoder(nn.Module):\n    def __init__(self, **model_params):\n        super().__init__()\n        self.model_params = model_params\n        embedding_dim = self.model_params['embedding_dim']\n        head_num = self.model_params['head_num']\n        qkv_dim = self.model_params['qkv_dim']\n\n        self.Wq_0 = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wq_1 = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wk = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n        self.Wv = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n\n        self.multi_head_combine = nn.Linear(head_num * qkv_dim, embedding_dim)\n\n        self._k = None  # saved key, for multi-head attention\n        self._v = None  # saved value, for multi-head_attention\n        self._single_head_key = None  # saved key, for single-head attention\n        self._q1 = None  # saved q1, for multi-head attention\n\n    def set_kv(self, encoded_jobs):\n        # encoded_jobs.shape: (batch, job, embedding)\n        head_num = self.model_params['head_num']\n\n        self._k = reshape_by_heads(self.Wk(encoded_jobs), head_num=head_num)\n        self._v = reshape_by_heads(self.Wv(encoded_jobs), head_num=head_num)\n        # shape: (batch, head_num, job, qkv_dim)\n        self._single_head_key = encoded_jobs.transpose(1, 2)\n        # shape: (batch, embedding, job)\n\n    def set_q1(self, encoded_q1):\n        # encoded_q.shape: (batch, n, embedding)  # n can be 1 or pomo\n        head_num = self.model_params['head_num']\n\n        self._q1 = reshape_by_heads(self.Wq_1(encoded_q1), head_num=head_num)\n        # shape: (batch, head_num, n, qkv_dim)\n\n    def execute(self, encoded_q0, ninf_mask):\n        # encoded_q4.shape: (batch, pomo, embedding)\n        # ninf_mask.shape: (batch, pomo, job)\n\n        head_num = self.model_params['head_num']\n\n        #  Multi-Head Attention\n        #######################################################\n        q0 = reshape_by_heads(self.Wq_0(encoded_q0), head_num=head_num)\n        # shape: (batch, head_num, pomo, qkv_dim)\n\n        q = self._q1 + q0\n        # shape: (batch, head_num, pomo, qkv_dim)\n\n        out_concat = self._multi_head_attention(q, self._k, self._v, rank3_ninf_mask=ninf_mask)\n        # shape: (batch, pomo, head_num*qkv_dim)\n\n        mh_atten_out = self.multi_head_combine(out_concat)\n        # shape: (batch, pomo, embedding)\n\n        #  Single-Head Attention, for probability calculation\n        #######################################################\n        score = jt.matmul(mh_atten_out, self._single_head_key)\n        # shape: (batch, pomo, job)\n\n        sqrt_embedding_dim = self.model_params['sqrt_embedding_dim']\n        logit_clipping = self.model_params['logit_clipping']\n\n        score_scaled = score / sqrt_embedding_dim\n        # shape: (batch, pomo, job)\n\n        score_clipped = logit_clipping * jt.tanh(score_scaled)\n\n        score_masked = score_clipped + ninf_mask\n\n        probs = jt.nn.softmax(score_masked, dim=2)\n        # shape: (batch, pomo, job)\n\n        return probs\n\n    def _multi_head_attention(self, q, k, v, rank2_ninf_mask=None, rank3_ninf_mask=None):\n        # q shape: (batch, head_num, n, key_dim)   : n can be either 1 or pomo\n        # k,v shape: (batch, head_num, node, key_dim)\n        # rank2_ninf_mask.shape: (batch, node)\n        # rank3_ninf_mask.shape: (batch, group, node)\n\n        batch_s = q.size(0)\n        n = q.size(2)\n        node_cnt = k.size(2)\n\n        head_num = self.model_params['head_num']\n        qkv_dim = self.model_params['qkv_dim']\n        sqrt_qkv_dim = self.model_params['sqrt_qkv_dim']\n\n        score = jt.matmul(q, k.transpose(2, 3))\n        # shape: (batch, head_num, n, node)\n\n        score_scaled = score / sqrt_qkv_dim\n        if rank2_ninf_mask is not None:\n            score_scaled = score_scaled + rank2_ninf_mask[:, None, None, :].expand(batch_s, head_num, n, node_cnt)\n        if rank3_ninf_mask is not None:\n            score_scaled = score_scaled + rank3_ninf_mask[:, None, :, :].expand(batch_s, head_num, n, node_cnt)\n\n        weights = jt.nn.softmax(score_scaled, dim=3)\n        # shape: (batch, head_num, n, node)\n\n        out = jt.matmul(weights, v)\n        # shape: (batch, head_num, n, key_dim)\n\n        out_transposed = out.transpose(1, 2)\n        # shape: (batch, n, head_num, key_dim)\n\n        out_concat = out_transposed.reshape(batch_s, n, head_num * qkv_dim)\n        # shape: (batch, n, head_num*key_dim)\n\n        return out_concat\n\n\n########################################\n# NN SUB FUNCTIONS\n########################################\n\ndef reshape_by_heads(qkv, head_num):\n    # q.shape: (batch, n, head_num*key_dim)   : n can be either 1 or PROBLEM_SIZE\n\n    batch_s = qkv.size(0)\n    n = qkv.size(1)\n\n    q_reshaped = qkv.reshape(batch_s, n, head_num, -1)\n    # shape: (batch, n, head_num, key_dim)\n\n    q_transposed = q_reshaped.transpose(1, 2)\n    # shape: (batch, head_num, n, key_dim)\n\n    return q_transposed",
  "description": "Combined Analysis:\n- [MatDIFFNet/src/env.py]: This file implements the core data environment for MatDIFFNet, which is part of the UniCO framework. It handles multiple combinatorial optimization problems (TSP, ATSP, SAT, HCP, VC) by generating or loading their matrix-encoded TSP representations. The environment produces distance matrices (C_ij) and reference tours, aligning with the paper's reduction approach. Key methods include generate_data for batch generation, process_data for converting tours to adjacency matrices, and problem-specific generators (e.g., gen_vertex_cover for VC reduction). This directly supports the unified training of neural solvers on matrix-encoded general TSP instances.\n- [MatDIFFNet/src/model.py]: This file implements the core diffusion-based generative model (MatDIFFNet) for solving the matrix-encoded general TSP as described in the UniCO paper. It directly handles the distance matrix input (dists) and performs the diffusion process to generate adjacency matrices (heatmaps) representing TSP tours. Key components include: 1) The categorical diffusion process with posterior sampling (categorical_posterior, guided_categorical_posterior), 2) Denoising steps (categorical_denoise_step, guided_categorical_denoise_step) that use the GNN encoder to predict clean adjacency matrices, 3) The solve_encode method that runs the reverse diffusion process from noise to generate heatmaps, and 4) Training and inference pipelines (train_test_encode, encode) that align with the paper's algorithm. The model operates directly on the cost matrix without Euclidean coordinates, addressing the general TSP domain with asymmetric/non-metric distances. The code matches the paper's MatDIFFNet approach for solving reduced CO problems via diffusion-based generation of TSP tours.\n- [MatDIFFNet/src/solver.py]: This file implements the solver component of the MatDIFFNet algorithm, which is part of the UniCO framework's neural TSP solver for matrix-encoded general TSP. The core logic involves: 1) Encoding the input distance matrix (which represents the reduced CO problem) into a heatmap using the MatDIFFNet model's encode method; 2) Decoding the heatmap into a TSP tour using the model's decoder. The solver inherits from ATSPSolver and uses ATSPEvaluator to compute the objective value ∑C_ij x_ij for the generated tours. This directly corresponds to the optimization model's objective and the algorithm steps of using a diffusion-based generative model (MatDIFFNet) to solve the general TSP instance after problem reduction.\n- [MatDIFFNet_jittor/src/model.py]: This file implements the core MatDIFFNet model from the UniCO framework, which solves the general TSP using a diffusion-based generative approach. The model takes arbitrary distance matrices (representing reduced CO problems) as input and generates adjacency heatmaps for tours through a categorical diffusion process. Key components include: 1) Diffusion posterior sampling (categorical_posterior) for denoising binary adjacency matrices, 2) A GNN encoder that processes distance matrices and noisy graphs, 3) Training via cross-entropy loss on adjacency matrices, and 4) Inference through iterative denoising steps. The model directly addresses the paper's objective of solving matrix-encoded general TSP instances, supporting asymmetric/non-metric distances without Euclidean coordinates.\n- [MatDIFFNet_jittor/src/solver.py]: This file implements the inference/solving component of the MatDIFFNet algorithm for general TSP. The solver takes arbitrary cost matrices (which may be asymmetric/non-metric) as input, processes them through the diffusion-based neural network (MatDIFFNetModel), and outputs TSP tours. It directly corresponds to the algorithmic step of solving matrix-encoded general TSP instances using the trained neural solver. The mathematical optimization model is implicitly handled by the neural network's architecture and training, which learns to produce feasible tours minimizing the objective ∑C_ij x_ij. The solver acts as the interface between problem instances (distance matrices) and the neural model that generates solutions.\n- [MatPOENet/ATSPEnv.py]: This file implements the core environment for the matrix-encoded general TSP as described in the UniCO paper. The ATSPEnv class handles multiple CO problems (ATSP, Euclidean TSP, HCP, 3SAT) by reducing them to a unified TSP representation via cost matrices. It manages the sequential construction of tours (Hamiltonian cycles) and computes the objective function ∑C_ij x_ij through the _get_total_distance method. The environment enforces TSP constraints implicitly by preventing node revisits via ninf_mask and ensuring complete tours. This directly corresponds to the paper's reduction framework where diverse CO problems are transformed into general TSP instances solvable by neural networks like MatPOENet.\n- [MatPOENet/ATSPModel.py]: This file implements the core MatPOENet neural solver for general TSP as described in the UniCO paper. The ATSPModel class is a Transformer-based encoder-decoder architecture that processes arbitrary cost matrices (asymmetric/non-metric) to sequentially generate TSP tours. Key components: 1) Encoder with row/column attention blocks that process the cost matrix, 2) Decoder with multi-head attention for sequential node selection, 3) Pseudo one-hot embedding scheme via positional encoding integration. The model directly implements the neural solving algorithm for matrix-encoded general TSP, which is the central component of UniCO's problem reduction framework.\n- [MatPOENet/ATSPTrainer.py]: This file implements the training pipeline for MatPOENet, which is the reinforcement learning-based neural solver for general TSP in the UniCO framework. The ATSPTrainer class orchestrates the training process using policy gradient reinforcement learning (REINFORCE with baseline). Key aspects:\n1. It trains a model (ATSPModel) to solve ATSP instances represented purely by cost matrices, aligning with the paper's matrix-encoded general TSP formulation.\n2. The training uses POMO (Policy Optimization with Multiple Optima) rollouts where the model sequentially selects nodes to construct TSP tours.\n3. The loss function uses advantage (reward minus average reward) and log probabilities of actions, implementing REINFORCE with baseline.\n4. The validation method demonstrates the framework's ability to handle multiple problem types (ATSP, 2DTSP, HCP, SAT) by loading different problem instances from files, though this is currently commented out.\n5. The code handles the core optimization objective indirectly through reward maximization (negative tour length minimization).\nThe implementation corresponds to the MatPOENet algorithm described in the paper, which learns to solve general TSP instances that can represent various reduced CO problems.\n- [MatPOENet_jittor/ATSPModel.py]: This file implements the MatPOENet neural solver for the general TSP problem, which is the core algorithmic component of the UniCO framework. The ATSPModel class is a Transformer-based encoder-decoder architecture that processes arbitrary cost matrices (asymmetric, non-metric, or discrete) to generate TSP tours. The encoder (ATSP_Encoder) uses mixed-score multi-head attention to embed row and column representations from the cost matrix, while the decoder (ATSP_Decoder) sequentially selects nodes using attention mechanisms with masking to enforce constraints. The execute() method implements the autoregressive tour construction, with training using REINFORCE (via multinomial sampling) and evaluation via greedy selection. This directly corresponds to the MatPOENet algorithm described in the paper for solving matrix-encoded general TSP instances.",
  "dependencies": [
    "FakeDataset",
    "ATSPModel",
    "utils.ATSProblemDef.load_single_problem_from_file",
    "torch.utils.data",
    "tqdm.trange",
    "ml4co_kit.to_numpy",
    "sys",
    "ml4co_kit.iterative_execution",
    "utils.positional_encoding.make_positional_encoding_cosh_recur",
    "ml4co_kit.ATSPEvaluator",
    "logging",
    "torch.optim.lr_scheduler.MultiStepLR",
    "utils.utils.*",
    "ml4co_kit.TSPSolver",
    "torch.nn.functional",
    "InferenceSchedule",
    ".model.MatDIFFNetModel",
    "typing",
    "utils.generate_data.gen_3sat",
    "MatDIFFNetEnv",
    "ml4co_kit.to_tensor",
    "ml4co_kit.BaseEnv",
    "ml4co_kit.ATSPDataGenerator",
    "utils.generate_data.gen_hcp",
    "CategoricalDiffusion",
    "tqdm",
    "AddAndInstanceNormalization",
    "FeedForward",
    "get_coords_by_dists",
    "GNNEncoder",
    "dataclasses.dataclass",
    "PEAddAndInstanceNormalization",
    "ml4co_kit.BaseModel",
    "torch.optim.Adam",
    "utils.positional_encoding",
    "os",
    "PEFeedForward",
    "typing.List",
    "jittor.nn",
    "MixedScore_MultiHeadAttention",
    "utils.base_methods.BaseSolver",
    "utils.generate_data.gen_Euclidean",
    "torch.Tensor",
    "numpy",
    "MatDIFFNetDecoder",
    "ml4co_kit.SOLVER_TYPE",
    "sortedcollections.OrderedSet",
    "ATSPEnv",
    "ml4co_kit.ATSPSolver",
    "ATSPModel_LIB",
    "ml4co_kit.check_dim",
    "torch.nn",
    "jittor.Var",
    "utils.ATSProblemDef.get_random_problems",
    "jittor",
    "torch",
    "scipy.spatial.distance.cdist",
    "utils_jittor.positional_encoding"
  ]
}