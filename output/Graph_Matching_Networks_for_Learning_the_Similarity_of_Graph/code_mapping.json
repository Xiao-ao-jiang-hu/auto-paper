{
  "file_path": "COMMON/models/COMMON/model.py, GMN/graphmatchingnetwork.py",
  "function_name": "Backbone.forward, Net.forward, GraphMatchingNet, GraphPropMatchingLayer, batch_block_pair_attention, compute_cross_attention",
  "code_snippet": "\n\n# ==========================================\n# File: COMMON/models/COMMON/model.py\n# Function/Context: Backbone.forward, Net.forward\n# ==========================================\nimport torch\nimport itertools\nimport numpy as np\n\nfrom models.COMMON.sconv_archs import SiameseSConvOnNodes, SiameseNodeFeaturesToEdgeFeatures\nfrom src.feature_align import feature_align\nfrom src.factorize_graph_matching import construct_aff_mat\nfrom src.utils.pad_tensor import pad_tensor\nfrom src.lap_solvers.sinkhorn import Sinkhorn\nfrom src.lap_solvers.hungarian import hungarian\n\nfrom src.utils.config import cfg\n\nfrom src.backbone import *\n\nfrom src.loss_func import *\n\nCNN = eval(cfg.BACKBONE)\n\n\ndef lexico_iter(lex):\n    return itertools.combinations(lex, 2)\n\n\ndef normalize_over_channels(x):\n    channel_norms = torch.norm(x, dim=1, keepdim=True)\n    return x / channel_norms\n\n\ndef concat_features(embeddings, num_vertices):\n    res = torch.cat([embedding[:, :num_v] for embedding, num_v in zip(embeddings, num_vertices)], dim=-1)\n    return res.transpose(0, 1)\n\n\nclass InnerProduct(nn.Module):\n    def __init__(self, output_dim):\n        super(InnerProduct, self).__init__()\n        self.d = output_dim\n\n    def _forward(self, X, Y):\n        assert X.shape[1] == Y.shape[1] == self.d, (X.shape[1], Y.shape[1], self.d)\n        X = torch.nn.functional.normalize(X, dim=-1)\n        Y = torch.nn.functional.normalize(Y, dim=-1)\n        res = torch.matmul(X, Y.transpose(0, 1))\n        return res\n\n    def forward(self, Xs, Ys):\n        return [self._forward(X, Y) for X, Y in zip(Xs, Ys)]\n\n\nclass Backbone(CNN):\n    def __init__(self):\n        super(Backbone, self).__init__()\n        self.message_pass_node_features = SiameseSConvOnNodes(input_node_dim=cfg.COMMON.FEATURE_CHANNEL * 2)\n        self.build_edge_features_from_node_features = SiameseNodeFeaturesToEdgeFeatures(\n            total_num_nodes=self.message_pass_node_features.num_node_features\n        )\n        self.vertex_affinity = InnerProduct(256)\n        self.rescale = cfg.PROBLEM.RESCALE\n        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / cfg.COMMON.SOFTMAXTEMP))\n\n        self.projection = nn.Sequential(\n            nn.Linear(1024, 1024, bias=True),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 256, bias=True),\n            nn.BatchNorm1d(256),\n            nn.ReLU()\n        )\n\n    def forward(self, data_dict, online=True):\n        with torch.no_grad():\n            self.logit_scale.clamp_(0, 4.6052)  # clamp temperature to be between 0.01 and 1\n\n        images = data_dict['images']\n        points = data_dict['Ps']\n        n_points = data_dict['ns']\n        graphs = data_dict['pyg_graphs']\n        batch_size = data_dict['batch_size']\n        num_graphs = len(images)\n        orig_graph_list = []\n\n        for image, p, n_p, graph in zip(images, points, n_points, graphs):\n            # extract feature\n            nodes = self.node_layers(image)\n            edges = self.edge_layers(nodes)\n\n            nodes = normalize_over_channels(nodes)\n            edges = normalize_over_channels(edges)\n\n            # arrange features, following BBGM\n            U = feature_align(nodes, p, n_p, self.rescale)\n            F = feature_align(edges, p, n_p, self.rescale)\n            U = concat_features(U, n_p)\n            F = concat_features(F, n_p)\n            node_features = torch.cat((U, F), dim=1)\n\n            # GNN\n            graph.x = node_features\n            graph = self.message_pass_node_features(graph)\n            orig_graph = self.build_edge_features_from_node_features(graph)\n            orig_graph_list.append(orig_graph)\n\n        unary_affs_list = [\n            self.vertex_affinity([self.projection(item.x) for item in g_1], [self.projection(item.x) for item in g_2])\n            for (g_1, g_2) in lexico_iter(orig_graph_list)\n        ]\n\n        # prepare aligned node features for computing contrastive loss\n        keypoint_number_list = []  # the number of keypoints in each image pair\n        node_feature_list = []  # node features for computing contrastive loss\n\n        node_feature_graph1 = torch.zeros([batch_size, data_dict['gt_perm_mat'].shape[1], node_features.shape[1]],\n                                         device=node_features.device)\n        node_feature_graph2 = torch.zeros([batch_size, data_dict['gt_perm_mat'].shape[2], node_features.shape[1]],\n                                         device=node_features.device)\n        # count the available keypoints in number list\n        for index in range(batch_size):\n            node_feature_graph1[index, :orig_graph_list[0][index].x.shape[0]] = orig_graph_list[0][index].x\n            node_feature_graph2[index, :orig_graph_list[1][index].x.shape[0]] = orig_graph_list[1][index].x\n            keypoint_number_list.append(torch.sum(data_dict['gt_perm_mat'][index]))\n        number = int(sum(keypoint_number_list))  # calculate the number of correspondence\n\n        # pre-align the keypoints for further computing the contrastive loss\n        node_feature_graph2 = torch.bmm(data_dict['gt_perm_mat'], node_feature_graph2)\n        final_node_feature_graph1 = torch.zeros([number, node_features.shape[1]], device=node_features.device)\n        final_node_feature_graph2 = torch.zeros([number, node_features.shape[1]], device=node_features.device)\n        count = 0\n        for index in range(batch_size):\n            final_node_feature_graph1[count: count + int(keypoint_number_list[index])] \\\n                = node_feature_graph1[index, :int(keypoint_number_list[index])]\n            final_node_feature_graph2[count: count + int(keypoint_number_list[index])] \\\n                = node_feature_graph2[index, :int(keypoint_number_list[index])]\n            count += int(keypoint_number_list[index])\n        node_feature_list.append(self.projection(final_node_feature_graph1))\n        node_feature_list.append(self.projection(final_node_feature_graph2))\n\n        if online == False:\n            # output of the momentum network\n            return node_feature_list\n        elif online == True:\n            # output of the online network\n            x_list = []\n            for unary_affs, (idx1, idx2) in zip(unary_affs_list, lexico_iter(range(num_graphs))):\n                Kp = torch.stack(pad_tensor(unary_affs), dim=0)\n                # conduct hungarian matching to get the permutation matrix for evaluation\n                x = hungarian(Kp, n_points[idx1], n_points[idx2])\n                x_list.append(x)\n            return node_feature_list, x_list\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.onlineNet = Backbone()\n        self.momentumNet = Backbone()  # initialize the online network and momentum network\n        self.momentum = cfg.COMMON.MOMENTUM  # momentum parameter for the momentum network\n        self.backbone_params = list(self.onlineNet.backbone_params) # used in train_eval.py\n        self.warmup_step = cfg.COMMON.WARMUP_STEP  # warmup steps for the distillation\n        self.epoch_iters = cfg.TRAIN.EPOCH_ITERS  # iterations for one epoch, specified by the training dataset\n\n        self.model_pairs = [[self.onlineNet, self.momentumNet]]\n        self.copy_params()  # initialize the momentum network\n\n        assert cfg.PROBLEM.TYPE == '2GM'  # only support 2GM problem currently\n\n    def forward(self, data_dict, training=False, iter_num=0, epoch=0):\n        # calculate the distillation weight alpha\n        if epoch * self.epoch_iters + iter_num >= self.warmup_step:\n            alpha = cfg.COMMON.ALPHA\n        else:\n            alpha = cfg.COMMON.ALPHA * min(1, (epoch * self.epoch_iters + iter_num) / self.warmup_step)\n\n        # output of the online network\n        node_feature_list, x_list = self.onlineNet(data_dict)\n\n        if training == True:\n            # the momentum network is only using for training\n            assert cfg.COMMON.DISTILL == True\n\n            # obtain output of the momentum network\n            with torch.no_grad():\n                self._momentum_update()\n                node_feature_m_list = self.momentumNet(data_dict, online=False)\n            # loss function\n            contrastloss = Distill_InfoNCE()\n            loss = contrastloss(node_feature_list, node_feature_m_list, alpha,\n                                self.onlineNet.logit_scale, self.momentumNet.logit_scale)\n            crossloss = Distill_QuadraticContrast()\n            loss = loss + crossloss(node_feature_list, node_feature_m_list,\n                                    self.onlineNet.logit_scale, self.momentumNet.logit_scale)\n\n            if cfg.PROBLEM.TYPE == '2GM':\n                data_dict.update({\n                    'perm_mat': x_list[0],\n                    'loss': loss,\n                    'ds_mat': None,\n                })\n        else:\n            # directly output the results\n            if cfg.PROBLEM.TYPE == '2GM':\n                data_dict.update({\n                    'perm_mat': x_list[0],\n                    'ds_mat': None,\n                })\n        return data_dict\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    @torch.no_grad()\n    def copy_params(self):\n        for model_pair in self.model_pairs:\n            for param, param_m in zip(model_pair[0].parameters(), model_pair[1].parameters()):\n                param_m.data.copy_(param.data)  # initialize\n                param_m.requires_grad = False  # not update by gradient\n\n    @torch.no_grad()\n    def _momentum_update(self):\n        for model_pair in self.model_pairs:\n            for param, param_m in zip(model_pair[0].parameters(), model_pair[1].parameters()):\n                param_m.data = param_m.data * self.momentum + param.data * (1. - self.momentum)\n\n# ==========================================\n# File: GMN/graphmatchingnetwork.py\n# Function/Context: GraphMatchingNet, GraphPropMatchingLayer, batch_block_pair_attention, compute_cross_attention\n# ==========================================\nfrom graphembeddingnetwork import GraphEmbeddingNet\nfrom graphembeddingnetwork import GraphPropLayer\nimport torch\n\n\ndef pairwise_euclidean_similarity(x, y):\n    \"\"\"Compute the pairwise Euclidean similarity between x and y.\n\n    This function computes the following similarity value between each pair of x_i\n    and y_j: s(x_i, y_j) = -|x_i - y_j|^2.\n\n    Args:\n      x: NxD float tensor.\n      y: MxD float tensor.\n\n    Returns:\n      s: NxM float tensor, the pairwise euclidean similarity.\n    \"\"\"\n    s = 2 * torch.mm(x, torch.transpose(y, 1, 0))\n    diag_x = torch.sum(x * x, dim=-1)\n    diag_x = torch.unsqueeze(diag_x, 0)\n    diag_y = torch.reshape(torch.sum(y * y, dim=-1), (1, -1))\n\n    return s - diag_x - diag_y\n\n\ndef pairwise_dot_product_similarity(x, y):\n    \"\"\"Compute the dot product similarity between x and y.\n\n    This function computes the following similarity value between each pair of x_i\n    and y_j: s(x_i, y_j) = x_i^T y_j.\n\n    Args:\n      x: NxD float tensor.\n      y: MxD float tensor.\n\n    Returns:\n      s: NxM float tensor, the pairwise dot product similarity.\n    \"\"\"\n    return torch.mm(x, torch.transpose(y, 1, 0))\n\n\ndef pairwise_cosine_similarity(x, y):\n    \"\"\"Compute the cosine similarity between x and y.\n\n    This function computes the following similarity value between each pair of x_i\n    and y_j: s(x_i, y_j) = x_i^T y_j / (|x_i||y_j|).\n\n    Args:\n      x: NxD float tensor.\n      y: MxD float tensor.\n\n    Returns:\n      s: NxM float tensor, the pairwise cosine similarity.\n    \"\"\"\n    x = torch.div(x, torch.sqrt(torch.max(torch.sum(x ** 2), 1e-12)))\n    y = torch.div(y, torch.sqrt(torch.max(torch.sum(y ** 2), 1e-12)))\n    return torch.mm(x, torch.transpose(y, 1, 0))\n\n\nPAIRWISE_SIMILARITY_FUNCTION = {\n    'euclidean': pairwise_euclidean_similarity,\n    'dotproduct': pairwise_dot_product_similarity,\n    'cosine': pairwise_cosine_similarity,\n}\n\n\ndef get_pairwise_similarity(name):\n    \"\"\"Get pairwise similarity metric by name.\n\n    Args:\n      name: string, name of the similarity metric, one of {dot-product, cosine,\n        euclidean}.\n\n    Returns:\n      similarity: a (x, y) -> sim function.\n\n    Raises:\n      ValueError: if name is not supported.\n    \"\"\"\n    if name not in PAIRWISE_SIMILARITY_FUNCTION:\n        raise ValueError('Similarity metric name \"%s\" not supported.' % name)\n    else:\n        return PAIRWISE_SIMILARITY_FUNCTION[name]\n\n\ndef compute_cross_attention(x, y, sim):\n    \"\"\"Compute cross attention.\n\n    x_i attend to y_j:\n    a_{i->j} = exp(sim(x_i, y_j)) / sum_j exp(sim(x_i, y_j))\n    y_j attend to x_i:\n    a_{j->i} = exp(sim(x_i, y_j)) / sum_i exp(sim(x_i, y_j))\n    attention_x = sum_j a_{i->j} y_j\n    attention_y = sum_i a_{j->i} x_i\n\n    Args:\n      x: NxD float tensor.\n      y: MxD float tensor.\n      sim: a (x, y) -> similarity function.\n\n    Returns:\n      attention_x: NxD float tensor.\n      attention_y: NxD float tensor.\n    \"\"\"\n    a = sim(x, y)\n    a_x = torch.softmax(a, dim=1)  # i->j\n    a_y = torch.softmax(a, dim=0)  # j->i\n    attention_x = torch.mm(a_x, y)\n    attention_y = torch.mm(torch.transpose(a_y, 1, 0), x)\n    return attention_x, attention_y\n\n\ndef batch_block_pair_attention(data,\n                               block_idx,\n                               n_blocks,\n                               similarity='dotproduct'):\n    \"\"\"Compute batched attention between pairs of blocks.\n\n    This function partitions the batch data into blocks according to block_idx.\n    For each pair of blocks, x = data[block_idx == 2i], and\n    y = data[block_idx == 2i+1], we compute\n\n    x_i attend to y_j:\n    a_{i->j} = exp(sim(x_i, y_j)) / sum_j exp(sim(x_i, y_j))\n    y_j attend to x_i:\n    a_{j->i} = exp(sim(x_i, y_j)) / sum_i exp(sim(x_i, y_j))\n\n    and\n\n    attention_x = sum_j a_{i->j} y_j\n    attention_y = sum_i a_{j->i} x_i.\n\n    Args:\n      data: NxD float tensor.\n      block_idx: N-dim int tensor.\n      n_blocks: integer.\n      similarity: a string, the similarity metric.\n\n    Returns:\n      attention_output: NxD float tensor, each x_i replaced by attention_x_i.\n\n    Raises:\n      ValueError: if n_blocks is not an integer or not a multiple of 2.\n    \"\"\"\n    if not isinstance(n_blocks, int):\n        raise ValueError('n_blocks (%s) has to be an integer.' % str(n_blocks))\n\n    if n_blocks % 2 != 0:\n        raise ValueError('n_blocks (%d) must be a multiple of 2.' % n_blocks)\n\n    sim = get_pairwise_similarity(similarity)\n\n    results = []\n\n    # This is probably better than doing boolean_mask for each i\n    partitions = []\n    for i in range(n_blocks):\n        partitions.append(data[block_idx == i, :])\n\n    for i in range(0, n_blocks, 2):\n        x = partitions[i]\n        y = partitions[i + 1]\n        attention_x, attention_y = compute_cross_attention(x, y, sim)\n        results.append(attention_x)\n        results.append(attention_y)\n    results = torch.cat(results, dim=0)\n\n    return results\n\n\nclass GraphPropMatchingLayer(GraphPropLayer):\n    \"\"\"A graph propagation layer that also does cross graph matching.\n\n    It assumes the incoming graph data is batched and paired, i.e. graph 0 and 1\n    forms the first pair and graph 2 and 3 are the second pair etc., and computes\n    cross-graph attention-based matching for each pair.\n    \"\"\"\n\n    def forward(self,\n                node_states,\n                from_idx,\n                to_idx,\n                graph_idx,\n                n_graphs,\n                similarity='dotproduct',\n                edge_features=None,\n                node_features=None):\n        \"\"\"Run one propagation step with cross-graph matching.\n\n        Args:\n          node_states: [n_nodes, node_state_dim] float tensor, node states.\n          from_idx: [n_edges] int tensor, from node indices for each edge.\n          to_idx: [n_edges] int tensor, to node indices for each edge.\n          graph_idx: [n_onodes] int tensor, graph id for each node.\n          n_graphs: integer, number of graphs in the batch.\n          similarity: type of similarity to use for the cross graph attention.\n          edge_features: if not None, should be [n_edges, edge_feat_dim] tensor,\n            extra edge features.\n          node_features: if not None, should be [n_nodes, node_feat_dim] tensor,\n            extra node features.\n\n        Returns:\n          node_states: [n_nodes, node_state_dim] float tensor, new node states.\n\n        Raises:\n          ValueError: if some options are not provided correctly.\n        \"\"\"\n        aggregated_messages = self._compute_aggregated_messages(\n            node_states, from_idx, to_idx, edge_features=edge_features)\n\n        cross_graph_attention = batch_block_pair_attention(\n            node_states, graph_idx, n_graphs, similarity=similarity)\n        attention_input = node_states - cross_graph_attention\n\n        return self._compute_node_update(node_states,\n                                         [aggregated_messages, attention_input],\n                                         node_features=node_features)\n\n\nclass GraphMatchingNet(GraphEmbeddingNet):\n    \"\"\"Graph matching net.\n\n    This class uses graph matching layers instead of the simple graph prop layers.\n\n    It assumes the incoming graph data is batched and paired, i.e. graph 0 and 1\n    forms the first pair and graph 2 and 3 are the second pair etc., and computes\n    cross-graph attention-based matching for each pair.\n    \"\"\"\n\n    def __init__(self,\n                 encoder,\n                 aggregator,\n                 node_state_dim,\n                 edge_state_dim,\n                 edge_hidden_sizes,\n                 node_hidden_sizes,\n                 n_prop_layers,\n                 share_prop_params=False,\n                 edge_net_init_scale=0.1,\n                 node_update_type='residual',\n                 use_reverse_direction=True,\n                 reverse_dir_param_different=True,\n                 layer_norm=False,\n                 layer_class=GraphPropLayer,\n                 similarity='dotproduct',\n                 prop_type='embedding'):\n        super(GraphMatchingNet, self).__init__(\n            encoder,\n            aggregator,\n            node_state_dim,\n            edge_state_dim,\n            edge_hidden_sizes,\n            node_hidden_sizes,\n            n_prop_layers,\n            share_prop_params=share_prop_params,\n            edge_net_init_scale=edge_net_init_scale,\n            node_update_type=node_update_type,\n            use_reverse_direction=use_reverse_direction,\n            reverse_dir_param_different=reverse_dir_param_different,\n            layer_norm=layer_norm,\n            layer_class=GraphPropMatchingLayer,\n            prop_type=prop_type,\n        )\n        self._similarity = similarity\n\n    def _apply_layer(self,\n                     layer,\n                     node_states,\n                     from_idx,\n                     to_idx,\n                     graph_idx,\n                     n_graphs,\n                     edge_features):\n        \"\"\"Apply one layer on the given inputs.\"\"\"\n        return layer(node_states, from_idx, to_idx, graph_idx, n_graphs,\n                     similarity=self._similarity, edge_features=edge_features)",
  "description": "Combined Analysis:\n- [COMMON/models/COMMON/model.py]: This file implements the core optimization logic for graph matching through a neural network architecture. The Backbone class computes node embeddings via CNN and GNN layers, then constructs an affinity matrix (unary_affs_list) using inner product similarity. The Hungarian algorithm (hungarian) solves the linear assignment problem to find the optimal permutation matrix Ï€ that minimizes the graph edit distance objective. The Net class orchestrates training with momentum networks and contrastive losses. This directly corresponds to the paper's objective of learning similarity metrics via graph matching networks, with the Hungarian solver providing the discrete permutation constraint.\n- [GMN/graphmatchingnetwork.py]: This file implements the core cross-graph attention mechanism for Graph Matching Networks (GMNs) as described in the paper. The key components are:\n1. Pairwise similarity functions (Euclidean, dot product, cosine) that compute node-level similarity scores.\n2. Cross-attention computation (compute_cross_attention) that implements soft attention between nodes of two graphs.\n3. Batched cross-graph attention (batch_block_pair_attention) that processes paired graphs in a batch.\n4. GraphPropMatchingLayer extends standard graph propagation with cross-graph attention, allowing nodes to attend to nodes in the paired graph.\n5. GraphMatchingNet uses these matching layers to enable iterative cross-graph information exchange during propagation.\n\nThe implementation directly corresponds to the paper's algorithm where cross-graph attention is computed at each propagation step, allowing the model to learn a similarity metric through data-driven training rather than explicit graph edit distance minimization. The attention mechanism approximates soft node correspondences between graphs, which is central to the GMN approach.",
  "dependencies": [
    "concat_features",
    "src.utils.config.cfg",
    "src.feature_align.feature_align",
    "InnerProduct",
    "pairwise_dot_product_similarity",
    "src.backbone",
    "normalize_over_channels",
    "models.COMMON.sconv_archs.SiameseNodeFeaturesToEdgeFeatures",
    "Backbone",
    "pairwise_euclidean_similarity",
    "src.loss_func",
    "pairwise_cosine_similarity",
    "get_pairwise_similarity",
    "Net",
    "batch_block_pair_attention",
    "numpy",
    "lexico_iter",
    "graphembeddingnetwork.GraphPropLayer",
    "compute_cross_attention",
    "graphembeddingnetwork.GraphEmbeddingNet",
    "src.utils.pad_tensor.pad_tensor",
    "models.COMMON.sconv_archs.SiameseSConvOnNodes",
    "torch",
    "src.lap_solvers.hungarian.hungarian",
    "itertools"
  ]
}