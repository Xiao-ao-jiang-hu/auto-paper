{
  "file_path": "nonlinear_shortest_path/solve_surco.py, table_sharding/dreamshard/models.py, table_sharding/dreamshard/sharders.py, table_sharding/dreamshard/training.py",
  "function_name": "solve_surco_zero, Model.diff_opt_forward, surco_prior, surco_zero, surco_hybrid, train_diff_opt",
  "code_snippet": "\n\n# ==========================================\n# File: nonlinear_shortest_path/solve_surco.py\n# Function/Context: solve_surco_zero\n# ==========================================\nimport torch\nimport networkx as nx\nimport numpy as np\nfrom torch import distributions\n\nclass DifferentiableShortestPath(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, edge_weights, G, lambda_val, source_node, dest_node):\n        torch_path_one_hot = solve_shortest_path_with_weights(\n            edge_weights, G, source_node=source_node, dest_node=dest_node)\n        ctx.lambda_val = lambda_val\n        ctx.G = G\n        ctx.source_node = source_node\n        ctx.dest_node = dest_node\n        ctx.save_for_backward(torch_path_one_hot, edge_weights)\n        return torch_path_one_hot\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        torch_path_one_hot, edge_weights = ctx.saved_tensors\n        new_weights = edge_weights + ctx.lambda_val * grad_output\n        new_weights = torch.relu(new_weights)\n\n        improved_path = solve_shortest_path_with_weights(\n            new_weights, ctx.G, source_node=ctx.source_node, dest_node=ctx.dest_node)\n        grad_input = (improved_path - torch_path_one_hot)\n        return grad_input, None, None, None, None\n\ndef torch_cdf(x, mu, sigma):\n    return distributions.Normal(0, 1).cdf((x-mu)/sigma)\n\ndef solve_surco_zero(G, source_node, dest_node, threshold, lambda_val=1e3,\n                     learning_rate=1e-1, max_iters=30, patience=5):\n    \"\"\"\n    solves the shortest path problem using surco_zero\n    \"\"\"\n    edges = list(G.edges)\n    all_edge_data = G.edges(data=True)\n    all_edge_means = torch.tensor([p[\"mean\"] for u, v, p in all_edge_data])\n    all_edge_variances = torch.tensor(\n        [p[\"variance\"] for u, v, p in all_edge_data])\n    torch_raw_edge_weights = torch.randn(len(edges), requires_grad=True)\n    optimizer = torch.optim.Adam([torch_raw_edge_weights], lr=learning_rate)\n    history = defaultdict(list)\n    best_solution = None\n    best_solution_value = -np.inf\n    for i in range(max_iters):\n        optimizer.zero_grad()\n        torch_edge_weights = torch.sigmoid(torch_raw_edge_weights)\n        torch_path_one_hot = DifferentiableShortestPath.apply(\n            torch_edge_weights, G, lambda_val, source_node, dest_node)\n        torch_path_one_hot.retain_grad()\n        path_mean = all_edge_means@torch_path_one_hot\n        path_variance = all_edge_variances@torch_path_one_hot\n        prob_meeting_deadline = torch_cdf(\n            threshold, path_mean, torch.sqrt(path_variance))\n\n        loss = -(threshold - path_mean)/torch.sqrt(path_variance)\n        # loss = -prob_meeting_deadline\n\n        history[\"cdf\"].append(prob_meeting_deadline.detach().numpy().item())\n        history[\"mean\"].append(path_mean.detach().numpy().item())\n        history[\"variance\"].append(path_variance.detach().numpy().item())\n        history[\"loss\"].append(loss.detach().numpy().item())\n\n        loss.backward()\n        optimizer.step()\n\n        if prob_meeting_deadline > best_solution_value:\n            best_solution = torch_path_one_hot.detach()\n            best_solution_value = prob_meeting_deadline\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        if patience_counter > patience:\n            break\n    # convert one-hot edges to list of nodes\n    surco_edges = [i for i, j in zip(edges, best_solution) if j == 1]\n    new_G = nx.Graph()\n    new_G.add_edges_from(surco_edges)\n    surco_nodes = list(nx.dfs_preorder_nodes(new_G, source_node))\n    return surco_nodes, history\n\ndef solve_shortest_path_with_weights(edge_weights, G, source_node, dest_node):\n    edges = list(G.edges)\n    torch_G = nx.to_networkx_graph(G)\n    for (i, (u, v)) in enumerate(edges):\n        torch_G[u][v]['weight'] = edge_weights[i]\n    torch_path = nx.shortest_path(\n        torch_G, source_node, dest_node, weight='weight', method=\"bellman-ford\"\n    )\n    torch_path_edges = list(zip(torch_path, torch_path[1:]))\n    torch_path_one_hot = torch.zeros(len(edges))\n    for (u, v) in torch_path_edges:\n        if (u, v) in edges:\n            torch_path_one_hot[edges.index((u, v))] = 1\n        else:\n            torch_path_one_hot[edges.index((v, u))] = 1\n    return torch_path_one_hot\n\n# ==========================================\n# File: table_sharding/dreamshard/models.py\n# Function/Context: Model.diff_opt_forward\n# ==========================================\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport time\nimport warnings\n\n# import pulp\nimport cvxpy as cp\nfrom cvxpylayers.torch import CvxpyLayer\nimport cvxpy.settings as s\nimport numpy as np\n\n\nclass Model(nn.Module):\n    def __init__(self, table_feature_dim, num_devices=4, integer_deployment=True):\n        super().__init__()\n        table_latent_dim = 32\n        # Table feature extraction\n        self.table_fc_0 = nn.Linear(table_feature_dim, 128)\n        self.table_fc_1 = nn.Linear(128, table_latent_dim)\n\n        # Table feature extraction RL\n        self.rl_table_fc_0 = nn.Linear(table_feature_dim, 128)\n        self.rl_table_fc_1 = nn.Linear(128, table_latent_dim)\n\n        # Forward head\n        self.forward_fc_0 = nn.Linear(table_latent_dim, 64)\n        self.forward_fc_1 = nn.Linear(64, 1)\n\n        # Communication head\n        self.communication_fc_0 = nn.Linear(table_latent_dim, 64)\n        self.communication_fc_1 = nn.Linear(64, 1)\n\n        # Backward head\n        self.backward_fc_0 = nn.Linear(table_latent_dim, 64)\n        self.backward_fc_1 = nn.Linear(64, 1)\n\n        # Overall head\n        self.overall_fc_0 = nn.Linear(table_latent_dim, 64)\n        self.overall_fc_1 = nn.Linear(64, 1)\n\n        # Cost features extraction\n        self.cost_fc_0 = nn.Linear(3, 64)\n        self.cost_fc_1 = nn.Linear(64, 32)\n\n        self.surrogate_cost_net = nn.Linear(table_latent_dim, num_devices)\n\n        # 32 for table raw features\n        # 32 for cost features\n        self.policy_net = nn.Linear(32*2, 1)\n\n        # Value net\n        # 32 for table raw features\n        # 32 for cost features\n        # We consider 4 devices\n        self.value_net = nn.Linear(32*2*4, 1)\n\n        self.integer_deployment = integer_deployment\n    \n    def diff_opt_parameters(self):\n        \"\"\"\n        _get_diff_opt_latent([[torch.stack(env.table_features)]])\n        cost_estimates = self.surrogate_cost_net\n        table_forward_rl,\n        kernel_forward\n        \"\"\"\n        # all params except table_fc_0, table_fc_1, overall_fc_0, overall_fc_1\n        params = torch.nn.ParameterList([x for name, x in self.named_parameters() if not (name.startswith(\"table_fc\") or name.startswith(\"overall_fc\"))])\n        # return [*self.surrogate_cost_net.parameters(), ]\n        return params\n\n    def kernel_forward(self, X):\n        \"\"\" Forward, backward, communication\n        \"\"\"\n        # X is a list of tensors, B x number of tables in a shard x table_feature_dim\n        # Forward\n        X_len = torch.tensor([x.shape[0] for x in X])\n        B = X_len.shape[0]\n\n        X = torch.cat(X, dim=0)\n        X = self.table_forward(X)\n\n        ind = torch.repeat_interleave(torch.arange(len(X_len)), X_len)\n        tmp = torch.zeros((X_len.shape[0], X.shape[1]))\n        tmp.index_add_(0, ind, X)\n        X = tmp\n\n        # X here is batch size by latent dimension\n\n        forward_cost = F.relu(self.forward_fc_0(X))\n        forward_cost = self.forward_fc_1(forward_cost)\n        forward_cost = forward_cost.flatten()\n\n        # Communication\n        communication_cost = F.relu(self.communication_fc_0(X))\n        communication_cost = self.communication_fc_1(communication_cost)\n        communication_cost = communication_cost.flatten()\n\n        # Backward\n        backward_cost = F.relu(self.backward_fc_0(X))\n        backward_cost = self.backward_fc_1(backward_cost)\n        backward_cost = backward_cost.flatten()\n\n        return forward_cost, communication_cost, backward_cost\n    \n    def _get_diff_opt_latent(self, table_obs):\n        X_len = torch.tensor([[x.shape[0] for x in index_X] for index_X in table_obs])\n        B, D = X_len.shape\n        X_len = X_len.flatten()\n        table_obs = [j for sub in table_obs for j in sub]\n\n        # Get the cost features latent\n        with torch.no_grad():\n            forward_cost, backward_cost, communication_cost = self.kernel_forward(table_obs)\n        cost_obs = torch.cat(\n            (\n                forward_cost.view(B, D, -1).detach(),\n                backward_cost.view(B, D, -1).detach(),\n                communication_cost.view(B, D, -1).detach(),\n            ),\n            dim=-1,\n        )\n        cost_obs = F.relu(self.cost_fc_0(cost_obs))\n        cost_obs = F.relu(self.cost_fc_1(cost_obs))\n\n        # Get the table latent\n        table_obs = torch.cat(table_obs, dim=0)\n        table_obs = self.table_forward_rl(table_obs)\n        return table_obs\n\n    def table_forward(self, X):\n        # X: B x table_feature_dim\n        X = F.relu(self.table_fc_0(X))\n        X = F.relu(self.table_fc_1(X))\n        return X\n\n    def table_forward_rl(self, X):\n        # X: B x table_feature_dim\n        X = F.relu(self.rl_table_fc_0(X))\n        X = F.relu(self.rl_table_fc_1(X))\n        return X\n\n    def get_surrogate_costs(self, env):\n        table_latent_obs = self._get_diff_opt_latent([[torch.stack(env.table_features)]])\n        cost_estimates = self.surrogate_cost_net(table_latent_obs)\n        cost_estimates = torch.sigmoid(cost_estimates)\n        return cost_estimates\n    \n    def get_individual_table_costs(self, env):\n        # returns list of table costs\n        all_costs = []\n        for f in env.table_features:\n            forward_cost, backward_cost, communication_cost = self.kernel_forward([f.unsqueeze(0)])\n            all_costs.append(forward_cost + backward_cost + communication_cost)\n        all_costs = torch.cat(all_costs)\n        return all_costs\n\n    def diff_opt_forward(self, env, use_soft_solution=True, deployment=False):\n        surrogate_costs = self.get_surrogate_costs(env)\n        individual_table_costs = self.get_individual_table_costs(env)\n        # breakpoint()\n        table_sizes = env.table_sizes\n\n        num_tables = len(env.table_features)\n        num_devices = env.ndevices\n        max_memory = env.max_memory\n\n        x = cp.Variable(\n            (num_tables, num_devices),\n            name=\"table_device_assignment\",\n            # nonneg=True,\n            integer=True if deployment else False # explicitly say integer in deployment\n            )\n        z = cp.Variable(name=\"obj\")\n        costs = cp.Parameter((num_tables, num_devices), nonneg=True)\n        individual_costs = cp.Parameter((num_tables), nonneg=True)\n        constraints = [\n            x >= 0, # who knows if nonneg works\n            x <= 1,\n            cp.sum(x, axis=1) == 1,\n            cp.sum(x, axis=0) >= 1,\n            np.array(table_sizes) @ x <= max_memory,\n            # individual_table_costs @ x <= z\n            ]\n        # max latency objective\n        # objective = cp.Minimize(cp.sum(cp.multiply(costs, x)) + cp.max(individual_costs @ x))\n        objective = cp.Minimize(cp.sum(cp.multiply(costs, x)))\n        # squared latency objective\n        # objective = cp.Minimize(cp.sum(cp.multiply(costs, x)) + cp.sum(cp.power(individual_costs @ x, 2)))\n        problem = cp.Problem(objective, constraints)\n\n        cvxpylayer = CvxpyLayer(problem, parameters=[costs, individual_costs], variables=[x])\n\n        # solve the problem\n        solution, = cvxpylayer(surrogate_costs, individual_table_costs)\n\n        # correct some small infeasibilities in assignment\n        soft_assignment = F.relu(solution)\n        soft_assignment = soft_assignment / soft_assignment.sum(axis=1)[:, None]\n        if use_soft_solution:\n            return soft_assignment\n        else:\n            hard_assignment = F.one_hot(torch.argmax(soft_assignment, axis=1), num_classes=num_devices)\n            # use pass through gradient\n            return soft_assignment + (hard_assignment - soft_assignment).detach()\n            # if samples are needed then use this\n            # hard_assignment = torch.multinomial(soft_assignments, 1)\n\n# ==========================================\n# File: table_sharding/dreamshard/sharders.py\n# Function/Context: surco_prior, surco_zero, surco_hybrid\n# ==========================================\nfrom dataclasses import dataclass\nimport numpy as np\n\nfrom dreamshard.utils import allocation2plan, plan2allocation\n\n_sharders = {}\n\n@dataclass\nclass TableInfo:\n    index: int\n    cost: float\n    size: float\n\n    def __lt__(self, o: \"TableInfo\") -> bool:\n        return (self.cost, self.size, self.index) < (o.cost, o.size, o.index)\n\ndef table_size(hash_size, embedding_dim, fp16: bool = False) -> float:\n    gb_size = hash_size * embedding_dim / (1024 * 1024 * 1024)\n    if fp16:\n        gb_size = 2 * gb_size\n    else:\n        gb_size = 4 * gb_size\n    return gb_size\n\ndef register_sharder(sharder_name):\n    def decorate(func):\n        _sharders[sharder_name] = func\n        return func\n    return decorate\n\n# get device indices for tables\n# e.g 8 tables, No. [1,3,5,6] on device 0, No. [2,4,7,8] on device 1, then\n# return [0, 1, 0, 1, 0, 0, 1, 1]\ndef shard(env, alg=\"naive\"):\n    if alg not in _sharders:\n        import sys\n        sys.exit(f\"ERROR: sharder {alg} not found\")\n    return _sharders[alg](env)\n\n@register_sharder(\"surco_prior\")\ndef surco_prior(env, return_plan=False):\n    import torch\n    with torch.no_grad():\n        solution = env.model.opt_forward(env)\n    allocation = []\n    for i in range(env.num_tables):\n        ind = solution[i].argmax().item()\n        allocation.append(ind)\n    if return_plan == True:\n        return plan2allocation(allocation, env.ndevices)\n    else:\n        return allocation\n\n@register_sharder(\"surco_zero\")\ndef surco_zero(env, return_plan=False):\n    solution = env.model.on_the_fly_opt_forward(env, warm_start_surrogate_costs=False)\n    allocation = []\n    for i in range(env.num_tables):\n        ind = solution[i].argmax().item()\n        allocation.append(ind)\n    if return_plan == True:\n        return plan2allocation(allocation, env.ndevices)\n    else:\n        return allocation\n\n@register_sharder(\"surco_hybrid\")\ndef surco_hybrid(env, return_plan=False):\n    solution = env.model.on_the_fly_opt_forward(env, warm_start_surrogate_costs=True)\n    allocation = []\n    for i in range(env.num_tables):\n        ind = solution[i].argmax().item()\n        allocation.append(ind)\n    if return_plan == True:\n        return plan2allocation(allocation, env.ndevices)\n    else:\n        return allocation\n\n# ==========================================\n# File: table_sharding/dreamshard/training.py\n# Function/Context: train_diff_opt\n# ==========================================\nimport os\nfrom pathlib import Path\nimport traceback\nimport time\n\nimport numpy as np\nimport torch\nfrom torch.nn import functional as F\n\nfrom dreamshard.models import Model\nfrom dreamshard.env import Env\nfrom dreamshard.buffer import Buffer\nfrom dreamshard.utils import (\n    load_table_configs_features_sizes,\n    get_table_ids_list,\n)\nfrom dreamshard.utils import allocation2plan\nfrom dreamshard.multi_gpu_bench_interface import Evaluator\n\ndef train_diff_opt(\n    model,\n    envs,\n    optimizer,\n    num_batches,\n    batch_size,\n    entropy_weight,\n    iteration,\n):\n    for batch_id in range(num_batches):\n        optimizer.zero_grad()\n        all_losses = []\n        for episode_id in range(batch_size):\n            task_id = np.random.randint(len(envs))\n            env = envs[task_id]\n            done = False\n            obs, info = env.reset()\n            start_time = time.time()\n            solution = model.diff_opt_forward(env, use_soft_solution=False)\n            # compute reward based on predictive model\n            loss = model.evaluate_solution(solution, env)\n\n            all_losses.append(loss.cpu().detach().numpy()[0])\n\n            loss.backward()\n\n        mean_reward = np.mean(all_losses)\n        optimizer.step()\n        print(\"Diff Opt -->\", str(batch_id+1)+\"/\"+str(num_batches), \"Task ID:\", task_id, \"RL reward:\", mean_reward)\n\n\ndef collect_diff_opt_data(   \n    envs,\n    model,\n    evaluator,\n    buf,\n    steps,\n    iteration,\n    ndevices,\n    random_sample=False,\n):\n    overall_costs = []\n    for bench_id in range(steps):\n        task_id = np.random.randint(len(envs))\n        env = envs[task_id]\n        done = False\n        obs, info = env.reset()\n        with torch.no_grad():\n            solution = env.model.opt_forward(env)\n        allocation = []\n        for i in range(env.num_tables):\n            ind = solution[i].argmax().item()\n            allocation.append(ind)\n        \n        sharding = allocation\n        plan = allocation2plan(sharding, ndevices)\n        \n        max_latency, latency = evaluator.evaluate(task_id, sharding)\n        overall_costs.append(max_latency)\n        plan = allocation2plan(sharding, ndevices)\n        buf.add_overall(plan, max_latency, task_id)\n\n        forward_y = latency[:, 0]\n        communication_y = latency[:, 2]\n        backward_y = latency[:, -1]\n        for i in range(len(plan)):\n            buf.add_kernel(\n                plan[i],\n                forward_y[i],\n                communication_y[i],\n                backward_y[i],\n                task_id,\n            )\n        device_latencies = np.sum(latency, axis=1)\n        max_latency = max(device_latencies)\n        min_latency = min(device_latencies)\n        mean_latency = np.mean(device_latencies)\n        print(\"EVAL -->\", str(bench_id+1)+\"/\"+str(steps), \"Task ID:\", task_id, \"Latency:\", max_latency, \"min latency\", min_latency, \"mean latency\", mean_latency, \"min/max\", min_latency/max_latency)\n    return overall_costs",
  "description": "Combined Analysis:\n- [nonlinear_shortest_path/solve_surco.py]: This file implements the core SurCo algorithm for the nonlinear shortest path problem. The key components are:\n1. DifferentiableShortestPath: A custom PyTorch autograd Function that implements a differentiable surrogate for the combinatorial shortest path problem. The forward pass solves a linear shortest path problem using edge weights (surrogate costs), while the backward pass computes gradients using a perturbation method.\n2. solve_surco_zero: The main training loop that learns linear surrogate costs (edge_weights) to optimize the original nonlinear objective (probability of meeting deadline). It uses gradient descent to update surrogate costs, then solves the linear surrogate problem to obtain combinatorial solutions.\n3. The algorithm follows the SurCo framework: (a) Initialize random surrogate costs, (b) Solve linear surrogate problem (shortest path), (c) Compute nonlinear objective (Gaussian CDF), (d) Backpropagate through surrogate solver, (e) Update surrogate costs via gradient descent.\n4. The implementation directly maps to the paper's methodology: learning linear surrogates for combinatorial nonlinear optimization, using existing combinatorial solvers (shortest path algorithm) as a differentiable layer, and updating surrogates via gradient-based optimization.\n- [table_sharding/dreamshard/models.py]: This file implements the core SurCo algorithm for table sharding. The Model class learns linear surrogate costs ĉ_{t,d} via neural networks (surrogate_cost_net). The diff_opt_forward method formulates the combinatorial optimization problem as a linear program with constraints: (1) each table assigned to exactly one device (cp.sum(x, axis=1) == 1), (2) memory constraints per device (np.array(table_sizes) @ x <= max_memory), (3) binary assignment (x ∈ {0,1}). It uses CvxpyLayer to create a differentiable optimization layer that minimizes the linear surrogate objective cp.sum(cp.multiply(costs, x)). The surrogate costs are learned via gradient descent to minimize the original nonlinear latency function (implemented elsewhere in training). This directly matches the SurCo paper's approach of learning linear surrogates for combinatorial nonlinear optimization.\n- [table_sharding/dreamshard/sharders.py]: This file implements the core inference logic of SurCo for table sharding. The three functions (surco_prior, surco_zero, surco_hybrid) directly map to the SurCo algorithm steps: they use learned linear surrogate costs to solve the combinatorial assignment problem. Specifically:\n1. They call the model's optimization forward pass (opt_forward or on_the_fly_opt_forward) which solves the linear surrogate problem min_x ĉ^⊤ x subject to the table sharding constraints.\n2. The solution is a binary assignment matrix where each table is assigned to exactly one device (satisfying ∑_d x_{t,d} = 1).\n3. The argmax operation extracts the device assignment for each table from the solution matrix.\n4. The memory constraints (∑_t m_t x_{t,d} ≤ M) are handled within the optimization forward pass.\n5. The functions return either an allocation vector or a sharding plan, which represents the binary decision variables x_{t,d}.\nThe implementation assumes the environment (env) provides the problem instance parameters and the trained model provides the surrogate costs and optimization solver.\n- [table_sharding/dreamshard/training.py]: This file implements the core SurCo algorithm for table sharding. The key function train_diff_opt performs differentiable optimization: it calls model.diff_opt_forward to solve the linear surrogate problem (which internally learns linear surrogate costs and uses a combinatorial solver), then computes the loss via model.evaluate_solution using the original nonlinear latency function, and backpropagates to update the surrogate costs. The collect_diff_opt_data function evaluates the current policy by solving the surrogate problem via env.model.opt_forward (which returns a solution matrix where each table is assigned to one device), then measures the actual nonlinear latency using the evaluator. This matches the SurCo paper's three-step algorithm: 1) Learn linear surrogate costs, 2) Solve linear surrogate problem with constraints, 3) Update surrogate costs via gradient descent on the original nonlinear objective.",
  "dependencies": [
    "numpy",
    "dreamshard.multi_gpu_bench_interface.Evaluator",
    "networkx",
    "collections.defaultdict",
    "cvxpy",
    "torch.optim.Adam",
    "torch.nn.functional",
    "dreamshard.buffer.Buffer",
    "dreamshard.utils.allocation2plan",
    "dreamshard.models.Model",
    "dreamshard.utils.plan2allocation",
    "cvxpylayers",
    "torch",
    "torch.autograd.Function",
    "dreamshard.env.Env"
  ]
}