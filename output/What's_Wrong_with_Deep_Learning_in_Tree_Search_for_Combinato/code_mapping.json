{
  "file_path": "solvers/dgl_treesearch/model.py, solvers/dgl_treesearch/treesearch.py",
  "function_name": "GCN, HindsightLoss, _TreeSearch",
  "code_snippet": "\n\n# ==========================================\n# File: solvers/dgl_treesearch/model.py\n# Function/Context: GCN, HindsightLoss\n# ==========================================\nimport torch\nimport torch.nn as nn\nfrom dgl.nn.pytorch import GraphConv\n\nclass GCN(nn.Module):\n    def __init__(self,\n                 in_feats,\n                 n_hidden,\n                 n_classes,\n                 n_layers,\n                 activation,\n                 dropout):\n        super(GCN, self).__init__()\n        self.layers = nn.ModuleList()\n\n        # input layer\n        self.layers.append(GraphConv(in_feats, n_hidden, activation=activation))\n        # hidden layers\n        for i in range(n_layers - 1):\n            self.layers.append(GraphConv(n_hidden, n_hidden, activation=activation))\n        # output layer\n        self.layers.append(GraphConv(n_hidden, n_classes, activation=torch.sigmoid))\n\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, g, features):\n        h = features\n        for i, layer in enumerate(self.layers):\n            if i != 0:\n                h = self.dropout(h)\n            h = layer(g, h)\n        return h\n\nclass HindsightLoss(nn.Module):\n    def __init__(self):\n        super(HindsightLoss, self).__init__()\n        self.ce_func = nn.BCELoss(reduction=\"none\")\n\n    def forward(self, output, labels):\n        probmaps = output.shape[1]\n        _labels = torch.unsqueeze(labels, 0)\n        _labels = _labels.float().repeat(probmaps, 1)\n        output = output.permute(1, 0)\n\n        loss = torch.min(torch.mean(self.ce_func(output, _labels), axis=1))\n        return loss\n\n# ==========================================\n# File: solvers/dgl_treesearch/treesearch.py\n# Function/Context: _TreeSearch\n# ==========================================\nimport numpy as np\nimport time\nimport torch\nimport dgl\nimport gc\nimport sys\nimport copy\nimport pickle\n\nfrom reducelib.reducelib import reducelib\nfrom utils import _load_model, _locked_log\n\nclass _TreeSearch():\n    def __init__(self, pid, num_threads, queue, lock, weight_file, pickle_path, g, time_budget, solution_budget, self_loop, max_prob_maps, model_prob_maps, cuda_devs, reduction, local_search, queue_pruning, noise_as_prob_maps, weighted_queue_pop, optimum_found):\n        self.queue = queue\n        self.num_threads = num_threads\n        self.queue_unlabeled_counts = []\n        self.neighbor_map = dict()\n        self.lock = lock\n        self.weight_file = weight_file\n        self.pickle_path = pickle_path\n        self.g = g\n        self.time_budget = time_budget\n        self.solution_budget = solution_budget\n        self.self_loop = self_loop\n        self.max_prob_maps = max_prob_maps\n        self.model_prob_maps = model_prob_maps\n        self.queue_pruning = queue_pruning\n        self.noise_as_prob_maps = noise_as_prob_maps\n        self.weighted_queue_pop = weighted_queue_pop\n        self.reduction = reduction\n        self.local_search = local_search\n\n        self.cuda = bool(cuda_devs) # use cuda if devices are supplied\n        self.cuda_dev = cuda_devs[pid % len(cuda_devs)] if self.cuda else None\n        self.cuda_devs = cuda_devs\n\n        self.pid = pid\n        self.total_solutions = 0\n        self.best_solution = None\n        self.best_solution_vertices = None\n        self.best_solution_weight = None\n        self.best_solution_time = None\n        self.best_solution_process_time = None\n\n        self.last_status_report = time.monotonic() - 1000\n        self.min_unlabeled = 99999999999\n        self.max_unlabeled = 0\n\n        self.weighted = torch.any(self.g.ndata[\"weight\"] != 1)\n        self.rdlib = reducelib() if reduction or local_search else None \n\n        if isinstance(optimum_found, bool):\n            self.optimum_found = False\n        else:\n            self.optimum_found = optimum_found # Multiprocessing\n\n        self.update_fn1 = lambda nodes: {'ts_label': torch.ones_like(nodes.data['ts_label'])}\n        self.update_fn2 = lambda nodes: {'ts_label': torch.zeros_like(nodes.data['ts_label'])}\n\n        if self.queue_pruning:\n            self.max_queue_length = int(min(self.g.num_nodes() * 10, 16384) / num_threads)\n\n        self.labels_given = \"label\" in self.g.ndata.keys()\n        if self.labels_given:\n            _lbls = self.g.ndata[\"label\"].detach()\n            self.optimal_mwis = torch.sum(self.g.ndata['weight'][_lbls == 1]).item()\n            _locked_log(self.lock, f\"{self.pid}: Labeled graph given. optimal_mwis={self.optimal_mwis}\", \"DEBUG\")\n\n    def run(self):\n        with torch.no_grad():\n            self.start_time = time.monotonic()\n            self.start_process_time = time.process_time()\n            self.load_model()\n            self.prepare_queue()\n            self.generate_neighborhood_map()\n            while time.monotonic() - self.start_time <= self.time_budget:\n                should_break = self.search_step()\n\n                if should_break:\n                    break\n\n        return self.wrap_up()\n\n\n    def search_step(self):\n        if self.should_break():\n            return True\n\n        incomplete_solution = self.pop_incomplete_solution()\n        residual = self.create_residual(incomplete_solution)\n        self.total_solutions += 1\n        \n        if self.reduction:\n            residual, should_return = self.do_reduction(incomplete_solution, residual)\n            if should_return: # reduction might have solved the MIS problem, then we need to stop with the search step here\n                return False\n\n        if not self.noise_as_prob_maps and self.cuda:\n            residual = residual.to(self.cuda_dev)\n\n        out = self.infer_prob_maps(residual)\n        residual = residual.cpu()\n\n        self.explore_solutions(incomplete_solution, residual, out)\n\n        if self.queue_pruning:\n            self.prune_queue()\n\n        del residual\n        del incomplete_solution\n\n        return False\n\n    def explore_solutions(self, incomplete_solution, residual, prob_maps):\n        num_prob_maps = min(prob_maps.shape[1], self.max_prob_maps)\n        solutions_to_append = []\n        # explore all solutions\n        for pmap in range(num_prob_maps):\n            # copy incomplete solution, in order to represent final result\n            result = copy.deepcopy(incomplete_solution).formats(\"coo\")\n\n            _out = prob_maps[:, pmap].cpu().detach().numpy() # this is the current output we care about\n\n            _sorted = np.flip(np.argsort(_out))\n            progress = False\n\n            marked_zero = []\n            marked_one = []\n\n            for v in _sorted:\n                _v = residual.ndata['id_map'][v][0].item() # _v is the _name_ of the vth node of the residual graph, such that we can find the according node in the original graph\n                if _v in marked_zero or _v in marked_one or result.ndata['ts_label'][_v][0].item() > -1:\n                    assert progress # if progress is False, something is wrong with the residual...\n                    break\n                else:\n                    progress = True\n                    marked_one.append(_v)\n                    marked_zero += self.neighbor_map[_v]\n\n            result.apply_nodes(self.update_fn2, v=marked_zero)\n            result.apply_nodes(self.update_fn1, v=marked_one)\n\n            tslabels = result.ndata['ts_label'].detach().squeeze(1)\n            num_unlabeled = torch.sum(tslabels == -1).item()\n\n            self.min_unlabeled = min(num_unlabeled, self.min_unlabeled)\n            self.max_unlabeled = max(num_unlabeled, self.max_unlabeled)\n\n            self.maybe_print_status_report(result)\n\n            if num_unlabeled == 0:\n                self.update_best_solution(result)\n            else:\n                solutions_to_append.append((result, num_unlabeled))\n\n        self.queue.extend(map(lambda x: x[0], solutions_to_append))\n        self.queue_unlabeled_counts.extend(map(lambda x: x[1], solutions_to_append))\n\n    def load_model(self):\n        self.model = _load_model(self.model_prob_maps, weight_file=self.weight_file, cuda_dev=self.cuda_dev)\n        self.model.eval()\n\n    def prepare_queue(self):\n        ### Prepare Queue ###\n        if self.queue is not None:\n            _locked_log(self.lock, f\"{self.pid}: Starting with queue of length {len(self.queue)}\", \"DEBUG\")\n        else:\n            self.queue = []\n            # Starting queue is empty, hence we need to push a first graph into it\n            if self.g is None:\n                raise ValueError(\"Cannot start with empty queue and no start graph\")\n\n            self.g = self.g.cpu().formats(\"coo\")\n\n            # initialize attribute\n            self.g.ndata['ts_label'] = torch.tensor(np.full((self.g.num_nodes(), 1), -1), dtype=torch.int8)\n            self.g.ndata['id_map'] = torch.tensor(np.arange(self.g.num_nodes()).reshape((self.g.num_nodes(),1)), dtype=torch.int32)\n\n            # we fix self loops before pushing in the queue, so we don't need to do it for every residual\n            if self.self_loop:\n                self.g = dgl.remove_self_loop(self.g)\n                self.g = dgl.add_self_loop(self.g)\n            else:\n                self.g = dgl.remove_self_loop(self.g)\n\n            self.queue.append(self.g)\n\n        # Precompute unlabeled vertex counts\n        for result in self.queue:\n            tslabels = result.ndata['ts_label'].detach().squeeze(1)\n            self.queue_unlabeled_counts.append(torch.sum(tslabels == -1).item())\n\n    def generate_neighborhood_map(self):\n        ### create neighborhood map ###\n        _locked_log(self.lock, f\"{self.pid}: Generating neighborhood map\", \"DEBUG\")\n\n        for v in self.g.nodes():\n            _v = v.item()\n            self.neighbor_map[_v] = torch.cat((self.g.predecessors(_v), self.g.successors(_v))).tolist()\n\n        _locked_log(self.lock, f\"{self.pid}: Map generated\", \"DEBUG\")\n\n    def should_break(self):\n        if isinstance(self.optimum_found, bool):\n            opt_found = self.optimum_found\n        else:\n            opt_found = self.optimum_found.value\n\n        if opt_found:\n            _locked_log(self.lock, f\"{self.pid}:  Process is exiting, as optimum has been found in some thread\", \"INFO\")\n            return True\n\n        if len(self.queue) == 0:\n            _locked_log(self.lock, f\"{self.pid}: Process is exiting, due to empty queue\", \"INFO\")\n            return True\n\n        if self.solution_budget and self.total_solutions > self.solution_budget:\n            _locked_log(self.lock, f\"{self.pid}: Process is exiting, due to exhausted solution budget\", \"DEBUG\")\n            return True\n\n        return False\n\n    def pop_incomplete_solution(self):\n        if self.weighted_queue_pop:\n            nu = np.array(self.queue_unlabeled_counts)\n            unnormalized_pop_p = 1 / nu\n            pop_p = unnormalized_pop_p / unnormalized_pop_p.sum() # distribution summing up to 1\n        else:\n            pop_p = 1 / np.full(len(self.queue), len(self.queue))\n\n        queue_choice = np.random.choice(np.arange(len(self.queue)), p=pop_p)\n        incomplete_solution = self.queue.pop(queue_choice)\n        self.queue_unlabeled_counts.pop(queue_choice)\n\n        return incomplete_solution\n\n    def create_residual(self, incomplete_solution):\n        residual = copy.deepcopy(incomplete_solution).formats(\"coo\")\n        to_remove = residual.filter_nodes(lambda nodes: (nodes.data['ts_label'] != -1).squeeze(1))\n        residual.remove_nodes(to_remove)\n\n        return residual\n\n    def do_reduction(self, incomplete_solution, residual):\n        if self.weighted:\n            _, reduction_result = self.rdlib.weighted_reduce_graph(residual)\n        else:\n            _, reduction_result = self.rdlib.unweighted_reduce_graph(residual)\n\n        marked_zero_residual_ids = np.ravel(np.argwhere(reduction_result == 1)) # KaMIS output is inverted\n        marked_one_residual_ids = np.ravel(np.argwhere(reduction_result == 0))\n\n        # if the reduction did stuff\n        if marked_zero_residual_ids.shape[0] > 0 or marked_one_residual_ids.shape[0] > 0:\n            # map residual vertex ids to original graph vertex ids\n            marked_zero = list(map(lambda x: residual.ndata['id_map'][x][0].item(), marked_zero_residual_ids))\n            marked_one = list(map(lambda x: residual.ndata['id_map'][x][0].item(), marked_one_residual_ids))\n\n            for v in marked_one:\n                marked_zero.extend(self.neighbor_map[v])\n\n            marked_zero = np.array(marked_zero)\n            marked_one = np.array(marked_one)\n\n            # Update incomplete solution\n            incomplete_solution.apply_nodes(self.update_fn2, v=marked_zero)\n            incomplete_solution.apply_nodes(self.update_fn1, v=marked_one)\n\n            # Check if reduction solved MIS\n            tslabels = incomplete_solution.ndata['ts_label'].detach().squeeze(1)\n            num_unlabeled = torch.sum(tslabels == -1).item()\n\n            if num_unlabeled == 0:\n                self.update_best_solution(incomplete_solution)\n                return None, True\n\n            # recreate residual graph based on new information\n            residual = self.create_residual(incomplete_solution)\n\n        return residual, False\n\n    def update_best_solution(self, labeled_graph):\n        if self.local_search and self.rdlib is not None:\n            if self.weighted:\n                ls_result = self.rdlib.weighted_local_search(labeled_graph)\n            else:\n                ls_result = self.rdlib.unweighted_local_search(labeled_graph)\n\n            labeled_graph.ndata['ts_label'] = torch.tensor(ls_result, dtype=torch.int8).unsqueeze(1)\n\n        tslabels = labeled_graph.ndata['ts_label'].detach().squeeze(1)\n        num_mis = torch.sum(tslabels == 1).item()\n\n        if num_mis > 0:\n            mis_vertices = labeled_graph.ndata['id_map'][(tslabels == 1)].to(torch.long)\n            mis_weight = torch.sum(labeled_graph.ndata['weight'][mis_vertices].to(torch.float32)).item()\n\n            if (self.best_solution is None) or (self.best_solution_weight < mis_weight):\n                _locked_log(self.lock, f\"{self.pid}: Found new Maximum {'Weighted' if self.weighted else ''} Independent Set with n = {num_mis} and weight = {mis_weight}\", \"INFO\")\n                self.best_solution = mis_vertices.detach().numpy()\n                self.best_solution_vertices = num_mis\n                self.best_solution_weight = mis_weight\n                self.best_solution_time = time.monotonic() - self.start_time\n                self.best_solution_process_time = time.process_time() - self.start_process_time\n                if self.labels_given and self.best_solution_weight >= self.optimal_mwis:\n                    _locked_log(self.lock, f\"{self.pid}: Found optimal solution.\", \"INFO\")\n                    if isinstance(self.optimum_found, bool):\n                        self.optimum_found = True\n                    else:\n                        with self.lock:\n                            self.optimum_found.value = True\n\n        else:\n            _locked_log(self.lock, f\"{self.pid}: Labeled all vertices in this graph as not belonging to MIS, something is off. Ignoring.\", \"WARNING\")\n\n    def infer_prob_maps(self, residual):\n        features = residual.ndata['weight']\n        if not self.noise_as_prob_maps:\n            # actual model inference\n            out = self.model(residual, features)\n        else:\n            # Replace GNN output probability maps with random noise\n            out = torch.rand(features.shape[0], self.max_prob_maps)\n        return out\n\n    def maybe_print_status_report(self, result):\n        if time.monotonic() - self.last_status_report > 15:\n            _locked_log(self.lock, f\"{self.pid}: Cuda Device={self.cuda_dev} (out of {self.cuda_devs}). Currently {self.min_unlabeled}/{len(list(result.nodes()))} vertices are unlabeled in the best solution, and {self.max_unlabeled}/{len(list(result.nodes()))} are unlabeled in the worst solution. We have {len(self.queue)} solutions in the queue. The queue is {sys.getsizeof(self.queue)} big. Time spent: {time.monotonic() - self.start_time}. Max Prob Maps = {self.max_prob_maps}. Total solutions done = {self.total_solutions}\", \"INFO\")\n            self.last_status_report = time.monotonic()\n            gc.collect()\n\n    def prune_queue(self):\n        while len(self.queue) > self.max_queue_length:\n            g = self.queue.pop(0)\n            del g\n            self.queue_unlabeled_counts.pop(0)\n\n\n    def wrap_up(self):\n        _locked_log(self.lock,f\"{self.pid}: Wrapping up\", \"INFO\")\n\n        if self.pickle_path:\n            _locked_log(self.lock,f\"{self.pid}: Saving result\", \"DEBUG\")\n            with open(self.pickle_path / f\"{self.pid}.pickle\", 'wb') as f:\n                results = { \n                    \"total_solutions\": self.total_solutions,\n                    \"mis_vertices\": self.",
  "description": "Combined Analysis:\n- [solvers/dgl_treesearch/model.py]: This file implements the core Graph Convolutional Network (GCN) model and the HindsightLoss function used in the DGL-TreeSearch algorithm for the Maximum Independent Set problem. The GCN is a key component that predicts vertex probabilities for inclusion in the independent set, guiding the tree search. The HindsightLoss is a specialized loss function for training the GCN in a supervised manner. While this file does not directly implement the full tree search algorithm or the mathematical optimization constraints, it provides the neural network backbone that drives the learning-based search strategy described in the paper.\n- [solvers/dgl_treesearch/treesearch.py]: This file implements the core tree search algorithm for the Maximum (Weighted) Independent Set problem as described in the paper. The _TreeSearch class encapsulates the entire search process, including: 1) Loading a pre-trained GCN model to predict vertex probabilities, 2) Maintaining a queue of partial solutions, 3) Iteratively expanding solutions by selecting vertices based on predicted probabilities (greedy assignment), 4) Applying reduction rules and local search from KaMIS, 5) Enforcing the independent set constraint via neighbor exclusion. The algorithm directly corresponds to the tree search approach using GCN guidance, with key steps like residual graph creation, probability inference, and solution exploration implementing the paper's described methodology.",
  "dependencies": [
    "reducelib.reducelib.reducelib",
    "numpy",
    "copy",
    "dgl.nn.pytorch.GraphConv",
    "utils._load_model",
    "utils._locked_log",
    "pickle",
    "sys",
    "torch.nn",
    "dgl",
    "gc",
    "torch",
    "time"
  ]
}