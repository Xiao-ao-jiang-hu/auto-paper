{
  "file_path": "src/astar_genn.py, src/hungarian_ged.py, src/priority_queue.hpp",
  "function_name": "GENN.forward, GENN.net_prediction, GENN.node_metric, hungarian_ged, TreeNode struct and tree_node_priority_queue type alias",
  "code_snippet": "\n\n# ==========================================\n# File: src/astar_genn.py\n# Function/Context: GENN.forward, GENN.net_prediction, GENN.node_metric\n# ==========================================\nimport time\nimport torch\nimport random\nimport numpy as np\nimport torch.nn.functional as F\nfrom tqdm import tqdm, trange\nfrom scipy.stats import spearmanr, kendalltau\nfrom itertools import combinations\n\nfrom src.layers import AttentionModule, TensorNetworkModule, Block, DiffPool\nfrom src.utils import calculate_ranking_correlation, calculate_prec_at_k\nfrom src.hungarian_ged import hungarian_ged\n\nfrom torch_geometric.nn import GCNConv, GINConv, SplineConv\nfrom torch_geometric.data import DataLoader, Data, Batch\nfrom torch_geometric.utils import to_dense_batch, to_dense_adj, degree, dense_to_sparse, subgraph\nfrom torch_geometric.transforms import OneHotDegree, Constant\n\nfrom src.a_star import a_star\n\nVERY_LARGE_INT = 65536\nPRINT_TIMING = False\n\nclass GENN(torch.nn.Module):\n    def __init__(self, args, number_of_labels):\n        \"\"\"\n        :param args: Arguments object.\n        :param number_of_labels: Number of node labels.\n        \"\"\"\n        super(GENN, self).__init__()\n        self.args = args\n        self.number_labels = number_of_labels\n        self.setup_layers()\n        self.enable_a_star = self.args.enable_astar\n        if self.enable_a_star:\n            self.gnn_1_cache = dict()\n            self.gnn_2_cache = dict()\n            self.heuristic_cache = dict()\n\n    def forward(self, data):\n        \"\"\"\n        Forward pass with graphs.\n        :param data: Data dictionary.\n        :return score: Similarity score.\n        \"\"\"\n        device = next(self.parameters()).device\n\n        edge_index_1 = data[\"g1\"].edge_index\n        edge_index_2 = data[\"g2\"].edge_index\n        if hasattr(data[\"g1\"], 'edge_attr') and hasattr(data[\"g2\"], 'edge_attr'):\n            edge_attr_1 = data[\"g1\"].edge_attr\n            edge_attr_2 = data[\"g2\"].edge_attr\n        else:\n            edge_attr_1 = None\n            edge_attr_2 = None\n        node_1 = data[\"g1\"].x\n        node_2 = data[\"g2\"].x\n        batch_1 = data[\"g1\"].batch if hasattr(data[\"g1\"], 'batch') else torch.tensor((), dtype=torch.long).new_zeros(data[\"g1\"].num_nodes)\n        batch_2 = data[\"g2\"].batch if hasattr(data[\"g2\"], 'batch') else torch.tensor((), dtype=torch.long).new_zeros(data[\"g2\"].num_nodes)\n\n        batch_num = data[\"g1\"].num_graphs\n\n        ns_1 = torch.bincount(data[\"g1\"].batch)\n        ns_2 = torch.bincount(data[\"g2\"].batch)\n\n        adj_1 = to_dense_adj(edge_index_1, batch=batch_1, edge_attr=edge_attr_1)\n        dummy_adj_1 = torch.zeros(adj_1.shape[0], adj_1.shape[1] + 1, adj_1.shape[2] + 1, device=device)\n        dummy_adj_1[:, :-1, :-1] = adj_1\n        adj_2 = to_dense_adj(edge_index_2, batch=batch_2, edge_attr=edge_attr_2)\n        dummy_adj_2 = torch.zeros(adj_2.shape[0], adj_2.shape[1] + 1, adj_2.shape[2] + 1, device=device)\n        dummy_adj_2[:, :-1, :-1] = adj_2\n\n        node_1, _ = to_dense_batch(node_1, batch=batch_1)\n        node_2, _ = to_dense_batch(node_2, batch=batch_2)\n\n        dummy_node_1 = torch.zeros(adj_1.shape[0], node_1.shape[1] + 1, node_1.shape[-1], device=device)\n        dummy_node_1[:, :-1, :] = node_1\n        dummy_node_2 = torch.zeros(adj_2.shape[0], node_2.shape[1] + 1, node_2.shape[-1], device=device)\n        dummy_node_2[:, :-1, :] = node_2\n\n        k_diag = self.node_metric(dummy_node_1, dummy_node_2)\n\n        mask_1 = torch.zeros_like(dummy_adj_1)\n        mask_2 = torch.zeros_like(dummy_adj_2)\n        for b in range(batch_num):\n            mask_1[b, :ns_1[b] + 1, :ns_1[b] + 1] = 1\n            mask_1[b, :ns_1[b], :ns_1[b]] -= torch.eye(ns_1[b], device=mask_1.device)\n            mask_2[b, :ns_2[b] + 1, :ns_2[b] + 1] = 1\n            mask_2[b, :ns_2[b], :ns_2[b]] -= torch.eye(ns_2[b], device=mask_2.device)\n\n        a1 = dummy_adj_1.reshape(batch_num, -1, 1)\n        a2 = dummy_adj_2.reshape(batch_num, 1, -1)\n        m1 = mask_1.reshape(batch_num, -1, 1)\n        m2 = mask_2.reshape(batch_num, 1, -1)\n        k = torch.abs(a1 - a2) * torch.bmm(m1, m2)\n        k[torch.logical_not(torch.bmm(m1, m2).to(dtype=torch.bool))] = VERY_LARGE_INT\n        k = k.reshape(batch_num, dummy_adj_1.shape[1], dummy_adj_1.shape[2], dummy_adj_2.shape[1], dummy_adj_2.shape[2])\n        k = k.permute([0, 1, 3, 2, 4])\n        k = k.reshape(batch_num, dummy_adj_1.shape[1] * dummy_adj_2.shape[1], dummy_adj_1.shape[2] * dummy_adj_2.shape[2])\n        k = k / 2\n\n        for b in range(batch_num):\n            k_diag_view = torch.diagonal(k[b])\n            k_diag_view[:] = k_diag[b].reshape(-1)\n\n        if self.enable_a_star:\n            self.reset_cache()\n            start = time.process_time()\n            x_pred, tree_size = a_star(\n                data, k, ns_1.cpu().numpy(), ns_2.cpu().numpy(),\n                self.net_prediction_cache,\n                self.heuristic_prediction_hun,\n                net_pred=self.args.astar_use_net,\n                beam_width=self.args.astar_beamwidth,\n                trust_fact=self.args.astar_trustfact,\n                no_pred_size=self.args.astar_nopred,\n            )\n            time_spent = time.process_time() - start\n            # x_pred = self.a_star(data, k, ns_1.numpy(), ns_2.numpy(), beam_width=0, trust_fact=1.)\n            ged = self.comp_ged(x_pred, k)\n\n            if self.training:\n                scores, sup_scores = [], []\n                x_pred = x_pred[0]\n                for matched_len in range(1, torch.sum(x_pred).to(torch.long)+1):\n                    for matched_pairs in combinations(torch.nonzero(x_pred, as_tuple=False), matched_len):\n                        partial_x = x_pred.clone()\n                        for r, c in matched_pairs:\n                            partial_x[r, c] = 0\n                        if partial_x[:-1, :].sum() == ns_1[0] or partial_x[:, :-1].sum() == ns_2[0]:\n                            continue\n                        score = self.net_prediction_cache(data, partial_pmat=partial_x, return_ged_norm=True)\n                        g_p = self.comp_ged(partial_x, k[0])\n                        h_p = ged - g_p\n                        n1plsn2 = ns_1[0] + ns_2[0] - partial_x[:-1, :].sum() - partial_x[:, :-1].sum()\n                        sup_score = torch.exp(- h_p * 2 / n1plsn2)\n                        scores.append(score)\n                        sup_scores.append(sup_score)\n                return torch.cat(scores), torch.cat(sup_scores)\n            else:\n                norm_ged = ged * 2 / (ns_1 + ns_2).to(device)\n                return torch.exp(-norm_ged), torch.tensor(tree_size), time_spent\n        else:\n            return self.net_prediction(data, return_ged_norm=True)\n\n    def node_metric(self, node1, node2):\n        if 'AIDS' in self.args.dataset:\n            encoding = torch.sum(torch.abs(node1[:, :, :29].unsqueeze(2) - node2[:, :, :29].unsqueeze(1)), dim=-1).to(dtype=torch.long)\n            mapping = torch.Tensor([0, 1, 1])\n        elif self.args.dataset in ['Willow']:\n            encoding = torch.sum(torch.abs(node1[:, :, :].unsqueeze(2) - node2[:, :, :].unsqueeze(1)), dim=-1).to(dtype=torch.long)\n            mapping = torch.Tensor([0, VERY_LARGE_INT, 0])\n        else:\n            encoding = torch.sum(torch.abs(node1.unsqueeze(2) - node2.unsqueeze(1)), dim=-1).to(dtype=torch.long)\n            mapping = torch.Tensor([0, 1, 0])\n        return mapping[encoding]\n\n    def net_prediction(self, data, batch_idx=None, partial_pmat=None, cur_idx=None, return_ged_norm=False):\n        \"\"\"\n        Forward pass with graphs.\n        :param data: Data dictionary.\n        :return score: Similarity score.\n        \"\"\"\n        start000 = time.process_time()\n        edge_index_1 = data[\"g1\"].edge_index\n        edge_index_2 = data[\"g2\"].edge_index\n        if hasattr(data[\"g1\"], 'edge_attr') and hasattr(data[\"g2\"], 'edge_attr'):\n            edge_attr_1 = data[\"g1\"].edge_attr\n            edge_attr_2 = data[\"g2\"].edge_attr\n        else:\n            edge_attr_1 = None\n            edge_attr_2 = None\n        features_1 = data[\"g1\"].x\n        features_2 = data[\"g2\"].x\n        batch_1 = data[\"g1\"].batch\n        batch_2 = data[\"g2\"].batch\n\n        if self.enable_a_star:\n            assert partial_pmat is not None\n            assert torch.all(batch_1 == 0)\n            assert torch.all(batch_2 == 0)\n\n            start = time.process_time()\n            graph_1_mask = torch.ones_like(batch_1)\n            graph_2_mask = torch.ones_like(batch_2)\n            if PRINT_TIMING: print('create graph_mask', time.process_time() - start)\n\n            start = time.process_time()\n            graph_1_matched = partial_pmat.sum(dim=-1).to(dtype=torch.bool)[:graph_1_mask.shape[0]]\n            graph_2_matched = partial_pmat.sum(dim=-2).to(dtype=torch.bool)[:graph_2_mask.shape[0]]\n            if PRINT_TIMING: print('graph_matched', time.process_time() - start)\n\n            start = time.process_time()\n            graph_1_mask = torch.logical_not(graph_1_matched)\n            graph_2_mask = torch.logical_not(graph_2_matched)\n            if PRINT_TIMING: print('graph_mask', time.process_time() - start)\n\n            start = time.process_time()\n            edge_index_1, edge_attr_1 = subgraph(graph_1_mask, edge_index_1, edge_attr_1, relabel_nodes=True)\n            edge_index_2, edge_attr_2 = subgraph(graph_2_mask, edge_index_2, edge_attr_2, relabel_nodes=True)\n            if PRINT_TIMING: print('subgraph', time.process_time() - start)\n\n            start = time.process_time()\n            features_1 = features_1[graph_1_mask]\n            features_2 = features_2[graph_2_mask]\n\n            batch_1 = batch_1[graph_1_mask]\n            batch_2 = batch_2[graph_2_mask]\n            if PRINT_TIMING: print('features[mask], batch[mask]', time.process_time() - start)\n\n# ==========================================\n# File: src/hungarian_ged.py\n# Function/Context: hungarian_ged\n# ==========================================\nimport torch\nfrom src.hungarian import hungarian\n\ndef hungarian_ged(node_cost_mat, n1, n2):\n    assert node_cost_mat.shape[-2] == n1+1\n    assert node_cost_mat.shape[-1] == n2+1\n    device = node_cost_mat.device\n    upper_left = node_cost_mat[:n1, :n2]\n    upper_right = torch.full((n1, n1), float('inf'), device=device)\n    torch.diagonal(upper_right)[:] = node_cost_mat[:-1, -1]\n    lower_left = torch.full((n2, n2), float('inf'), device=device)\n    torch.diagonal(lower_left)[:] = node_cost_mat[-1, :-1]\n    lower_right = torch.zeros((n2, n1), device=device)\n\n    large_cost_mat = torch.cat((torch.cat((upper_left, upper_right), dim=1),\n                                torch.cat((lower_left, lower_right), dim=1)), dim=0)\n\n    large_pred_x = hungarian(-large_cost_mat)\n    pred_x = torch.zeros_like(node_cost_mat)\n    pred_x[:n1, :n2] = large_pred_x[:n1, :n2]\n    pred_x[:-1, -1] = torch.sum(large_pred_x[:n1, n2:], dim=1)\n    pred_x[-1, :-1] = torch.sum(large_pred_x[n1:, :n2], dim=0)\n\n    ged_lower_bound = torch.sum(pred_x * node_cost_mat)\n\n    return pred_x, ged_lower_bound\n\n# ==========================================\n# File: src/priority_queue.hpp\n# Function/Context: TreeNode struct and tree_node_priority_queue type alias\n# ==========================================\n#include <functional>\n#include <queue>\n\nstruct TreeNode\n{\n    std::pair<std::vector<long>, std::vector<long> > x_indices;\n    double gplsh;\n    long idx;\n    TreeNode();\n    TreeNode(const int &);\n    TreeNode(const std::pair<std::vector<long>, std::vector<long> > &, const double &, const long &);\n    bool operator>(const TreeNode &) const;\n};\n\nTreeNode::TreeNode()\n{\n    this->x_indices = std::pair<std::vector<long>, std::vector<long> >();\n    this->gplsh = 0;\n    this->idx = 0;\n}\n\nTreeNode::TreeNode(const int & len)\n{\n    this->x_indices = std::pair<std::vector<long>, std::vector<long> >(std::vector<long>(len), std::vector<long>(len));\n    this->gplsh = 0;\n    this->idx = 0;\n}\n\nTreeNode::TreeNode(const std::pair<std::vector<long>, std::vector<long> > &x_indices, const double &gplsh, const long &idx)\n{\n    this->x_indices = x_indices;\n    this->gplsh = gplsh;\n    this->idx = idx;\n}\n\nbool TreeNode::operator>(const TreeNode &c) const\n{\n    return this->gplsh > c.gplsh;\n}\n\nusing tree_node_priority_queue = std::priority_queue<TreeNode, std::vector<TreeNode>, std::greater<TreeNode> >;",
  "description": "Combined Analysis:\n- [src/astar_genn.py]: This file implements the core integration of Graph Edit Neural Network (GENN) with A* search for Graph Edit Distance. The GENN class provides dynamic embeddings and heuristic predictions during A* search. Key components: 1) The forward method constructs the edit cost matrix and calls A* with neural network heuristics, 2) The net_prediction method dynamically computes embeddings for subgraphs during search, 3) The node_metric computes node substitution costs. The implementation matches the paper's algorithm of using learned heuristics to guide A* search while caching embeddings for efficiency.\n- [src/hungarian_ged.py]: This file implements a key component of the GED optimization model: the Hungarian algorithm for computing a lower bound on graph edit distance. The function constructs an extended cost matrix that includes node substitutions (upper-left block), node deletions (upper-right diagonal), and node insertions (lower-left diagonal), then solves the assignment problem using the Hungarian algorithm. This provides a heuristic lower bound for the A* search algorithm, which is crucial for the paper's approach of accelerating GED computation. While not the complete GENN-A* algorithm, it implements the traditional heuristic that the paper's learned approach aims to improve upon.\n- [src/priority_queue.hpp]: This file implements the core priority queue data structure for the A* search algorithm used in GENN-A*. The TreeNode struct represents a search node in the A* algorithm with: 1) x_indices - a pair of vectors encoding partial node assignments between source and target graphs (representing the current edit path), 2) gplsh - the f-score (g + h) where g is the actual cost of the partial edit path and h is the heuristic prediction from GENN, 3) idx - an identifier. The operator> enables comparison based on f-score for priority queue ordering. The tree_node_priority_queue is a min-heap that always expands the node with the smallest f-score, which is essential for A* search efficiency. This directly implements the algorithmic step of maintaining and expanding the frontier in the A* search for optimal edit paths.",
  "dependencies": [
    "src.hungarian_ged",
    "C++ Standard Library: <functional>",
    "src.utils",
    "std::pair",
    "std::vector",
    "time",
    "torch_geometric.nn",
    "src.a_star",
    "torch.nn.functional",
    "tqdm",
    "torch_geometric.data",
    "torch_geometric.transforms",
    "C++ Standard Library: <queue>",
    "std::greater",
    "src.layers",
    "numpy",
    "torch_geometric.utils",
    "std::priority_queue",
    "torch",
    "scipy.stats",
    "src.hungarian.hungarian",
    "itertools"
  ]
}