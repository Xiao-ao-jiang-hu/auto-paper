{
  "paper_id": "A_Deep_Reinforcement_Learning_Framework_For_Column_Generatio",
  "title": "A Deep Reinforcement Learning Framework for Column Generation",
  "abstract": "Column Generation (CG) is an iterative algorithm for solving linear programs (LPs) with an extremely large number of variables (columns). CG is the workhorse for tackling large-scale integer linear programs, which rely on CG to solve LP relaxations within a branch and price algorithm. Two canonical applications are the Cutting Stock Problem (CSP) and Vehicle Routing Problem with Time Windows (VRPTW). In VRPTW, for example, each binary variable represents the decision to include or exclude a route, of which there are exponentially many; CG incrementally grows the subset of columns being used, ultimately converging to an optimal solution. We propose RLCG, the first Reinforcement Learning (RL) approach for CG. Unlike typical column selection rules which myopically select a column based on local information at each iteration, we treat CG as a sequential decision-making problem: the column selected in a given iteration affects subsequent column selections. This perspective lends itself to a Deep Reinforcement Learning approach that uses Graph Neural Networks (GNNs) to represent the variable-constraint structure in the LP of interest. We perform an extensive set of experiments using the publicly available BPPLIB benchmark for CSP and Solomon benchmark for VRPTW. RLCG converges faster and reduces the number of CG iterations by 22.4% for CSP and 40.9% for VRPTW on average compared to a commonly used greedy policy.",
  "problem_description_natural": "The paper addresses the acceleration of the Column Generation (CG) algorithm, which solves large-scale linear programs with exponentially many variables (columns). In problems like the Cutting Stock Problem (CSP) and the Vehicle Routing Problem with Time Windows (VRPTW), explicitly enumerating all variables is infeasible. CG iteratively adds promising columns (variables) to a Restricted Master Problem (RMP) by solving a sub-problem that identifies columns with negative reduced cost. The goal is to reach an optimal LP solution in as few iterations as possible. The authors propose replacing the standard greedy column selection (which picks the column with the most negative reduced cost) with a reinforcement learning agent that learns to select columns strategically over the sequence of CG iterations to minimize total convergence time.",
  "problem_type": "Linear Programming (LP) with exponentially many variables, solved via Column Generation; embedded within Branch-and-Price for Integer Linear Programming (ILP)",
  "datasets": [
    "BPPLIB",
    "Solomon benchmark"
  ],
  "performance_metrics": [
    "Number of iterations for CG to converge",
    "Time in seconds"
  ],
  "lp_model": {
    "objective": "$\\min \\sum_{p \\in \\mathcal{P}} \\lambda_p$",
    "constraints": [
      "$\\sum_{p \\in \\mathcal{P}} x_{ip} \\lambda_p = d_i \\quad \\forall i \\in \\{1,\\ldots,n\\}$",
      "$\\lambda_p \\in \\mathbb{N} \\quad \\forall p \\in \\mathcal{P}$"
    ],
    "variables": [
      "$\\lambda_p$: integer variable representing the number of times pattern $p$ is used, for each $p \\in \\mathcal{P}$",
      "$x_{ip}$: parameter indicating the number of cuts of type $i$ in pattern $p$, defined for feasible patterns in $\\mathcal{P}$"
    ]
  },
  "raw_latex_model": "$$ \\min_{\\lambda \\in \\mathbb{N}^{|\\mathcal{P}|}} \\left\\{ \\sum_{p \\in \\mathcal{P}} \\lambda_p : \\sum_{p \\in \\mathcal{P}} x_{ip} \\lambda_p = d_i \\; \\forall i \\in \\{1,2,\\ldots,n\\} \\right\\}, $$ where $\\mathcal{P} = \\left\\{ x_k \\in \\mathbb{N}^n : \\sum_{i=1}^{n} a_i x_{ik} \\leq L, x_{ik} \\geq 0 \\quad \\forall i \\in \\{1,2,\\ldots,n\\}, \\forall k \\in \\{1,2,\\ldots,|\\mathcal{P}|\\} \\right\\}$.",
  "algorithm_description": "Deep Reinforcement Learning framework (RLCG) using Graph Neural Networks as Q-function approximators to learn a column selection policy for Column Generation, applied to solve linear program relaxations of the Cutting Stock Problem and Vehicle Routing Problem with Time Windows, aiming to minimize the number of iterations for convergence."
}