{
  "file_path": "BB_GM/model.py",
  "function_name": "Net.forward",
  "code_snippet": "\n\n# ==========================================\n# File: BB_GM/model.py\n# Function/Context: Net.forward\n# ==========================================\nimport torch\n\nimport utils.backbone\nfrom BB_GM.affinity_layer import InnerProductWithWeightsAffinity\nfrom BB_GM.sconv_archs import SiameseSConvOnNodes, SiameseNodeFeaturesToEdgeFeatures\nfrom lpmp_py import GraphMatchingModule\nfrom lpmp_py import MultiGraphMatchingModule\nfrom utils.config import cfg\nfrom utils.feature_align import feature_align\nfrom utils.utils import lexico_iter\nfrom utils.visualization import easy_visualize\n\n\ndef normalize_over_channels(x):\n    channel_norms = torch.norm(x, dim=1, keepdim=True)\n    return x / channel_norms\n\n\ndef concat_features(embeddings, num_vertices):\n    res = torch.cat([embedding[:, :num_v] for embedding, num_v in zip(embeddings, num_vertices)], dim=-1)\n    return res.transpose(0, 1)\n\n\nclass Net(utils.backbone.VGG16_bn):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.message_pass_node_features = SiameseSConvOnNodes(input_node_dim=1024)\n        self.build_edge_features_from_node_features = SiameseNodeFeaturesToEdgeFeatures(\n            total_num_nodes=self.message_pass_node_features.num_node_features\n        )\n        self.global_state_dim = 1024\n        self.vertex_affinity = InnerProductWithWeightsAffinity(\n            self.global_state_dim, self.message_pass_node_features.num_node_features)\n        self.edge_affinity = InnerProductWithWeightsAffinity(\n            self.global_state_dim,\n            self.build_edge_features_from_node_features.num_edge_features)\n\n    def forward(\n        self,\n        images,\n        points,\n        graphs,\n        n_points,\n        perm_mats,\n        visualize_flag=False,\n        visualization_params=None,\n    ):\n\n        global_list = []\n        orig_graph_list = []\n        for image, p, n_p, graph in zip(images, points, n_points, graphs):\n            # extract feature\n            nodes = self.node_layers(image)\n            edges = self.edge_layers(nodes)\n\n            global_list.append(self.final_layers(edges)[0].reshape((nodes.shape[0], -1)))\n            nodes = normalize_over_channels(nodes)\n            edges = normalize_over_channels(edges)\n\n            # arrange features\n            U = concat_features(feature_align(nodes, p, n_p, (256, 256)), n_p)\n            F = concat_features(feature_align(edges, p, n_p, (256, 256)), n_p)\n            node_features = torch.cat((U, F), dim=-1)\n            graph.x = node_features\n\n            graph = self.message_pass_node_features(graph)\n            orig_graph = self.build_edge_features_from_node_features(graph)\n            orig_graph_list.append(orig_graph)\n\n        global_weights_list = [\n            torch.cat([global_src, global_tgt], axis=-1) for global_src, global_tgt in lexico_iter(global_list)\n        ]\n        global_weights_list = [normalize_over_channels(g) for g in global_weights_list]\n\n        unary_costs_list = [\n            self.vertex_affinity([item.x for item in g_1], [item.x for item in g_2], global_weights)\n            for (g_1, g_2), global_weights in zip(lexico_iter(orig_graph_list), global_weights_list)\n        ]\n\n        # Similarities to costs\n        unary_costs_list = [[-x for x in unary_costs] for unary_costs in unary_costs_list]\n\n        if self.training:\n            unary_costs_list = [\n                [\n                    x + 1.0*gt[:dim_src, :dim_tgt]  # Add margin with alpha = 1.0\n                    for x, gt, dim_src, dim_tgt in zip(unary_costs, perm_mat, ns_src, ns_tgt)\n                ]\n                for unary_costs, perm_mat, (ns_src, ns_tgt) in zip(unary_costs_list, perm_mats, lexico_iter(n_points))\n            ]\n\n        quadratic_costs_list = [\n            self.edge_affinity([item.edge_attr for item in g_1], [item.edge_attr for item in g_2], global_weights)\n            for (g_1, g_2), global_weights in zip(lexico_iter(orig_graph_list), global_weights_list)\n        ]\n\n        # Similarities to costs\n        quadratic_costs_list = [[-0.5 * x for x in quadratic_costs] for quadratic_costs in quadratic_costs_list]\n\n        if cfg.BB_GM.solver_name == \"lpmp\":\n            all_edges = [[item.edge_index for item in graph] for graph in orig_graph_list]\n            gm_solvers = [\n                GraphMatchingModule(\n                    all_left_edges,\n                    all_right_edges,\n                    ns_src,\n                    ns_tgt,\n                    cfg.BB_GM.lambda_val,\n                    cfg.BB_GM.solver_params,\n                )\n                for (all_left_edges, all_right_edges), (ns_src, ns_tgt) in zip(\n                    lexico_iter(all_edges), lexico_iter(n_points)\n                )\n            ]\n            matchings = [\n                gm_solver(unary_costs, quadratic_costs)\n                for gm_solver, unary_costs, quadratic_costs in zip(gm_solvers, unary_costs_list, quadratic_costs_list)\n            ]\n        elif cfg.BB_GM.solver_name == \"multigraph\":\n            all_edges = [[item.edge_index for item in graph] for graph in orig_graph_list]\n            gm_solver = MultiGraphMatchingModule(\n                all_edges, n_points, cfg.BB_GM.lambda_val, cfg.BB_GM.solver_params)\n            matchings = gm_solver(unary_costs_list, quadratic_costs_list)\n        else:\n            raise ValueError(f\"Unknown solver {cfg.BB_GM.solver_name}\")\n\n        if visualize_flag:\n            easy_visualize(\n                orig_graph_list,\n                points,\n                n_points,\n                images,\n                unary_costs_list,\n                quadratic_costs_list,\n                matchings,\n                **visualization_params,\n            )\n\n        return matchings",
  "description": "Combined Analysis:\n- [BB_GM/model.py]: This file implements the core optimization pipeline described in the paper. The forward method of the Net class:\n1. Extracts visual features from images using a VGG16 backbone\n2. Computes vertex (unary) costs via vertex_affinity layer (negative similarity scores)\n3. Computes edge (quadratic) costs via edge_affinity layer (negative similarity scores with 0.5 scaling)\n4. During training, adds margin to unary costs using ground truth permutations\n5. Passes the computed costs to combinatorial solvers (GraphMatchingModule or MultiGraphMatchingModule) from lpmp_py\n6. The solvers implement the exact optimization model: minimizing sum of vertex and edge costs subject to matching constraints\n7. The solvers are made differentiable via blackbox backpropagation, enabling end-to-end training\n\nKey compatibility points:\n- The unary_costs_list corresponds to vertex costs c^v in the paper\n- The quadratic_costs_list corresponds to edge costs c^e in the paper\n- The GraphMatchingModule solves the exact quadratic assignment problem with constraints\n- The MultiGraphMatchingModule enables multi-graph matching for cycle consistency\n- The lambda_val parameter controls the trade-off between unary and edge terms\n- The solver_params configure the underlying combinatorial algorithm\n- The implementation follows the paper's architecture: feature extraction → cost computation → blackbox solver integration",
  "dependencies": [
    "lpmp_py.GraphMatchingModule",
    "normalize_over_channels",
    "BB_GM.affinity_layer.InnerProductWithWeightsAffinity",
    "utils.feature_align.feature_align",
    "concat_features",
    "utils.config.cfg",
    "lpmp_py.MultiGraphMatchingModule",
    "utils.backbone",
    "BB_GM.sconv_archs.SiameseSConvOnNodes",
    "torch",
    "utils.utils.lexico_iter",
    "BB_GM.sconv_archs.SiameseNodeFeaturesToEdgeFeatures",
    "utils.visualization.easy_visualize"
  ]
}