{
  "file_path": "DeepPlace/NonLinearPlace.py, DeepPlace/PlaceObj.py, DeepPlace/a2c_ppo_acktr/algo/ppo.py, DeepPlace/a2c_ppo_acktr/model.py, DeepPlace/fullplace_env.py, DeepPlace/main.py, DeepPlace/ops/density_map/density_map.py, DeepPlace/ops/hpwl/hpwl.py, DeepPlace/place_env.py",
  "function_name": "NonLinearPlace.__call__, PlaceObj, PPO.update, CNNBase.forward, Placememt, main, DensityMap.forward, HPWL, HPWLFunction, HPWLAtomicFunction, Placememt",
  "code_snippet": "\n\n# ==========================================\n# File: DeepPlace/NonLinearPlace.py\n# Function/Context: NonLinearPlace.__call__\n# ==========================================\nimport os\nimport sys\nimport time\nimport pickle\nimport numpy as np\nimport logging\nimport torch\nimport gzip\nimport copy\nimport matplotlib.pyplot as plt\nif sys.version_info[0] < 3:\n    import cPickle as pickle\nelse:\n    import _pickle as pickle\nimport BasicPlace\nimport PlaceObj\nimport NesterovAcceleratedGradientOptimizer\nimport EvalMetrics\nimport pdb\n\n\nclass NonLinearPlace(BasicPlace.BasicPlace):\n    \"\"\"\n    @brief Nonlinear placement engine. \n    It takes parameters and placement database and runs placement flow. \n    \"\"\"\n    def __init__(self, params, placedb):\n        \"\"\"\n        @brief initialization. \n        @param params parameters \n        @param placedb placement database \n        \"\"\"\n        super(NonLinearPlace, self).__init__(params, placedb)\n\n    def __call__(self, params, placedb):\n        \"\"\"\n        @brief Top API to solve placement. \n        @param params parameters \n        @param placedb placement database \n        \"\"\"\n        iteration = 0\n        all_metrics = []\n\n        # global placement\n        if params.global_place_flag:\n            assert len(placedb.regions) == 0, \"FENCE REGIONS are not supported in global placement yet\"\n            # global placement may run in multiple stages according to user specification\n            for global_place_params in params.global_place_stages:\n\n                # we formulate each stage as a 3-nested optimization problem\n                # f_gamma(g_density(h(x) ; density weight) ; gamma)\n                # Lgamma      Llambda        Lsub\n                # When optimizing an inner problem, the outer parameters are fixed.\n                # This is a generalization to the eplace/RePlAce approach\n\n                # As global placement may easily diverge, we record the position of best overflow\n                best_metric = [None]\n                best_pos = [None]\n\n                if params.gpu:\n                    torch.cuda.synchronize()\n                tt = time.time()\n                # construct model and optimizer\n                density_weight = 0.0\n                # construct placement model\n                model = PlaceObj.PlaceObj(density_weight, params, placedb, self.data_collections, self.op_collections, global_place_params).to(self.data_collections.pos[0].device)\n                optimizer_name = global_place_params[\"optimizer\"]\n\n                # determine optimizer\n                if optimizer_name.lower() == \"adam\":\n                    optimizer = torch.optim.Adam(self.parameters(), lr=0)\n                elif optimizer_name.lower() == \"sgd\":\n                    optimizer = torch.optim.SGD(self.parameters(), lr=0)\n                elif optimizer_name.lower() == \"sgd_momentum\":\n                    optimizer = torch.optim.SGD(self.parameters(), lr=0, momentum=0.9, nesterov=False)\n                elif optimizer_name.lower() == \"sgd_nesterov\":\n                    optimizer = torch.optim.SGD(self.parameters(), lr=0, momentum=0.9, nesterov=True)\n                elif optimizer_name.lower() == \"nesterov\":\n                    optimizer = NesterovAcceleratedGradientOptimizer.NesterovAcceleratedGradientOptimizer(\n                        self.parameters(),\n                        lr=0,\n                        obj_and_grad_fn=model.obj_and_grad_fn,\n                        constraint_fn=self.op_collections.move_boundary_op,\n                    )\n                else:\n                    assert 0, \"unknown optimizer %s\" % (optimizer_name)\n\n                logging.info(\"use %s optimizer\" % (optimizer_name))\n                model.train()\n                # defining evaluation ops\n                eval_ops = {\n                    #\"wirelength\" : self.op_collections.wirelength_op,\n                    #\"density\" : self.op_collections.density_op,\n                    #\"objective\" : model.obj_fn,\n                    \"hpwl\": self.op_collections.hpwl_op,\n                    \"overflow\": self.op_collections.density_overflow_op\n                }\n                if params.routability_opt_flag:\n                    eval_ops.update({\n                        'route_utilization': self.op_collections.route_utilization_map_op,\n                        'pin_utilization': self.op_collections.pin_utilization_map_op\n                    })\n\n                # a function to initialize learning rate\n                def initialize_learning_rate(pos):\n                    learning_rate = model.estimate_initial_learning_rate(pos, global_place_params[\"learning_rate\"])\n                    # update learning rate\n                    for param_group in optimizer.param_groups:\n                        param_group['lr'] = learning_rate.data\n\n                if iteration == 0:\n                    if params.gp_noise_ratio > 0.0:\n                        logging.info(\"add %g%% noise\" % (params.gp_noise_ratio * 100))\n                        model.op_collections.noise_op(model.data_collections.pos[0], params.gp_noise_ratio)\n                        initialize_learning_rate(model.data_collections.pos[0])\n                # the state must be saved after setting learning rate\n                initial_state = copy.deepcopy(optimizer.state_dict())\n\n                if params.gpu:\n                    torch.cuda.synchronize()\n                logging.info(\"%s initialization takes %g seconds\" % (optimizer_name, (time.time() - tt)))\n\n                # as nesterov requires line search, we cannot follow the convention of other solvers\n                if optimizer_name.lower() in {\"sgd\", \"adam\", \"sgd_momentum\", \"sgd_nesterov\"}:\n                    model.obj_and_grad_fn(model.data_collections.pos[0])\n                elif optimizer_name.lower() != \"nesterov\":\n                    assert 0, \"unsupported optimizer %s\" % (optimizer_name)\n\n                # stopping criteria\n                def Lgamma_stop_criterion(Lgamma_step, metrics):\n                    with torch.no_grad():\n                        if len(metrics) > 1:\n                            cur_metric = metrics[-1][-1][-1]\n                            prev_metric = metrics[-2][-1][-1]\n                            if Lgamma_step > 100 and ((cur_metric.overflow < params.stop_overflow and cur_metric.hpwl > prev_metric.hpwl) or cur_metric.max_density < params.target_density):\n                                logging.debug(\n                                    \"Lgamma stopping criteria: %d > 100 and (( %g < 0.1 and %g > %g ) or %g < 1.0)\"\n                                    % (Lgamma_step, cur_metric.overflow,\n                                       cur_metric.hpwl, prev_metric.hpwl,\n                                       cur_metric.max_density))\n                                return True\n                        # a heuristic to detect divergence and stop early \n                        if len(metrics) > 50:\n                            cur_metric = metrics[-1][-1][-1]\n                            prev_metric = metrics[-50][-1][-1]\n                            # record HPWL and overflow increase, and check divergence \n                            if cur_metric.overflow > prev_metric.overflow and cur_metric.hpwl > best_metric[0].hpwl * 2: \n                                return True \n                        return False\n\n                def Llambda_stop_criterion(Lgamma_step, Llambda_density_weight_step, metrics):\n                    with torch.no_grad():\n                        if len(metrics) > 1:\n                            cur_metric = metrics[-1][-1]\n                            prev_metric = metrics[-2][-1]\n                            if (cur_metric.overflow < params.stop_overflow and cur_metric.hpwl > prev_metric.hpwl) or cur_metric.max_density < 1.0:\n                                logging.debug(\n                                    \"Llambda stopping criteria: %d and (( %g < 0.1 and %g > %g ) or %g < 1.0)\"\n                                    % (Llambda_density_weight_step,\n                                       cur_metric.overflow, cur_metric.hpwl,\n                                       prev_metric.hpwl, cur_metric.max_density))\n                                return True\n                    return False\n\n                # use a moving average window for stopping criteria, for an example window of 3\n                # 0, 1, 2, 3, 4, 5, 6\n                #    window2\n                #             window1\n                moving_avg_window = max(min(model.Lsub_iteration // 2, 3), 1)\n\n                def Lsub_stop_criterion(Lgamma_step, Llambda_density_weight_step, Lsub_step, metrics):\n                    with torch.no_grad():\n                        if len(metrics) >= moving_avg_window * 2:\n                            cur_avg_obj = 0\n                            prev_avg_obj = 0\n                            for i in range(moving_avg_window):\n                                cur_avg_obj += metrics[-1 - i].objective\n                                prev_avg_obj += metrics[-1 - moving_avg_window - i].objective\n                            cur_avg_obj /= moving_avg_window\n                            prev_avg_obj /= moving_avg_window\n                            threshold = 0.999\n                            if cur_avg_obj >= prev_avg_obj * threshold:\n                                logging.debug(\n                                    \"Lsub stopping criteria: %d and %g > %g * %g\"\n                                    % (Lsub_step, cur_avg_obj, prev_avg_obj,\n                                       threshold))\n                                return True\n                    return False\n\n                def one_descent_step(Lgamma_step, Llambda_density_weight_step, Lsub_step, iteration, metrics):\n                    t0 = time.time()\n\n                    # metric for this iteration\n                    cur_metric = EvalMetrics.EvalMetrics(iteration, (Lgamma_step, Llambda_density_weight_step, Lsub_step))\n                    cur_metric.gamma = model.gamma.data\n                    cur_metric.density_weight = model.density_weight.data\n                    metrics.append(cur_metric)\n                    pos = model.data_collections.pos[0]\n\n                    # move any out-of-bound cell back to placement region\n                    self.op_collections.move_boundary_op(pos)\n\n                    if torch.eq(model.density_weight, 0.0):\n                        model.initialize_density_weight(params, placedb)\n                        logging.info(\"density_weight = %.6E\" % (model.density_weight.data))\n\n                    optimizer.zero_grad()\n\n                    # t1 = time.time()\n                    cur_metric.evaluate(placedb, eval_ops, pos)\n                    model.overflow = cur_metric.overflow.data.clone()\n                    #logging.debug(\"evaluation %.3f ms\" % ((time.time()-t1)*1000))\n                    #t2 = time.time()\n\n                    # as nesterov requires line search, we cannot follow the convention of other solvers\n                    if optimizer_name.lower() in [\"sgd\", \"adam\", \"sgd_momentum\", \"sgd_nesterov\"]:\n                        obj, grad = model.obj_and_grad_fn(pos)\n                        cur_metric.objective = obj.data.clone()\n                    elif optimizer_name.lower() != \"nesterov\":\n                        assert 0, \"unsupported optimizer %s\" % (optimizer_name)\n\n                    # plot placement\n                    if params.plot_flag and iteration % 100 == 0:\n                        cur_pos = self.pos[0].data.clone().cpu().numpy()\n                        self.plot(params, placedb, iteration, cur_pos)\n\n                    t3 = time.time()\n                    optimizer.step()\n                    logging.info(\"optimizer step %.3f ms\" % ((time.time() - t3) * 1000))\n\n                    # nesterov has already computed the objective of the next step\n                    if optimizer_name.lower() == \"nesterov\":\n                        cur_metric.objective = optimizer.param_groups[0]['obj_k_1'][0].data.clone()\n\n                    # actually reports the metric before step\n                    logging.info(cur_metric)\n                    # record the best overflow\n                    if best_metric[0] is None or best_metric[0].overflow > cur_metric.overflow:\n                        best_metric[0] = cur_metric\n                        if best_pos[0] is None:\n                            best_pos[0] = self.pos[0].data.clone()\n                        else:\n                            best_pos[0].data.copy_(self.pos[0].data)\n\n                    logging.info(\"full step %.3f ms\" % ((time.time() - t0) * 1000))\n\n                Lgamma_metrics = all_metrics\n\n                if params.routability_opt_flag:\n                    adjust_area_flag = True\n                    adjust_route_area_flag = params.adjust_nctugr_area_flag or params.adjust_rudy_area_flag \n                    adjust_pin_area_flag = params.adjust_pin_area_flag\n                    num_area_adjust = 0\n\n                Llambda_flat_iteration = 0\n                for Lgamma_step in range(model.Lgamma_iteration):\n                    Lgamma_metrics.append([])\n                    Llambda_metrics = Lgamma_metrics[-1]\n                    for Llambda_density_weight_step in range(model.Llambda_density_weight_iteration):\n                        Llambda_metrics.append([])\n                        Lsub_metrics = Llambda_metrics[-1]\n                        for Lsub_step in range(model.Lsub_iteration):\n                            one_descent_step(Lgamma_step, Llambda_density_weight_step, Lsub_step, iteration, Lsub_metrics)\n                            iteration += 1\n                            # stopping criteria\n                            if Lsub_stop_criterion(Lgamma_step, Llambda_density_weight_step, Lsub_step, Lsub_metrics):\n                                break\n                        Llambda_flat_iteration += 1\n                        # update density weight\n                        if Llambda_flat_iteration > 1:\n                            model.op_collections.update_density_weight_op(\n                                Llambda_metrics[-1][-1],\n                                Llambda_metrics[-2][-1] if len(Llambda_metrics) > 1 else Lgamma_metrics[-2][-1][-1],\n                                Llambda_flat_iteration)\n                        #logging.debug(\"update density weight %.3f ms\" % ((time.time()-t2)*1000))\n                        if Llambda_stop_criterion(Lgamma_step, Llambda_density_weight_step, Llambda_metrics):\n                            break\n\n                        # for routability optimization\n                        if params.routability_opt_flag and num_area_adjust < params.max_num_area_adjust and Llambda_metrics[-1][-1].overflow < params.node_area_adjust_overflow:\n                            content = \"routability optimization round %d: adjust area flags = (%d, %d, %d)\" % (\n                                    num_area_adjust, adjust_area_flag, \n                                    \n            \n\n# ==========================================\n# File: DeepPlace/PlaceObj.py\n# Function/Context: PlaceObj\n# ==========================================\nimport os\nimport sys\nimport time\nimport numpy as np\nimport itertools\nimport logging\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pdb\nimport gzip\nif sys.version_info[0] < 3:\n    import cPickle as pickle\nelse:\n    import _pickle as pickle\nimport dreamplace.ops.weighted_average_wirelength.weighted_average_wirelength as weighted_average_wirelength\nimport dreamplace.ops.logsumexp_wirelength.logsumexp_wirelength as logsumexp_wirelength\nimport dreamplace.ops.electric_potential.electric_potential as electric_potential\nimport dreamplace.ops.density_potential.density_potential as density_potential\nimport dreamplace.ops.rudy.rudy as rudy\nimport dreamplace.ops.pin_utilization.pin_utilization as pin_utilization\nimport dreamplace.ops.nctugr_binary.nctugr_binary as nctugr_binary\nimport dreamplace.ops.adjust_node_area.adjust_node_area as adjust_node_area\n\n\nclass PreconditionOp:\n    \"\"\"Preconditioning engine is critical for convergence. \n    Need to be carefully designed. \n    \"\"\"\n    def __init__(self, placedb, data_collections):\n        self.placedb = placedb\n        self.data_collections = data_collections\n        self.iteration = 0\n        self.alpha = 1.0\n        self.best_overflow = None\n        self.overflows = []\n\n    def set_overflow(self, overflow):\n        self.overflows.append(overflow)\n        if self.best_overflow is None:\n            self.best_overflow = overflow\n        else:\n            self.best_overflow = min(self.best_overflow, overflow)\n\n    def __call__(self, grad, density_weight):\n        \"\"\"Introduce alpha parameter to avoid divergence. \n        It is tricky for this parameter to increase. \n        \"\"\"\n        with torch.no_grad():\n            precond = self.data_collections.num_pins_in_nodes + self.alpha * density_weight * self.data_collections.node_areas\n            precond.clamp_(min=1.0)\n            grad[0:self.placedb.num_nodes].div_(precond)\n            grad[self.placedb.num_nodes:self.placedb.num_nodes * 2].div_(precond)\n            self.iteration += 1\n\n            # assume overflow has been updated\n            if self.overflows and self.overflows[-1] < 0.3 and self.alpha < 1024:\n                if (self.iteration % 20) == 0:\n                    self.alpha *= 2\n                    logging.info(\n                        \"preconditioning alpha = %g, best_overflow %g, overflow %g\"\n                        % (self.alpha, self.best_overflow, self.overflows[-1]))\n\n        return grad\n\n\nclass PlaceObj(nn.Module):\n    \"\"\"\n    @brief Define placement objective:\n        wirelength + density_weight * density penalty\n    It includes various ops related to global placement as well.\n    \"\"\"\n    def __init__(self, density_weight, params, placedb, data_collections,\n                 op_collections, global_place_params):\n        \"\"\"\n        @brief initialize ops for placement\n        @param density_weight density weight in the objective\n        @param params parameters\n        @param placedb placement database\n        @param data_collections a collection of all data and variables required for constructing the ops\n        @param op_collections a collection of all ops\n        @param global_place_params global placement parameters for current global placement stage\n        \"\"\"\n        super(PlaceObj, self).__init__()\n\n        self.gpu = params.gpu\n        self.data_collections = data_collections\n        self.op_collections = op_collections\n        self.density_weight = torch.tensor(\n            [density_weight],\n            dtype=self.data_collections.pos[0].dtype,\n            device=self.data_collections.pos[0].device)\n        self.gamma = torch.tensor(10 * self.base_gamma(params, placedb),\n                                  dtype=self.data_collections.pos[0].dtype,\n                                  device=self.data_collections.pos[0].device)\n\n        # compute weighted average wirelength from position\n        num_bins_x = global_place_params[\"num_bins_x\"] if global_place_params[\n            \"num_bins_x\"] else placedb.num_bins_x\n        num_bins_y = global_place_params[\"num_bins_y\"] if global_place_params[\n            \"num_bins_y\"] else placedb.num_bins_y\n        name = \"%dx%d bins\" % (num_bins_x, num_bins_y)\n        if global_place_params[\"wirelength\"] == \"weighted_average\":\n            self.op_collections.wirelength_op, self.op_collections.update_gamma_op = self.build_weighted_average_wl(\n                params, placedb, self.data_collections,\n                self.op_collections.pin_pos_op)\n        elif global_place_params[\"wirelength\"] == \"logsumexp\":\n            self.op_collections.wirelength_op, self.op_collections.update_gamma_op = self.build_logsumexp_wl(\n                params, placedb, self.data_collections,\n                self.op_collections.pin_pos_op)\n        else:\n            assert 0, \"unknown wirelength model %s\" % (\n                global_place_params[\"wirelength\"])\n        #self.op_collections.density_op = self.build_density_potential(params, placedb, self.data_collections, num_bins_x, num_bins_y, padding=1, name)\n        self.op_collections.density_op = self.build_electric_potential(\n            params,\n            placedb,\n            self.data_collections,\n            num_bins_x,\n            num_bins_y,\n            padding=0,\n            name=name)\n        self.op_collections.update_density_weight_op = self.build_update_density_weight(\n            params, placedb)\n        self.op_collections.precondition_op = self.build_precondition(\n            params, placedb, self.data_collections)\n        self.op_collections.noise_op = self.build_noise(\n            params, placedb, self.data_collections)\n        if params.routability_opt_flag:\n            # compute congestion map, RISA/RUDY congestion map\n            self.op_collections.route_utilization_map_op = self.build_route_utilization_map(\n                params, placedb, self.data_collections)\n            self.op_collections.pin_utilization_map_op = self.build_pin_utilization_map(\n                params, placedb, self.data_collections)\n            self.op_collections.nctugr_congestion_map_op = self.build_nctugr_congestion_map(\n                params, placedb, self.data_collections)\n            # adjust instance area with congestion map\n            self.op_collections.adjust_node_area_op = self.build_adjust_node_area(\n                params, placedb, self.data_collections)\n\n        self.Lgamma_iteration = global_place_params[\"iteration\"]\n        if 'Llambda_density_weight_iteration' in global_place_params:\n            self.Llambda_density_weight_iteration = global_place_params[\n                'Llambda_density_weight_iteration']\n        else:\n            self.Llambda_density_weight_iteration = 1\n        if 'Lsub_iteration' in global_place_params:\n            self.Lsub_iteration = global_place_params['Lsub_iteration']\n        else:\n            self.Lsub_iteration = 1\n        if 'routability_Lsub_iteration' in global_place_params:\n            self.routability_Lsub_iteration = global_place_params[\n                'routability_Lsub_iteration']\n        else:\n            self.routability_Lsub_iteration = self.Lsub_iteration\n\n    def obj_fn(self, pos):\n        \"\"\"\n        @brief Compute objective.\n            wirelength + density_weight * density penalty\n        @param pos locations of cells\n        @return objective value\n        \"\"\"\n        self.wirelength = self.op_collections.wirelength_op(pos)\n        self.density = self.op_collections.density_op(pos)\n        return self.wirelength + self.density_weight * self.density\n\n    def obj_and_grad_fn(self, pos):\n        \"\"\"\n        @brief compute objective and gradient.\n            wirelength + density_weight * density penalty\n        @param pos locations of cells\n        @return objective value\n        \"\"\"\n        #self.check_gradient(pos)\n        obj = self.obj_fn(pos)\n\n        if pos.grad is not None:\n            pos.grad.zero_()\n\n        #self.wirelength.backward()\n        #wirelength_grad = pos.grad.data.clone()\n\n        #if pos.grad is not None:\n        #    pos.grad.zero_()\n\n        #self.density.backward()\n        #density_grad = pos.grad.data.clone()\n\n        ## overall gradient \n        #pos.grad.data.copy_(wirelength_grad + self.density_weight * density_grad)\n\n        obj.backward()\n\n        ## compute preconditioning alpha\n        #wirelength_grad_norm = wirelength_grad.norm(p=1)\n        #density_grad_norm = density_grad.norm(p=1)\n        #precond_alpha = (density_grad_norm / wirelength_grad_norm).clamp_(min=1.0)\n        #self.op_collections.precondition_op.alpha = precond_alpha \n\n        self.op_collections.precondition_op(pos.grad, self.density_weight)\n\n        return obj, pos.grad\n\n    def forward(self):\n        \"\"\"\n        @brief Compute objective with current locations of cells.\n        \"\"\"\n        return self.obj_fn(self.data_collections.pos[0])\n\n    def check_gradient(self, pos):\n        \"\"\"\n        @brief check gradient for debug\n        @param pos locations of cells\n        \"\"\"\n        wirelength = self.op_collections.wirelength_op(pos)\n\n        if pos.grad is not None:\n            pos.grad.zero_()\n        wirelength.backward()\n        wirelength_grad = pos.grad.clone()\n\n        pos.grad.zero_()\n        density = self.density_weight * self.op_collections.density_op(pos)\n        density.backward()\n        density_grad = pos.grad.clone()\n\n        wirelength_grad_norm = wirelength_grad.norm(p=1)\n        density_grad_norm = density_grad.norm(p=1)\n\n        logging.info(\"wirelength_grad norm = %.6E\" % (wirelength_grad_norm))\n        logging.info(\"density_grad norm    = %.6E\" % (density_grad_norm))\n        pos.grad.zero_()\n\n    def estimate_initial_learning_rate(self, x_k, lr):\n        \"\"\"\n        @brief Estimate initial learning rate by moving a small step. \n        Computed as | x_k - x_k_1 |_2 / | g_k - g_k_1 |_2. \n        @param x_k current solution \n        @param lr small step \n        \"\"\"\n        obj_k, g_k = self.obj_and_grad_fn(x_k)\n        x_k_1 = torch.autograd.Variable(x_k - lr * g_k, requires_grad=True)\n        obj_k_1, g_k_1 = self.obj_and_grad_fn(x_k_1)\n\n        return (x_k - x_k_1).norm(p=2) / (g_k - g_k_1).norm(p=2)\n\n    def build_weighted_average_wl(self, params, placedb, data_collections,\n                                  pin_pos_op):\n        \"\"\"\n        @brief build the op to compute weighted average wirelength\n        @param params parameters\n        @param placedb placement database\n        @param data_collections a collection of data and variables required for constructing ops\n        @param pin_pos_op the op to compute pin locations according to cell locations\n        \"\"\"\n\n        # use WeightedAverageWirelength atomic\n        wirelength_for_pin_op = weighted_average_wirelength.WeightedAverageWirelength(\n            flat_netpin=data_collections.flat_net2pin_map,\n            netpin_start=data_collections.flat_net2pin_start_map,\n            pin2net_map=data_collections.pin2net_map,\n            net_weights=data_collections.net_weights,\n            net_mask=data_collections.net_mask_ignore_large_degrees,\n            pin_mask=data_collections.pin_mask_ignore_fixed_macros,\n            gamma=self.gamma,\n            algorithm='merged')\n\n        # wirelength for position\n        def build_wirelength_op(pos):\n            return wirelength_for_pin_op(pin_pos_op(pos))\n\n        # update gamma\n        base_gamma = self.base_gamma(params, placedb)\n\n        def build_update_gamma_op(iteration, overflow):\n            self.update_gamma(iteration, overflow, base_gamma)\n            #logging.debug(\"update gamma to %g\" % (wirelength_for_pin_op.gamma.data))\n\n        return build_wirelength_op, build_update_gamma_op\n\n    def build_logsumexp_wl(self, params, placedb, data_collections,\n                           pin_pos_op):\n        \"\"\"\n        @brief build the op to compute log-sum-exp wirelength\n        @param params parameters\n        @param placedb placement database\n        @param data_collections a collection of data and variables required for constructing ops\n        @param pin_pos_op the op to compute pin locations according to cell locations\n        \"\"\"\n\n        wirelength_for_pin_op = logsumexp_wirelength.LogSumExpWirelength(\n            flat_netpin=data_collections.flat_net2pin_map,\n            netpin_start=data_collections.flat_net2pin_start_map,\n            pin2net_map=data_collections.pin2net_map,\n            net_weights=data_collections.net_weights,\n            net_mask=data_collections.net_mask_ignore_large_degrees,\n            pin_mask=data_collections.pin_mask_ignore_fixed_macros,\n            gamma=self.gamma,\n            algorithm='merged')\n\n        # wirelength for position\n        def build_wirelength_op(pos):\n            return wirelength_for_pin_op(pin_pos_op(pos))\n\n        # update gamma\n        base_gamma = self.base_gamma(params, placedb)\n\n        def build_update_gamma_op(iteration, overflow):\n            self.update_gamma(iteration, overflow, base_gamma)\n            #logging.debug(\"update gamma to %g\" % (wirelength_for_pin_op.gamma.data))\n\n        return build_wirelength_op, build_update_gamma_op\n\n    def build_density_potential(self, params, placedb, data_collections,\n                                num_bins_x, num_bins_y, padding, name):\n        \"\"\"\n        @brief NTUPlace3 density potential\n        @param params parameters\n        @param placedb placement database\n        @param data_collections a collection of data and variables required for constructing ops\n        @param num_bins_x number of bins in horizontal direction\n        @param num_bins_y number of bins in vertical direction\n        @param padding number of padding bins to left, right, bottom, top of the placement region\n        @param name string for printing\n        \"\"\"\n        bin_size_x = (placedb.xh - placedb.xl) / num_bins_x\n        bin_size_y = (placedb.yh - placedb.yl) / num_bins_y\n\n        xl = placedb.xl - padding * bin_size_x\n        xh = placedb.xh + padding * bin_size_x\n        yl = placedb.yl - padding * bin_size_y\n        yh = placedb.yh + padding * bin_size_y\n        local_num_bins_x = num_bins_x + 2 * padding\n        local_num_bins_y = num_bins_y + 2 * padding\n        max_num_bins_x = np.ceil(\n            (np.amax(placedb.node_size_x) + 4 * bin_size_x) / bin_size_x)\n        max_num_bins_y = np.ceil(\n            (np.amax(placedb.node_size_y) + 4 * bin_size_y) / bin_size_y)\n        max_num_bins = max(int(max_num_bins_x), int(max_num_bins_y))\n        logging.info(\n            \"%s #bins %dx%d, bin sizes %gx%g, max_num_bins = %d, padding = %d\"\n            % (name, local_num_bins_x, local_num_bins_y,\n               bin_size_x / placedb.row_height,\n               bin_size_y / placedb.row_height, max_num_bins, padding))\n        if local_num_bins_x < max_num_bins:\n            logging.warning(\"local_num_bins_x (%d)\"\n\n# ==========================================\n# File: DeepPlace/a2c_ppo_acktr/algo/ppo.py\n# Function/Context: PPO.update\n# ==========================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n\nclass PPO():\n    def __init__(self,\n                 actor_critic,\n                 clip_param,\n                 ppo_epoch,\n                 num_mini_batch,\n                 value_loss_coef,\n                 entropy_coef,\n                 lr=None,\n                 eps=None,\n                 max_grad_norm=None,\n                 use_clipped_value_loss=True):\n\n        self.actor_critic = actor_critic\n\n        self.clip_param = clip_param\n        self.ppo_epoch = ppo_epoch\n        self.num_mini_batch = num_mini_batch\n\n        self.value_loss_coef = value_loss_coef\n        self.entropy_coef = entropy_coef\n\n        self.max_grad_norm = max_grad_norm\n        self.use_clipped_value_loss = use_clipped_value_loss\n\n        self.optimizer = optim.Adam(actor_critic.parameters(), lr=lr, eps=eps)\n\n    def update(self, rollouts, features):\n        advantages = rollouts.returns[:-1] - rollouts.value_preds[:-1]\n        advantages = (advantages - advantages.mean()) / (\n            advantages.std() + 1e-5)\n\n        value_loss_epoch = 0\n        action_loss_epoch = 0\n        dist_entropy_epoch = 0\n\n        for e in range(self.ppo_epoch):\n            if self.actor_critic.is_recurrent:\n                data_generator = rollouts.recurrent_generator(\n                    advantages, self.num_mini_batch)\n            else:\n                data_generator = rollouts.feed_forward_generator(\n                    advantages, self.num_mini_batch)\n\n            for sample in data_generator:\n                obs_batch, recurrent_hidden_states_batch, actions_batch, \\\n                   value_preds_batch, return_batch, masks_batch, old_action_log_probs_batch, \\\n                        adv_targ = sample\n\n                # Reshape to do in a single forward pass for all steps\n                values, action_log_probs, dist_entropy, _ = self.actor_critic.evaluate_actions(\n                    obs_batch, recurrent_hidden_states_batch, masks_batch,\n                    actions_batch, features)\n\n                ratio = torch.exp(action_log_probs -\n                                  old_action_log_probs_batch)\n                surr1 = ratio * adv_targ\n                surr2 = torch.clamp(ratio, 1.0 - self.clip_param,\n                                    1.0 + self.clip_param) * adv_targ\n                action_loss = -torch.min(surr1, surr2).mean()\n\n                if self.use_clipped_value_loss:\n                    value_pred_clipped = value_preds_batch + \\\n                        (values - value_preds_batch).clamp(-self.clip_param, self.clip_param)\n                    value_losses = (values - return_batch).pow(2)\n                    value_losses_clipped = (\n                        value_pred_clipped - return_batch).pow(2)\n                    value_loss = 0.5 * torch.max(value_losses,\n                                                 value_losses_clipped).mean()\n                else:\n                    value_loss = 0.5 * (return_batch - values).pow(2).mean()\n\n                self.optimizer.zero_grad()\n                (value_loss * self.value_loss_coef + action_loss -\n                 dist_entropy * self.entropy_coef).backward()\n                nn.utils.clip_grad_norm_(self.actor_critic.parameters(),\n                                         self.max_grad_norm)\n                self.optimizer.step()\n\n                value_loss_epoch += value_loss.item()\n                action_loss_epoch += action_loss.item()\n                dist_entropy_epoch += dist_entropy.item()\n\n        num_updates = self.ppo_epoch * self.num_mini_batch\n\n        value_loss_epoch /= num_updates\n        action_loss_epoch /= num_updates\n        dist_entropy_epoch /= num_updates\n\n        return value_loss_epoch, action_loss_epoch, dist_entropy_epoch\n\n# ==========================================\n# File: DeepPlace/a2c_ppo_acktr/model.py\n# Function/Context: CNNBase.forward\n# ==========================================\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport dgl\nimport dgl.function as fn\nfrom os.path import dirname, abspath\nfrom a2c_ppo_acktr.distributions import Bernoulli, Categorical, DiagGaussian\nfrom a2c_ppo_acktr.utils import init\n\n\ngcn_msg = fn.copy_u(u='h', out='m')\ngcn_reduce = fn.sum(msg='m', out='h')\n\n\ndef build_graph():\n    path1 = dirname(dirname(abspath(__file__))) + '/data/edges_1.dat'\n    path2 = dirname(dirname(abspath(__file__))) + '/data/edges_2.dat'\n    f = open(path1, \"r\")\n    for line in f:\n        x1 = eval(line)\n\n    f1 = open(path2, \"r\")\n    for line in f1:\n        x2 = eval(line)\n    g = dgl.DGLGraph()\n    g.add_nodes(710)\n    g.add_edges(x1, x2)\n    # edges are directional in DGL; make them bi-directional\n    g.add_edges(x2, x1)\n\n    return g\n\n\nclass GCNLayer(nn.Module):\n    def __init__(self, in_feats, out_feats):\n        super(GCNLayer, self).__init__()\n        self.linear = nn.Linear(in_feats, out_feats)\n\n    def forward(self, g, feature):\n        # Creating a local scope so that all the stored ndata and edata\n        # (such as the `'h'` ndata below) are automatically popped out\n        # when the scope exits.\n        with g.local_scope():\n            g.ndata['h'] = feature\n            g.update_all(gcn_msg, gcn_reduce)\n            h = g.ndata['h']\n            return self.linear(h)\n\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\n\n\nclass CNNBase(NNBase):\n    def __init__(self, num_inputs, recurrent=False, hidden_size=512):\n        super(CNNBase, self).__init__(recurrent, hidden_size, hidden_size)\n\n        init_ = lambda m: init(m, nn.init.orthogonal_, lambda x: nn.init.\n                               constant_(x, 0), nn.init.calculate_gain('relu'))\n\n        self.main = nn.Sequential(\n            init_(nn.Conv2d(num_inputs, 32, 8, stride=4)), nn.ReLU(),\n            init_(nn.Conv2d(32, 64, 4, stride=2)), nn.ReLU(),\n            init_(nn.Conv2d(64, 32, 3, stride=1)), nn.ReLU(), Flatten(),\n            init_(nn.Linear(32 * 7 * 7, hidden_size - 16)), nn.ReLU())\n\n        init_ = lambda m: init(m, nn.init.orthogonal_, lambda x: nn.init.\n                               constant_(x, 0))\n\n        self.critic_linear = init_(nn.Linear(hidden_size, 1))\n\n        self.train()\n        self.g = build_graph().to('cuda:0')\n        self.layer1 = GCNLayer(2, 16)\n        self.layer2 = GCNLayer(16, 32)\n        self.layer4 = GCNLayer(32, 16)\n\n    def forward(self, inputs, rnn_hxs, masks, features, n, flag=True):\n        x = self.main(inputs / 255.0)\n        features = features.cuda()\n        x1 = F.relu(self.layer1(self.g, features))\n        x2 = F.relu(self.layer2(self.g, x1))\n        if flag:\n            x4 = F.relu(self.layer4(self.g, x2))[n].unsqueeze(0)\n        else:\n            x4 = F.relu(self.layer4(self.g, x2))\n        x = torch.cat([x, x4], 1)\n\n        if self.is_recurrent:\n            x, rnn_hxs = self._forward_gru(x, rnn_hxs, masks)\n\n        return self.critic_linear(x), x, rnn_hxs\n\n# ==========================================\n# File: DeepPlace/fullplace_env.py\n# Function/Context: Placememt\n# ==========================================\nfrom gym.spaces import Discrete\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom gym.utils import seeding\nimport os\nimport sys\nimport logging\nroot_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nif root_dir not in sys.path:\n    sys.path.append(root_dir)\nimport dreamplace.configure as configure\nimport Params\nimport PlaceDB\nimport NonLinearPlace\nimport pdb\n\nfrom rnd import RNDModel\nimport torch.optim as optim\n\n\nnp.set_printoptions(threshold=np.inf)\nrnd = RNDModel((1, 1, 84, 84), 32*32)\nforward_mse = nn.MSELoss(reduction='none')\noptimizer = optim.Adam(rnd.predictor.parameters(), lr=2e-6)\n\ndef compute_intrinsic_reward(rnd, next_obs):\n    target_next_feature = rnd.target(next_obs)\n    predict_next_feature = rnd.predictor(next_obs)\n\n    forward_loss = forward_mse(predict_next_feature, target_next_feature).mean(-1)\n    intrinsic_reward = (target_next_feature - predict_next_feature).pow(2).sum(1) / 2\n    optimizer.zero_grad()\n    forward_loss.backward()\n\n    return intrinsic_reward.item()/200\n\n\ndef place(params):\n    \"\"\"\n    @brief Top API to run the entire placement flow. \n    @param params parameters \n    \"\"\"\n\n    assert (not params.gpu) or configure.compile_configurations[\"CUDA_FOUND\"] == 'TRUE', \\\n            \"CANNOT enable GPU without CUDA compiled\"\n\n    np.random.seed(params.random_seed)\n    # read database\n    placedb = PlaceDB.PlaceDB()\n    placedb(params)\n\n    # solve placement\n    placer = NonLinearPlace.NonLinearPlace(params, placedb)\n    metrics = placer(params, placedb)\n    result = metrics[-3][0]\n\n    # write placement solution\n    path = \"%s/%s\" % (params.result_dir, params.design_name())\n    if not os.path.exists(path):\n        os.system(\"mkdir -p %s\" % (path))\n    gp_out_file = os.path.join(\n        path,\n        \"%s.gp.%s\" % (params.design_name(), params.solution_file_suffix()))\n    placedb.write(params, gp_out_file)\n\n    # call external detailed placement\n    # TODO: support more external placers, currently only support\n    # 1. NTUplace3/NTUplace4h with Bookshelf format\n    # 2. NTUplace_4dr with LEF/DEF format\n    if params.detailed_place_engine and os.path.exists(\n            params.detailed_place_engine):\n        logging.info(\"Use external detailed placement engine %s\" %\n                     (params.detailed_place_engine))\n        if params.solution_file_suffix() == \"pl\" and any(\n                dp_engine in params.detailed_place_engine\n                for dp_engine in ['ntuplace3', 'ntuplace4h']):\n            dp_out_file = gp_out_file.replace(\".gp.pl\", \"\")\n            # add target density constraint if provided\n            target_density_cmd = \"\"\n            if params.target_density < 1.0 and not params.routability_opt_flag:\n                target_density_cmd = \" -util %f\" % (params.target_density)\n            cmd = \"%s -aux %s -loadpl %s %s -out %s -noglobal %s\" % (\n                params.detailed_place_engine, params.aux_input, gp_out_file,\n                target_density_cmd, dp_out_file, params.detailed_place_command)\n            logging.info(\"%s\" % (cmd))\n            # tt = time.time()\n            os.system(cmd)\n            # logging.info(\"External detailed placement takes %.2f seconds\" %\n            #              (time.time() - tt))\n\n            if params.plot_flag:\n                # read solution and evaluate\n                placedb.read_pl(params, dp_out_file + \".ntup.pl\")\n                iteration = len(metrics)\n                pos = placer.init_pos\n                pos[0:placedb.num_physical_nodes] = placedb.node_x\n                pos[placedb.num_nodes:placedb.num_nodes +\n                    placedb.num_physical_nodes] = placedb.node_y\n                hpwl, density_overflow, max_density = placer.validate(\n                    placedb, pos, iteration)\n                logging.info(\n                    \"iteration %4d, HPWL %.3E, overflow %.3E, max density %.3E\"\n                    % (iteration, hpwl, density_overflow, max_density))\n                placer.plot(params, placedb, iteration, pos)\n        elif 'ntuplace_4dr' in params.detailed_place_engine:\n            dp_out_file = gp_out_file.replace(\".gp.def\", \"\")\n            cmd = \"%s\" % (params.detailed_place_engine)\n            for lef in params.lef_input:\n                if \"tech.lef\" in lef:\n                    cmd += \" -tech_lef %s\" % (lef)\n                else:\n                    cmd += \" -cell_lef %s\" % (lef)\n            cmd += \" -floorplan_def %s\" % (gp_out_file)\n            cmd += \" -verilog %s\" % (params.verilog_input)\n            cmd += \" -out ntuplace_4dr_out\"\n            cmd += \" -placement_constraints %s/placement.constraints\" % (\n                os.path.dirname(params.verilog_input))\n            cmd += \" -noglobal %s ; \" % (params.detailed_place_command)\n            cmd += \"mv ntuplace_4dr_out.fence.plt %s.fense.plt ; \" % (\n                dp_out_file)\n            cmd += \"mv ntuplace_4dr_out.init.plt %s.init.plt ; \" % (\n                dp_out_file)\n            cmd += \"mv ntuplace_4dr_out %s.ntup.def ; \" % (dp_out_file)\n            cmd += \"mv ntuplace_4dr_out.ntup.overflow.plt %s.ntup.overflow.plt ; \" % (\n                dp_out_file)\n            cmd += \"mv ntuplace_4dr_out.ntup.plt %s.ntup.plt ; \" % (\n                dp_out_file)\n            if os.path.exists(\"%s/dat\" % (os.path.dirname(dp_out_file))):\n                cmd += \"rm -r %s/dat ; \" % (os.path.dirname(dp_out_file))\n            cmd += \"mv dat %s/ ; \" % (os.path.dirname(dp_out_file))\n            # logging.info(\"%s\" % (cmd))\n            # tt = time.time()\n            os.system(cmd)\n            # logging.info(\"External detailed placement takes %.2f seconds\" %\n            #              (time.time() - tt))\n        else:\n            logging.warning(\n                \"External detailed placement only supports NTUplace3/NTUplace4dr API\"\n            )\n    elif params.detailed_place_engine:\n        logging.warning(\n            \"External detailed placement engine %s or aux file NOT found\" %\n            (params.detailed_place_engine))\n\n    return result\n\n\ndef write(res):\n    dic = np.load('./DeepPlace/data/3_dic.npy', allow_pickle=True).item()\n    f = open(\"./benchmarks/ispd2005/adaptec3/adaptec3.pl\", \"w\")\n    with open(\"./DeepPlace/data/adaptec3.pl\", \"r\") as f2:\n        for line in f2:\n            line = line.strip()\n            l = line.split()\n            if line and l[0][0] == 'o':\n                num = int(l[0].lstrip('o'))\n                if num - 450927 in dic.keys():\n                    index = dic[num - 450927]\n                    pos = res[index]\n                    x = int(pos[0] / 32 * 22653)\n                    y = int(pos[1] / 32 * 23122)\n                    l[1] = str(x)\n                    l[2] = str(y)\n                    line = '\\t'.join(l)\n\n            f.write(line)\n            f.write('\\n')\n\n\ndef new_cal_re(res, params):\n    write(res)\n    r = place(params)\n    wl = float(r[0].hpwl.data)\n    overf = float(r[0].overflow.data)\n    reward = -2 * (wl - 2.4e8) * 1e-6 - overf * 20\n    print(reward, wl)\n    return reward\n\n\ndef search(ob, x, y, depth, n):\n    if ob[x, y] < 1.0:\n        return x, y\n    if depth > 7:\n        return -1, -1\n    elif x-1 >= 0 and ob[x-1, y] < 1.0:\n        return x-1, y\n    elif x+1 < n and ob[x+1, y] < 1.0:\n        return x+1, y\n    elif y-1 >= 0 and ob[x, y-1] < 1.0:\n        return x, y-1\n    elif y+1 < n and ob[x, y+1] < 1.0:\n        return x, y+1\n    else:\n        return search(ob, x-1, y-1, depth+1, n)\n\n\ndef is_valid(x, y):\n    if -1 < x < 32 and -1 < y < 32:\n        return True\n    return False\n\n\ndef find(ob, n):\n    center = [n//2, n//2]\n    for i in range(n):\n        for j in range(i):\n            if is_valid(center[0]-j, center[1]-(i-j)) and ob[center[0]-j, center[1]-(i-j)] < 1.0:\n                return center[0]-j, center[1]-(i-j)\n            if is_valid(center[0]-j, center[1]+(i-j)) and ob[center[0]-j, center[1]+(i-j)] < 1.0:\n                return center[0]-j, center[1]+(i-j)\n            if is_valid(center[0]+j, center[1]-(i-j)) and ob[center[0]+j, center[1]-(i-j)] < 1.0:\n                return center[0]+j, center[1]-(i-j)\n            if is_valid(center[0]+j, center[1]+(i-j)) and ob[center[0]+j, center[1]+(i-j)] < 1.0:\n                return center[0]+j, center[1]+(i-j)\n\n\nclass Placememt():\n    def __init__(self, grid_size=32, num_cell=710):\n        self.n = grid_size\n        self.steps = num_cell\n        self.action_space = Discrete(self.n * self.n)\n        self.obs_space = (1, 84, 84)\n        self.obs = torch.zeros((1, 1, self.n, self.n))\n        self.results = []\n        self.best = -500\n        self.f = open(\"./DeepPlace/result/result.txt\", 'w')\n\n        f = open(\"./DeepPlace/data/n_edges_710.dat\", \"r\")\n        for line in f:\n            self.net = eval(line)\n        self.seed()\n        logging.root.name = 'DREAMPlace'\n        self.params = Params.Params()\n\n        # load parameters\n        add = \"test/ispd2005/adaptec3.json\"\n        self.params.load(add)\n        os.environ[\"OMP_NUM_THREADS\"] = \"%d\" % (self.params.num_threads)\n    \n    def seed(self, seed=None):\n        self.np_random, seed = seeding.np_random(seed)\n        return [seed]\n    \n    def reset(self):\n        self.obs = torch.zeros((1, 1, self.n, self.n))\n        return self.obs\n    \n    def to(self, device):\n        self.obs = self.obs.to(device)\n\n    def transform(self, x):\n        up = nn.Upsample(size=84, mode='bilinear', align_corners=False)\n        return up(x)*255\n    \n    def step(self, action):\n        x = action // self.n\n        y = action % self.n\n        x, y = search(self.obs[0, 0], x, y, 0, self.n)\n        if x == -1 or y == -1:\n            x, y = find(self.obs[0, 0], self.n)\n        self.obs[0, 0, x, y] = 1\n        self.results.append([int(x), int(y)])\n        obs = self.transform(self.obs)\n\n        if len(self.results) == self.steps:\n            done = True\n            reward = new_cal_re(self.results, self.params)\n            if reward > self.best:\n                self.best = reward\n                self.f.write(str(self.obs))\n                self.f.write(str(self.results))\n                self.f.write('\\n')\n                self.f.write(str(reward))\n                self.f.write('\\n')\n            self.results = []\n        else:\n            done = False\n            reward = compute_intrinsic_reward(rnd, obs / 255.0)\n        return obs, done, torch.FloatTensor([[reward]])\n\n\ndef fullplace_envs():\n    return Placememt()\n\n# ==========================================\n# File: DeepPlace/main.py\n# Function/Context: main\n# ==========================================\nimport copy\nimport glob\nimport os\nimport time\nfrom collections import deque\n\nimport gym\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom a2c_ppo_acktr import algo, utils\nfrom a2c_ppo_acktr.algo import gail\nfrom a2c_ppo_acktr.arguments import get_args\nfrom a2c_ppo_acktr.envs import make_vec_envs\nfrom a2c_ppo_acktr.model import Policy\nfrom a2c_ppo_acktr.storage import RolloutStorage\nfrom evaluation import evaluate\nfrom place_env import place_envs\nfrom fullplace_env import fullplace_envs\n\ndef main():\n    args = get_args()\n\n    torch.manual_seed(args.seed)\n    torch.cuda.manual_seed_all(args.seed)\n\n    if args.cuda and torch.cuda.is_available() and args.cuda_deterministic:\n        torch.backends.cudnn.benchmark = False\n        torch.backends.cudnn.deterministic = True\n\n    log_dir = os.path.expanduser(args.log_dir)\n    eval_log_dir = log_dir + \"_eval\"\n    utils.cleanup_log_dir(log_dir)\n    utils.cleanup_log_dir(eval_log_dir)\n\n    torch.set_num_threads(1)\n    device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n\n    if args.task == 'place':\n        envs = place_envs()\n    \n    elif args.task == 'fullplace':\n        envs = fullplace_envs()\n\n    actor_critic = Policy(\n        envs.obs_space,\n        envs.action_space,\n        base_kwargs={'recurrent': args.recurrent_policy})\n\n    actor_critic.to(device)\n\n    if args.algo == 'a2c':\n        agent = algo.A2C_ACKTR(\n            actor_critic,\n            args.value_loss_coef,\n            args.entropy_coef,\n            lr=args.lr,\n            eps=args.eps,\n            alpha=args.alpha,\n            max_grad_norm=args.max_grad_norm)\n    elif args.algo == 'ppo':\n        agent = algo.PPO(\n            actor_critic,\n            args.clip_param,\n            args.ppo_epoch,\n            args.num_mini_batch,\n            args.value_loss_coef,\n            args.entropy_coef,\n            lr=args.lr,\n            eps=args.eps,\n            max_grad_norm=args.max_grad_norm)\n    elif args.algo == 'acktr':\n        agent = algo.A2C_ACKTR(\n            actor_critic, args.value_loss_coef, args.entropy_coef, acktr=True)\n\n    if args.gail:\n        assert len(envs.obs_space) == 1\n        discr = gail.Discriminator(\n            envs.obs_space[0] + envs.action_space[1], 100,\n            device)\n        file_name = os.path.join(\n            args.gail_experts_dir, \"trajs_{}.pt\".format(\n                args.env_name.split('-')[0].lower()))\n        \n        expert_dataset = gail.ExpertDataset(\n            file_name, num_trajectories=4, subsample_frequency=20)\n        drop_last = len(expert_dataset) > args.gail_batch_size\n        gail_train_loader = torch.utils.data.DataLoader(\n            dataset=expert_dataset,\n            batch_size=args.gail_batch_size,\n            shuffle=True,\n            drop_last=drop_last)\n\n    rollouts = RolloutStorage(args.num_steps, args.num_processes,\n                              envs.obs_space, envs.action_space,\n                              actor_critic.recurrent_hidden_state_size)\n\n    obs = envs.reset()\n    envs.to(device)\n    rollouts.obs[0].copy_(envs.transform(obs))\n    rollouts.to(device)\n\n    episode_rewards = deque(maxlen=10)\n\n    start = time.time()\n    num_updates = int(\n        args.num_env_steps) // args.num_steps // args.num_processes\n\n    features = torch.zeros(710, 2)\n\n    for j in range(800):\n\n        if args.use_linear_lr_decay:\n            # decrease learning rate linearly\n            utils.update_linear_schedule(\n                agent.optimizer, j, num_updates,\n                agent.optimizer.lr if args.algo == \"acktr\" else args.lr)\n\n        for step in range(args.num_steps):\n            # Sample actions\n            n = len(envs.results)\n            with torch.no_grad():\n                value, action, action_log_prob, recurrent_hidden_states = actor_critic.act(\n                    rollouts.obs[step], rollouts.recurrent_hidden_states[step],\n                    rollouts.masks[step], features, n)\n\n            # Obser reward and next obs\n            obs, done, reward = envs.step(action)\n            features[n][0] = action // 32\n            features[n][1] = action % 32\n\n            masks = torch.FloatTensor(\n                [[0.0] if done else [1.0]])\n            bad_masks = torch.FloatTensor([[1.0]])\n   \n            rollouts.insert(obs, recurrent_hidden_states, action,\n                            action_log_prob, value, reward, masks, bad_masks)\n            if done:\n                episode_rewards.append(reward)\n                obs = envs.reset()\n                features = torch.zeros(710, 2)\n\n        with torch.no_grad():\n            next_value = actor_critic.get_value(\n                rollouts.obs[-1], rollouts.recurrent_hidden_states[-1],\n                rollouts.masks[-1], features, n).detach()\n\n        if args.gail:\n            if j >= 10:\n                envs.venv.eval()\n\n            gail_epoch = args.gail_epoch\n            if j < 10:\n                gail_epoch = 100  # Warm up\n            for _ in range(gail_epoch):\n                discr.update(gail_train_loader, rollouts,\n                             utils.get_vec_normalize(envs)._obfilt)\n\n            for step in range(args.num_steps):\n                rollouts.rewards[step] = discr.predict_reward(\n                    rollouts.obs[step], rollouts.actions[step], args.gamma,\n                    rollouts.masks[step])\n\n        rollouts.compute_returns(next_value, args.use_gae, args.gamma,\n                                 args.gae_lambda, args.use_proper_time_limits)\n\n        value_loss, action_loss, dist_entropy = agent.update(rollouts, features)\n\n        rollouts.after_update()\n\n        # save for every interval-th episode or for the last epoch\n        if (j % args.save_interval == 0\n                or j == num_updates - 1) and args.save_dir != \"\":\n            save_path = os.path.join(args.save_dir, args.algo)\n            try:\n                os.makedirs(save_path)\n            except OSError:\n                pass\n            torch.save([\n                actor_critic,\n                None\n            ], \"./trained_models/placement_\" + str(j) + \".pt\")\n\n        if j % args.log_interval == 0 and len(episode_rewards) > 1:\n            total_num_steps = (j + 1) * args.num_processes * args.num_steps\n            end = time.time()\n            print(\n                \"Updates {}, num timesteps {}, FPS {} \\n Last {} training episodes: mean/median reward {:.1f}/{:.1f}, min/max reward {:.1f}/{:.1f}\\n\"\n                .format(j, total_num_steps,\n                        int(total_num_steps / (end - start)),\n                        len(episode_rewards), torch.mean(torch.stack(list(episode_rewards))),\n                        torch.median(torch.stack(list(episode_rewards))), torch.min(torch.stack(list(episode_rewards))),\n                        torch.max(torch.stack(list(episode_rewards))), dist_entropy, value_loss,\n                        action_loss))\n\n        if (args.eval_interval is not None and len(episode_rewards) > 1\n                and j % args.eval_interval == 0):\n            ob_rms = None\n            evaluate(actor_critic, ob_rms, args.env_name, args.seed,\n                     args.num_processes, eval_log_dir, device)\n\nif __name__ == \"__main__\":\n    main()\n\n# ==========================================\n# File: DeepPlace/ops/density_map/density_map.py\n# Function/Context: DensityMap.forward\n# ==========================================\nimport math\nimport torch\nfrom torch import nn\nfrom torch.autograd import Function\n\nimport dreamplace.ops.density_map.density_map_cpp as density_map_cpp\nimport dreamplace.configure as configure\nif configure.compile_configurations[\"CUDA_FOUND\"] == \"TRUE\":\n    import dreamplace.ops.density_map.density_map_cuda as density_map_cuda\n\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\n\nimport pdb\n\n\nclass DensityMapFunction(Function):\n    \"\"\"\n    @brief compute density map.\n    \"\"\"\n    @staticmethod\n    def forward(pos, node_size_x, node_size_y, bin_center_x, bin_center_y,\n                initial_density_map, xl, yl, xh, yh, bin_size_x, bin_size_y,\n                num_movable_nodes, num_filler_nodes):\n        if pos.is_cuda:\n            func = density_map_cuda.forward\n        else:\n            func = density_map_cpp.forward\n        output = func(pos.view(pos.numel()), node_size_x, node_size_y,\n                      bin_center_x, bin_center_y, initial_density_map, xl, yl,\n                      xh, yh, bin_size_x, bin_size_y, num_movable_nodes,\n                      num_filler_nodes)\n        return output\n\n\nclass DensityMap(object):\n    \"\"\"\n    @brief Compute density map for both movable and fixed cells.\n    The density map for fixed cells is pre-computed. \n    Each call will only compute the density map for movable cells. \n    \"\"\"\n    def __init__(self, node_size_x, node_size_y, bin_center_x, bin_center_y,\n                 xl, yl, xh, yh, bin_size_x, bin_size_y, num_movable_nodes,\n                 num_terminals, num_filler_nodes):\n        \"\"\"\n        @brief initialization \n        @param node_size_x cell width array consisting of movable cells, fixed cells, and filler cells in order  \n        @param node_size_y cell height array consisting of movable cells, fixed cells, and filler cells in order   \n        @param bin_center_x bin center x locations \n        @param bin_center_y bin center y locations \n        @param xl left boundary \n        @param yl bottom boundary \n        @param xh right boundary \n        @param yh top boundary \n        @param bin_size_x bin width \n        @param bin_size_y bin height \n        @param num_movable_nodes number of movable cells \n        @param num_terminals number of fixed cells \n        @param num_filler_nodes number of filler cells \n        \"\"\"\n        super(DensityMap, self).__init__()\n        self.node_size_x = node_size_x\n        self.node_size_y = node_size_y\n        self.bin_center_x = bin_center_x\n        self.bin_center_y = bin_center_y\n        self.xl = xl\n        self.yl = yl\n        self.xh = xh\n        self.yh = yh\n        self.bin_size_x = bin_size_x\n        self.bin_size_y = bin_size_y\n        self.num_movable_nodes = num_movable_nodes\n        self.num_terminals = num_terminals\n        self.num_filler_nodes = num_filler_nodes\n        self.initial_density_map = None\n\n    def forward(self, pos):\n        \"\"\"\n        @brief API \n        @param pos cell locations. The array consists of x locations of movable cells, fixed cells, and filler cells, then y locations of them \n        \"\"\"\n        if self.initial_density_map is None:\n            if pos.is_cuda:\n                func = density_map_cuda.fixed_density_map\n            else:\n                func = density_map_cpp.fixed_density_map\n            self.initial_density_map = func(\n                pos, self.node_size_x, self.node_size_y, self.bin_center_x,\n                self.bin_center_y, self.xl, self.yl, self.xh, self.yh,\n                self.bin_size_x, self.bin_size_y, self.num_movable_nodes,\n                self.num_terminals)\n            #plot(self.initial_density_map.clone().div(self.bin_size_x*self.bin_size_y).cpu().numpy(), 'initial_density_map')\n\n        density_map = DensityMapFunction.forward(\n            pos=pos,\n            node_size_x=self.node_size_x,\n            node_size_y=self.node_size_y,\n            bin_center_x=self.bin_center_x,\n            bin_center_y=self.bin_center_y,\n            initial_density_map=self.initial_density_map,\n            xl=self.xl,\n            yl=self.yl,\n            xh=self.xh,\n            yh=self.yh,\n            bin_size_x=self.bin_size_x,\n            bin_size_y=self.bin_size_y,\n            num_movable_nodes=self.num_movable_nodes,\n            num_filler_nodes=self.num_filler_nodes)\n\n        return density_map\n\n# ==========================================\n# File: DeepPlace/ops/hpwl/hpwl.py\n# Function/Context: HPWL, HPWLFunction, HPWLAtomicFunction\n# ==========================================\nimport torch\nfrom torch.autograd import Function\nfrom torch import nn\nimport numpy as np\nimport pdb\n\nimport dreamplace.ops.hpwl.hpwl_cpp as hpwl_cpp\nimport dreamplace.ops.hpwl.hpwl_cpp_atomic as hpwl_cpp_atomic\nimport dreamplace.configure as configure\nif configure.compile_configurations[\"CUDA_FOUND\"] == \"TRUE\":\n    import dreamplace.ops.hpwl.hpwl_cuda as hpwl_cuda\n    import dreamplace.ops.hpwl.hpwl_cuda_atomic as hpwl_cuda_atomic\n\n\nclass HPWLFunction(Function):\n    \"\"\"compute half-perimeter wirelength.\n    @param pos pin location (x array, y array), not cell location \n    @param flat_netpin flat netpin map, length of #pins \n    @param netpin_start starting index in netpin map for each net, length of #nets+1, the last entry is #pins  \n    @param net_weights weight of nets \n    @param net_mask a boolean mask containing whether a net should be computed \n    @param pin2net_map pin2net map, second set of options \n    \"\"\"\n    @staticmethod\n    def forward(ctx, pos, flat_netpin, netpin_start, net_weights, net_mask):\n        output = pos.new_empty(1)\n        if pos.is_cuda:\n            func = hpwl_cuda.forward\n        else:\n            func = hpwl_cpp.forward\n        output = func(pos.view(pos.numel()), flat_netpin, netpin_start,\n                      net_weights, net_mask)\n        return output\n\n\nclass HPWLAtomicFunction(Function):\n    \"\"\"compute half-perimeter wirelength using atomic max/min.\n    @param pos pin location (x array, y array), not cell location \n    @param pin2net_map pin2net map, second set of options \n    @param net_weights weight of nets \n    @param net_mask a boolean mask containing whether a net should be computed \n    \"\"\"\n    @staticmethod\n    def forward(ctx, pos, pin2net_map, net_weights, net_mask):\n        output = pos.new_empty(1)\n        if pos.is_cuda:\n            func = hpwl_cuda_atomic.forward\n        else:\n            func = hpwl_cpp_atomic.forward\n        output = func(pos.view(pos.numel()), pin2net_map, net_weights,\n                      net_mask)\n        return output\n\n\nclass HPWL(nn.Module):\n    \"\"\" \n    @brief Compute half-perimeter wirelength. \n    Support two algoriths: net-by-net and atomic. \n    Different parameters are required for different algorithms. \n    \"\"\"\n    def __init__(self,\n                 flat_netpin=None,\n                 netpin_start=None,\n                 pin2net_map=None,\n                 net_weights=None,\n                 net_mask=None,\n                 algorithm='atomic'):\n        \"\"\"\n        @brief initialization \n        @param flat_netpin flat netpin map, length of #pins \n        @param netpin_start starting index in netpin map for each net, length of #nets+1, the last entry is #pins  \n        @param pin2net_map pin2net map \n        @param net_weights weight of nets \n        @param net_mask whether to compute wirelength, 1 means to compute, 0 means to ignore  \n        @param algorithm must be net-by-net | atomic\n        \"\"\"\n        super(HPWL, self).__init__()\n        assert net_mask is not None, \"net_mask is a requried parameter\"\n        if algorithm == 'net-by-net':\n            assert flat_netpin is not None and netpin_start is not None, \"flat_netpin, netpin_start are requried parameters for algorithm net-by-net\"\n        elif algorithm == 'atomic':\n            assert pin2net_map is not None, \"pin2net_map is required for algorithm atomic\"\n        self.flat_netpin = flat_netpin\n        self.netpin_start = netpin_start\n        self.pin2net_map = pin2net_map\n        self.net_weights = net_weights\n        self.net_mask = net_mask\n        self.algorithm = algorithm\n\n    def forward(self, pos):\n        if self.algorithm == 'net-by-net':\n            return HPWLFunction.apply(pos, self.flat_netpin, self.netpin_start,\n                                      self.net_weights, self.net_mask)\n        elif self.algorithm == 'atomic':\n            return HPWLAtomicFunction.apply(pos, self.pin2net_map,\n                                            self.net_weights, self.net_mask)\n\n# ==========================================\n# File: DeepPlace/place_env.py\n# Function/Context: Placememt\n# ==========================================\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom gym.utils import seeding\nfrom gym.spaces import Discrete\n\nnp.set_printoptions(threshold=np.inf)\n\ndef is_valid(x, y):\n    if -1 < x < 32 and -1 < y < 32:\n        return True\n    return False\n\ndef search(ob, x, y, depth, n):\n    if ob[x, y] < 1.0:\n        return x, y\n    if depth > 7:\n        return -1, -1\n    elif x-1 >= 0 and ob[x-1, y] < 1.0:\n        return x-1, y\n    elif x+1 < n and ob[x+1, y] < 1.0:\n        return x+1, y\n    elif y-1 >= 0 and ob[x, y-1] < 1.0:\n        return x, y-1\n    elif y+1 < n and ob[x, y+1] < 1.0:\n        return x, y+1\n    else:\n        return search(ob, x-1, y-1, depth+1, n)\n\ndef find(ob, n):\n    center = [n//2, n//2]\n    for i in range(n):\n        for j in range(i):\n            if is_valid(center[0]-j, center[1]-(i-j)) and ob[center[0]-j, center[1]-(i-j)] < 1.0:\n                return center[0]-j, center[1]-(i-j)\n            if is_valid(center[0]-j, center[1]+(i-j)) and ob[center[0]-j, center[1]+(i-j)] < 1.0:\n                return center[0]-j, center[1]+(i-j)\n            if is_valid(center[0]+j, center[1]-(i-j)) and ob[center[0]+j, center[1]-(i-j)] < 1.0:\n                return center[0]+j, center[1]-(i-j)\n            if is_valid(center[0]+j, center[1]+(i-j)) and ob[center[0]+j, center[1]+(i-j)] < 1.0:\n                return center[0]+j, center[1]+(i-j)\n\ndef cal_re(r, x):\n    wl = 0\n    con = np.zeros((32, 32))\n    for net in x:\n        left = 31\n        right = 0\n        up = 31\n        down = 0\n        for i in net:\n            left = min(left, r[i][1])\n            right = max(right, r[i][1])\n            up = min(up, r[i][0])\n            down = max(down, r[i][0])\n        wn = int(right-left+1)\n        hn = int(down-up+1)\n        dn = (wn+hn) / (wn*hn)\n        con[up:down+1, left:right+1] += dn\n        wl += wn + hn\n    con = list(con.flatten())\n    con.sort(reverse=True)\n    return (-np.mean(con[:32]) - (wl-34000)*0.1)*0.2\n\nclass Placememt():\n    def __init__(self, grid_size=32, num_cell=710):\n        self.n = grid_size\n        self.steps = num_cell\n        self.action_space = Discrete(self.n * self.n)\n        self.obs_space = (1, 84, 84)\n        self.obs = torch.zeros((1, 1, self.n, self.n))\n        self.results = []\n        self.best = -500\n        self.f = open(\"./result/result.txt\", 'w')\n\n        f = open(\"./data/n_edges_710.dat\", \"r\")\n        for line in f:\n            self.net = eval(line)\n        self.seed()\n\n    def seed(self, seed=None):\n        self.np_random, seed = seeding.np_random(seed)\n        return [seed]\n    \n    def reset(self):\n        self.obs = torch.zeros((1, 1, self.n, self.n))\n        return self.obs\n    \n    def to(self, device):\n        self.obs = self.obs.to(device)\n        \n    def transform(self, x):\n        up = nn.Upsample(size=84, mode='bilinear', align_corners=False)\n        return up(x)*255\n    \n    def step(self, action):\n        x = action // self.n\n        y = action % self.n\n        x, y = search(self.obs[0, 0], x, y, 0, self.n)\n        if x == -1 or y == -1:\n            x, y = find(self.obs[0, 0], self.n)\n        self.obs[0, 0, x, y] = 1\n        self.results.append([int(x), int(y)])\n        obs = self.transform(self.obs)\n\n        if len(self.results) == self.steps:\n            done = True\n            reward = cal_re(self.results, self.net)\n            if reward > self.best:\n                self.best = reward\n                self.f.write(str(self.obs))\n                self.f.write(str(self.results))\n                self.f.write('\\n')\n                self.f.write(str(reward))\n                self.f.write('\\n')\n            self.results = []\n        else:\n            done = False\n            reward = compute_intrinsic_reward(rnd, obs / 255.0)\n        return obs, done, torch.FloatTensor([[reward]])\n\ndef place_envs():\n    return Placememt()",
  "description": "Combined Analysis:\n- [DeepPlace/NonLinearPlace.py]: This file implements the core gradient-based optimization for standard cell placement described in the DeepPlace paper. The mathematical model minimizes HPWL (Half-Perimeter Wirelength) with density constraints using a nested optimization framework (Lgamma, Llambda, Lsub). The implementation uses various gradient optimizers (SGD, Adam, Nesterov) to solve the continuous placement problem, which corresponds to the standard cell placement component of the joint learning framework. The code handles wirelength and density objectives, with routability optimization extensions, aligning with the paper's objective of minimizing wirelength and congestion. However, it does not implement the RL-based macro placement or routing components, focusing solely on the gradient-based placement optimization.\n- [DeepPlace/PlaceObj.py]: This file implements the core placement optimization model from the DeepPlace paper, specifically the gradient-based optimization for standard cell placement. The PlaceObj class defines the objective function as wirelength + density_weight * density penalty, which corresponds to the paper's objective of minimizing HPWL (approximated via weighted average or log-sum-exp wirelength) and congestion (via density penalty). The code includes wirelength approximation, density potential computation, preconditioning for gradient optimization, and routability-aware operations (RUDY congestion maps) that align with the joint placement-routing objective. The mathematical model is realized through differentiable operators that compute gradients for continuous standard cell positions, while macros are handled separately (not in this file).\n- [DeepPlace/a2c_ppo_acktr/algo/ppo.py]: This file implements the Proximal Policy Optimization (PPO) algorithm, which is a key component of the reinforcement learning framework used in the paper. The PPO.update() method performs the core policy optimization steps: 1) Computing advantages from rollouts, 2) Multiple epochs of mini-batch updates with clipped surrogate objective for policy improvement, 3) Value function optimization with optional clipping, and 4) Entropy regularization for exploration. This directly corresponds to the RL algorithm used for macro placement optimization in the paper's joint learning framework, where the objective (wirelength + congestion) is encoded in the reward signal within the rollouts.\n- [DeepPlace/a2c_ppo_acktr/model.py]: This file implements the multi-view embedding model (CNN + GNN) described in the DeepPlace paper. The CNNBase class processes chip canvas state via CNN (input normalization /255.0) and circuit graph features via GCN layers (GCNLayer). The forward method concatenates CNN and GNN embeddings, which aligns with the paper's multi-view representation for joint placement and routing. The graph structure is built from edge files (edges_1.dat, edges_2.dat) representing circuit connectivity. This neural architecture supports the RL policy (PPO) for macro placement decisions while incorporating routing-aware features through graph convolutions.\n- [DeepPlace/fullplace_env.py]: This file implements the RL environment for macro placement as described in the DeepPlace paper. The Placememt class defines a discrete action space (32x32 grid) where each action corresponds to placing a macro at a grid location. The environment enforces the constraint that each macro is placed exactly once (via the results list) and prevents overlap (via search/find functions that find empty grid cells). The reward function in new_cal_re combines HPWL (wirelength) and overflow (congestion) from DREAMPlace's gradient-based optimization for standard cells, matching the paper's joint optimization objective. The step method implements the RL interaction loop where macro placements are made sequentially, and after all placements are done, DREAMPlace is called to optimize standard cell positions and compute the final reward.\n- [DeepPlace/main.py]: This file implements the core RL training loop for the DeepPlace algorithm. It uses Proximal Policy Optimization (PPO) as specified in the paper's algorithm steps. The code initializes the placement environment (place_envs/fullplace_envs), creates an actor-critic policy network, and runs the PPO training loop with rollouts. The environment step function (envs.step) and reward calculation encapsulate the optimization objective combining HPWL and congestion. The features tensor tracks placed positions (710 components with 2D coordinates), aligning with the placement constraints. The training loop matches the joint learning approach where RL optimizes macro placement while standard cell placement is handled via gradient methods in the environment.\n- [DeepPlace/ops/density_map/density_map.py]: This file implements the density map computation for placement optimization, which directly corresponds to the density constraints in the paper's optimization model. The DensityMap class computes the spatial distribution of cells across bins on the chip canvas, which is essential for evaluating placement legality and congestion. The forward method calculates the density contribution from movable cells while using pre-computed fixed cell density. This density map is used to enforce the constraint that the total cell area in each bin does not exceed available space, which relates to the paper's congestion term Congestion(P, H) in the objective function. The implementation uses both CPU (C++) and GPU (CUDA) backends for performance optimization.\n- [DeepPlace/ops/hpwl/hpwl.py]: This file directly implements the HPWL (Half-Perimeter Wirelength) computation, which is the first term in the optimization objective: $\\sum_{i \\in E} HPWL(n_i)$. The HPWLFunction and HPWLAtomicFunction classes compute the wirelength using two different algorithms (net-by-net and atomic reduction), while the HPWL class provides a unified interface. This is a core component of the wirelength minimization objective in the DeepPlace paper, used for evaluating placement quality during both macro placement (RL) and standard cell placement (gradient optimization).\n- [DeepPlace/place_env.py]: This file implements the core placement environment for the DeepPlace paper. Key aspects:\n1. Mathematical Model Implementation:\n   - Objective: The reward function `cal_re()` computes combined wirelength (HPWL via bounding box) and congestion (via density distribution `con`).\n   - Constraints: The `search()` and `find()` functions enforce the one-cell-per-grid constraint by finding nearest empty locations.\n   - State Representation: The observation is a 3232 grid (upscaled to 8484) tracking placed cells.\n2. Algorithm Steps:\n   - Sequential placement of 710 cells via discrete actions (grid positions).\n   - Uses intrinsic reward (RND) during placement for exploration.\n   - Final reward combines HPWL and congestion with weighting factors (0.1 for wirelength deviation, 0.2 scaling).\n3. Compatibility: Directly implements the placement component of the joint learning framework, though routing is not included in this file. The reward function approximates the paper's objective of minimizing HPWL + Congestion.",
  "dependencies": [
    "a2c_ppo_acktr (custom RL library)",
    "fullplace_env",
    "plot",
    "copy",
    "a2c_ppo_acktr.distributions",
    "rollouts (custom module)",
    "sys",
    "BasicPlace",
    "dreamplace.ops.hpwl.hpwl_cpp",
    "torch.optim",
    "NonLinearPlace",
    "matplotlib",
    "dreamplace.ops.density_map.density_map_cpp",
    "actor_critic (custom neural network module)",
    "time",
    "dreamplace.ops.weighted_average_wirelength",
    "logging",
    "torch.nn.functional",
    "dgl",
    "dreamplace.ops.pin_utilization",
    "gym.utils.seeding",
    "gym.spaces",
    "dreamplace.configure",
    "NesterovAcceleratedGradientOptimizer",
    "dreamplace.ops.nctugr_binary",
    "DensityMapFunction",
    "dreamplace.ops.hpwl.hpwl_cuda_atomic",
    "gym",
    "dreamplace.ops.adjust_node_area",
    "dreamplace.ops.hpwl.hpwl_cpp_atomic",
    "torch.optim.Adam",
    "EvalMetrics",
    "os",
    "place_env",
    "nn.Upsample",
    "rnd.RNDModel",
    "dreamplace.ops.density_map.density_map_cuda",
    "PlaceDB",
    "evaluation",
    "torch.autograd.Function",
    "numpy",
    "dreamplace.ops.logsumexp_wirelength",
    "compute_intrinsic_reward",
    "dreamplace.ops.electric_potential",
    "pdb",
    "PlaceObj",
    "dreamplace.ops.hpwl.hpwl_cuda",
    "torch.nn",
    "dreamplace.ops.density_potential",
    "Params",
    "dreamplace.ops.rudy",
    "torch",
    "a2c_ppo_acktr.utils"
  ]
}