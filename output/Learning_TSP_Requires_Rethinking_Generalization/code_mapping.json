{
  "file_path": "nets/attention_model.py, nets/nar_model.py, problems/tsp/problem_tsp.py, problems/tsp/state_tsp.py, train.py, utils/beam_search.py, utils/nar_beam_search.py",
  "function_name": "AttentionModel.forward, NARModel, TSP.get_costs, StateTSP, train_epoch, train_batch, train_epoch_sl, train_batch_sl, _beam_search, BatchBeam, beam_search, Beamsearch",
  "code_snippet": "\n\n# ==========================================\n# File: nets/attention_model.py\n# Function/Context: AttentionModel.forward\n# ==========================================\nimport math\nimport numpy as np\nfrom typing import NamedTuple\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.checkpoint import checkpoint\nfrom torch.nn import DataParallel\n\nfrom utils.tensor_functions import compute_in_batches\nfrom utils.beam_search import CachedLookup\nfrom utils.functions import sample_many\n\n\nclass AttentionModelFixed(NamedTuple):\n    \"\"\"\n    Context for AttentionModel decoder that is fixed during decoding so can be precomputed/cached\n    This class allows for efficient indexing of multiple Tensors at once\n    \"\"\"\n    node_embeddings: torch.Tensor\n    context_node_projected: torch.Tensor\n    glimpse_key: torch.Tensor\n    glimpse_val: torch.Tensor\n    logit_key: torch.Tensor\n\n    def __getitem__(self, key):\n        if torch.is_tensor(key) or isinstance(key, slice):\n            return AttentionModelFixed(\n                node_embeddings=self.node_embeddings[key],\n                context_node_projected=self.context_node_projected[key],\n                glimpse_key=self.glimpse_key[:, key],  # dim 0 are the heads\n                glimpse_val=self.glimpse_val[:, key],  # dim 0 are the heads\n                logit_key=self.logit_key[key]\n            )\n        return super(AttentionModelFixed, self).__getitem__(key)\n\n\nclass AttentionModel(nn.Module):\n\n    def __init__(self,\n                 problem,\n                 embedding_dim,\n                 encoder_class,\n                 n_encode_layers,\n                 aggregation=\"sum\",\n                 aggregation_graph=\"mean\",\n                 normalization=\"layer\",\n                 learn_norm=True,\n                 track_norm=False,\n                 gated=True,\n                 n_heads=8,\n                 tanh_clipping=10.0,\n                 mask_inner=True,\n                 mask_logits=True,\n                 mask_graph=False,\n                 checkpoint_encoder=False,\n                 shrink_size=None,\n                 extra_logging=False,\n                 *args, **kwargs):\n        super(AttentionModel, self).__init__()\n        \n        self.problem = problem\n        self.embedding_dim = embedding_dim\n        self.encoder_class = encoder_class\n        self.n_encode_layers = n_encode_layers\n        self.aggregation = aggregation\n        self.aggregation_graph = aggregation_graph\n        self.normalization = normalization\n        self.learn_norm = learn_norm\n        self.track_norm = track_norm\n        self.gated = gated\n        self.n_heads = n_heads\n        self.tanh_clipping = tanh_clipping\n        self.mask_inner = mask_inner\n        self.mask_logits = mask_logits\n        self.mask_graph = mask_graph\n        self.checkpoint_encoder = checkpoint_encoder\n        self.shrink_size = shrink_size\n        \n        self.extra_logging = extra_logging\n        \n        self.decode_type = None\n        self.temp = 1.0\n        \n        self.allow_partial = problem.NAME == 'sdvrp'\n        self.is_vrp = problem.NAME == 'cvrp' or problem.NAME == 'sdvrp'\n        self.is_orienteering = problem.NAME == 'op'\n        self.is_pctsp = problem.NAME == 'pctsp'\n\n        if self.is_vrp or self.is_orienteering or self.is_pctsp:\n            step_context_dim = embedding_dim + 1\n\n            if self.is_pctsp:\n                node_dim = 4\n            else:\n                node_dim = 3\n\n            self.init_embed_depot = nn.Linear(2, embedding_dim)\n            \n            if self.is_vrp and self.allow_partial:  \n                self.project_node_step = nn.Linear(1, 3 * embedding_dim, bias=False)\n        \n        else:\n            assert problem.NAME in (\"tsp\", \"tspsl\"), \"Unsupported problem: {}\".format(problem.NAME)\n            step_context_dim = 2 * embedding_dim\n            node_dim = 2\n            self.W_placeholder = nn.Parameter(torch.Tensor(2 * embedding_dim))\n            self.W_placeholder.data.uniform_(-1, 1)\n        \n        self.init_embed = nn.Linear(node_dim, embedding_dim, bias=True)        \n        \n        self.embedder = self.encoder_class(n_layers=n_encode_layers, \n                                           n_heads=n_heads,\n                                           hidden_dim=embedding_dim, \n                                           aggregation=aggregation, \n                                           norm=normalization, \n                                           learn_norm=learn_norm,\n                                           track_norm=track_norm,\n                                           gated=gated)\n\n        self.project_node_embeddings = nn.Linear(embedding_dim, 3 * embedding_dim, bias=False)\n        self.project_fixed_context = nn.Linear(embedding_dim, embedding_dim, bias=False)\n        self.project_step_context = nn.Linear(step_context_dim, embedding_dim, bias=False)\n        assert embedding_dim % n_heads == 0\n        self.project_out = nn.Linear(embedding_dim, embedding_dim, bias=False)\n\n    def forward(self, nodes, graph, supervised=False, targets=None, class_weights=None, return_pi=False):\n        if self.checkpoint_encoder:\n            embeddings = checkpoint(self.embedder, self._init_embed(nodes), graph)\n        else:\n            embeddings = self.embedder(self._init_embed(nodes), graph)\n        \n        if self.extra_logging:\n            self.embeddings_batch = embeddings\n\n        if self.problem.NAME == 'tspsl' and supervised:\n            assert targets is not None, \"Pass targets during training in supervised mode\"\n            \n            _log_p, pi = self._inner(nodes, graph, embeddings, supervised=supervised, targets=targets)\n            \n            if self.extra_logging:\n                self.log_p_batch = _log_p\n                self.log_p_sel_batch = _log_p.gather(2, pi.unsqueeze(-1)).squeeze(-1)\n            \n            cost, mask = self.problem.get_costs(nodes, pi)\n            \n            logits = _log_p.permute(0, 2, 1)\n            logits[logits == -float(np.inf)] = -1000  \n            loss = nn.NLLLoss(reduction='mean')(logits, targets)\n            \n            if return_pi:\n                return cost, loss, pi \n            return cost, loss\n        \n        else:\n            _log_p, pi = self._inner(nodes, graph, embeddings)\n            \n            if self.extra_logging:\n                self.log_p_batch = _log_p\n                self.log_p_sel_batch = _log_p.gather(2, pi.unsqueeze(-1)).squeeze(-1)\n            \n            cost, mask = self.problem.get_costs(nodes, pi)\n            \n            ll = self._calc_log_likelihood(_log_p, pi, mask)\n            \n            if return_pi:\n                return cost, ll, pi\n            return cost, ll\n\n    def _calc_log_likelihood(self, _log_p, a, mask):\n        log_p = _log_p.gather(2, a.unsqueeze(-1)).squeeze(-1)\n\n        if mask is not None:\n            log_p[mask] = 0\n\n        assert (log_p > -1000).data.all(), \"Logprobs should not be -inf, check sampling procedure!\"\n\n        return log_p.sum(1)\n\n    def _init_embed(self, nodes):\n        if self.is_vrp or self.is_orienteering or self.is_pctsp:\n            if self.is_vrp:\n                features = ('demand', )\n            elif self.is_orienteering:\n                features = ('prize', )\n            else:\n                assert self.is_pctsp\n                features = ('deterministic_prize', 'penalty')\n            return torch.cat(\n                (\n                    self.init_embed_depot(nodes['depot'])[:, None, :],\n                    self.init_embed(torch.cat((\n                        nodes['loc'],\n                        *(nodes[feat][:, :, None] for feat in features)\n                    ), -1))\n                ),\n                1\n            )\n        \n        return self.init_embed(nodes)\n\n    def _inner(self, nodes, graph, embeddings, supervised=False, targets=None):\n        outputs = []\n        sequences = []\n        \n        state = self.problem.make_state(nodes, graph)\n\n        fixed = self._precompute(embeddings)\n\n        batch_size, num_nodes, _ = nodes.shape\n\n        i = 0\n        while not (self.shrink_size is None and state.all_finished()):\n\n            if self.shrink_size is not None:\n                unfinished = torch.nonzero(state.get_finished() == 0)\n                if len(unfinished) == 0:\n                    break\n                unfinished = unfinished[:, 0]\n                if 16 <= len(unfinished) <= state.ids.size(0) - self.shrink_size:\n                    # Filter states\n                    # ... (truncated for brevity, but this is the core autoregressive decoding loop)\n\n# ==========================================\n# File: nets/nar_model.py\n# Function/Context: NARModel\n# ==========================================\nimport math\nimport numpy as np\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\nfrom utils.nar_beam_search import Beamsearch\nfrom utils.functions import get_best\n\n\nclass NARModel(nn.Module):\n\n    def __init__(self,\n                 problem,\n                 embedding_dim,\n                 encoder_class,\n                 n_encode_layers,\n                 aggregation=\"sum\",\n                 normalization=\"layer\",\n                 learn_norm=True,\n                 track_norm=False,\n                 gated=True,\n                 n_heads=8,\n                 mask_graph=False,\n                 *args, **kwargs):\n        \"\"\"\n        Models with a GNN/Transformer/MLP encoder and the Non-autoregressive decoder using attention mechanism\n\n        Args:\n            problem: TSP/TSPSL, to identify the learning paradigm\n            embedding_dim: Hidden dimension for encoder/decoder\n            encoder_class: GNN/Transformer/MLP encoder\n            n_encode_layers: Number of layers for encoder\n            aggregation: Aggregation function for GNN encoder\n            normalization: Normalization scheme ('batch'/'layer'/'none')\n            learn_norm: Flag for enabling learnt affine transformation during normalization\n            track_norm: Flag to enable tracking training dataset stats instead of using batch stats during normalization\n            gated: Flag to enbale anisotropic GNN aggregation\n            n_heads: Number of attention heads for Transformer encoder/MHA in decoder\n            mask_graph: Flag to use graph mask during decoding\n\n        References:\n            - A. Nowak, S. Villar, A. S. Bandeira, and J. Bruna. A note on learning algorithms for quadratic assignment with graph neural networks. arXiv preprint arXiv:1706.07450, 2017.\n            - C. K. Joshi, T. Laurent, and X. Bresson. An efficient graph convolutional network technique for the travelling salesman problem. arXiv preprint arXiv:1906.01227, 2019.\n        \"\"\"\n\n        assert problem.NAME in ['tsp', 'tspsl'], \"NAR Attention Decoder only supports TSP and TSPSL.\"\n\n        super(NARModel, self).__init__()\n\n        self.problem = problem\n        self.embedding_dim = embedding_dim\n        self.encoder_class = encoder_class\n        self.n_encode_layers = n_encode_layers\n        self.aggregation = aggregation\n        self.normalization = normalization\n        self.learn_norm = learn_norm\n        self.track_norm = track_norm\n        self.gated = gated\n        self.n_heads = n_heads\n        self.mask_graph = mask_graph\n        \n        # Input embedding layer\n        self.init_embed = nn.Linear(2, embedding_dim, bias=True)        \n        \n        # Encoder model\n        self.embedder = self.encoder_class(n_layers=n_encode_layers, \n                                           n_heads=n_heads,\n                                           hidden_dim=embedding_dim, \n                                           aggregation=aggregation, \n                                           norm=normalization, \n                                           learn_norm=learn_norm,\n                                           track_norm=track_norm,\n                                           gated=gated)\n        \n        # Edge prediction layer\n        self.project_node_emb = nn.Linear(embedding_dim, embedding_dim, bias=True)\n        self.project_graph_emb = nn.Linear(embedding_dim, embedding_dim, bias=True)\n        self.edge_pred = nn.Linear(embedding_dim, 2, bias=True)\n\n    def set_decode_type(self, decode_type, **kwargs):\n        self.decode_type = decode_type\n\n    def forward(self, nodes, graph, supervised=False, targets=None, class_weights=None, return_pi=False):\n        \"\"\"\n        Args:\n            nodes: Input graph nodes (B x V x 2)\n            graph: Graph as **NEGATIVE** adjacency matrices (B x V x V)\n            supervised: Toggles SL training, teacher forcing and BCE loss computation\n            targets: Targets for teacher forcing and BCE loss\n            return_pi: Toggles returning the output sequences \n                       Not compatible with DataParallel as the results \n                       may be of different lengths on different GPUs\n        \"\"\"\n\n        # Supervised learning\n        if self.problem.NAME == 'tspsl' and supervised:\n            assert targets is not None, \"Pass targets during training in supervised mode\"\n            assert class_weights is not None, \"Pass class weights during training in supervised mode for NAR models\"\n            \n            if return_pi:\n                # Perform greedy search during training if we want to log cost, pi during training\n                logits, _, pi, cost = self.greedy_search(nodes, graph)\n                loss = nn.CrossEntropyLoss(weight=class_weights, reduction='mean')(\n                    logits.permute(0, 3, 1, 2), targets)\n                return cost, loss, pi\n\n            else:\n                # Only perform _inner function for faster training\n                logits, _ = self._inner(nodes, graph)\n                loss = nn.CrossEntropyLoss(weight=class_weights, reduction='mean')(\n                    logits.permute(0, 3, 1, 2), targets)\n                return torch.zeros(nodes.shape[0]), loss\n\n        # Reinforcement learning or inference\n        else:\n            _, log_p, pi, cost = self.greedy_search(nodes, graph)\n            ll = self._calc_log_likelihood(log_p[:, :, :, 1], pi)\n\n            if return_pi:\n                return cost, ll, pi\n            return cost, ll\n\n    def _init_embed(self, nodes):\n        return self.init_embed(nodes)\n\n    def _inner(self, nodes, graph):\n        \"\"\"\n        Returns:\n            logits: Unnormalized logits over graph edges (B x V x V x 2)\n            log_p: Log-Softmax over final dimension of `logits` (B x V x V)\n        \"\"\"\n        batch_size, num_nodes, _ = nodes.shape\n        \n        # Compute node embeddings\n        embeddings = self.embedder(self._init_embed(nodes), graph)\n        \n        # Compute edge embeddings (B x V x V x H)\n        Ux = self.project_node_emb(embeddings)\n        Gx = self.project_graph_emb(embeddings.mean(dim=1))\n        edge_embeddings = F.relu(Ux[:, :, None, :] + Ux[:, None, :, :] + Gx[:, None, None, :])\n        \n        if self.mask_graph:\n            edge_embeddings[graph[:, :, :, None].expand_as(edge_embeddings)] = 0\n        \n        # Compute logits\n        logits = self.edge_pred(edge_embeddings)  # B x V x V x 2\n        log_p = F.log_softmax(logits, dim=3)\n        \n        return logits, log_p\n\n    def _calc_log_likelihood(self, _log_p, a):\n        # Get log_p corresponding to selected actions\n        log_p = _log_p.gather(2, a.unsqueeze(-1)).squeeze(-1)\n        assert (log_p > -1000).data.all(), \"Logprobs should not be -inf, check sampling procedure!\"\n        \n        # Calculate log_likelihood\n        return log_p.sum(1)\n\n    def beam_search(self, nodes, graph, beam_size):\n        \"\"\"Method to perform graph search (beam search or greedy search)\n\n        Args:\n            nodes: Input graph nodes (B x V x 2)\n            graph: Graph as **NEGATIVE** adjacency matrices (B x V x V)\n            beam_size: Beam search width (=1 to enable greedy search)\n\n        Returns:\n            logits, log_p: Outputs of inner function\n            pi: Tour sequence for shortest out of `beam_size` candidate tours\n            cost: Tour length for shortest out of `beam_size` candidate tours\n        \"\"\"\n        batch_size, num_nodes, _ = nodes.shape\n\n        # Compute logits\n        logits, log_p = self._inner(nodes, graph)\n        \n        # Perform beamsearch\n        with torch.no_grad():\n            _log_p = log_p.clone().detach()[:, :, :, 1]\n            _log_p[_log_p == 0] = -1e-10  # Set 0s (i.e. log(1)s) to very small negative number\n            \n            beamsearch = Beamsearch(beam_size, batch_size, num_nodes, device=_log_p.device, decode_type=self.decode_type)\n            trans_probs = _log_p.gather(1, beamsearch.get_current_state())\n            for step in range(num_nodes - 1):\n                beamsearch.advance(trans_probs)\n                trans_probs = _log_p.gather(1, beamsearch.get_current_state())\n\n            # Find TSP tour with highest probability among beam_size candidates\n            ends = torch.zeros(batch_size, 1, device=_log_p.device)\n            pi = beamsearch.get_hypothesis(ends)\n            \n            if beam_size == 1:\n                # Compute tour costs\n                cost, _ = self.problem.get_costs(nodes, pi)\n\n            elif beam_size > 1:\n                # Beam search\n                sequences = []\n                costs = []\n                ids = []\n                \n                # Iterate over all positions in beam\n                for pos in range(0, beam_size):\n                    ends = pos * torch.ones(batch_size, 1, device=_log_p.device)  # New positions\n                    \n                    try:\n                        pi_temp = beamsearch.get_hypothesis(ends)\n                        cost_temp, _ = self.problem.get_costs(nodes, pi_temp)\n                        cost_temp, pi_temp = cost_temp.cpu().numpy(), pi_temp.cpu().numpy()\n                        \n                        sequences.append(pi_temp)\n                        costs.append(cost_temp)\n                        ids.append(list(range(batch_size)))\n\n                    except AssertionError:\n                        # Handles error if the temporary solution is an invalid tour\n                        continue\n                    \n                sequences = np.array(sequences)\n                costs = np.array(costs)\n                ids = np.array(ids)\n\n                # Reshape/permute sequences, costs, ids\n                valid_beam, batch_size, num_nodes = sequences.shape\n                sequences = sequences.reshape(valid_beam * batch_size, num_nodes)\n                s_idx = []\n                for i in range(batch_size):\n                    for j in range(valid_beam):\n                        s_idx.append(i + j * batch_size)\n                \n                # Get sequences and costs of shortest tours\n                pi, cost = get_best(sequences[s_idx], costs.T.flatten(), ids.T.flatten())\n\n        return logits, log_p, pi, cost\n\n    def greedy_search(self, nodes, graph):\n        return self.beam_search(nodes, graph, beam_size=1)\n\n    def sample_many(self, nodes, graph, batch_rep=1, iter_rep=1):\n        assert batch_rep == 1 and iter_rep == 1, \"Sampling solutions is not supported. Use beam search instead.\"\n        return self.greedy_search(nodes, graph)\n\n# ==========================================\n# File: problems/tsp/problem_tsp.py\n# Function/Context: TSP.get_costs\n# ==========================================\nfrom torch.utils.data import Dataset\nimport torch\nimport os\nimport pickle\nimport numpy as np\nfrom tqdm import tqdm\nfrom scipy.spatial.distance import pdist, squareform\n\nfrom problems.tsp.state_tsp import StateTSP\nfrom utils.beam_search import beam_search\n\n\ndef nearest_neighbor_graph(nodes, neighbors, knn_strat):\n    \"\"\"Returns k-Nearest Neighbor graph as a **NEGATIVE** adjacency matrix\n    \"\"\"\n    num_nodes = len(nodes)\n    # If `neighbors` is a percentage, convert to int\n    if knn_strat == 'percentage':\n        neighbors = int(num_nodes * neighbors)\n    \n    if neighbors >= num_nodes-1 or neighbors == -1:\n        W = np.zeros((num_nodes, num_nodes))\n    else:\n        # Compute distance matrix\n        W_val = squareform(pdist(nodes, metric='euclidean'))\n        W = np.ones((num_nodes, num_nodes))\n        \n        # Determine k-nearest neighbors for each node\n        knns = np.argpartition(W_val, kth=neighbors, axis=-1)[:, neighbors::-1]\n        # Make connections\n        for idx in range(num_nodes):\n            W[idx][knns[idx]] = 0\n    \n    # Remove self-connections\n    np.fill_diagonal(W, 1)\n    return W\n\n\ndef tour_nodes_to_W(tour_nodes):\n    \"\"\"Computes edge adjacency matrix representation of tour\n    \"\"\"\n    num_nodes = len(tour_nodes)\n    tour_edges = np.zeros((num_nodes, num_nodes))\n    for idx in range(len(tour_nodes) - 1):\n        i = tour_nodes[idx]\n        j = tour_nodes[idx + 1]\n        tour_edges[i][j] = 1\n        tour_edges[j][i] = 1\n    # Add final connection\n    tour_edges[j][tour_nodes[0]] = 1\n    tour_edges[tour_nodes[0]][j] = 1\n    return tour_edges\n\n\nclass TSP(object):\n    \"\"\"Class representing the Travelling Salesman Problem\n    \"\"\"\n\n    NAME = 'tsp'\n\n    @staticmethod\n    def get_costs(dataset, pi):\n        \"\"\"Returns TSP tour length for given graph nodes and tour permutations\n\n        Args:\n            dataset: graph nodes (torch.Tensor)\n            pi: node permutations representing tours (torch.Tensor)\n\n        Returns:\n            TSP tour length, None\n        \"\"\"\n        # Check that tours are valid, i.e. contain 0 to n -1\n        assert (\n            torch.arange(pi.size(1), out=pi.data.new()).view(1, -1).expand_as(pi) ==\n            pi.data.sort(1)[0]\n        ).all(), \"Invalid tour:\\n{}\\n{}\".format(dataset, pi)\n\n        # Gather dataset in order of tour\n        d = dataset.gather(1, pi.unsqueeze(-1).expand_as(dataset))\n\n        # Length is distance (L2-norm of difference) from each next location from its prev and of last from first\n        return (d[:, 1:] - d[:, :-1]).norm(p=2, dim=2).sum(1) + (d[:, 0] - d[:, -1]).norm(p=2, dim=1), None\n\n# ==========================================\n# File: problems/tsp/state_tsp.py\n# Function/Context: StateTSP\n# ==========================================\nimport torch\nfrom typing import NamedTuple\nfrom utils.boolmask import mask_long2bool, mask_long_scatter\n\n\nclass StateTSP(NamedTuple):\n    \"\"\"Class used to keep track of TSP state, mainly used during beam search\n    \"\"\"\n\n    # Fixed input\n    loc: torch.Tensor\n    dist: torch.Tensor\n\n    # If this state contains multiple copies (i.e. beam search) for the same instance, then for memory efficiency\n    # the loc and dist tensors are not kept multiple times, so we need to use the ids to index the correct rows.\n    ids: torch.Tensor  # Keeps track of original fixed data index of rows\n\n    # State\n    first_a: torch.Tensor\n    prev_a: torch.Tensor\n    visited_: torch.Tensor  # Keeps track of nodes that have been visited\n    lengths: torch.Tensor\n    cur_coord: torch.Tensor\n    i: torch.Tensor  # Keeps track of step\n    graph: torch.Tensor\n\n    @property\n    def visited(self):\n        if self.visited_.dtype == torch.uint8:\n            return self.visited_\n        else:\n            return mask_long2bool(self.visited_, n=self.loc.size(-2))\n\n    def __getitem__(self, key):\n        if torch.is_tensor(key) or isinstance(key, slice):  # If tensor, idx all tensors by this tensor:\n            return self._replace(\n                ids=self.ids[key],\n                first_a=self.first_a[key],\n                prev_a=self.prev_a[key],\n                visited_=self.visited_[key],\n                lengths=self.lengths[key],\n                cur_coord=self.cur_coord[key] if self.cur_coord is not None else None,\n            )\n        return super(StateTSP, self).__getitem__(key)\n\n    @staticmethod\n    def initialize(loc, graph, visited_dtype=torch.uint8):\n\n        batch_size, n_loc, _ = loc.size()\n        prev_a = torch.zeros(batch_size, 1, dtype=torch.long, device=loc.device)\n        return StateTSP(\n            loc=loc,\n            dist=(loc[:, :, None, :] - loc[:, None, :, :]).norm(p=2, dim=-1),\n            ids=torch.arange(batch_size, dtype=torch.int64, device=loc.device)[:, None],  # Add steps dimension\n            first_a=prev_a,\n            prev_a=prev_a,\n            # Keep visited with depot so we can scatter efficiently (if there is an action for depot)\n            visited_=(  # Visited as mask is easier to understand, as long more memory efficient\n                torch.zeros(\n                    batch_size, 1, n_loc,\n                    dtype=torch.uint8, device=loc.device\n                )\n                if visited_dtype == torch.uint8\n                else torch.zeros(batch_size, 1, (n_loc + 63) // 64, dtype=torch.int64, device=loc.device)  # Ceil\n            ),\n            lengths=torch.zeros(batch_size, 1, device=loc.device),\n            cur_coord=None,\n            i=torch.zeros(1, dtype=torch.int64, device=loc.device),  # Vector with length num_steps\n            graph=graph\n        )\n\n    def get_final_cost(self):\n\n        assert self.all_finished()\n        # assert self.visited_.\n\n        return self.lengths + (self.loc[self.ids, self.first_a, :] - self.cur_coord).norm(p=2, dim=-1)\n\n    def update(self, selected):\n\n        # Update the state\n        prev_a = selected[:, None]  # Add dimension for step\n\n        # Add the length\n        # cur_coord = self.loc.gather(\n        #     1,\n        #     selected[:, None, None].expand(selected.size(0), 1, self.loc.size(-1))\n        # )[:, 0, :]\n        cur_coord = self.loc[self.ids, prev_a]\n        lengths = self.lengths\n        if self.cur_coord is not None:  # Don't add length for first action (selection of start node)\n            lengths = self.lengths + (cur_coord - self.cur_coord).norm(p=2, dim=-1)  # (batch_dim, 1)\n\n        # Update should only be called with just 1 parallel step,\n        # in which case we can check this way if we should update\n        first_a = prev_a if self.i.item() == 0 else self.first_a\n\n        if self.visited_.dtype == torch.uint8:\n            # Add one dimension since we write a single value\n            visited_ = self.visited_.scatter(-1, prev_a[:, :, None], 1)\n        else:\n            visited_ = mask_long_scatter(self.visited_, prev_a)\n\n        return self._replace(first_a=first_a, prev_a=prev_a, visited_=visited_,\n                             lengths=lengths, cur_coord=cur_coord, i=self.i + 1)\n\n    def all_finished(self):\n        # Exactly n steps\n        return self.i.item() >= self.loc.size(-2)\n\n    def get_current_node(self):\n        return self.prev_a\n\n    def get_mask(self):\n        return self.visited\n    \n    def get_graph_mask(self):\n        batch_size, n_loc, _ = self.loc.size()\n        if self.i.item() == 0:\n            return torch.zeros(batch_size, 1, n_loc, dtype=torch.uint8, device=self.loc.device)\n        else:\n            return self.graph.gather(1, self.prev_a.unsqueeze(-1).expand(-1, -1, n_loc))\n            \n    def get_graph(self):\n        return self.graph\n        \n    def get_nn(self, k=None):\n        # Insert step dimension\n        # Nodes already visited get inf so they do not make it\n        if k is None:\n            k = self.loc.size(-2) - self.i.item()  # Number of remaining\n        return (self.dist[self.ids, :, :] + self.visited.float()[:, :, None, :] * 1e6).topk(k, dim=-1, largest=False)[1]\n\n    def get_nn_current(self, k=None):\n        assert False, \"Currently not implemented, look into which neighbours to use in step 0?\"\n        # Note: if this is called in step 0, it will have k nearest neighbours to node 0, which may not be desired\n        # so it is probably better to use k = None in the first iteration\n        if k is None:\n            k = self.loc.size(-2)\n        k = min(k, self.loc.size(-2) - self.i.item())  # Number of remaining\n        return (\n            self.dist[\n                self.ids,\n                self.prev_a\n            ] +\n            self.visited.float() * 1e6\n        ).topk(k, dim=-1, largest=False)[1]\n\n    def construct_solutions(self, actions):\n        return actions\n\n# ==========================================\n# File: train.py\n# Function/Context: train_epoch, train_batch, train_epoch_sl, train_batch_sl\n# ==========================================\nimport os\nimport time\nfrom tqdm import tqdm\nimport torch\nimport math\nimport numpy as np\n\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom torch.utils.data import DataLoader, RandomSampler\nfrom torch.nn import DataParallel\n\nfrom utils.log_utils import log_values, log_values_sl\nfrom utils.data_utils import BatchedRandomSampler\nfrom utils import move_to\n\n\ndef get_inner_model(model):\n    return model.module if isinstance(model, DataParallel) else model\n\n\ndef set_decode_type(model, decode_type):\n    if isinstance(model, DataParallel):\n        model = model.module\n    model.set_decode_type(decode_type)\n\n\ndef validate(model, dataset, problem, opts):\n    # Validate\n    print(f'\\nValidating on {dataset.size} samples from {dataset.filename}...')\n    cost = rollout(model, dataset, opts)\n    gt_cost = rollout_groundtruth(problem, dataset, opts)\n    opt_gap = ((cost/gt_cost - 1) * 100)\n    \n    print('Validation groundtruth cost: {:.3f} +- {:.3f}'.format(\n        gt_cost.mean(), torch.std(gt_cost)))\n    print('Validation average cost: {:.3f} +- {:.3f}'.format(\n        cost.mean(), torch.std(cost)))\n    print('Validation optimality gap: {:.3f}% +- {:.3f}'.format(\n        opt_gap.mean(), torch.std(opt_gap)))\n\n    return cost.mean(), opt_gap.mean()\n\n\ndef rollout(model, dataset, opts):\n    # Put in greedy evaluation mode!\n    set_decode_type(model, \"greedy\")\n    model.eval()\n    \n    def eval_model_bat(bat):\n        with torch.no_grad():\n            cost, _ = model(move_to(bat['nodes'], opts.device), move_to(bat['graph'], opts.device))\n        return cost.data.cpu()\n\n    return torch.cat([\n        eval_model_bat(bat)\n        for bat in tqdm(\n            DataLoader(dataset, batch_size=opts.batch_size, shuffle=False, num_workers=opts.num_workers), \n            disable=opts.no_progress_bar, ascii=True\n        )\n    ], 0)\n\n\ndef rollout_groundtruth(problem, dataset, opts):\n    return torch.cat([\n        problem.get_costs(bat['nodes'], bat['tour_nodes'])[0]\n        for bat in DataLoader(\n            dataset, batch_size=opts.batch_size, shuffle=False, num_workers=opts.num_workers)\n    ], 0)\n\n\ndef clip_grad_norms(param_groups, max_norm=math.inf):\n    \"\"\"Clips the norms for all param groups to max_norm and returns gradient norms before clipping\n    \"\"\"\n    grad_norms = [\n        torch.nn.utils.clip_grad_norm_(\n            group['params'],\n            max_norm if max_norm > 0 else math.inf,  # Inf so no clipping but still call to calc\n            norm_type=2\n        )\n        for group in param_groups\n    ]\n    grad_norms_clipped = [min(g_norm, max_norm) for g_norm in grad_norms] if max_norm > 0 else grad_norms\n    return grad_norms, grad_norms_clipped\n\n\ndef train_epoch(model, optimizer, baseline, lr_scheduler, epoch, val_datasets, problem, tb_logger, opts):\n    print(\"\\nStart train epoch {}, lr={} for run {}\".format(epoch, optimizer.param_groups[0]['lr'], opts.run_name))\n    step = epoch * (opts.epoch_size // opts.batch_size)\n    start_time = time.time()\n\n    if not opts.no_tensorboard:\n        tb_logger.log_value('learnrate_pg0', optimizer.param_groups[0]['lr'], step)\n\n    # Generate new training data for each epoch\n    train_dataset = baseline.wrap_dataset(\n        problem.make_dataset(\n            min_size=opts.min_size, max_size=opts.max_size, batch_size=opts.batch_size, \n            num_samples=opts.epoch_size, distribution=opts.data_distribution, \n            neighbors=opts.neighbors, knn_strat=opts.knn_strat\n        ))\n    train_dataloader = DataLoader(\n        train_dataset, batch_size=opts.batch_size, shuffle=False, num_workers=opts.num_workers)\n\n    # Put model in train mode!\n    model.train()\n    optimizer.zero_grad()\n    set_decode_type(model, \"sampling\")\n\n    for batch_id, batch in enumerate(tqdm(train_dataloader, disable=opts.no_progress_bar, ascii=True)):\n\n        train_batch(\n            model,\n            optimizer,\n            baseline,\n            epoch,\n            batch_id,\n            step,\n            batch,\n            tb_logger,\n            opts\n        )\n\n        step += 1\n    \n    lr_scheduler.step(epoch)\n\n    epoch_duration = time.time() - start_time\n    print(\"Finished epoch {}, took {} s\".format(epoch, time.strftime('%H:%M:%S', time.gmtime(epoch_duration))))\n\n    if (opts.checkpoint_epochs != 0 and epoch % opts.checkpoint_epochs == 0) or epoch == opts.n_epochs - 1:\n        print('Saving model and state...')\n        torch.save(\n            {\n                'model': get_inner_model(model).state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'rng_state': torch.get_rng_state(),\n                'cuda_rng_state': torch.cuda.get_rng_state_all(),\n                'baseline': baseline.state_dict()\n            },\n            os.path.join(opts.save_dir, 'epoch-{}.pt'.format(epoch))\n        )\n\n    for val_idx, val_dataset in enumerate(val_datasets):\n        avg_reward, avg_opt_gap = validate(model, val_dataset, problem, opts)\n        if not opts.no_tensorboard:\n            tb_logger.log_value('val{}/avg_reward'.format(val_idx+1), avg_reward, step)\n            tb_logger.log_value('val{}/opt_gap'.format(val_idx+1), avg_opt_gap, step)\n\n    baseline.epoch_callback(model, epoch)\n\n\ndef train_batch(model, optimizer, baseline, epoch, \n                batch_id, step, batch, tb_logger, opts):\n    # Unwrap baseline\n    bat, bl_val = baseline.unwrap_batch(batch)\n    \n    # Optionally move Tensors to GPU\n    x = move_to(bat['nodes'], opts.device)\n    graph = move_to(bat['graph'], opts.device)\n    bl_val = move_to(bl_val, opts.device) if bl_val is not None else None\n\n    # Evaluate model, get costs and log probabilities\n    cost, log_likelihood = model(x, graph)\n\n    # Evaluate baseline, get baseline loss if any (only for critic)\n    bl_val, bl_loss = baseline.eval(x, graph, cost) if bl_val is None else (bl_val, 0)\n\n    # Calculate loss\n    reinforce_loss = ((cost - bl_val) * log_likelihood).mean()\n    loss = reinforce_loss + bl_loss\n    \n    # Normalize loss for gradient accumulation\n    loss = loss / opts.accumulation_steps\n\n    # Perform backward pass\n    loss.backward()\n    \n    # Clip gradient norms and get (clipped) gradient norms for logging\n    grad_norms = clip_grad_norms(optimizer.param_groups, opts.max_grad_norm)\n    \n    # Perform optimization step after accumulating gradients\n    if step % opts.accumulation_steps == 0:\n        optimizer.step()\n        optimizer.zero_grad()\n\n    # Logging\n    if step % int(opts.log_step) == 0:\n        log_values(cost, grad_norms, epoch, batch_id, step, log_likelihood, \n                   reinforce_loss, bl_loss, tb_logger, opts)\n\n        \ndef train_epoch_sl(model, optimizer, lr_scheduler, epoch, train_dataset, val_datasets, problem, tb_logger, opts):\n    print(\"\\nStart train epoch {}, lr={} for run {}\".format(epoch, optimizer.param_groups[0]['lr'], opts.run_name))\n    step = epoch * (opts.epoch_size // opts.batch_size)\n    start_time = time.time()\n\n    if not opts.no_tensorboard:\n        tb_logger.log_value('learnrate_pg0', optimizer.param_groups[0]['lr'], step)\n\n    # Create data loader with random sampling\n    train_dataloader = DataLoader(train_dataset, batch_size=opts.batch_size, num_workers=opts.num_workers, \n                                  sampler=BatchedRandomSampler(train_dataset, opts.batch_size))\n\n    # Put model in train mode!\n    model.train()\n    optimizer.zero_grad()\n    set_decode_type(model, \"greedy\")\n\n    for batch_id, batch in enumerate(tqdm(train_dataloader, disable=opts.no_progress_bar, ascii=True)):\n\n        train_batch_sl(\n            model,\n            optimizer,\n            epoch,\n            batch_id,\n            step,\n            batch,\n            tb_logger,\n            opts\n        )\n\n        step += 1\n    \n    lr_scheduler.step(epoch)\n\n    epoch_duration = time.time() - start_time\n    print(\"Finished epoch {}, took {} s\".format(epoch, time.strftime('%H:%M:%S', time.gmtime(epoch_duration))))\n\n    if (opts.checkpoint_epochs != 0 and epoch % opts.checkpoint_epochs == 0) or epoch == opts.n_epochs - 1:\n        print('Saving model and state...')\n        torch.save(\n            {\n                'model': get_inner_model(model).state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'rng_state': torch.get_rng_state(),\n                'cuda_rng_state': torch.cuda.get_rng_state_all()\n            },\n            os.path.join(opts.save_dir, 'epoch-{}.pt'.format(epoch))\n        )\n\n    for val_idx, val_dataset in enumerate(val_datasets):\n        avg_reward, avg_opt_gap = validate(model, val_dataset, problem, opts)\n        if not opts.no_tensorboard:\n            tb_logger.log_value('val{}/avg_reward'.format(val_idx+1), avg_reward, step)\n            tb_logger.log_value('val{}/opt_gap'.format(val_idx+1), avg_opt_gap, step)\n    \n\ndef train_batch_sl(model, optimizer, epoch, batch_id, \n                   step, batch, tb_logger, opts):\n    # Optionally move Tensors to GPU\n    x = move_to(batch['nodes'], opts.device)\n    graph = move_to(batch['graph'], opts.device)\n    \n    if opts.model == 'nar':\n        targets = move_to(batch['tour_edges'], opts.device)\n        # Compute class weights for NAR decoder\n        _targets = batch['tour_edges'].numpy().flatten()\n        class_weights = compute_class_weight(\"balanced\", classes=np.unique(_targets), y=_targets)\n        class_weights = move_to(torch.FloatTensor(class_weights), opts.device)\n    else:\n        class_weights = None\n        targets = move_to(batch['tour_nodes'], opts.device)\n    \n    # Evaluate model, get costs and loss\n    cost, loss = model(x, graph, supervised=True, targets=targets, class_weights=class_weights)\n    \n    # Normalize loss for gradient accumulation\n    loss = loss / opts.accumulation_steps\n    \n    # Perform backward pass\n    loss.backward()\n    \n    # Clip gradient norms and get (clipped) gradient norms for logging\n    grad_norms = clip_grad_norms(optimizer.param_groups, opts.max_grad_norm)\n    \n    # Perform optimization step after accumulating gradients\n    if step % opts.accumulation_steps == 0:\n        optimizer.step()\n        optimizer.zero_grad()\n\n    # Logging\n    if step % int(opts.log_step) == 0:\n        log_values_sl(cost, grad_norms, epoch, batch_id, \n                      step, loss, tb_logger, opts)\n\n# ==========================================\n# File: utils/beam_search.py\n# Function/Context: _beam_search, BatchBeam, beam_search\n# ==========================================\nimport time\nimport torch\nfrom typing import NamedTuple\nfrom utils.lexsort import torch_lexsort\n\n\ndef beam_search(*args, **kwargs):\n    beams, final_state = _beam_search(*args, **kwargs)\n    return get_beam_search_results(beams, final_state)\n\n\ndef get_beam_search_results(beams, final_state):\n    beam = beams[-1]  # Final beam\n    if final_state is None:\n        return None, None, None, None, beam.batch_size\n\n    # First state has no actions/parents and should be omitted when backtracking\n    actions = [beam.action for beam in beams[1:]]\n    parents = [beam.parent for beam in beams[1:]]\n\n    solutions = final_state.construct_solutions(backtrack(parents, actions))\n    return beam.score, solutions, final_state.get_final_cost()[:, 0], final_state.ids.view(-1), beam.batch_size\n\n\ndef _beam_search(state, beam_size, propose_expansions=None,\n                keep_states=False):\n\n    beam = BatchBeam.initialize(state)\n\n    # Initial state\n    beams = [beam if keep_states else beam.clear_state()]\n\n    # Perform decoding steps\n    while not beam.all_finished():\n\n        # Use the model to propose and score expansions\n        parent, action, score = beam.propose_expansions() if propose_expansions is None else propose_expansions(beam)\n        if parent is None:\n            return beams, None\n\n        # Expand and update the state according to the selected actions\n        beam = beam.expand(parent, action, score=score)\n\n        # Get topk\n        beam = beam.topk(beam_size)\n\n        # Collect output of step\n        beams.append(beam if keep_states else beam.clear_state())\n\n    # Return the final state separately since beams may not keep state\n    return beams, beam.state\n\n\nclass BatchBeam(NamedTuple):\n    \"\"\"\n    Class that keeps track of a beam for beam search in batch mode.\n    Since the beam size of different entries in the batch may vary, the tensors are not (batch_size, beam_size, ...)\n    but rather (sum_i beam_size_i, ...), i.e. flattened. This makes some operations a bit cumbersome.\n    \"\"\"\n    score: torch.Tensor  # Current heuristic score of each entry in beam (used to select most promising)\n    state: None  # To track the state\n    parent: torch.Tensor\n    action: torch.Tensor\n    batch_size: int  # Can be used for optimizations if batch_size = 1\n    device: None  # Track on which device\n\n    # Indicates for each row to which batch it belongs (0, 0, 0, 1, 1, 2, ...), managed by state\n    @property\n    def ids(self):\n        return self.state.ids.view(-1)  # Need to flat as state has steps dimension\n\n    def __getitem__(self, key):\n        if torch.is_tensor(key) or isinstance(key, slice):  # If tensor, idx all tensors by this tensor:\n            return self._replace(\n                # ids=self.ids[key],\n                score=self.score[key] if self.score is not None else None,\n                state=self.state[key],\n                parent=self.parent[key] if self.parent is not None else None,\n                action=self.action[key] if self.action is not None else None\n            )\n        return super(BatchBeam, self).__getitem__(key)\n\n    # Do not use __len__ since this is used by namedtuple internally and should be number of fields\n    # def __len__(self):\n    #     return len(self.ids)\n\n    @staticmethod\n    def initialize(state):\n        batch_size = len(state.ids)\n        device = state.ids.device\n        return BatchBeam(\n            score=torch.zeros(batch_size, dtype=torch.float, device=device),\n            state=state,\n            parent=None,\n            action=None,\n            batch_size=batch_size,\n            device=device\n        )\n\n    def propose_expansions(self):\n        mask = self.state.get_mask()\n        # Mask always contains a feasible action\n        expansions = torch.nonzero(mask[:, 0, :] == 0)\n        parent, action = torch.unbind(expansions, -1)\n        return parent, action, None\n\n    def expand(self, parent, action, score=None):\n        return self._replace(\n            score=score,  # The score is cleared upon expanding as it is no longer valid, or it must be provided\n            state=self.state[parent].update(action),  # Pass ids since we replicated state\n            parent=parent,\n            action=action\n        )\n\n    def topk(self, k):\n        idx_topk = segment_topk_idx(self.score, k, self.ids)\n        return self[idx_topk]\n\n    def all_finished(self):\n        return self.state.all_finished()\n\n    def cpu(self):\n        return self.to(torch.device('cpu'))\n\n    def to(self, device):\n        if device == self.device:\n            return self\n        return self._replace(\n            score=self.score.to(device) if self.score is not None else None,\n            state=self.state.to(device),\n            parent=self.parent.to(device) if self.parent is not None else None,\n            action=self.action.to(device) if self.action is not None else None\n        )\n\n    def clear_state(self):\n        return self._replace(state=None)\n\n    def size(self):\n        return self.state.ids.size(0)\n\n\ndef segment_topk_idx(x, k, ids):\n    \"\"\"\n    Finds the topk per segment of data x given segment ids (0, 0, 0, 1, 1, 2, ...).\n    Note that there may be fewer than k elements in a segment so the returned length index can vary.\n    x[result], ids[result] gives the sorted elements per segment as well as corresponding segment ids after sorting.\n    :param x:\n    :param k:\n    :param ids:\n    :return:\n    \"\"\"\n    assert x.dim() == 1\n    assert ids.dim() == 1\n\n    # Since we may have varying beam size per batch entry we cannot reshape to (batch_size, beam_size)\n    # And use default topk along dim -1, so we have to be creative\n    # Now we have to get the topk per segment which is really annoying :(\n    # we use lexsort on (ids, score), create array with offset per id\n    # offsets[ids] then gives offsets repeated and only keep for which arange(len) < offsets + k\n    splits_ = torch.nonzero(ids[1:] - ids[:-1])\n\n    if len(splits_) == 0:  # Only one group\n        _, idx_topk = x.topk(min(k, x.size(0)))\n        return idx_topk\n\n    splits = torch.cat((ids.new_tensor([0]), splits_[:, 0] + 1))\n    # Make a new array in which we store for each id the offset (start) of the group\n    # This way ids does not need to be increasing or adjacent, as long as each group is a single range\n    group_offsets = splits.new_zeros((splits.max() + 1,))\n    group_offsets[ids[splits]] = splits\n    offsets = group_offsets[ids]  # Look up offsets based on ids, effectively repeating for the repetitions per id\n\n    # We want topk so need to sort x descending so sort -x (be careful with unsigned data type!)\n    idx_sorted = torch_lexsort((-(x if x.dtype != torch.uint8 else x.int()).detach(), ids))\n\n    # This will filter first k per group (example k = 2)\n    # ids     = [0, 0, 0, 1, 1, 1, 1, 2]\n    # splits  = [0, 3, 7]\n    # offsets = [0, 0, 0, 3, 3, 3, 3, 7]\n    # offs+2  = [2, 2, 2, 5, 5, 5, 5, 9]\n    # arange  = [0, 1, 2, 3, 4, 5, 6, 7]\n    # filter  = [1, 1, 0, 1, 1, 0, 0, 1]\n    # Use filter to get only topk of sorting idx\n    return idx_sorted[torch.arange(ids.size(0), out=ids.new()) < offsets + k]\n\n\ndef backtrack(parents, actions):\n\n    # Now backtrack to find aligned action sequences in reversed order\n    cur_parent = parents[-1]\n    reversed_aligned_sequences = [actions[-1]]\n    for parent, sequence in reversed(list(zip(parents[:-1], actions[:-1]))):\n        reversed_aligned_sequences.append(sequence.gather(-1, cur_parent))\n        cur_parent = parent.gather(-1, cur_parent)\n\n    return torch.stack(list(reversed(reversed_aligned_sequences)), -1)\n\n# ==========================================\n# File: utils/nar_beam_search.py\n# Function/Context: Beamsearch\n# ==========================================\nimport math\nimport numpy as np\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nclass Beamsearch(object):\n    \"\"\"Class for managing internals of beamsearch procedure.\n\n    References:\n        - General: https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/translate/beam.py\n        - For TSP: https://github.com/chaitjo/graph-convnet-tsp/blob/master/utils/beamsearch.py\n    \"\"\"\n\n    def __init__(self, beam_size, batch_size, num_nodes, device='cpu', decode_type='greedy'):\n        \"\"\"\n        Args:\n            beam_size: Beam size\n            batch_size: Batch size\n            num_nodes: Number of nodes in TSP tours\n            device: GPU/CPU device\n            decode_type: Allows sampling from multinomial or greedy decoding\n        \"\"\"\n        # Beamsearch parameters\n        self.batch_size = batch_size\n        self.beam_size = beam_size\n        self.num_nodes = num_nodes\n        self.device = device\n        self.decode_type = decode_type\n        # Set beamsearch starting nodes\n        self.start_nodes = torch.zeros(batch_size, beam_size, dtype=torch.long).to(self.device)\n        # Mask for constructing valid hypothesis\n        self.mask = torch.ones(batch_size, beam_size, num_nodes, dtype=torch.float).to(self.device)\n        self.update_mask(self.start_nodes)  # Mask the starting node of the beam search\n        # Score for each translation on the beam\n        self.scores = torch.zeros(batch_size, beam_size, dtype=torch.float).to(self.device)\n        self.all_scores = []\n        # Backpointers at each time-step\n        self.prev_Ks = []\n        # Outputs at each time-step\n        self.next_nodes = [self.start_nodes]\n\n    def get_current_state(self):\n        \"\"\"Get the output of the beam at the current timestep.\n        \"\"\"\n        current_state = (self.next_nodes[-1].unsqueeze(2)\n                         .expand(self.batch_size, self.beam_size, self.num_nodes))\n        return current_state\n\n    def get_current_origin(self):\n        \"\"\"Get the backpointers for the current timestep.\n        \"\"\"\n        return self.prev_Ks[-1]\n\n    def advance(self, trans_probs):\n        \"\"\"Advances the beam based on transition probabilities.\n\n        Args:\n            trans_probs: Probabilities of advancing from the previous step (batch_size, beam_size, num_nodes)\n        \"\"\"\n        # Compound the previous scores\n        if len(self.prev_Ks) > 0:\n            beam_lk = trans_probs + self.scores.unsqueeze(2).expand_as(trans_probs)\n        else:\n            beam_lk = trans_probs\n            beam_lk[:, 1:] = -1e10 * torch.ones(beam_lk[:, 1:].size(), dtype=torch.float).to(self.device)\n        # Multiply by mask\n        beam_lk = beam_lk * self.mask\n        beam_lk = beam_lk.view(self.batch_size, -1)  # (batch_size, beam_size * num_nodes)\n        # Get top k scores and indexes (k = beam_size)\n        bestScores, bestScoresId = beam_lk.topk(self.beam_size, 1, True, True)\n        # Update scores\n        self.scores = bestScores\n        # Update backpointers\n        prev_k = bestScoresId / self.num_nodes\n        self.prev_Ks.append(prev_k)\n        # Update outputs\n        new_nodes = bestScoresId - prev_k * self.num_nodes\n        self.next_nodes.append(new_nodes)\n        # Re-index mask\n        perm_mask = prev_k.unsqueeze(2).expand_as(self.mask)  # (batch_size, beam_size, num_nodes)\n        self.mask = self.mask.gather(1, perm_mask)\n        # Mask newly added nodes\n        self.update_mask(new_nodes)\n\n    def update_mask(self, new_nodes):\n        \"\"\"Sets new_nodes to zero in mask.\n        \"\"\"\n        arr = (torch.arange(0, self.num_nodes).unsqueeze(0).unsqueeze(1)\n               .expand_as(self.mask).type(torch.long).to(self.device))\n        new_nodes = new_nodes.unsqueeze(2).expand_as(self.mask)\n        update_mask = 1 - torch.eq(arr, new_nodes).type(torch.float).to(self.device)\n        self.mask = self.mask * update_mask\n        self.mask[self.mask == 0] = 1e10\n\n    def sort_best(self):\n        \"\"\"Sort the beam.\n        \"\"\"\n        return torch.sort(self.scores, 0, True)\n\n    def get_best(self):\n        \"\"\"Get the score and index of the best hypothesis in the beam.\n        \"\"\"\n        scores, ids = self.sort_best()\n        return scores[1], ids[1]\n\n    def get_hypothesis(self, k):\n        \"\"\"Walk back to construct the full hypothesis.\n\n        Args:\n            k: Position in the beam to construct (usually 0s for most probable hypothesis)\n        \"\"\"\n        assert self.num_nodes == len(self.prev_Ks) + 1\n        \n        k = k.type(torch.long).to(self.device)\n        hyp = -1 * torch.ones(self.batch_size, self.num_nodes, dtype=torch.long).to(self.device)\n        for j in range(len(self.prev_Ks) - 1, -2, -1):\n            hyp[:, j + 1] = self.next_nodes[j + 1].gather(1, k).view(1, self.batch_size)\n            k = self.prev_Ks[j].gather(1, k)\n        return hyp",
  "description": "Combined Analysis:\n- [nets/attention_model.py]: This file implements the core neural combinatorial optimization pipeline described in the paper. It contains the AttentionModel class that performs:\n1. Graph embedding using GNN/Transformer/MLP encoder (self.embedder)\n2. Autoregressive solution decoding via attention mechanism (_inner method)\n3. Training with both supervised learning (imitating optimal tours) and reinforcement learning (policy gradient)\n\nThe model takes 2D Euclidean coordinates as input, embeds them through the encoder, then uses an autoregressive decoder with attention to sequentially construct TSP tours. The forward method handles both training paradigms and computes tour costs via the problem's get_costs method. The implementation matches the paper's described architecture with configurable encoder types, attention heads, and masking strategies.\n- [nets/nar_model.py]: This file implements the core neural network architecture for non-autoregressive TSP solving as described in the paper. It contains: 1) Graph embedding via GNN/Transformer/MLP encoder (embedder), 2) Non-autoregressive decoder that predicts edge probabilities using attention mechanisms, 3) Beam search decoding to construct valid tours from edge probabilities, 4) Integration of both supervised learning (cross-entropy loss with teacher forcing) and reinforcement learning (log-likelihood computation) paradigms. The mathematical optimization model is executed through beam search that enforces permutation constraints and computes tour costs via problem.get_costs().\n- [problems/tsp/problem_tsp.py]: This file implements the core optimization objective for the Euclidean TSP. The TSP.get_costs() method directly computes the mathematical objective: minimizing the total Euclidean distance of a tour permutation. It validates permutation constraints (each city visited exactly once) and computes the L2-norm distances between consecutive cities including the return to origin. The implementation matches the mathematical formulation exactly: $\\min \\left( \\|x_{\\pi_n} - x_{\\pi_1}\\|_2 + \\sum_{i=1}^{n-1} \\|x_{\\pi_i} - x_{\\pi_{i+1}}\\|_2 \\right)$. The file also provides infrastructure for dataset generation, k-NN graph construction, and beam search decoding - all essential components of the neural combinatorial optimization pipeline described in the paper.\n- [problems/tsp/state_tsp.py]: This file implements the core state management logic for the TSP optimization model. The StateTSP class tracks the solution construction process during beam search/decoding, implementing key aspects of the TSP mathematical model:\n\n1. Objective Calculation: The `get_final_cost()` method computes the complete tour length by adding the return distance from last to first city to the accumulated `lengths`. The `update()` method incrementally adds Euclidean distances between consecutive cities using L2 norm.\n\n2. Constraint Enforcement: The `visited_` tensor and `get_mask()` method enforce the constraint that each city is visited exactly once by masking already-visited cities. The `all_finished()` method ensures exactly n steps are taken.\n\n3. State Representation: The class maintains all necessary state variables: current/last city (`prev_a`), first city (`first_a`), visited mask, accumulated tour length, and current coordinates.\n\n4. Algorithm Integration: This state management system supports the autoregressive decoding described in the paper, where solutions are constructed step-by-step. The `update()` method implements the state transition when a new city is selected, while `initialize()` sets up the initial state.\n\nThe implementation directly corresponds to the TSP optimization model: minimizing Euclidean distance while visiting each city exactly once and returning to the origin.\n- [train.py]: This file implements the core training algorithms for the neural combinatorial optimization pipeline described in the paper. It contains two main training paradigms: 1) Reinforcement Learning (RL) using policy gradient methods (REINFORCE with baseline) in train_epoch/train_batch, which directly optimizes the TSP tour length objective. 2) Supervised Learning (SL) in train_epoch_sl/train_batch_sl, which trains the model to imitate optimal tours from Concorde. Both methods use the same neural network architecture (GNN encoder + decoder) and evaluation protocols. The code handles gradient accumulation, clipping, logging, and model checkpointing. The mathematical optimization model is implemented through the problem.get_costs function (computes Euclidean distances) and the neural network's output (tour probabilities).\n- [utils/beam_search.py]: This file implements the beam search algorithm for neural combinatorial optimization, which is a key component of the solution decoding step in the pipeline. It provides a batch-aware beam search that maintains multiple candidate solutions (beams) and expands them using a learned policy (propose_expansions). The algorithm handles the combinatorial constraints implicitly through state masks and backtracking to construct valid tours. While it doesn't directly encode the TSP objective function, it orchestrates the search for high-quality permutations that minimize tour length, interfacing with neural network models for scoring expansions.\n- [utils/nar_beam_search.py]: This file implements the beam search decoding algorithm for the TSP solution generation. It directly corresponds to the 'Solution Decoding' step in the neural combinatorial optimization pipeline. The Beamsearch class manages the construction of valid TSP tours (permutations) by maintaining masks to enforce the constraint that each node is visited exactly once (_i  _j for all i  j). It uses transition probabilities from a neural network decoder to sequentially build tours while tracking multiple hypotheses (beams). The advance() method combines scores and applies masks to ensure valid tours, implementing the core search logic for generating candidate permutations that minimize tour length.",
  "dependencies": [
    "nearest_neighbor_graph",
    "typing.NamedTuple",
    "utils.log_utils.log_values",
    "utils.functions.sample_many",
    "utils.beam_search.beam_search",
    "utils.boolmask.mask_long2bool",
    "self.problem.get_costs",
    "model.set_decode_type",
    "utils.move_to",
    "torch.utils.data.DataLoader",
    "time",
    "problem.get_costs",
    "scipy.spatial.distance.pdist",
    "sklearn.utils.class_weight.compute_class_weight",
    "utils.data_utils.BatchedRandomSampler",
    "utils.lexsort.torch_lexsort",
    "torch.nn.functional",
    "utils.nar_beam_search.Beamsearch",
    "utils.boolmask.mask_long_scatter",
    "utils.beam_search.CachedLookup",
    "problems.tsp.state_tsp.StateTSP",
    "model.forward",
    "torch.utils.checkpoint.checkpoint",
    "baseline.wrap_dataset",
    "utils.functions.get_best",
    "baseline.unwrap_batch",
    "tour_nodes_to_W",
    "utils.tensor_functions.compute_in_batches",
    "tqdm",
    "math",
    "scipy.spatial.distance.squareform",
    "utils.log_utils.log_values_sl",
    "os",
    "torch.utils.data.RandomSampler",
    "baseline.eval",
    "numpy",
    "torch.nn.DataParallel",
    "baseline.epoch_callback",
    "torch.nn",
    "torch"
  ]
}