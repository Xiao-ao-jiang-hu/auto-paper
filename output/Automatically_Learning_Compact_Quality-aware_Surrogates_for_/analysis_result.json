{
  "paper_id": "Automatically_Learning_Compact_Quality-aware_Surrogates_for_",
  "title": "Automatically Learning Compact Quality-aware Surrogates for Optimization Problems",
  "abstract": "Solving optimization problems with unknown parameters often requires learning a predictive model to predict the values of the unknown parameters and then solving the problem using these values. Recent work has shown that including the optimization problem as a layer in the model training pipeline results in predictions of the unobserved parameters that lead to higher decision quality. Unfortunately, this process comes at a large computational cost because the optimization problem must be solved and differentiated through in each training iteration; furthermore, it may also sometimes fail to improve solution quality due to non-smoothness issues that arise when training through a complex optimization layer. To address these shortcomings, we learn a low-dimensional surrogate model of a large optimization problem by representing the feasible space in terms of meta-variables, each of which is a linear combination of the original variables. By training a low-dimensional surrogate model end-to-end, and jointly with the predictive model, we achieve: i) a large reduction in training and inference time; and ii) improved performance by focusing attention on the more important variables in the optimization and learning in a smoother space. Empirically, we demonstrate these improvements on a non-convex adversary modeling task, a submodular recommendation task and a convex portfolio optimization task.",
  "problem_description_natural": "The paper addresses decision-making under uncertainty where key parameters of an optimization problem are unknown at decision time but can be predicted from available features. The goal is to learn a predictive model that maps features to parameter estimates such that, when these estimates are plugged into the optimization problem, the resulting decisions perform well on the true (unknown) parameters. Instead of solving the full optimization problem during training—which is computationally expensive and may cause non-smooth gradients—the authors propose replacing it with a compact surrogate problem defined over a low-dimensional space of 'meta-variables', each a linear combination of the original decision variables. This surrogate is learned jointly with the predictive model to maximize decision quality while reducing computational cost.",
  "problem_type": "Mixed-type optimization (includes convex, submodular, and non-convex problems)",
  "datasets": [
    "MovieLens",
    "Quandl WIKI dataset",
    "Random geometric graphs"
  ],
  "performance_metrics": [
    "Regret"
  ],
  "lp_model": {
    "objective": "$\\max_{\\mathbf{x}} \\sum_{j \\in C} \\max_{\\substack{z_j \\in \\{0,1\\}^n \\\\ \\text{s.t.} \\sum_i z_{ij} = T}} \\sum_{i=1}^{n} x_i z_{ij} \\theta_{ij}$",
    "constraints": [
      "$x_i \\in \\{0,1\\} \\quad \\forall i$",
      "$\\sum_{i=1}^{n} x_i = k$"
    ],
    "variables": [
      "$x_i$: binary decision variable for acquiring movie $i$"
    ]
  },
  "raw_latex_model": "$$\\begin{aligned} \\max_{\\mathbf{x}} & \\sum_{j \\in C} \\max_{\\substack{z_j \\in \\{0,1\\}^n \\\\ \\text{s.t.} \\sum_i z_{ij} = T}} \\sum_{i=1}^{n} x_i z_{ij} \\theta_{ij} \\\\ \\text{s.t.} & x_i \\in \\{0,1\\} \\quad \\forall i, \\\\ & \\sum_{i=1}^{n} x_i = k \\end{aligned}$$",
  "algorithm_description": "The paper uses a surrogate learning approach where a linear reparameterization matrix $P$ is learned to create a low-dimensional surrogate optimization problem. This surrogate is solved and differentiated through using differentiable optimization techniques (e.g., via KKT conditions), enabling joint training of the predictive model and the surrogate to minimize decision-focused loss, thereby improving scalability and solution quality."
}