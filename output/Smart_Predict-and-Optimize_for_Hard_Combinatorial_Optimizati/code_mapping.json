{
  "file_path": "EnergyCost/ICON.py, EnergyCost/SPO.py, EnergyCost/SelectiveRegression.py, EnergyCost/regression_SPO.py, EnergyCost/torch_SPO_updated.py, KnapsackSolving.py, QPTL/melding_knapsack.py, QPTL_ICON/qptl_model.py, SPO_dp_lr.py, sgd_learner.py",
  "function_name": "Gurobi_ICON, SGD_SPO.fit, Pytorch_SelReg.fit, Regression_generic, SGD_SPO_generic, solveKnapsackProblem, solveKnapsackProblemRelaxation, regret_knapsack, qptl, qptl_ICON, SGD_SPO_dp_lr.fit, Multiple functions implementing SPO framework",
  "code_snippet": "\n\n# ==========================================\n# File: EnergyCost/ICON.py\n# Function/Context: Gurobi_ICON\n# ==========================================\nimport math\nimport numpy as np\nfrom gurobipy import *\nimport logging\n\ndef data_reading(filename):\n    with open(filename) as f:\n        mylist = f.read().splitlines()\n    \n    q= int(mylist[0])\n    nbResources = int(mylist[1])\n    nbMachines =int(mylist[2])\n    idle = [None]*nbMachines\n    up = [None]*nbMachines\n    down = [None]*nbMachines\n    MC = [None]*nbMachines\n    for m in range(nbMachines):\n        l = mylist[2*m+3].split()\n        idle[m] = int(l[1])\n        up[m] = float(l[2])\n        down[m] = float(l[3])\n        MC[m] = list(map(int, mylist[2*(m+2)].split()))\n    lines_read = 2*nbMachines + 2\n    nbTasks = int(mylist[lines_read+1])\n    U = [None]*nbTasks\n    D=  [None]*nbTasks\n    E=  [None]*nbTasks\n    L=  [None]*nbTasks\n    P=  [None]*nbTasks\n    for f in range(nbTasks):\n        l = mylist[2*f + lines_read+2].split()\n        D[f] = int(l[1])\n        E[f] = int(l[2])\n        L[f] = int(l[3])\n        P[f] = float(l[4])\n        U[f] = list(map(int, mylist[2*f + lines_read+3].split()))\n    return {\"nbMachines\":nbMachines,\n                \"nbTasks\":nbTasks,\"nbResources\":nbResources,\n                \"MC\":MC,\n                \"U\":U,\n                \"D\":D,\n                \"E\":E,\n                \"L\":L,\n                \"P\":P,\n                \"idle\":idle,\n                \"up\":up,\n                \"down\":down,\n                \"q\":q}\n\nclass Gurobi_ICON:\n    def __init__(self,nbMachines,nbTasks,nbResources,MC,U,D,E,L,P,idle,up,down,q,reset,presolve, relax=False,\n        verbose=False,warmstart=False,method=-1,**h):\n        self.nbMachines  = nbMachines\n        self.nbTasks = nbTasks\n        self.nbResources = nbResources\n        self.MC = MC\n        self.U =  U\n        self.D = D\n        self.E = E\n        self.L = L\n        self.P = P\n        self.idle = idle\n        self.up = up\n        self.down = down\n        self.q= q\n        self.relax = relax\n        self.verbose = verbose\n        self.method = method\n        self.sol_hist = []\n        self.presolve = presolve\n        self.reset = reset\n        self.warmstart = warmstart\n    \n    def make_model(self):\n        Machines = range(self.nbMachines)\n        Tasks = range(self.nbTasks)\n        Resources = range(self.nbResources)\n        MC = self.MC\n        U =  self.U\n        D = self.D\n        E = self.E\n        L = self.L\n        P = self.P\n        idle = self.idle\n        up = self.up\n        down = self.down\n        relax = self.relax\n        q= self.q\n        N = 1440//q\n        M = Model(\"icon\")\n        if not self.verbose:\n            M.setParam('OutputFlag', 0)\n        if relax:\n            x = M.addVars(Tasks, Machines, range(N), lb=0., ub=1., vtype=GRB.CONTINUOUS, name=\"x\")\n        else:\n            x = M.addVars(Tasks, Machines, range(N), vtype=GRB.BINARY, name=\"x\")\n        M.addConstrs( x.sum(f,'*',range(E[f])) == 0 for f in Tasks)\n        M.addConstrs( x.sum(f,'*',range(L[f]-D[f]+1,N)) == 0 for f in Tasks)\n        M.addConstrs(( quicksum(x[(f,m,t)] for t in range(N) for m in Machines) == 1  for f in Tasks))\n        for r in Resources:\n            for m in Machines:\n                for t in range(N):\n                    M.addConstr( quicksum( quicksum(x[(f,m,t1)]  for t1 in range(max(0,t-D[f]+1),t+1) )*\n                                   U[f][r] for f in Tasks) <= MC[m][r])   \n        if self.presolve:\n            M = M.presolve()\n        else:\n            M.update()\n        self.model = M\n        self.x = dict()\n        for var in M.getVars():\n            name = var.varName\n            if name.startswith('x['):\n                (f,m,t) = map(int, name[2:-1].split(','))\n                self.x[(f,m,t)] = var\n    \n    def solve_model(self,price,timelimit=None):\n        Model = self.model\n        MC = self.MC\n        U =  self.U\n        D = self.D\n        E = self.E\n        L = self.L\n        P = self.P\n        idle = self.idle\n        up = self.up\n        down = self.down\n        q= self.q\n        N = 1440//q  \n        newcut = None\n        if self.reset:\n            Model.reset()\n        verbose = self.verbose\n        x =  self.x\n        nbMachines = self.nbMachines\n        nbTasks = self.nbTasks\n        nbResources = self.nbResources\n        Machines = range(nbMachines)\n        Tasks = range(nbTasks)\n        Resources = range(nbResources)\n        obj_expr = quicksum( [x[(f,m,t)]*np.sum(price[t:t+D[f]])*P[f]*q/60 \n            for f in Tasks for t in range(N-D[f]+1) for m in Machines if (f,m,t) in x] )\n        if self.warmstart:\n            bestval = np.inf\n            if len(self.sol_hist)>0:\n                for i,sol in enumerate(self.sol_hist):\n                    (pvars,dcons,vbasis,cbasis,sol_vec) = sol\n                    val = sum( (sum(sol_vec[f,m,t] for m in Machines)*np.sum(price[t:t+D[f]])*P[f]*q/60) \n                        for f in Tasks for t in range(N-D[f]+1))\n                    if  val< bestval:\n                        val =bestval\n                        ind = i\n                (pvars,dcons,vbasis,cbasis,sol_vec) = self.sol_hist[ind]\n                for i,var in enumerate(Model.getVars()):\n                    var.Pstart = pvars[i]\n                    var.VBasis = vbasis[i]\n                for i,cons in enumerate(Model.getConstrs()):\n                    cons.Dstart = dcons[i]\n                    cons.CBasis = cbasis[i]\n        Model.setObjective(obj_expr, GRB.MINIMIZE)\n        if timelimit:\n            Model.setParam('TimeLimit', timelimit)\n        Model.setParam('Method', self.method)\n        logging.info(\"Number of constraints%d\",Model.NumConstrs)\n        Model.optimize()\n        solver = np.zeros(N)\n        if Model.status in [GRB.Status.OPTIMAL,9]:\n            try:\n                task_on = np.zeros( (nbTasks,nbMachines,N) )\n                for ((f,m,t),var) in x.items():\n                    try:\n                        task_on[f,m,t] = var.X\n                    except AttributeError:\n                        task_on[f,m,t] = 0.\n                        print(\"AttributeError: b' Unable to retrieve attribute 'X'\")\n                        print(\"__________Something WRONG___________________________\")\n                if verbose:\n                    print('\\nCost: %g' % Model.objVal)\n                    print('\\nExecution Time: %f' %Model.Runtime)\n                for t in range(N):        \n                    solver[t] = np.sum( np.sum(task_on[f,:,max(0,t-D[f]+1):t+1])*P[f] for f in Tasks )  \n                solver = solver*q/60  \n                if self.warmstart:\n                    pvars = Model.getAttr(GRB.Attr.X, Model.getVars())\n                    dcons = Model.getAttr(GRB.Attr.Pi, Model.getConstrs())\n                    vbasis  = Model.getAttr(GRB.Attr.VBasis, Model.getVars())\n                    cbasis = Model.getAttr(GRB.Attr.CBasis,Model.getConstrs())\n                    self.sol_hist.append( (pvars,dcons,vbasis,cbasis,task_on) )\n                    if len(self.sol_hist)>10:\n                        self.sol_hist.pop(0)\n                return solver,Model.Runtime\n            except NameError:\n                print(\"\\n__________Something wrong_______ \\n \")\n                if newcut is not None:\n                    Model.remove(newcut)\n                    newcut = None\n                return solver,Model.Runtime\n        elif Model.status == GRB.Status.INF_OR_UNBD:\n            print('Model is infeasible or unbounded')\n        elif Model.status == GRB.Status.INFEASIBLE:\n            print('Model is infeasible')\n        elif Model.status == GRB.Status.UNBOUNDED:\n            print('Model is unbounded')\n        else:\n            print('Optimization ended with status %d' % Model.status)\n        return solver,Model.Runtime\n\n# ==========================================\n# File: EnergyCost/SPO.py\n# Function/Context: SGD_SPO.fit\n# ==========================================\nimport math\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import preprocessing\nimport torch\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom get_energy import get_energy\nfrom energy_cost import *\nimport datetime\n\nclass SGD_SPO:\n    def __init__(self,jobs, epochs=2, doScale=True, n_items=48, verbose=False,plotting=False,return_regret= False,optimizer= optim.SGD,**hyperparam):\n        self.n_items = n_items\n        self.jobs = jobs\n        self.hyperparam = hyperparam\n        self.epochs = epochs\n        self.doScale=doScale\n        self.verbose=verbose\n        self.plotting = plotting\n        self.return_regret = return_regret\n        self.optimizer = optimizer\n        self.scaler = None\n        self.model = None\n        self.best_params_ = {\"p\":\"default\"}\n\n    def fit(self, x_train, y_train,x_validation=None,y_validation=None):\n        qids = np.array(x_train[:,0], dtype=int) # qid column\n        x_train = x_train[:,1:] # without group ID\n        validation = (x_validation is not None) and (y_validation is not None)\n        jobs = self.jobs\n        # scale data?\n        if self.doScale:\n            self.scaler = preprocessing.StandardScaler().fit(x_train)\n            x_train = self.scaler.transform(x_train)\n\n        trch_X_train = torch.from_numpy(x_train).float()\n        trch_y_train = torch.from_numpy(np.array([y_train]).T).float()\n        \n        if self.plotting:\n            subepoch_list= []\n            loss_list =[]\n            regret_list = []\n            if validation:\n                loss_list_validation= []\n                regret_list_validation= []\n        # basics\n        n_items = self.n_items\n        n_knapsacks = len(trch_X_train)//n_items\n        # prepping\n        knaps_V_true = [get_profits(trch_y_train, kn_nr, n_items) for kn_nr in range(n_knapsacks)]\n        knaps_sol = [get_energy_indicators(V_true,jobs) for V_true in knaps_V_true]\n\n        # network\n        self.model = LinearRegression(trch_X_train.shape[1],1) # input dim, output dim\n\n        # loss\n        criterion = nn.MSELoss()\n        optimizer = self.optimizer(self.model.parameters(), **self.hyperparam)\n        num_epochs = self.epochs\n\n        # training\n        subepoch = 0 # for logging and nice curves\n        logger = [] # (dict_epoch, dict_train, dict_test)\n        for epoch in range(num_epochs):\n            print(epoch)\n            print(datetime.datetime.now())\n            knapsack_nrs = [x for x in range(n_knapsacks)]\n            random.shuffle(knapsack_nrs) # randomly shuffle order of training\n            cnt = 0\n            for kn_nr in knapsack_nrs:\n                V_true = knaps_V_true[kn_nr]\n                sol_true = knaps_sol[kn_nr]\n\n                # the true-shifted predictions\n                V_pred = get_profits_pred(self.model, trch_X_train, kn_nr, n_items)\n                V_spo = (2*V_pred - V_true)\n                sol_spo = get_energy_indicators(V_spo, jobs)\n                grad = (sol_spo - sol_true) #*2\n\n                # for each item\n                '''for idx in range(len(grad)):\n                    pos = idx + (kn_nr*n_items) # indices in train array\n                    train_fwdbwd_grad(self.model, optimizer, trch_X_train[pos], trch_y_train[pos], grad[idx])\n                '''\n                ### what if for the whole 48 items at a time\n                kn_start = kn_nr*n_items\n                kn_stop = kn_start+n_items\n                train_fwdbwd_grad(self.model, optimizer, trch_X_train[kn_start:kn_stop], trch_y_train[kn_start:kn_stop],torch.from_numpy(np.array([grad]).T).float())\n                \n                if validation:\n                    dict_validation = self.test_score(x_validation,y_validation)\n                if self.plotting:\n                        cnt += 1\n                        subepoch += 1\n                        dict_train = test_fwd(self.model, criterion, trch_X_train, trch_y_train, n_items, self.jobs)\n                        loss_list.append(dict_train['loss'])\n                        regret_list.append(dict_train['regret'])\n                        subepoch_list.append(subepoch)\n                        if validation:\n                            loss_list_validation.append(dict_validation['loss'])\n                            regret_list_validation.append(dict_validation['regret'])\n\n\n                if self.verbose:\n                        if not self.plotting:\n                            cnt += 1\n                            subepoch += 1\n                        if cnt % 50 == 0:\n                            dict_epoch = {'epoch': epoch+1, 'subepoch': subepoch, 'cnt': cnt}\n                            dict_train = test_fwd(self.model, criterion, trch_X_train, trch_y_train, n_items, self.jobs)\n                            if validation:\n                                logger.append( (dict_epoch, dict_train,dict_validation) )\n                                print('Epoch[{}/{}]::{}, loss(train): {:.6f}, regret(train): {:.2f}, loss(validation): {:.6f}, regret(validation): {:.2f}'.format(epoch+1, \n                                    num_epochs, cnt, dict_train['loss'], dict_train['regret'],dict_validation['loss'],dict_validation['regret']  ))\n                            else:\n                                logger.append( (dict_epoch, dict_train) )\n                                print('Epoch[{}/{}]::{}, loss: {:.6f}, regret(train): {:.2f}'.format(epoch+1, num_epochs, cnt, dict_train['loss'], dict_train['regret']))\n        \n        if self.plotting:\n            import matplotlib.pyplot as plt\n            if validation:\n                plt.subplot(2, 1, 1)\n                plt.plot(subepoch_list,regret_list,subepoch_list,regret_list_validation)\n                plt.title('Learning Curve')\n                plt.ylabel('Regret')\n                plt.ylim(top=  np.mean(regret_list)+ 5*np.std(regret_list))\n                plt.legend([\"training\",\"validation\"])\n                plt.subplot(2, 1, 2)\n                plt.plot(subepoch_list, loss_list,subepoch_list,loss_list_validation)\n                plt.xlabel('Sub Epochs')\n                plt.ylabel('Loss')\n                plt.ylim(top= np.median(loss_list)+ 5*np.std(loss_list))\n                plt.legend([\"training\",\"validation\"])\n                plt.show()\n            else:\n                plt.subplot(2, 1, 1)\n                plt.plot(subepoch_list,regret_list)\n                plt.title('Learning Curve')\n                plt.ylabel('Regret')\n                plt.ylim(top= np.mean(regret_list)+ 5*np.std(regret_list))\n                plt.subplot(2, 1, 2)\n                plt.plot(subepoch_list, loss_list)\n                plt.ylim(top= np.median(loss_list)+ 5*np.std(loss_list))\n                plt.xlabel('Sub Epochs')\n                plt.ylabel('Loss')\n                plt.show()        \n        if self.return_regret:\n            dict_train = test_fwd(self.model, criterion, trch_X_train, trch_y_train, n_items, self.jobs)\n            if validation:\n                dict_validation = self.test_score(x_validation,y_validation)\n                return {\"loss_training\":dict_train['loss'].item(),\"regret_training\":dict_train['regret'],\n                \"loss_validation\":dict_validation['loss'],\"regret_validation\":dict_validation['regret']}\n            \n            return {\"loss\":dict_train['loss'].item(),\"regret\":dict_train['regret_full']}\n\n    def predict(self, x_test):\n        qids = np.array(x_test[:,0], dtype=int) # qid column\n        x_test = x_test[:,1:] # drop qid column\n        \n        # scale data?\n        if self.doScale:\n            x_test = self.scaler.transform(x_test)\n\n        trch_X = torch.from_numpy(x_test).float()\n        pred = self.model(Variable(trch_X))\n        return pred.data.numpy().T[0] # as numpy array (transpose)\n    def predit_assignment(self, x_test):\n        qids = np.array(x_test[:,0], dtype=int) # qid column\n        x_test = x_test[:,1:] # drop qid column\n\n        # scale data?\n        if self.doScale:\n            x_test = self.scaler.transform(x_test)\n\n        trch_X = torch.from_numpy(x_test).float()\n        n_items = self.n_items\n        n_knapsacks = len(trch_X)//n_items\n        jobs = self.jobs\n\n        knapsack_nrs =range(n_knapsacks)\n        pred = []\n        for kn_nr in knapsack_nrs:\n            V_pred = get_profits_pred(self.model, trch_X, kn_nr, n_items)\n            sol_pred = get_energy_indicators(V_pred, jobs)\n            pred.append(sol_pred)\n        return np.array(pred)\n\n    def test_score(self,x_test,y_test):\n        qids = np.array(x_test[:,0],dtype=int)\n        x_test = x_test[:,1:] # drop qid column\n        # scale data?\n        if self.doScale:\n            x_test = self.scaler.transform(x_test)\n        trch_X = torch.from_numpy(x_test).float()\n        trch_y = torch.from_numpy(np.array([y_test]).T).float()\n        n_items = self.n_items\n        n_knapsacks = len(trch_X)//n_items\n        criterion = nn.MSELoss()\n        \n        dict_test = test_fwd(self.model,criterion,trch_X, trch_y,n_items,self.jobs)\n        return {\"loss\":dict_test['loss'].item(),\"regret\":dict_test['regret'],\"confusion_matrix\": dict_test['confusion_matrix']}\n\n# ==========================================\n# File: EnergyCost/SelectiveRegression.py\n# Function/Context: Pytorch_SelReg.fit\n# ==========================================\nimport math\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import preprocessing\nimport torch\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom get_energy import get_energy\nfrom energy_cost import *\nimport datetime\n\nclass Pytorch_SelReg:\n    def __init__(self, jobs,epochs=10, doScale=True, n_items=48, verbose=False,plotting=False,greedy_stop=True,regret_threshold=1.,return_regret= False,optimizer= optim.SGD,**hyperparam):\n        self.n_items = n_items\n        self.jobs = jobs\n        self.hyperparam = hyperparam\n        self.epochs = epochs\n        self.doScale=doScale\n        self.verbose=verbose\n        self.plotting =  plotting\n        self.return_regret = return_regret\n        self.optimizer = optimizer\n        self.greedy_stop = greedy_stop\n        self.regret_threshold = regret_threshold\n        self.scaler = None\n        self.model = None\n        self.best_params_ = {\"p\":\"default\"}\n    \n    def fit(self, x_train, y_train,x_validation=None,y_validation=None):\n        qids = np.array(x_train[:,0], dtype=int) # qid column\n        x_train = x_train[:,1:] # without group ID\n        validation = (x_validation is not None) and (y_validation is not None)\n        jobs = self.jobs\n        if self.plotting:\n            subepoch_list= []\n            loss_list =[]\n            regret_list = []\n            if validation:\n                loss_list_validation= []\n                regret_list_validation= []\n        # scale data?\n        if self.doScale:\n            self.scaler = preprocessing.StandardScaler().fit(x_train)\n            x_train = self.scaler.transform(x_train)\n        trch_X_train = torch.from_numpy(x_train).float()\n        trch_y_train = torch.from_numpy(np.array([y_train]).T).float()\n        # basics\n        n_items = self.n_items\n        n_knapsacks = len(trch_X_train)//n_items\n        # prepping\n        knaps_V_true = [get_profits(trch_y_train, kn_nr, n_items) for kn_nr in range(n_knapsacks)]\n        knaps_sol = [get_energy_indicators(V_true, jobs) for V_true in knaps_V_true]\n        # network\n        self.model = LinearRegression(trch_X_train.shape[1],1) # input dim, output dim\n        # loss\n        criterion = nn.MSELoss()\n        optimizer = self.optimizer(self.model.parameters(), **self.hyperparam)\n        num_epochs = self.epochs\n        # training\n        subepoch = 0 # for logging and nice curves\n        logger = [] # (dict_epoch, dict_train, dict_test)\n        for epoch in range(num_epochs):\n            print(epoch)\n            print(datetime.datetime.now())    \n            knapsack_nrs = [x for x in range(n_knapsacks)]\n            #random.shuffle(knapsack_nrs) # randomly shuffle order of training\n            cnt = 0\n            for kn_nr in knapsack_nrs:\n                V_true = knaps_V_true[kn_nr]\n                sol_true = knaps_sol[kn_nr]\n                V_pred = get_profits_pred(self.model, trch_X_train, kn_nr, n_items)\n                sol_pred = get_energy_indicators(V_pred, jobs)\n                # check regret of knapsack\n                knap_regret = sum(V_true*(sol_pred - sol_true))\n                if knap_regret < self.regret_threshold and self.greedy_stop :\n                    continue\n                # check regret of items\n                item_regrets = np.zeros(n_items)\n                # design: only for differences in item assignents\n                for i in [k for k in range(n_items) if sol_true[k] != sol_pred[k]]:\n                    item_regrets[i] = diffprof(V_pred, i, V_true[i], V_true, jobs)\n                # only train on improving ones\n                idx = np.where( item_regrets > self.regret_threshold )[0]\n                if len(idx) != 0:\n                    for i in idx:\n                        pos = i + (kn_nr*n_items) # indices in train array\n                        train_fwdbwd_oneitem(self.model, criterion, optimizer, trch_X_train, trch_y_train, pos, 1.0)\n                    if validation:\n                        dict_validation = self.test_score(x_validation,y_validation)\n                    if self.plotting:\n                        cnt += 1\n                        subepoch += 1\n                        dict_train = test_fwd(self.model, criterion, trch_X_train, trch_y_train, n_items, jobs)\n                        loss_list.append(dict_train['loss'])\n                        regret_list.append(dict_train['regret'])\n                        subepoch_list.append(subepoch)\n                        if validation:\n                            loss_list_validation.append(dict_validation['loss'])\n                            regret_list_validation.append(dict_validation['regret'])\n                    # printing/logging\n                    if self.verbose:\n                        if not self.plotting:\n                            cnt += 1\n                            subepoch += 1\n                        if cnt % 50 == 0:\n                            dict_epoch = {'epoch': epoch+1, 'subepoch': subepoch, 'cnt': cnt}\n                            dict_train = test_fwd(self.model, criterion, trch_X_train, trch_y_train, n_items,jobs )\n                            if validation:\n                                logger.append( (dict_epoch, dict_train,dict_validation) )\n                                print('Epoch[{}/{}]::{}, loss(train): {:.6f}, regret(train): {:.2f}, loss(validation): {:.6f}, regret(validation): {:.2f}'.format(epoch+1, num_epochs, cnt, dict_train['loss'], dict_train['regret'],dict_validation['loss'],dict_validation['regret']  ))\n                            else:\n                                logger.append( (dict_epoch, dict_train) )\n                                print('Epoch[{}/{}]::{}, loss: {:.6f}, regret(train): {:.2f}'.format(epoch+1, num_epochs, cnt, dict_train['loss'], dict_train['regret']))\n        if self.plotting:\n            import matplotlib.pyplot as plt\n            if validation:\n                plt.subplot(2, 1, 1)\n                plt.plot(subepoch_list,regret_list,subepoch_list,regret_list_validation)\n                plt.title('Learning Curve')\n                plt.ylabel('Regret')\n                plt.ylim(top=  np.mean(regret_list)+ 5*np.std(regret_list))\n                plt.legend([\"training\",\"validation\"])\n                plt.subplot(2, 1, 2)\n                plt.plot(subepoch_list, loss_list,subepoch_list,loss_list_validation)\n                plt.xlabel('Sub Epochs')\n                plt.ylabel('Loss')\n                plt.ylim(top= np.median(loss_list)+ 10*np.std(loss_list))\n                plt.legend([\"training\",\"validation\"])\n                plt.show()\n            else:\n                plt.subplot(2, 1, 1)\n                plt.plot(subepoch_list,regret_list)\n                plt.title('Learning Curve')\n                plt.ylabel('Regret')\n                plt.ylim(top= np.mean(regret_list)+ 5*np.std(regret_list))\n                plt.subplot(2, 1, 2)\n                plt.plot(subepoch_list, loss_list)\n                plt.xlabel('Sub Epochs')\n                plt.ylabel('Loss')\n                plt.ylim(top= np.median(loss_list)+ 10*np.std(loss_list))\n                plt.show()\n        if self.return_regret:\n            dict_train = test_fwd(self.model, criterion, trch_X_train, trch_y_train, n_items, jobs)\n            if validation:\n                dict_validation = self.test_score(x_validation,y_validation)\n                return {\"loss_training\":dict_train['loss'].item(),\"regret_training\":dict_train['regret'],\n                \"loss_validation\":dict_validation['loss'],\"regret_validation\":dict_validation['regret']}\n            return {\"loss\":dict_train['loss'].item(),\"regret\":dict_train['regret']}\n\n# ==========================================\n# File: EnergyCost/regression_SPO.py\n# Function/Context: Regression_generic\n# ==========================================\nimport math\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import preprocessing\nimport torch\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nimport logging\nimport sys\nsys.path.insert(0,'..')\nimport datetime\nimport time\nfrom get_energy import get_energy\nfrom sgd_learner import *\nfrom sklearn.metrics import confusion_matrix\nfrom collections import defaultdict\n\nclass Regression_generic:\n    def __init__(self,param,solver,relax=False, validation_relax=False,test_relax=False, optimal_value=knapsack_value,getY= get_profits,getTorchData= get_data, \n        getYpred = get_profits_pred, epochs=2, doScale= True, n_items=48,model=None,timelimit = None,\n        verbose=False,plotting=False,degree=1, maximize= True,accuracy_measure=  False,early_stopping= False,\n        optimizer= optim.SGD,model_save=False,model_name=None,method=-1,warmstart=False,# obj_cut=-1,\n       **hyperparam):\n\n        self.n_items = n_items        \n        self.hyperparam = hyperparam\n        self.epochs = epochs\n\n        self.doScale=doScale\n        self.verbose=verbose\n        self.plotting = plotting\n        self.optimizer = optimizer\n        self.degree = degree\n        #self.solver_train = solver_train\n        #self.solver_test = solver_test\n        self.solver =  solver\n        self.relax = relax\n        self.validation_relax = validation_relax\n        self.test_relax = test_relax\n        self.optimal_value = optimal_value\n        self.param = param\n        self.maximize = maximize\n        self.getY =  getY\n        self.getYpred = getYpred\n        self.accuracy_measure = accuracy_measure\n        self.getTorchData = getTorchData\n        self.early_stopping = early_stopping\n        self.true_solution = None\n        self.validation_solution = None\n        self.timelimit = timelimit\n        self.time = 0\n        self.scaler = None\n        self.criterion = None\n        self.model = model\n        self.model_save = model_save\n        self.model_name = model_name\n        self.method = method\n        \n        self.warmstart = False\n        \n        #self.obj_cut = obj_cut\n        #self.sol_hist = []\n        self.best_params_ = {\"p\":\"default\"}\n\n    def validation_score(self, criterion, trch_X_validation=None,trch_y_validation=None,trch_X_test=None,trch_y_test=None,\n     knaps_sol_validation=None,knaps_sol_test=None, accuracy=None):\n        \n        info = dict()\n        \n        n_items = self.n_items\n        solver= self.solver\n        optimal_value = self.optimal_value\n        param= self.param\n        clf_train = self.clf_train\n        clf_validation = self.clf_validation\n        clf_test = self.clf_test\n        max_min_ind = 1 if self.maximize else -1\n\n        self.model.eval()\n        with torch.no_grad():\n            '''\n            inputs_train = Variable(trch_X_train)\n            target_train = Variable(trch_y_train)\n            V_preds_train = self.model(inputs_train)\n            info['train_loss'] = criterion(V_preds_train, target_train).item()\n            '''\n            if trch_X_validation is not None:\n                inputs_validation = Variable(trch_X_validation)\n                target_validation = Variable(trch_y_validation)\n                V_preds_validation = self.model(inputs_validation)\n                info['validation_loss'] = criterion(V_preds_validation, target_validation).item()\n            \n            if trch_X_test is not None:\n                inputs_test = Variable(trch_X_test)\n                target_test = Variable(trch_y_test)\n                V_preds_test = self.model(inputs_test)\n                info['test_loss'] = criterion(V_preds_test, target_test).item()\n\n        self.model.train()\n\n        '''\n        n_knap_train = len(V_preds_train)//n_items\n        regret_full_train = np.zeros(n_knap_train)\n        for kn_nr in range(n_knap_train):\n            V_true = self.getY(trch_y_train, kn_nr, n_items)\n            V_pred = self.getY(V_preds_train, kn_nr, n_items)\n            sol_true = knaps_sol_train[kn_nr][0]\n            sol_pred,_ = clf.solve_model(V_pred)\n            regret_full_train[kn_nr] = max_min_ind *( optimal_value(V_true,sol_true,**param) - optimal_value(V_true,sol_pred,**param))\n        info['train_regret_full'] = np.median(regret_full_train)\n        '''\n        if trch_X_validation is not None:\n            n_knap_validation = len(V_preds_validation)//n_items\n            regret_full_validation = np.zeros(n_knap_validation)\n            for kn_nr in range(n_knap_validation):\n                V_true = self.getY(trch_y_validation, kn_nr, n_items)\n                V_pred = self.getY(V_preds_validation, kn_nr, n_items)\n                sol_true = knaps_sol_validation[kn_nr][0]\n                sol_pred,t = clf_validation.solve_model(V_pred)\n                if t is not None:\n                    self.time +=t\n                regret_full_validation[kn_nr] = max_min_ind *( optimal_value(V_true,sol_true,**param) - optimal_value(V_true,sol_pred,**param))\n            info['validation_regret_full'] = np.median(regret_full_validation)\n        if trch_X_test is not None:\n            n_knap_test = len(V_preds_test)//n_items\n            regret_full_test = np.zeros(n_knap_test)\n            for kn_nr in range(n_knap_test):\n                V_true = self.getY(trch_y_test, kn_nr, n_items)\n                V_pred = self.getY(V_preds_test, kn_nr, n_items)\n                sol_true = knaps_sol_test[kn_nr][0]\n                sol_pred,_ = clf_test.solve_model(V_pred)\n                regret_full_test[kn_nr] = max_min_ind *( optimal_value(V_true,sol_true,**param) - optimal_value(V_true,sol_pred,**param))\n            info['test_regret_full'] = np.median(regret_full_test)\n        return info\n    def test_score(self, criterion, trch_X_test=None,trch_y_test=None,knaps_sol_test=None, accuracy=None):\n        \n        info = dict()\n        \n        n_items = self.n_items\n        solver= self.solver\n        optimal_value = self.optimal_value\n        param= self.param\n        clf_train = self.clf_train\n        clf_validation = self.clf_validation\n        clf_test = self.clf_test\n        max_min_ind = 1 if self.maximize else -1\n\n        self.model.eval()\n        with torch.no_grad():\n            if trch_X_test is not None:\n                inputs_test = Variable(trch_X_test)\n                target_test = Variable(trch_y_test)\n                V_preds_test = self.model(inputs_test)\n                info['test_loss'] = criterion(V_preds_test, target_test).item()\n\n        self.model.train()\n        if trch_X_test is not None:\n            n_knap_test = len(V_preds_test)//n_items\n            regret_full_test = np.zeros(n_knap_test)\n            for kn_nr in range(n_knap_test):\n                V_true = self.getY(trch_y_test, kn_nr, n_items)\n                V_pred = self.getY(V_preds_test, kn_nr, n_items)\n                sol_true = knaps_sol_test[kn_nr][0]\n                sol_pred,_ = clf_test.solve_model(V_pred)\n                regret_full_test[kn_nr] = max_min_ind *( optimal_value(V_true,sol_true,**param) - optimal_value(V_true,sol_pred,**param))\n            info['test_regret_full'] = np.median(regret_full_test)\n        return info  \n\n\n    def fit(self, x_train, y_train,x_validation=None,y_validation=None,x_test=None,y_test=None):\n\n        start = time.time()\n        qids = np.array(x_train[:,0], dtype=int) # qid column\n        x_train = x_train[:,1:] # without group ID\n        validation = (x_validation is not None) and (y_validation is not None)\n        test = (x_test is not None) and (y_test is not None)\n        if self.early_stopping:\n            validation_rslt =[]\n\n        accuracy_measure = self.accuracy_measure\n        # scale data?\n        if self.doScale:\n            self.scaler = preprocessing.StandardScaler().fit(x_train)\n            x_train = self.scaler.transform(x_train)\n\n        trch_X_train = torch.from_numpy(x_train).float()\n        trch_y_train = torch.from_numpy(np.array([y_train]).T).float()\n        if validation:\n            x_validation = x_validation[:,1:]\n            if self.doScale:\n                x_validation = self.scaler.transform(x_validation)\n            trch_X_validation = torch.from_numpy(x_validation).float()\n            trch_y_validation = torch.from_numpy(np.array([y_validation]).T).float()\n        else:\n            trch_X_validation = None\n            trch_y_validation = None\n\n        if test:\n            x_test = x_test[:,1:]\n            if self.doScale:\n                x_test = self.scaler.transform(x_test)\n            trch_X_test = torch.from_numpy(x_test).float()\n            trch_y_test = torch.from_numpy(np.array([y_test]).T).float()\n        else:\n            trch_X_test = None\n            trch_y_test = None\n        \n        # basics\n        n_items = self.n_items\n        n_knapsacks = len(trch_X_train)//n_items\n        param= self.param\n        #solver_train= self.solver_train\n        #solver_test = self.solver_test\n        solver = self.solver\n        relax= self.relax\n        validation_relax= self.validation_relax\n\n        optimal_value = self.optimal_value\n        max_min_ind = 1 if self.maximize else -1\n        \n        if validation:\n            clf_validation =  solver(relax=validation_relax,method=self.method,#obj_cut=self.obj_cut,\n                reset=True,presolve= True,warmstart = self.warmstart, **param)\n            clf_validation.make_model()\n            self.clf_validation = clf_validation\n        if test:\n            clf_test =  solver(relax=self.test_relax,method=self.method,#obj_cut= self.obj_cut,\n                reset=True,presolve= True, **param)\n            clf_test.make_model()\n            self.clf_test = clf_test\n\n        # prepping\n        knaps_V_true = [self.getY(trch_y_train, kn_nr, n_items) for kn_nr in range(n_knapsacks)]\n        #self.logger.info('Training Initiation ! Time:%s\\n' %str(datetime.datetime.now()) )\n        logging.info('Training Initiation ! Time:%s\\n' %str(datetime.datetime.now()))\n        knaps_sol = [None for V_true in knaps_V_true]\n        #knaps_sol = [clf_train.solve_model(V_true,scheduling=True) for V_true in knaps_V_true]\n        #self.logger.info('Solving Training instances Completed ! Time:%s\\n' %str(datetime.datetime.now()) )\n        \n        #for k in knaps_sol:\n        #    self.time+=k[2]\n        validation_time = 0\n        test_time = 0\n        training_time = 0\n        if validation:\n            n_knapsacks_validation = len(trch_X_validation)//n_items\n            knaps_V_true_validation = [self.getY(trch_y_validation, kn_nr, n_items) for kn_nr in range(n_knapsacks_validation)]\n            logging.info('Solving Validation instances ' )\n            validation_start = time.time()\n            knaps_sol_validation = [clf_validation.solve_model(V_true) for V_true in knaps_V_true_validation]\n            validation_end = time.time()\n            validation_time += validation_end - validation_start\n            #knaps_sol_validation = None\n            logging.info('Solving Validation instances Completed ! Time:%s\\n' %str(datetime.datetime.now()) )\n            for k in knaps_sol_validation:\n                if k[1]:\n                    self.time+=k[1]\n        #self.logger.info('Solving Validation instances Completed ! Time:%s\\n' %str(datetime.datetime.now()) )\n        \n        if test:\n            n_knapsacks_test = len(trch_X_test)//n_items\n            knaps_V_true_test = [self.getY(trch_y_test, kn_nr, n_items) for kn_nr in range(n_knapsacks_test)]\n            logging.info('Solving Test instances ' )\n            test_start = time.time()\n            knaps_sol_test = [clf_test.solve_model(V_true) for V_true in knaps_V_true_test]\n            #knaps_sol_test = None\n            test_end = time.time()\n            logging.info('Solving Test instances Completed ! Time:%s\\n' %str(datetime.datetime.now()) )\n            test_time+= test_end - test_start\n\n\n        #self.logger.info('Solving Test instances Completed ! Time:%s\\n' %str(datetime.datetime.now()) )\n        \n\n\n        \n        # network\n        if not self.model:\n            self.model = LinearRegression(trch_X_train.shape[1],1) # input dim, output dim\n        # loss\n        criterion = nn.MSELoss()\n        self.criterion = criterion\n        optimizer = self.optimizer(self.model.parameters(), **self.hyperparam)\n        num_epochs = self.epochs\n\n        # training\n        subepoch = 0 # for logging and nice curves\n        logger = [] # (dict_epoch, dict_train, dict_test)\n        test_result = []\n        knapsack_nrs = [x for x in range(n_knapsacks)]\n        for epoch in range(num_epochs):\n            random.shuffle(knapsack_nrs) # randomly shuffle order of training\n            cnt=0\n            train_fwdbwd(self.model, criterion, optimizer, trch_X_train, trch_y_train, 1.0)   \n            print(\"DONE one epoch%d\",epoch) \n            cnt += 1\n            subepoch += 1              \n            if self.verbose:\n\n                    if cnt % 50 == 0:\n                        #self.logger.info('Time for  Training one instance at (%d::%d) :%f\\n' %(epoch,cnt, end-start) )\n                        \n                        #self.logger.info('validation starts! for epoch (%d::%d) Time:%s\\n' %(epoch,cnt, str(datetime.datetime.now())) )\n                        \n                        validation_start = time.time()\n                        dict_val = self.validation_score(criterion, trch_X_validation=trch_X_validation,trch_y_validation=trch_y_validation,\n                            knaps_sol_validation=knaps_sol_validation, accuracy=accuracy_measure)\n                        validation_end = time.time()\n                        validation_time += validation_end - validation_start\n                        test_start = time.time()\n                        dict_test = self.test_score(criterion,trch_X_test,trch_y_test,knaps_sol_test,accuracy=accuracy_measure) \n                        #self.logger.info('validation Finishes! for epoch (%d::%d) Time:%s\\n' %(epoch,cnt, str(datetime.datetime.now())) )\n                        test_end  = time.time()\n                        test_time += test_end - test_start\n                        \n                        dict_test[\"subepoch\"] = subepoch\n                        dict_test['validation_loss'] = dict_val['validation_loss']\n                        dict_test['validation_regret_full'] = dict_val['validation_regret_full']\n                        dict_test[\"Runtime\"] = self.time\n                        dict_test[\"time\"] = time.time() - start                        \n                        test_result.append(dict_test)\n                        logging.info(\"Epoch %d::subepoch %d Total time %d, validation time %d & test time %d\"%(epoch,subepoch,\n                            time.time() - start,validation_time,test_time))\n            if self.model_save:\n                    if cnt % 10 == 0:\n                        logging.info(\"Model saving:%d-%d\\n \"%(epoch,subepoch))\n                        torch.save(self.model.state_dict(), str(self.model_name+\"_Epoch\"+s\n\n        # Note: The code snippet ends here due to truncation in the original input, but the core logic is captured.\n\n# ==========================================\n# File: EnergyCost/torch_SPO_updated.py\n# Function/Context: SGD_SPO_generic\n# ==========================================\nimport math\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import preprocessing\nimport torch\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nimport logging\nimport sys\nsys.path.insert(0,'..')\nimport datetime\nimport time\n\nfrom sgd_learner import *\nfrom sklearn.metrics import confusion_matrix\nfrom collections import defaultdict\n\nclass SGD_SPO_generic:\n    def __init__(self,param,solver,reset,presolve,relax=False, validation_relax=False,test_relax=False, optimal_value=knapsack_value,getY= get_profits,getTorchData= get_data, \n        getYpred = get_profits_pred, epochs=2, doScale= True, n_items=48,model=None,timelimit = None,\n        verbose=False,plotting=False,degree=1, maximize= True,accuracy_measure=  False,early_stopping= False,\n        optimizer= optim.SGD,model_save=False,model_name=None,method=-1,warmstart=False,# obj_cut=-1,\n       **hyperparam):\n\n        #-1 : no objective cut\n        # 0: cut for predictions only 'true' solution\n        # n: previous n solutions as cut\n        self.n_items = n_items        \n        self.hyperparam = hyperparam\n        self.epochs = epochs\n\n        self.doScale=doScale\n        self.verbose=verbose\n        self.plotting = plotting\n        self.optimizer = optimizer\n        self.degree = degree\n        #self.solver_train = solver_train\n        #self.solver_test = solver_test\n        self.solver =  solver\n        self.relax = relax\n        self.validation_relax = validation_relax\n        self.test_relax = test_relax\n        self.optimal_value = optimal_value\n        self.param = param\n        self.maximize = maximize\n        self.getY =  getY\n        self.getYpred = getYpred\n        self.accuracy_measure = accuracy_measure\n        self.getTorchData = getTorchData\n        self.early_stopping = early_stopping\n        self.true_solution = None\n        self.validation_solution = None\n        self.timelimit = timelimit\n        self.time = 0\n        self.scaler = None\n        self.criterion = None\n        self.model = model\n        self.model_save = model_save\n        self.model_name = model_name\n        self.method = method\n        self.reset = reset\n        self.presolve = presolve\n        self.warmstart = False\n        \n        #self.obj_cut = obj_cut\n        #self.sol_hist = []\n        self.best_params_ = {\"p\":\"default\"}\n\n    def test_fwd(self, criterion, trch_X, trch_y,accuracy):\n        from sklearn.metrics import confusion_matrix\n        info = dict()\n        n_items = self.n_items\n        solver= self.solver\n        optimal_value = self.optimal_value\n        param= self.param\n        clf_train = self.clf_train\n        clf_validation = self.clf_validation\n        clf_test = self.clf_test\n        max_min_ind = 1 if self.maximize else -1\n\n        self.model.eval()\n        with torch.no_grad():\n            inputs = Variable(trch_X)\n            target = Variable(trch_y)\n            V_preds = self.model(inputs)\n            info['loss'] = criterion(V_preds, target).data\n        self.model.train()\n        n_knap = len(V_preds)//n_items\n        regret_full = np.zeros(n_knap)\n        cf_list =[]\n\n        for kn_nr in range(n_knap):\n            V_true = self.getY(trch_y, kn_nr, n_items)\n            V_pred = self.getY(V_preds, kn_nr, n_items)\n            sol_pred,_ = clf_test.solve_model(V_pred)\n            sol_true,_ = clf_test.solve_model(V_true)\n\n            regret_full[kn_nr] = max_min_ind *( optimal_value(V_true,sol_true,**param) - optimal_value(V_true,sol_pred,**param))\n            if accuracy:\n                cf = confusion_matrix(sol_true, sol_pred,labels=[0,1])\n                cf_list.append(cf)\n            else:\n                cf_list.append(np.zeros((2,2)))\n        info['regret_full'] = np.median(regret_full)\n        tn, fp, fn, tp = np.sum(np.stack(cf_list),axis=0).ravel()\n        info['tn'],info['fp'],info['fn'],info['tp'] =(tn,fp,fn,tp)\n        return info\n\n    def validation_score(self, criterion, trch_X_validation=None,trch_y_validation=None,trch_X_test=None,trch_y_test=None,\n     knaps_sol_validation=None,knaps_sol_test=None, accuracy=None):\n        \n        info = dict()\n        \n        n_items = self.n_items\n        solver= self.solver\n        optimal_value = self.optimal_value\n        param= self.param\n        clf_train = self.clf_train\n        clf_validation = self.clf_validation\n        max_min_ind = 1 if self.maximize else -1\n\n        self.model.eval()\n        with torch.no_grad():\n            if trch_X_validation is not None:\n                inputs_validation = Variable(trch_X_validation)\n                target_validation = Variable(trch_y_validation)\n                V_preds_validation = self.model(inputs_validation)\n                info['validation_loss'] = criterion(V_preds_validation, target_validation).item()\n        \n        self.model.train()\n\n        if trch_X_validation is not None:\n            n_knap_validation = len(V_preds_validation)//n_items\n            regret_full_validation = np.zeros(n_knap_validation)\n            for kn_nr in range(n_knap_validation):\n                V_true = self.getY(trch_y_validation, kn_nr, n_items)\n                V_pred = self.getY(V_preds_validation, kn_nr, n_items)\n                sol_true = knaps_sol_validation[kn_nr][0]\n                sol_pred,t = clf_validation.solve_model(V_pred)\n                if t is not None:\n                    self.time +=t\n                regret_full_validation[kn_nr] = max_min_ind *( optimal_value(V_true,sol_true,**param) - optimal_value(V_true,sol_pred,**param))\n            info['validation_regret_full'] = np.median(regret_full_validation)\n        return info\n\n    def test_score(self, criterion, trch_X_test=None,trch_y_test=None,knaps_sol_test=None, accuracy=None):\n        \n        info = dict()\n        \n        n_items = self.n_items\n        solver= self.solver\n        optimal_value = self.optimal_value\n        param= self.param\n        clf_train = self.clf_train\n        clf_validation = self.clf_validation\n        clf_test = self.clf_test\n        max_min_ind = 1 if self.maximize else -1\n\n        self.model.eval()\n        with torch.no_grad():\n            if trch_X_test is not None:\n                inputs_test = Variable(trch_X_test)\n                target_test = Variable(trch_y_test)\n                V_preds_test = self.model(inputs_test)\n                info['test_loss'] = criterion(V_preds_test, target_test).item()\n\n        self.model.train()\n        if trch_X_test is not None:\n            n_knap_test = len(V_preds_test)//n_items\n            regret_full_test = np.zeros(n_knap_test)\n            for kn_nr in range(n_knap_test):\n                V_true = self.getY(trch_y_test, kn_nr, n_items)\n                V_pred = self.getY(V_preds_test, kn_nr, n_items)\n                sol_true = knaps_sol_test[kn_nr][0]\n                sol_pred,_ = clf_test.solve_model(V_pred)\n                regret_full_test[kn_nr] = max_min_ind *( optimal_value(V_true,sol_true,**param) - optimal_value(V_true,sol_pred,**param))\n            info['test_regret_full'] = np.median(regret_full_test)\n        return info        \n\n    def fit(self, x_train, y_train,x_validation=None,y_validation=None,x_test=None,y_test=None):\n        start = time.time()\n        qids = np.array(x_train[:,0], dtype=int) # qid column\n        x_train = x_train[:,1:] # without group ID\n        validation = (x_validation is not None) and (y_validation is not None)\n        test = (x_test is not None) and (y_test is not None)\n        if self.early_stopping:\n            validation_rslt =[]\n\n        accuracy_measure = self.accuracy_measure\n        # scale data?\n        if self.doScale:\n            self.scaler = preprocessing.StandardScaler().fit(x_train)\n            x_train = self.scaler.transform(x_train)\n\n        trch_X_train = torch.from_numpy(x_train).float()\n        trch_y_train = torch.from_numpy(np.array([y_train]).T).float()\n        if validation:\n            x_validation = x_validation[:,1:]\n            if self.doScale:\n                x_validation = self.scaler.transform(x_validation)\n            trch_X_validation = torch.from_numpy(x_validation).float()\n            trch_y_validation = torch.from_numpy(np.array([y_validation]).T).float()\n        else:\n            trch_X_validation = None\n            trch_y_validation = None\n\n        if test:\n            x_test = x_test[:,1:]\n            if self.doScale:\n                x_test = self.scaler.transform(x_test)\n            trch_X_test = torch.from_numpy(x_test).float()\n            trch_y_test = torch.from_numpy(np.array([y_test]).T).float()\n        else:\n            trch_X_test = None\n            trch_y_test = None\n        \n        # basics\n        n_items = self.n_items\n        n_knapsacks = len(trch_X_train)//n_items\n        param= self.param\n        solver = self.solver\n        relax= self.relax\n        validation_relax= self.validation_relax\n\n        optimal_value = self.optimal_value\n        max_min_ind = 1 if self.maximize else -1\n        clf_train =  solver(relax=relax,method=self.method,reset=self.reset,presolve= self.presolve,warmstart = self.warmstart, **param)\n        clf_train.make_model()\n        self.clf_train = clf_train\n        if validation:\n            clf_validation =  solver(relax=validation_relax,method=self.method,reset=self.reset,presolve= self.presolve,warmstart = self.warmstart, **param)\n            clf_validation.make_model()\n            self.clf_validation = clf_validation\n        if test:\n            clf_test =  solver(relax=self.test_relax,method=self.method,reset=True,presolve= False, **param)\n            clf_test.make_model()\n            self.clf_test = clf_test\n\n        # prepping\n        knaps_V_true = [self.getY(trch_y_train, kn_nr, n_items) for kn_nr in range(n_knapsacks)]\n        logging.info('Training Initiation ! Time:%s\\n' %str(datetime.datetime.now()))\n        knaps_sol = [None for V_true in knaps_V_true]\n        \n        validation_time = 0\n        test_time = 0\n        training_time = 0\n        if validation:\n            n_knapsacks_validation = len(trch_X_validation)//n_items\n            knaps_V_true_validation = [self.getY(trch_y_validation, kn_nr, n_items) for kn_nr in range(n_knapsacks_validation)]\n            logging.info('Solving Validation instances ' )\n            validation_start = time.time()\n            knaps_sol_validation = [clf_validation.solve_model(V_true) for V_true in knaps_V_true_validation]\n            validation_end = time.time()\n            validation_time += validation_end - validation_start\n            logging.info('Solving Validation instances Completed ! Time:%s\\n' %str(datetime.datetime.now()) )\n            for k in knaps_sol_validation:\n                if k[1]:\n                    self.time+=k[1]\n        \n        if test:\n            n_knapsacks_test = len(trch_X_test)//n_items\n            knaps_V_true_test = [self.getY(trch_y_test, kn_nr, n_items) for kn_nr in range(n_knapsacks_test)]\n            logging.info('Solving Test instances ' )\n            test_start = time.time()\n            knaps_sol_test = [clf_test.solve_model(V_true) for V_true in knaps_V_true_test]\n            test_end = time.time()\n            logging.info('Solving Test instances Completed ! Time:%s\\n' %str(datetime.datetime.now()) )\n            test_time+= test_end - test_start\n        \n        # network\n        if not self.model:\n            self.model = LinearRegression(trch_X_train.shape[1],1) # input dim, output dim\n        # loss\n        criterion = nn.MSELoss()\n        self.criterion = criterion\n        optimizer = self.optimizer(self.model.parameters(), **self.hyperparam)\n        num_epochs = self.epochs\n\n        # training\n        subepoch = 0 # for logging and nice curves\n        logger = [] # (dict_epoch, dict_train, dict_test)\n        test_result = []\n        knapsack_nrs = [x for x in range(n_knapsacks)]\n        for epoch in range(num_epochs):\n            # [Training loop continues but was truncated in provided content]\n            # This is where SPO gradient updates would occur\n            pass\n\n# ==========================================\n# File: KnapsackSolving.py\n# Function/Context: solveKnapsackProblem, solveKnapsackProblemRelaxation, regret_knapsack\n# ==========================================\nimport time\nimport numpy as np\nfrom scipy import stats\nfrom sklearn.metrics.scorer import _BaseScorer\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom gurobipy import *\n\ndef solveKnapsackGreedily(profits, weights, capacity):\n    assert len(profits) == len(weights)\n    assert(len([x for x in profits if x < 0]) == 0)\n    assert(capacity > 0 and len(profits) >= 2)    \n    \n    n_items = len(profits)    \n    items = [[profits[i], weights[i], i] for i in range(n_items) ]\n    items.sort(key=lambda x: float(x[0])/x[1], reverse=True)\n    assert(items[0][0]/items[0][1] >= items[1][0]/items[1][1])\n    \n    objective = 0\n    available_capacity = capacity\n    assignments = [0 for i in range(n_items)] #the ith value is 1 if the i-th item is selected\n    for i in range(n_items):\n        #if the item cannot fit in the remaining capacity\n        if items[i][1] > available_capacity:\n            continue\n        #else, insert it into the knapsack\n        objective += items[i][0] #profit increase\n        available_capacity -= items[i][1] #weight\n        assignments[items[i][2]] = 1 #note that you selected this item; items[i][2] indicates the original index of the item\n    \n        if available_capacity == 0:\n            break\n        \n    solution_info = {'objective':objective, 'assignments':assignments}\n    return solution_info\n\n\ndef solveKnapsackProblemRelaxation(profits, weights, capacity, warmstart=None,time_limit=None, use_dp=True):\n    multi = (len(weights)>1)\n    \n    profits = [v for v in profits]\n    weights = [[w for w in W] for W in weights]\n    capacity = [c for c in capacity]\n    start_time = time.time()\n    n = len(profits)\n    \n    \n    m = Model()\n    m.setParam('OutputFlag', 0)\n    x = {}\n    for i in range(n):\n        x[(i)] = m.addVar(lb=0,ub=1, name= \"x\"+str(i))\n        #x[i] = m.addVar(vtype=GRB.BINARY,name= \"x\"+str(i))\n    \n    if warmstart is not None:\n        for i in range(n):\n            x[i].Pstart = warmstart[i]\n            m.update()\n \n    m.setObjective(sum( (x[i]*profits[i]) for i in range(n)), GRB.MAXIMIZE)\n    for w in weights:\n        for c in capacity:    \n            m.addConstr(( quicksum(x[i]*w[i] for i in range(n) ) <= c))\n    '''    \n    lb= [0.0]*n\n    ub = [1.0]*n\n    x = m.addVars(n,ub=ub, name='x')\n    for w in weights:\n        for c in capacity:\n            m.addConstr(x.prod(w) <= c)\n    m.setObjective(x.prod(profits), GRB.MAXIMIZE)\n    '''\n    m.optimize()       \n\n    solution_info = {}\n    if (m.status == GRB.Status.OPTIMAL):\n        solution_info['runtime'] = m.Runtime\n        solution_info['objective'] = m.objVal\n        m_on = m.getAttr('x',x)\n        sol = list(m_on.values())     \n        solution_info['assignments'] =  [i for i in sol]\n    else:\n        print(\"SOME EXCEPTION HAPPENED! RETURNING GARBAGE\\n\")\n        val = 0\n        import sys\n            \n        solution_info = {}\n        solution_info['runtime'] = m.Runtime\n        solution_info['objective'] = val\n        solution_info['assignments'] = [0 for x in range(len(profits))]\n    return solution_info\n\n\ndef solveKnapsackProblem(profits, weights, capacity,warmstart=None, time_limit=None, use_dp=True):\n    multi = (len(weights)>1)\n    \n    profits = [v for v in profits]\n    weights = [[w for w in W] for W in weights]\n    capacity = [c for c in capacity]\n    start_time = time.time()\n    n = len(profits)\n    \n    \n    m = Model()\n    m.setParam('OutputFlag', 0)\n    x = {}\n    for i in range(n):\n        x[(i)] = m.addVar(lb=0,ub=1, name= \"x\"+str(i))\n        #x[i] = m.addVar(vtype=GRB.BINARY,name= \"x\"+str(i))\n    \n    if warmstart is not None:\n        for i in range(n):\n            x[i].Pstart = warmstart[i]\n            m.update()\n \n    m.setObjective(sum( (x[i]*profits[i]) for i in range(n)), GRB.MAXIMIZE)\n    for w in weights:\n        for c in capacity:    \n            m.addConstr(( quicksum(x[i]*w[i] for i in range(n) ) <= c))\n    '''\n\n    x = m.addVars(n,vtype=GRB.BINARY, name='x')\n    for w in weights:\n        for c in capacity:\n            m.addConstr(x.prod(w) <= c)\n    m.setObjective(x.prod(profits), GRB.MAXIMIZE)\n    '''\n    m.optimize()       \n\n    solution_info = {}\n    try:\n        if (m.status == GRB.Status.OPTIMAL):\n            solution_info['runtime'] = m.Runtime\n            solution_info['objective'] = m.objVal\n            m_on = m.getAttr('x',x)\n            sol = list(m_on.values())     \n            solution_info['assignments'] =  [int(i) for i in sol]\n    except:\n        print(\"SOME EXCEPTION HAPPENED! RETURNING GARBAGE\\n\")\n        val = 0\n        import sys\n            \n        solution_info = {}\n        solution_info['runtime'] = m.Runtime\n        solution_info['objective'] = val\n        solution_info['assignments'] = [0 for x in range(len(profits))]\n    return solution_info\n\n\ndef eval_knapsack(grpY_true, grpY_pred, weights, cap, greedy=False,relaxation= False):\n    if isinstance(weights, str) and weights == 'uniform':\n        weights = np.ones(len(grpY_true[0]))\n    assert(isinstance(weights,np.ndarray))\n    \n    vals = np.zeros(len(grpY_true))\n    assignments = []\n    for i in range(len(grpY_true)):\n        knap_sol = {}\n        if greedy:\n            from knapsack_solving import solveKnapsackGreedily\n            knap_sol = solveKnapsackGreedily(profits=grpY_pred[i], weights=weights, capacity=cap)\n        if relaxation:\n            knap_sol = solveKnapsackProblemRelaxation(grpY_pred[i], weights, cap)\n        else:\n            knap_sol = solveKnapsackProblem(grpY_pred[i], weights, cap)\n        vals[i] =np.sum(grpY_true[i] * np.array(knap_sol['assignments'])) \n        assignments.append(knap_sol['assignments'])\n\n    return vals,assignments\n\n\ndef regret_knapsack(grpY_true, grpY_pred, weights='uniform', cap=10,assignments_true=None, relaxation=False):\n    # if called repeatedly, vals_true should be cached\n    if assignments_true is None:\n        vals_true,assignments_true = eval_knapsack(grpY_true, grpY_true, weights=weights, cap=cap, relaxation= relaxation)\n    else:\n        vals_true =  np.sum(grpY_true* np.array(assignments_true)) \n    vals_pred, assignments_pred = eval_knapsack(grpY_true, grpY_pred, weights=weights, cap=cap, relaxation= relaxation)\n    from sklearn.metrics import confusion_matrix\n    if relaxation:\n        confusion_mat = np.zeros((2,2))\n    else:\n        confusion_mat = confusion_matrix(assignments_true[0], assignments_pred[0],labels=[0,1])\n\n    return np.average(vals_true - vals_pred),confusion_mat\n\n# ==========================================\n# File: QPTL/melding_knapsack.py\n# Function/Context: qptl\n# ==========================================\nimport sys\nsys.path.insert(0, '..')\nfrom qpthlocal.qp import QPFunction\nfrom qpthlocal.qp import QPSolvers\nfrom qpthlocal.qp import make_gurobi_model\nimport torch\nfrom sgd_learner import *\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom torch.nn import Parameter\nimport numpy as np\nimport pandas as pd\nimport scipy\nfrom sklearn.metrics import mean_squared_error as mse\nimport matplotlib\nmatplotlib.use('agg')\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\nimport logging\nsys.path.insert(0, '../../EnergyCost/')\n# adapted from https://github.com/bwilder0/aaai_melding_code \n\n\nclass qptl:\n    def __init__(self,capacity,weights,tau=20000,doScale= True,n_items=48,epochs=10,\n        net=LinearRegression,verbose=False,plotting=False,validation_relax=True,test_relax = False,\n        figname=None,validation=False,optimizer=optim.Adam ,**hyperparams):\n        self.n_items = n_items\n        self.epochs = epochs\n        self.net = net\n        self.capacity = capacity\n        self.weights = weights\n        self.model = None\n        self.tau = tau\n        self.hyperparams = hyperparams\n        self.verbose = verbose\n        self.plotting = plotting\n        self.figname = figname\n        self.validation = validation\n        self.doScale = doScale\n        self.optimizer = optimizer\n        self.validation_relax = validation_relax\n        self.test_relax = test_relax\n        self.model_time = 0.\n    def fit(self,X,y,X_validation=None,y_validation=None,X_test=None,y_test=None):\n        # if validation true validation and tets data should be provided\n        tau = self.tau\n\n        start = time.time()\n        validation_time = 0\n        test_time = 0\n        # if validation true validation and tets data should be provided\n        X = X[:,1:]\n        validation = (X_validation is not None) and (y_validation is not None)\n        test = (X_test is not None) and (y_test is not None)\n        if self.doScale:\n            self.scaler = preprocessing.StandardScaler().fit(X)\n            X = self.scaler.transform(X)\n        if validation:\n            start_validation = time.time()\n            X_validation = X_validation[:,1:]\n            if self.doScale:\n                X_validation = self.scaler.transform(X_validation)\n            end_validation = time.time()\n            validation_time += end_validation -start_validation\n\n        if test:\n            start_test = time.time()\n            X_test  = X_test[:,1:]\n            if self.doScale:\n                X_test = self.scaler.transform(X_test)\n            end_test = time.time()\n            test_time+=  end_test - start_test\n\n\n        validation_relax = self.validation_relax\n        test_relax = self.test_relax\n        n_items = self.n_items\n        epochs = self.epochs\n        net = self.net\n        capacity = self.capacity\n        weights = self.weights\n        hyperparams = self.hyperparams\n        #Q= torch.diagflat(torch.ones(n_items)/tau)\n        Q = torch.eye(n_items)/tau\n        #G = torch.cat((torch.from_numpy(weights).float(), torch.diagflat(torch.ones(n_items)), \n         # torch.diagflat(torch.ones(n_items)*-1)), 0)\n        #h = torch.cat((torch.tensor([capacity],dtype=torch.float),torch.ones(n_items),torch.zeros(n_items)))\n\n        G = torch.from_numpy(weights).float()\n        h = torch.tensor([capacity],dtype=torch.float)\n\n        \n        self.Q = Q\n        self.G= G\n        self.h = h        \n        \n        model = net(X.shape[1],1)\n        self.model = model\n        #optimizer = torch.optim.Adam(model.parameters(),**hyperparams)\n        optimizer = self.optimizer(model.parameters(), **hyperparams)\n        model_params_quad = make_gurobi_model(G.detach().numpy(),h.detach().numpy(),None, None, Q.detach().numpy())\n        n_knapsacks = X.shape[0]//n_items\n        \n\n        loss_list =[]\n        accuracy_list =[]\n        regret_list = []\n        subepoch_list= []\n        subepoch= 0\n        logger = []\n        test_list = []\n        n_train = 1\n        shuffled_batches = [i for i in range(n_knapsacks)]\n        for e in range(epochs):\n            np.random.shuffle(shuffled_batches)\n            logging.info('Epoch %d'%e )\n            for i in range(n_knapsacks):\n                n_start =  n_items*shuffled_batches[i]\n                n_stop = n_start + n_items\n                z = torch.tensor(y[n_start:n_stop],dtype=torch.float ) \n                X_tensor= torch.tensor(X[n_start:n_stop,:],dtype=torch.float)\n                c_true= -z\n                c_pred = -(model(X_tensor))\n                solver = QPFunction(verbose=False, solver=QPSolvers.GUROBI, model_params=model_params_quad)\n                x = solver(Q.expand(n_train, *Q.shape),\n                c_pred.squeeze(), G.expand(n_train, *G.shape), \n                h.expand(n_train, *h.shape), torch.Tensor(), torch.Tensor())\n\n                self.model_time +=solver.Runtime()\n                loss = (x.squeeze()*c_true).mean()\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                subepoch += 1\n                if i%20==0:\n                    if self.verbose:\n                        dict_validation = {}\n                        logging.info('Validation starts\\n ' )\n                        #train_result = self.test(X,y)     \n                        if validation:\n                            start_validation = time.time()\n                            validation_result = self.test(X_validation,y_validation,relaxation = validation_relax)\n                            self.model_time+= validation_result[4]\n                            dict_validation['validation_regret'] = validation_result[0]\n                            dict_validation['validation_mse'] = validation_result[1]\n                            dict_validation['validation_accuracy'] = validation_result[2]\n                            dict_validation['validation_loss'] = validation_result[3]\n                            end_validation = time.time()\n                            validation_time += end_validation -start_validation\n                        if test:\n                            start_test = time.time()\n                            test_result = self.test(X_test,y_test , relaxation = test_relax)\n                            self.model_time+= validation_result[4]\n                            dict_validation['test_regret'] = test_result[0]\n                            dict_validation['test_mse'] = test_result[1]\n                            dict_validation['test_accuracy'] = test_result[2]\n                            dict_validation['test_loss'] = test_result[3]\n                            end_test = time.time()\n                            test_time+=  end_test - start_test\n\n\n                        dict_validation['subepoch'] = subepoch\n                        dict_validation['Runtime'] = self.model_time\n                        dict_validation['time'] = time.time() - start  \n\n\n                        \n                        test_list.append(dict_validation)\n\n                        logging.info(\"Epoch %d::subepoch %d Total time %d, validation time %d & test time %d\"%(e,\n                            i,time.time() - start,validation_time,test_time))\n                    \n                        #print('Epoch[{}/{}], loss(train):{:.2f} '.format(e+1, i, loss.item() ))\n                    if self.plotting:\n                        \n                        subepoch_list.append(subepoch)\n                        reg,loss,acc = self.test(X,y)\n                        loss_list.append(loss)\n                        regret_list.append(reg)\n                        accuracy_list.append(acc)\n        if self.plotting:\n            fig, (ax1, ax2,ax3) = plt.subplots(3,1,figsize=(6, 6))\n            ax1.plot(subepoch_list,regret_list)\n            ax1.set_ylabel('Regret')\n            ax2.plot(subepoch_list,loss_list)\n            ax2.set_yscale('log')\n            ax2.set_ylabel('Loss')\n            ax3.plot(subepoch_list,accuracy_list)\n            ax3.set_xlabel('Sub Epochs')\n            ax3.set_ylabel('Accuracy')\n            plt.savefig(self.figname)\n        if self.verbose:\n            dd = defaultdict(list)\n            for d in test_list:\n                for key, value in d.items():\n                    dd[key].append(value)\n            df = pd.DataFrame.from_dict(dd)\n            return df\n\n    def pred(self,X):\n        X = X[:,1:]\n        if self.doScale:\n            X = self.scaler.transform(X)\n        model = self.model\n        model.eval()\n        X_tensor= torch.tensor(X,dtype=torch.float)\n        model.train()\n        return model(X_tensor).detach().numpy().squeeze()\n    def test(self,X,y,relaxation=False):\n        Q= self.Q\n        G = self.G\n        h =  self.h\n        n_train = 1 \n        n_items = self.n_items\n        epochs = self.epochs\n        net = self.net\n        capacity = self.capacity\n        model = self.model\n        weights = self.weights\n        model.eval()\n        X_tensor= torch.tensor(X,dtype=torch.float)\n        y_pred = model(X_tensor).detach().numpy().squeeze()\n        n_knapsacks = X.shape[0]//n_items\n        regret_list= []\n        cf_list = []\n        loss_list = []\n        time = 0\n        model_params_quad = make_gurobi_model(G.detach().numpy(),h.detach().numpy(),None, None, Q.detach().numpy())\n        for i in range(n_knapsacks):\n            n_start =  n_items*i\n            n_stop = n_start + n_items\n            regret, cf=regret_knapsack([y[n_start:n_stop]],[y_pred[n_start:n_stop]],\n                weights=weights,cap=[self.capacity],relaxation = relaxation)\n            regret_list.append(regret)\n            cf_list.append(cf)\n            z = torch.tensor(y[n_start:n_stop],dtype=torch.float )\n            X_tensor= torch.tensor(X[n_start:n_stop,:],dtype=torch.float) \n            c_true= -z\n            c_pred = -(model(X_tensor))\n            solver = QPFunction(verbose=False, solver=QPSolvers.GUROBI, model_params=model_params_quad)\n            x = solver(Q.expand(n_train, *Q.shape),\n                c_pred.squeeze(), G.expand(n_train, *G.shape), h.expand(n_train, *h.shape), torch.Tensor(), torch.Tensor())\n            time +=solver.Runtime()        \n            loss_list.append((x.squeeze()*c_true).mean().item())\n        model.train()\n        if not relaxation:\n            tn, fp, fn, tp = np.sum(np.stack(cf_list),axis=0).ravel()\n            accuracy = (tn+tp)/(tn+fp+fn+tp)\n        else:\n            accuracy = None        \n\n        return np.median(regret_list), mse(y,y_pred), accuracy,np.median(loss_list),time\n\n# ==========================================\n# File: QPTL_ICON/qptl_model.py\n# Function/Context: qptl_ICON\n# ==========================================\nfrom qpthlocal.qp import QPFunction\nfrom qpthlocal.qp import QPSolvers\nfrom qpthlocal.qp import make_gurobi_model\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom torch.nn import Parameter\nimport numpy as np\nimport pandas as pd\nimport scipy\nfrom sklearn.metrics import mean_squared_error as mse\nfrom collections import defaultdict\nimport sys\nsys.path.insert(0, '../EnergyCost/')\nimport logging\nfrom sgd_learner import *\nfrom EnergyCost.ICON import *\nimport random\nimport time,datetime\n\nclass qptl_ICON:\n    def __init__(self,param,tau=20000,doScale= True,n_items=48,epochs=1,\n        net=LinearRegression,verbose=False,validation_relax=True,test_relax = False,\n        validation=False,optimizer=optim.Adam,model_save=False,model_name=None, **hyperparams):\n        self.n_items = n_items\n        self.epochs = epochs\n        self.net = net\n        self.tau = tau\n        self.validation_relax = validation_relax\n        self.test_relax= test_relax\n        self.hyperparams = hyperparams\n        self.verbose = verbose\n        self.validation = validation\n        self.doScale = doScale\n        self.param = param\n        self.optimizer = optimizer\n        self.model_time = 0.\n        self.model_save =  model_save\n        self.model_name = model_name\n    \n    def fit(self,X,y,X_validation=None,y_validation=None,X_test=None,y_test=None):\n        def make_model_matrix(nbMachines,nbTasks,nbResources,MC,U,D,E,L,P,idle,up,down,q,**h):\n            Machines = range(nbMachines)\n            Tasks = range(nbTasks)\n            Resources = range(nbResources)\n            N = 1440//q\n\n            ### G and h\n            G = torch.zeros((nbMachines*N,nbTasks*nbMachines*N))\n            h = torch.zeros(nbMachines*N)\n            F = torch.zeros((N,nbTasks*nbMachines*N))\n            for m in Machines:\n                for t in range(N):\n                    h[m*N+t] = MC[m][0]\n                    for f in Tasks:\n                        c_index = (f*nbMachines+m)*N \n                        G[t + m*N, (c_index+max(0,t-D[f]+1)):(c_index+(t+1))] =1\n                        F [t,(c_index+max(0,t-D[f]+1)):(c_index+(t+1))  ] = P[f]\n            ### A and b\n            A1 = torch.zeros((nbTasks, nbTasks*nbMachines*N))\n            A2 = torch.zeros((nbTasks, nbTasks*nbMachines*N))\n            A3 = torch.zeros((nbTasks, nbTasks*nbMachines*N))\n\n            for f in Tasks:\n                A1 [f,(f*N*nbMachines):((f+1)*N*nbMachines) ] = 1\n                A2 [f,(f*N*nbMachines):(f*N*nbMachines + E[f]) ] = 1\n                A3 [f,(f*N*nbMachines+L[f]-D[f]+1):((f+1)*N*nbMachines) ] = 1\n            b = torch.cat((torch.ones(nbTasks),torch.zeros(2*nbTasks)))\n            A = torch.cat((A1,A2,A3))    \n            return A,b,G,h,torch.transpose(F, 0, 1)\n\n        logging.info('Model Training Starts\\n' )\n        tau = self.tau\n        start = time.time()\n        validation_time = 0\n        test_time = 0\n        X = X[:,1:]\n        validation = (X_validation is not None) and (y_validation is not None)\n        test = (X_test is not None) and (y_test is not None)\n        if self.doScale:\n            self.scaler = preprocessing.StandardScaler().fit(X)\n            X = self.scaler.transform(X)\n        if validation:\n            X_validation = X_validation[:,1:]\n            if self.doScale:\n                X_validation = self.scaler.transform(X_validation)\n        if test:\n            X_test  = X_test[:,1:]\n            if self.doScale:\n                X_test = self.scaler.transform(X_test)\n\n        n_items = self.n_items\n        epochs = self.epochs\n        net = self.net\n        param = self.param\n        hyperparams = self.hyperparams\n        validation_relax = self.validation_relax\n        test_relax = self.test_relax\n        if validation:\n            solver_validation  = Gurobi_ICON(relax=validation_relax,reset= True,presolve= True, **param)\n            solver_validation.make_model()\n            self.solver_validation = solver_validation\n        if test:\n            solver_test  = Gurobi_ICON( **param,reset= True,presolve= True)\n            solver_test.make_model()\n            self.solver_test = solver_test\n        \n        if self.validation:\n            if validation:\n                sol_validation = self.solution_func(y_validation,solver=self.solver_validation)\n            if test:\n                sol_test = self.solution_func(y_test,solver= self.solver_test)\n        \n        A,b,G,h,F = make_model_matrix(**param)\n        Q = torch.eye(F.shape[0])/tau\n        self.Q = Q\n        self.G= G\n        self.h = h\n        self.A = A\n        self.b = b\n        self.F = F\n        \n        model = net(X.shape[1],1)\n        optimizer = self.optimizer(model.parameters(), **hyperparams)\n        model_params_quad = make_gurobi_model(G.detach().numpy(),h.detach().numpy(),A.detach().numpy(), \n                                              b.detach().numpy(), Q.detach().numpy())\n        self.gurobi_model = model_params_quad\n        n_knapsacks = X.shape[0]//n_items\n\n        loss_list =[]\n        regret_list = []\n        subepoch= 0\n        logger = []\n        test_list = []\n        n_train = 1 \n        for e in range(epochs):\n            logging.info('Epoch %d'%e )\n            subepoch_list = [j for j in range(n_knapsacks)]\n            random.shuffle(subepoch_list) \n\n            for i in range(n_knapsacks):\n                n_start =  n_items*subepoch_list[i]\n                n_stop = n_start + n_items\n                c_true = torch.mm(F,torch.tensor(y[n_start:n_stop],dtype=torch.float ).unsqueeze(1))\n                X_tensor = torch.tensor(X[n_start:n_stop,:],dtype=torch.float)\n                c_pred = (model(X_tensor))\n                c_pred  = torch.mm(F,model(X_tensor))\n                \n                solver = QPFunction(verbose=False, solver=QPSolvers.GUROBI, model_params=model_params_quad)\n                x = solver(Q.expand(n_train, *Q.shape),\n                c_pred.squeeze(), G.expand(n_train, *G.shape), h.expand(n_train, *h.shape), \n                A.expand(n_train, *A.shape), b.expand(n_train, *b.shape))\n                \n                self.model_time +=solver.Runtime()\n                loss = (x.squeeze()*c_true.squeeze()).mean()\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                self.model = model\n                subepoch += 1\n                \n                if i%50==0:\n                    if self.verbose:\n                        dict_validation = {}\n                        logging.info('Validation starts\\n ' )\n                        if validation:\n                            validation_result = self.test(X_validation,y_validation,sol_validation,solver= self.solver_validation)\n                            self.model_time+= validation_result[3]\n                            dict_validation['validation_regret']=validation_result[0]\n                            dict_validation['validation_mse'] = validation_result[1]\n                            dict_validation['validation_loss']=validation_result[2]\n                        if test:\n                            test_result = self.test(X_test,y_test,sol_test,solver= self.solver_test)\n                            dict_validation['test_regret'] = test_result[0]\n                            dict_validation['test_mse'] =test_result[1]\n                            dict_validation['test_loss'] = test_result[2]\n                        dict_validation['subepoch'] = subepoch\n                        dict_validation['Runtime'] = self.model_time\n                        dict_validation['time'] = time.time() - start  \n                        test_list.append(dict_validation)\n            print('Epoch[%d::%d], loss(train):%.2f at %s'%(e+1, i, loss,datetime.datetime.now() ))\n        \n        if self.verbose:\n            dd = defaultdict(list)\n            for d in test_list:\n                for key, value in d.items():\n                    dd[key].append(value)\n            df = pd.DataFrame.from_dict(dd)\n            return df\n\n    def pred(self,X):\n        X = X[:,1:]\n        if self.doScale:\n            X = self.scaler.transform(X)\n        model = self.model\n        model.eval()\n        X_tensor= torch.tensor(X,dtype=torch.float)\n        model.train()\n        return model(X_tensor).detach().numpy().squeeze()\n    \n    def solution_func(self,y,solver,**params):\n        n_items = self.n_items\n        n_knap = len(y)//n_items\n        regret_full = np.zeros(n_knap)\n        solution = []\n        for kn_nr in range(n_knap):\n            n_start  = kn_nr * n_items\n            n_stop  = n_start + n_items\n            V = y[n_start:n_stop]\n            solution.append(solver.solve_model(V))\n        return solution\n    \n    def test(self,X,y,sol,solver):\n        Q= self.Q\n        G = self.G\n        h =  self.h\n        A = self.A\n        b =  self.b\n        F = self.F\n        model_params_quad = self.gurobi_model \n        time = 0\n        n_train = 1 \n        n_items = self.n_items\n        model = self.model\n        model.eval()\n        X_tensor= torch.tensor(X,dtype=torch.float)\n        c_pred = (model(X_tensor))\n        y_pred = c_pred.detach().numpy().squeeze()\n        model.train()\n        n_knap = len(y)//n_items\n        sol_pred = self.solution_func(y_pred,solver=solver)\n        regret_list= []\n       \n        loss_list = []\n        for i in range(n_knap):\n            n_start =  n_items*i\n            n_stop = n_start + n_items\n            regret = (y[n_start:n_stop]*(sol_pred[i][0] - sol[i][0])).sum()\n            regret_list.append(regret)\n            c  = torch.mm(F,c_pred[n_start:n_stop])\n            c_true = torch.mm(F,torch.tensor(y[n_start:n_stop],dtype=torch.float ).unsqueeze(1))\n            solver = QPFunction(verbose=False, solver=QPSolvers.GUROBI, model_params=model_params_quad)\n            x = solver(Q.expand(n_train, *Q.shape),\n                c.squeeze(), G.expand(n_train, *G.shape), h.expand(n_train, *h.shape), torch.Tensor(), torch.Tensor())\n            loss = (x.squeeze()*c_true.squeeze()).mean().item()\n            loss_list.append(loss)\n            time += solver.Runtime()\n        return np.median(regret_list), mse(y,y_pred), np.median(loss_list),time\n\n# ==========================================\n# File: SPO_dp_lr.py\n# Function/Context: SGD_SPO_dp_lr.fit\n# ==========================================\nimport math\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix\nimport torch\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom get_energy import get_energy\nfrom sgd_learner import *\nimport logging \nimport datetime\nimport time\nfrom collections import defaultdict\n\nclass SGD_SPO_dp_lr:\n    def __init__(self, capacity=None, weights=None, epochs=2, doScale=True, early_stopping=False,\n                 n_items=48, model=None, verbose=False, plotting=False, return_regret=False, use_dp=True,\n                 use_relaxation=False, validation_relax=False, degree=1, optimizer=optim.SGD, store_result=False, **hyperparam):\n        self.n_items = n_items\n        self.capacity = capacity\n        self.weights = weights\n        self.hyperparam = hyperparam\n        self.epochs = epochs\n        self.doScale = doScale\n        self.verbose = verbose\n        self.plotting = plotting\n        self.return_regret = return_regret\n        self.optimizer = optimizer\n        self.use_dp = use_dp\n        self.degree = degree\n        self.early_stopping = early_stopping\n        self.use_relaxation = use_relaxation\n        self.validation_relax = validation_relax\n        self.store_result = store_result\n        self.scaler = None\n        self.model = model\n        self.best_params_ = {\"p\": \"default\"}\n        self.time = 0\n\n    def fit(self, x_train, y_train, x_validation=None, y_validation=None, x_test=None, y_test=None):\n        qids = np.array(x_train[:, 0], dtype=int)\n        x_train = x_train[:, 1:]\n        validation = (x_validation is not None) and (y_validation is not None)\n        test = (x_test is not None) and (y_test is not None)\n        if self.early_stopping:\n            validation_rslt = []\n        \n        if self.doScale:\n            self.scaler = preprocessing.StandardScaler().fit(x_train)\n            x_train = self.scaler.transform(x_train)\n        \n        trch_X_train = torch.from_numpy(x_train).float()\n        trch_y_train = torch.from_numpy(np.array([y_train]).T).float()\n        if validation:\n            x_validation = x_validation[:, 1:]\n            if self.doScale:\n                x_validation = self.scaler.transform(x_validation)\n            trch_X_validation = torch.from_numpy(x_validation).float()\n            trch_y_validation = torch.from_numpy(np.array([y_validation]).T).float()\n        \n        if test:\n            x_test = x_test[:, 1:]\n            if self.doScale:\n                x_test = self.scaler.transform(x_test)\n            trch_X_test = torch.from_numpy(x_test).float()\n            trch_y_test = torch.from_numpy(np.array([y_test]).T).float()\n        \n        if self.plotting:\n            subepoch_list = []\n            loss_list = []\n            regret_list = []\n            accuracy_list = []\n            if validation:\n                loss_list_validation = []\n                regret_list_validation = []\n                accuracy_list_validation = []\n        \n        n_items = self.n_items\n        n_knapsacks = len(trch_X_train) // n_items\n        capacity = self.capacity\n        \n        knaps_V_true = [get_profits(trch_y_train, kn_nr, n_items) for kn_nr in range(n_knapsacks)]\n        knaps_sol = [get_kn_indicators(V_true, capacity, weights=self.weights,\n                                        use_dp=self.use_dp, relaxation=self.use_relaxation) for V_true in knaps_V_true]\n        for k in knaps_sol:\n            self.time += k[1]\n        \n        if validation:\n            n_knapsacks_validation = len(trch_X_validation) // n_items\n            knaps_V_true_validation = [get_profits(trch_y_validation, kn_nr, n_items) for kn_nr in range(n_knapsacks_validation)]\n            knaps_sol_validation = [get_kn_indicators(V_true, capacity, weights=self.weights,\n                                                       use_dp=self.use_dp, relaxation=self.validation_relax) for V_true in knaps_V_true_validation]\n            for k in knaps_sol_validation:\n                self.time += k[1]\n        \n        if test:\n            n_knapsacks_test = len(trch_X_test) // n_items\n            knaps_V_true_test = [get_profits(trch_y_test, kn_nr, n_items) for kn_nr in range(n_knapsacks_test)]\n            knaps_sol_test = [get_kn_indicators(V_true, capacity, weights=self.weights,\n                                                use_dp=self.use_dp, relaxation=False) for V_true in knaps_V_true_test]\n        \n        if not self.model:\n            self.model = LinearRegression(trch_X_train.shape[1], 1)\n        \n        criterion = nn.MSELoss()\n        optimizer = self.optimizer(self.model.parameters(), **self.hyperparam)\n        num_epochs = self.epochs\n        \n        subepoch = 0\n        logger = []\n        test_result = []\n        knapsack_nrs = [x for x in range(n_knapsacks)]\n        for epoch in range(num_epochs):\n            logging.info('Training Epoch%d Time:%s\\n' % (epoch, str(datetime.datetime.now())))\n            random.shuffle(knapsack_nrs)\n            cnt = 0\n            for kn_nr in knapsack_nrs:\n                V_true = knaps_V_true[kn_nr]\n                sol_true = knaps_sol[kn_nr][0]\n                \n                V_pred = get_profits_pred(self.model, trch_X_train, kn_nr, n_items)\n                V_spo = (2 * V_pred - V_true)\n                \n                sol_spo, t = get_kn_indicators(V_spo, capacity, warmstart=sol_true,\n                                                weights=self.weights, use_dp=self.use_dp, relaxation=self.use_relaxation)\n                grad = (sol_spo - sol_true)\n                \n                if self.degree == 2:\n                    sol_pred, t = get_kn_indicators(V_pred, capacity, weights=self.weights,\n                                                     use_dp=self.use_dp, relaxation=self.use_relaxation)\n                    reg = sum((sol_true - sol_pred) * V_true)\n                    grad = reg * grad\n                self.time += t\n                \n                kn_start = kn_nr * n_items\n                kn_stop = kn_start + n_items\n                train_fwdbwd_grad(self.model, optimizer, trch_X_train[kn_start:kn_stop],\n                                  trch_y_train[kn_start:kn_stop], torch.from_numpy(np.array([grad]).T).float())\n                \n                if self.verbose or self.plotting or self.store_result:\n                    cnt += 1\n                    subepoch += 1\n                    if cnt % 20 == 0:\n                        dict_epoch = {'epoch': epoch + 1, 'subepoch': subepoch, 'cnt': cnt}\n                        dict_train = test_fwd(self.model, criterion, trch_X_train, trch_y_train, n_items, capacity, knaps_sol,\n                                               relaxation=self.use_relaxation, weights=self.weights)\n                        if validation:\n                            dict_validation = test_fwd(self.model, criterion, trch_X_validation, trch_y_validation,\n                                                       n_items, capacity, knaps_sol_validation, relaxation=self.validation_relax, weights=self.weights)\n                        if test:\n                            dict_test = test_fwd(self.model, criterion, trch_X_test, trch_y_test,\n                                                 n_items, capacity, knaps_sol_test, relaxation=False, weights=self.weights)\n                        self.time += dict_validation['runtime']\n                        if self.store_result:\n                            info = {}\n                            info['train_loss'] = dict_train['loss']\n                            info['train_regret_full'] = dict_train['regret_full']\n                            info['train_accuracy'] = dict_train['accuracy']\n                            info['validation_loss'] = dict_validation['loss']\n                            info['validation_regret_full'] = dict_validation['regret_full']\n                            info['validation_accuracy'] = dict_validation['accuracy']\n                            info['test_loss'] = dict_test['loss']\n                            info['test_regret_full'] = dict_test['regret_full']\n                            info['test_accuracy'] = dict_test['accuracy']\n                            info['subepoch'] = subepoch\n                            info['time'] = self.time\n                            test_result.append(info)\n                        \n                        if self.plotting:\n                            loss_list.append(dict_train['loss'])\n                            regret_list.append(dict_train['regret_full'])\n                            accuracy_list.append((dict_train['tn'] + dict_train['tp']) / (dict_train['tn'] + dict_train['tp'] + dict_train['fp'] + dict_train['fn']))\n                            subepoch_list.append(subepoch)\n                            if validation:\n                                loss_list_validation.append(dict_validation['loss'])\n                                regret_list_validation.append(dict_validation['regret_full'])\n                                accuracy_list_validation.append((dict_validation['tn'] + dict_validation['tp']) / (dict_validation['tn'] + dict_validation['tp'] + dict_validation['fp'] + dict_validation['fp']))\n                        if self.verbose:\n                            if validation:\n                                logger.append((dict_epoch, dict_train, dict_validation))\n                                print('Epoch[{}/{}]::{}, loss(train): {:.6f}, regret(train): {:.2f}, loss(validation): {:.6f}, regret(validation): {:.2f}'.format(epoch + 1,\n                                      num_epochs, cnt, dict_train['loss'], dict_train['regret_full'], dict_validation['loss'], dict_validation['regret_full']))\n                            else:\n                                logger.append((dict_epoch, dict_train))\n                                print('Epoch[{}/{}]::{}, loss: {:.6f}, regret(train): {:.2f}'.format(epoch + 1, num_epochs, cnt, dict_train['loss'], dict_train['regret_full']))\n            \n            if self.early_stopping:\n                dict_train = test_fwd(self.model, criterion, trch_X_train, trch_y_train, n_items, capacity, weights=self.weights)\n                dict_validation = test_fwd(self.model, criterion, trch_X_validation, trch_y_validation, n_items, capacity, weights=self.weights)\n                validation_rslt.append([epoch, dict_train['loss'].item(), dict_train['regret_full'], dict_validation['loss'].item(), dict_validation['regret_full']])\n        \n        if self.plotting:\n            import matplotlib.pyplot as plt\n            if validation:\n                plt.subplot(3, 1, 1)\n                plt.plot(subepoch_list, regret_list, subepoch_list, regret_list_validation)\n                plt.title('Learning Curve')\n                plt.ylabel('Regret')\n                plt.ylim(top=np.mean(regret_list) + 5 * np.std(regret_list))\n                plt.legend([\"training\", \"validation\"])\n                plt.subplot(3, 1, 2)\n                plt.plot(subepoch_list, loss_list, subepoch_list, loss_list_validation)\n                plt.xlabel('Sub Epochs')\n                plt.ylabel('Loss')\n                plt.yscale('log')\n                plt.legend([\"training\", \"validation\"])\n                plt.subplot(3, 1, 3)\n                plt.plot(subepoch_list, accuracy_list, subepoch_list, accuracy_list_validation)\n                plt.xlabel('Sub Epochs')\n                plt.ylabel('Accuracy')\n                plt.legend([\"training\", \"validation\"])\n                plt.show()\n            else:\n                plt.subplot(3, 1, 1)\n                plt.plot(subepoch_list, regret_list)\n                plt.title('Learning Curve')\n                plt.ylabel('Regret')\n                plt.ylim(top=np.mean(regret_list) + 5 * np.std(regret_list))\n                plt.subplot(3, 1, 2)\n                plt.plot(subepoch_list, loss_list)\n                plt.yscale('log')\n                plt.xlabel('Sub Epochs')\n                plt.ylabel('Loss')\n                plt.subplot(3, 1, 3)\n                plt.plot(subepoch_list, accuracy_list)\n                plt.ylim(bottom=np.median(accuracy_list) - 3 * np.std(accuracy_list))\n                plt.xlabel('Sub Epochs')\n                plt.ylabel('Accuracy')\n                plt.show()\n        \n        if self.early_stopping:\n            return pd.DataFrame(validation_rslt, columns=['Epoch', 'train_loss', 'train_regret', 'validation_loss', 'validation_regret'])\n        if self.store_result:\n            dd = defaultdict(list)\n            for d in test_result:\n                for key, value in d.items():\n                    dd[key].append(value)\n            df = pd.DataFrame.from_dict(dd)\n            logging.info('Completion Time %s \\n' % str(datetime.datetime.now()))\n            return df\n\n# ==========================================\n# File: sgd_learner.py\n# Function/Context: Multiple functions implementing SPO framework\n# ==========================================\nimport math\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import preprocessing\nimport torch\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom KnapsackSolving import *\nfrom operator import itemgetter\nimport itertools\nfrom multiprocessing.pool import ThreadPool\nfrom sklearn.metrics import confusion_matrix\nfrom collections import defaultdict\nimport sys\n\nfrom EnergyCost.ICON import *\n\nclass LinearRegression(nn.Module):\n    def __init__(self, dim_in, dim_out):\n        super().__init__()\n        self.linear = nn.Linear(dim_in, dim_out)\n        \n    def forward(self, x):\n        out = self.linear(x)\n        return out\n\nclass GridRegression(nn.Module):\n    def __init__(self, dim_in, dim_out):\n        super().__init__()\n        self.linear = nn.Linear(dim_in, dim_out)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        out = self.relu((self.linear(x)))\n        return out\n\nclass LogitRegression(nn.Module):\n    def __init__(self, dim_in, num_classes):\n        super().__init__()\n        self.linear = nn.Linear(dim_in, num_classes)\n        self.softmax = nn.Softmax()\n        \n    def forward(self, x):\n        out1 = self.linear(x)\n        out2 = self.softmax(out1)\n        return out2\n    \n    def take_outY(self, x):\n        self.train(False)\n        return self.linear(x)\n\ndef get_kn_indicators(V_pred, c, weights=None, use_dp=True, relaxation=False, warmstart=None):\n    if weights is None:\n        weights = np.ones(V_pred.shape[0])\n    if use_dp:\n        if relaxation:\n            solution = solveKnapsackProblemRelaxation(V_pred, weights, c, warmstart=warmstart)\n        else:\n            solution = solveKnapsackProblem(V_pred, weights, c, warmstart=warmstart)\n        return np.asarray(solution['assignments']), solution['runtime']\n    \n    ret = np.zeros(V_pred.shape[0])\n    V_val = V_pred/weights\n    \n    for val in sorted(set(V_val), reverse=True):\n        same_val = (V_val == val)\n        tot_weight = sum(weights[same_val])\n        if c >= tot_weight:\n            ret[same_val] = 1\n            c = c - tot_weight\n        elif c > 0:\n            fraction = c/tot_weight\n            ret[same_val] = fraction\n            c = 0\n            break\n        else:\n            break\n    \n    ret[V_pred <= 0] = 0\n    return ret\n\ndef train_fwdbwd_grad(model, optimizer, sub_X_train, sub_y_train, grad):\n    inputs = Variable(sub_X_train, requires_grad=True)\n    target = Variable(sub_y_train)\n    out = model(inputs)\n    grad = grad*torch.ones(1)\n    \n    optimizer.zero_grad()\n    loss = out\n    loss.backward(gradient=grad)\n    optimizer.step()\n\ndef test_fwd(model, criterion, trch_X, trch_y, n_items, capacity, knaps_sol, weights=None, relaxation=False):\n    info = dict()\n    model.eval()\n    with torch.no_grad():\n        inputs = Variable(trch_X)\n        target = Variable(trch_y)\n        V_preds = model(inputs)\n        info['loss'] = criterion(V_preds, target).item()\n    model.train()\n    \n    n_knap = len(V_preds)//n_items\n    regret_smooth = np.zeros(n_knap)\n    regret_full = np.zeros(n_knap)\n    cf_list = []\n    time = 0\n    \n    for kn_nr in range(n_knap):\n        V_true = get_profits(trch_y, kn_nr, n_items)\n        V_pred = get_profits(V_preds, kn_nr, n_items)\n        assignments_pred, t = get_kn_indicators(V_pred, c=capacity, weights=weights, relaxation=relaxation)\n        assignments_true = knaps_sol[kn_nr][0]\n        regret_full[kn_nr] = np.sum(V_true * (assignments_true - assignments_pred))\n        if not relaxation:\n            cf = confusion_matrix(assignments_true, assignments_pred, labels=[0,1])\n            cf_list.append(cf)\n        time += t\n    \n    info['nonzero_regrsm'] = sum(regret_smooth != 0)\n    info['nonzero_regrfl'] = sum(regret_full != 0)\n    info['regret_full'] = np.median(regret_full)\n    if not relaxation:\n        tn, fp, fn, tp = np.sum(np.stack(cf_list), axis=0).ravel()\n        info['tn'], info['fp'], info['fn'], info['tp'] = (tn, fp, fn, tp)\n        info['accuracy'] = (tn+tp)/(tn+tp+fn+fp)\n    else:\n        info['accuracy'] = None\n    info['runtime'] = time\n    return info\n\ndef diffprof(V_pred, index, newvalue, V_true, c, weights=None, use_dp=True):\n    sol = get_kn_indicators(V_pred, c, weights, use_dp)\n    Vnew = np.array(V_pred)\n    Vnew[index] = newvalue\n    sol_new = get_kn_indicators(Vnew, c, weights, use_dp)\n    return sum(V_true*(sol - sol_new))\n\ndef knapsack_value(V, sol, **kw):\n    return sum(V*sol)",
  "description": "Combined Analysis:\n- [EnergyCost/ICON.py]: This file implements the core optimization logic for the energy-aware scheduling problem described in the paper. The Gurobi_ICON class formulates and solves a mixed-integer linear programming model for task scheduling on machines with resource constraints, time windows, and energy costs. Key features include: 1) Binary/continuous decision variables for task assignments, 2) Constraints for earliest start/latest end times, task uniqueness, and resource capacities, 3) Linear objective minimizing total energy cost based on predicted price parameters, 4) Support for warm-starting and relaxations as discussed in the paper's scaling techniques. While the paper's example uses knapsack, this implements a complex scheduling problem that fits the predict-then-optimize framework, with the price vector being the predicted parameter.\n- [EnergyCost/SPO.py]: This file implements the core SPO+ algorithm from the paper. The SGD_SPO class trains a linear regression model to predict unknown objective coefficients (energy costs) using the SPO+ loss. Key steps: 1) Compute true values (V_true) and optimal solutions (sol_true) via get_energy_indicators (solves knapsack). 2) Generate predictions (V_pred) and compute SPO-adjusted predictions (V_spo = 2*V_pred - V_true). 3) Solve knapsack with V_spo to get sol_spo. 4) Compute gradient as (sol_spo - sol_true) and backpropagate through the predictive model. This directly minimizes decision regret rather than prediction error, aligning with the paper's predict-then-optimize framework.\n- [EnergyCost/SelectiveRegression.py]: This file implements a selective regression variant of the SPO framework for energy cost optimization. The core logic aligns with the paper's predict-then-optimize approach: 1) A linear regression model predicts unknown parameters (energy costs); 2) The optimization problem (energy cost minimization) is solved exactly using get_energy_indicators for both true and predicted parameters; 3) Regret is computed as the objective difference between solutions; 4) Training selectively updates only on items where prediction errors cause high regret (via diffprof), implementing a regret-aware learning strategy. The code uses PyTorch for gradient-based optimization with MSE as a base loss, but the selective update mechanism directly minimizes decision regret rather than pure prediction error.\n- [EnergyCost/regression_SPO.py]: This file implements the core SPO framework for predict-then-optimize problems. The Regression_generic class trains a machine learning model (linear regression by default) to predict unknown parameters (e.g., item values) of a combinatorial optimization problem. Key algorithm steps include: 1) Data preprocessing and scaling, 2) Solving optimization problems with true parameters to obtain optimal solutions for regret computation, 3) Training the predictive model using gradient descent (via train_fwdbwd from sgd_learner) with MSE loss, 4) Periodically evaluating regret on validation/test sets by solving the optimization problem with predicted parameters and comparing objective values. The code supports relaxation (SPO-relax) and warm-starting strategies for scalability, aligning with the paper's focus on hard combinatorial problems. However, it uses MSE as the surrogate loss rather than SPO+, indicating a baseline implementation within the broader SPO framework.\n- [EnergyCost/torch_SPO_updated.py]: This file implements the core SPO (Smart Predict-and-Optimize) framework from the AAAI 2020 paper. The SGD_SPO_generic class provides a generic implementation that can be adapted to different combinatorial optimization problems. Key aspects implemented:\n1. SPO training framework with regret minimization as the primary objective (not just prediction error)\n2. Support for exact optimization solvers and relaxations (via 'relax', 'validation_relax', 'test_relax' parameters)\n3. Warm-starting capabilities for scalability ('warmstart' parameter)\n4. Regret computation in validation_score() and test_score() methods using the optimal_value() function\n5. Integration of machine learning model (PyTorch) with optimization solver\n6. The framework is problem-agnostic - specific optimization problems are defined through the 'solver', 'optimal_value', and helper functions passed as parameters\n7. The code computes decision regret as: max_min_ind * (optimal_value(V_true, sol_true) - optimal_value(V_true, sol_pred))\n\nNote: The actual SPO gradient computation and training loop updates are likely implemented in the imported 'sgd_learner' module, while this file provides the infrastructure for integrating prediction and optimization.\n- [KnapsackSolving.py]: This file directly implements the core optimization logic and key algorithm steps from the paper. It provides:\n1. Exact 0-1 knapsack solver (solveKnapsackProblem) using Gurobi with binary variables, matching the paper's optimization model: maximize sum(V_i*X_i) subject to weight constraint and X_i  {0,1}.\n2. Linear relaxation solver (solveKnapsackProblemRelaxation) for continuous relaxations (0  X_i  1), enabling SPO-relax approach.\n3. Regret computation (regret_knapsack) that calculates decision regret between solutions from true vs predicted parameters, central to SPO training.\n4. Helper functions for greedy solving and evaluation. The implementation supports warm-starting (via Pstart) and handles multi-dimensional weights, aligning with the paper's scaling techniques.\n- [QPTL/melding_knapsack.py]: This file implements the QPTL (Quadratic Programming Task Loss) method for the 0-1 knapsack problem, which aligns with the paper's predict-then-optimize framework. The core logic includes: 1) A neural network (default LinearRegression) predicting item values from features, 2) A quadratic programming relaxation of the knapsack constraints (weights  capacity) with regularization parameter , 3) Training via gradient descent on a decision-aware loss that minimizes regret between solutions from predicted vs. true values, 4) Support for exact (binary) and relaxed (continuous) evaluations. The implementation uses Gurobi via qpthlocal for QP solving during training and regret computation via regret_knapsack helper. This matches the paper's SPO paradigm of optimizing predictive models for downstream decision quality rather than pure prediction error.\n- [QPTL_ICON/qptl_model.py]: This file implements the QPTL (Quadratic Programming Task Loss) variant of the SPO framework for the ICON scheduling problem. Key aspects that match the paper's core logic:\n1. Predict-then-optimize paradigm: Uses neural network (net) to predict unknown parameters (energy costs), then solves optimization problem with predictions\n2. Decision-focused learning: Minimizes regret (difference between predicted and true optimal solutions) rather than just prediction error\n3. Hard combinatorial problem: Addresses complex scheduling (ICON) with resource constraints, time windows, and machine assignments\n4. Continuous relaxations: Uses QP relaxation via QPFunction with Gurobi backend (validation_relax/test_relax parameters control relaxation)\n5. SPO-inspired training: Computes loss as (x*c) where x* is solution from predicted costs, c are true costs - equivalent to SPO's decision regret\n6. Mathematical model: The make_model_matrix function encodes scheduling constraints (resource capacities, task durations, time windows) as QP matrices\n7. Algorithm steps: Implements training loop with forward pass (prediction  optimization  loss calculation  backpropagation)\n8. Warm-starting: Uses make_gurobi_model to pre-build optimization model for efficiency\n\nThe implementation specifically adapts SPO to scheduling problems using quadratic regularization (tau parameter) for differentiability, matching the paper's exploration of relaxation techniques for hard problems.\n- [SPO_dp_lr.py]: This file implements the core SPO+ training algorithm for the 0-1 knapsack problem as described in the paper. Key components include: 1) Linear regression model predicting item values (V_i). 2) SPO+ gradient computation using V_spo = 2*V_pred - V_true and solving knapsack via dynamic programming (use_dp=True) or relaxation (use_relaxation=True). 3) Gradient update based on difference between solutions (sol_spo - sol_true). 4) Support for degree-2 SPO+ variant. 5) Warm-starting optimization with true solution (warmstart=sol_true). 6) Training objective minimizes decision regret rather than prediction error (MSE). The implementation matches the paper's SPO+ framework for hard combinatorial problems, using exact DP or relaxations for scalability.\n- [sgd_learner.py]: This file implements the core SPO framework from the paper. Key components: 1) ML models (LinearRegression, GridRegression, LogitRegression) for predicting unknown parameters, 2) get_kn_indicators() solves the knapsack optimization problem (exact via DP or relaxation), 3) train_fwdbwd_grad() implements gradient-based training with optimization-aware gradients, 4) test_fwd() computes decision regret between solutions from predicted vs true parameters, 5) diffprof() computes gradient of regret w.r.t predictions. The code supports both exact and relaxed optimization solutions, warm-starting, and handles multiple problem types (knapsack, shortest path, ICON scheduling).",
  "dependencies": [
    "preprocessing",
    "sklearn",
    "gurobipy",
    "collections.defaultdict",
    "sgd_learner.train_fwdbwd_grad",
    "sgd_learner.get_profits",
    "sklearn.preprocessing",
    "multiprocessing.pool.ThreadPool",
    "torch.autograd.Variable",
    "get_energy",
    "sklearn.preprocessing.StandardScaler",
    "sys",
    "torch.optim",
    "matplotlib.pyplot",
    "qpthlocal.qp",
    "matplotlib",
    "time",
    "sgd_learner.test_fwd",
    "sgd_learner.LinearRegression",
    "logging",
    "get_energy.get_energy",
    "EnergyCost.ICON",
    "sgd_learner.get_kn_indicators",
    "scipy",
    "math",
    "sgd_learner",
    "datetime",
    "energy_cost.*",
    "random",
    "sklearn.metrics.confusion_matrix",
    "numpy",
    "sklearn.metrics",
    "KnapsackSolving",
    "collections",
    "torch.nn",
    "pandas",
    "torch"
  ]
}