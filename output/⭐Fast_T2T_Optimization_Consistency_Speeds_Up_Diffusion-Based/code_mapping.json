{
  "file_path": "diffusion/consistency/mis.py, diffusion/consistency/tsp.py, diffusion/pl_meta_model.py, diffusion/pl_mis_model.py, diffusion/pl_tsp_model.py, diffusion/utils/diffusion_schedulers.py",
  "function_name": "MISConsistency, TSPConsistency, COMetaModel, MISModel, TSPModel, CategoricalDiffusion",
  "code_snippet": "\n\n# ==========================================\n# File: diffusion/consistency/mis.py\n# Function/Context: MISConsistency\n# ==========================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport scipy\nfrom torch_sparse import SparseTensor\nfrom diffusion.utils.diffusion_schedulers import InferenceSchedule\nfrom diffusion.consistency.meta import MetaConsistency\nfrom diffusion.utils.mis_utils import mis_decode_np\n\n\nclass MISConsistency(MetaConsistency):\n    def __init__(\n            self,\n            args,\n            sigma_max=1000,\n            sigma_min=0,\n            weight_schedule=\"uniform\",\n            boundary_func='truncate'\n    ):\n        super(MISConsistency, self).__init__(\n            sigma_max=sigma_max,\n            sigma_min=sigma_min,\n            weight_schedule=weight_schedule,\n            boundary_func=boundary_func)\n\n        self.args = args\n\n    def consistency_losses(self, model, batch):\n        _, graph_data, point_indicator = batch  # point_indicator: B, 1, number of nodes in each batch\n        node_labels = graph_data.x  # N*B\n        edge_index = graph_data.edge_index  # 2, E*B\n\n        x0 = F.one_hot(node_labels.long(), num_classes=2).float()\n\n        device = node_labels.device\n        t = torch.randint(1, model.diffusion.T + 1, [point_indicator.shape[0]]).to(device)\n        t2 = (model.args.alpha * t).int().to(device)\n\n        t = t.repeat_interleave(point_indicator.reshape(-1), dim=0)\n        t2 = t2.repeat_interleave(point_indicator.reshape(-1), dim=0)\n\n        x_t = model.diffusion.sample(x0.unsqueeze(1).unsqueeze(1), t.cpu().numpy())\n        x_t2 = model.diffusion.sample(x0.unsqueeze(1).unsqueeze(1), t2.cpu().numpy())\n\n        t = t.reshape(-1).float()\n        t2 = t2.reshape(-1).float()\n        x_t = x_t.reshape(-1).to(device)  # N\n        x_t2 = x_t2.reshape(-1).to(device)\n        edge_index = edge_index.to(device).reshape(2, -1)  # 2, E\n\n        model_output, denoise = self.denoise(model, x_t, t, edge_index, x0)\n        model_output2, denoise2 = self.denoise(model, x_t2, t2, edge_index, x0)\n\n        loss_func = nn.CrossEntropyLoss()\n        loss = loss_func(denoise, node_labels) + loss_func(denoise2, node_labels)\n\n        return loss\n\n    def denoise(self, model, x_t, t, edge_index, x0):\n        x_t = x_t * 2 - 1\n        x_t = x_t * (1.0 + 0.05 * torch.rand_like(x_t))\n        model_output = model(x_t, t, edge_index)\n\n        c_skip, c_out = [\n            self.append_dims(x, model_output.ndim)\n            for x in self.get_scalings_for_boundary_condition(t)\n        ]\n\n        denoise = c_out * model_output + c_skip * x0\n\n        return model_output, denoise\n\n    def consistency_test_step(self, model, batch, batch_idx, split='test'):\n        device = batch[-1].device\n\n        real_batch_idx, graph_data, point_indicator = batch\n        node_labels = graph_data.x\n        edge_index = graph_data.edge_index\n\n        stacked_predict_labels = []\n        edge_index = edge_index.to(node_labels.device).reshape(2, -1)\n        edge_index_np = edge_index.cpu().numpy()\n        adj_mat = scipy.sparse.coo_matrix(\n            (np.ones_like(edge_index_np[0]), (edge_index_np[0], edge_index_np[1])),\n        )\n\n        if model.args.parallel_sampling > 1:\n            edge_index = model.duplicate_edge_index(model.args.parallel_sampling, edge_index, node_labels.shape[0], device)\n\n        for _ in range(model.args.sequential_sampling):\n            xt = torch.randn_like(node_labels.float())\n            if model.args.parallel_sampling > 1:\n                xt = xt.repeat(model.args.parallel_sampling, 1, 1)\n                xt = torch.randn_like(xt)\n\n            xt = (xt > 0).long().reshape(-1)\n\n            steps = model.args.inference_diffusion_steps\n            time_schedule = InferenceSchedule(\n                inference_schedule=model.args.inference_schedule,\n                T=model.diffusion.T,\n                inference_T=steps,\n            )\n\n            for i in range(steps):\n                t1, t2 = time_schedule(i)\n                t1 = torch.tensor([t1], device=device).float()\n                xt_scale = xt * 2 - 1\n                xt_scale = xt_scale * (1.0 + 0.05 * torch.rand_like(xt.float(), device=device))\n                x0_pred = model(\n                    xt_scale.reshape(-1),\n                    t1.float().to(device),\n                    edge_index.long().to(device) if edge_index is not None else None,\n                )\n\n                x0_pred = x0_pred.reshape((1, xt.shape[0], -1, 2)).softmax(dim=-1)\n\n                if not t2.item == 0:\n                    x0 = torch.bernoulli(x0_pred[..., 1].clamp(0, 1))\n                    x0_onehot = F.one_hot(\n                        x0.long(), num_classes=2\n                    ).float()  # [B, N, N, 2]\n                    Q_bar = (\n                        torch.from_numpy(model.diffusion.Q_bar[t2])\n                        .float()\n                        .to(x0_onehot.device)\n                    )\n                    xt_prob = torch.matmul(x0_onehot, Q_bar)  # [B, N, N, 2]\n                    xt = torch.bernoulli(xt_prob[..., 1].clamp(0, 1))  # [B, N, N]\n\n            predict_labels = x0_pred[..., 1].float().cpu().detach().numpy().reshape(-1) + 1e-6  # 770,\n            stacked_predict_labels.append(predict_labels)\n\n        predict_labels = np.concatenate(stacked_predict_labels, axis=0)  # 770,\n\n        all_sampling = model.args.sequential_sampling * model.args.parallel_sampling\n        split_predict_labels = np.split(predict_labels, all_sampling)\n        solved_solutions = [mis_decode_np(predict_labels, adj_mat) for predict_labels in split_predict_labels]\n        solved_costs = [solved_solution.sum() for solved_solution in solved_solutions]\n        best_solved_cost = np.max(solved_costs)\n        best_solved_id = np.argmax(solved_costs)\n\n        gt_cost = node_labels.cpu().numpy().sum()\n        gap = (best_solved_cost - gt_cost) / gt_cost * 100\n\n        guided_gap, g_best_solved_cost = -1., -1.\n\n        # Local Rewrite\n        if model.args.rewrite:\n            g_best_solution = solved_solutions[best_solved_id]\n            g_best_solved_cost = best_solved_cost\n            for _ in range(model.args.rewrite_steps):\n                g_stacked_predict_labels = []\n                g_x0 = torch.from_numpy(g_best_solution).unsqueeze(0).to(device)    # 1, b*n\n                if model.args.parallel_sampling > 1:\n                    g_x0 = g_x0.repeat(1, model.args.parallel_sampling)\n\n                g_x0_onehot = F.one_hot(g_x0.long(), num_classes=2).float()\n\n                steps_T = int(model.args.diffusion_steps * model.args.rewrite_ratio)\n\n                Q_bar = torch.from_numpy(model.diffusion.Q_bar[steps_T]).float().to(g_x0_onehot.device)\n\n                g_xt_prob = torch.matmul(g_x0_onehot, Q_bar)  # [B, N, 2]\n\n                g_xt = torch.bernoulli(g_xt_prob[..., 1].clamp(0, 1)).to(g_x0_onehot.device)  # [B, N]\n\n                g_xt = g_xt.reshape(-1)\n                t = torch.tensor([model.args.diffusion_steps * model.args.rewrite_ratio]).int()\n\n                if model.args.guided:\n                    g_x0 = self.guided_denoise_step(model, g_xt_prob, g_x0.reshape(-1), t, device, edge_index)\n                else:\n                    g_x0 = self.denoise_step(model, g_xt, t, device, edge_index)    # 1, b*n, 1\n\n                g_predict_labels = g_x0.float().cpu().detach().numpy().reshape(-1) + 1e-6\n                g_stacked_predict_labels.append(g_predict_labels)\n                g_predict_labels = np.concatenate(g_stacked_predict_labels, axis=0)\n\n                g_split_predict_labels = np.split(g_predict_labels, model.args.parallel_sampling * 2\n                        if model.args.guided\n                        else model.args.parallel_sampling)\n                g_solved_solutions = [mis_decode_np(g_predict_labels, adj_mat) for g_predict_labels in\n                                      g_split_predict_labels]\n                g_solved_costs = [g_solved_solution.sum() for g_solved_solution in g_solved_solutions]\n\n                g_best_solved_cost_tmp, g_best_id = np.max(g_solved_costs), np.argmax(g_best_solved_cost)\n\n                if g_best_solved_cost_tmp > g_best_solved_cost:\n                    g_best_solved_cost = g_best_solved_cost_tmp\n                    g_best_solution = g_solved_solutions[g_best_id]\n                guided_gap = (g_best_solved_cost - gt_cost) / gt_cost * 100\n\n        if model.args.rewrite:\n            metrics = {\n                f\"{split}/rewrite_ratio\": float(model.args.rewrite_ratio),\n                f\"{split}/gap\": gap,\n                f\"{split}/guided_gap\": guided_gap,\n                f\"{split}/gt_cost\": gt_cost,\n                f\"{split}/guided_solved_cost\": g_best_solved_cost,\n            }\n        else:\n            metrics = {\n                f\"{split}/gap\": gap,\n                f\"{split}/gt_cost\": gt_cost,\n            }\n\n        for k, v in metrics.items():\n            model.log(k, v, on_epoch=True, sync_dist=True)\n        model.log(f\"{split}/solved_cost\", best_solved_cost, prog_bar=True, on_epoch=True, sync_dist=True)\n\n        return metrics\n\n    def denoise_step(self, model, xt, t, device, edge_index=None):\n        with torch.no_grad():\n            xt_scale = xt * 2 - 1\n            xt_scale = xt_scale * (\n                1.0 + 0.05 * torch.rand_like(xt.float(), device=device)\n            )   # b*n (700)\n\n            # [b*n, 2]\n            x0_pred = model.forward(\n                xt_scale.to(device),\n                t.float().to(device),\n                edge_index.long().to(device) if edge_index is not None else None,\n            )\n\n            x0_pred_prob = x0_pred.reshape((1, xt.shape[0], -1, 2)).softmax(dim=-1)     # 1, b*n, 1, 2\n            return x0_pred_prob[..., 1]\n\n    def guided_denoise_step(self, model, xt_prob, x0, t, device, edge_index):\n        torch.set_grad_enabled(True)\n\n        xt_prob.requires_grad = True\n        xt = xt_prob[..., 1].reshape(-1)    # b*n\n\n        with torch.inference_mode(False):\n            xt_scale = xt * 2 - 1\n            xt_scale = xt_scale * (1.0 + 0.05 * torch.rand_like(xt.float(), device=device))\n\n            x0_pred = model(\n                xt_scale,   # b*n\n                t.float().to(device),   # 1\n                edge_index.long().to(device) if edge_index is not None else None,   # 2, E(73742)\n            )   # b*n, 2\n\n            loss_func = nn.CrossEntropyLoss()\n\n            bce_loss = loss_func(x0_pred, x0.long())\n\n            p_theta = x0_pred.reshape((1, xt.shape[0], -1, 2)).softmax(dim=-1)\n\n            num_nodes = xt.shape[0]\n            adj_matrix = SparseTensor(\n                row=edge_index[0],\n                col=edge_index[1],\n                value=torch.ones_like(edge_index[0].float()),\n                sparse_sizes=(num_nodes, num_nodes),\n            ).to_dense()\n            adj_matrix.fill_diagonal_(0)\n            pred_nodes = p_theta[..., 1].squeeze(0)\n\n            f_mis = -pred_nodes.sum()\n            g_mis = adj_matrix @ pred_nodes\n            g_mis = (pred_nodes * g_mis).sum()\n            cost_est = f_mis + 0.5 * g_mis\n\n            loss = self.args.c1 * bce_loss + self.args.c2 * cost_est\n            loss.backward()\n\n        torch.set_grad_enabled(False)\n        assert xt_prob.grad is not None\n\n        with torch.no_grad():\n            xt_prob.grad = xt_prob.grad.clamp(-1, 1)    # without this, exp(grad) explodes!\n            p_phi = torch.exp(-xt_prob.grad)     # b, n, 2\n            xt_prob_u = (xt_prob * p_phi) / torch.sum(\n                (xt_prob * p_phi + 1e-6), dim=-1, keepdim=True\n            )\n\n            xt_u = torch.bernoulli(xt_prob_u[..., 1].clamp(0, 1))\n            xt_u = xt_u.float().reshape(-1)  # b * n\n            xt_scale_u = xt_u * 2 - 1\n            xt_scale_u = xt_scale_u * (\n                    1.0 + 0.05 * torch.rand_like(xt_u.float(), device=device)\n            )\n\n            x0_pred_u = model.forward(\n                xt_scale_u.to(device),  # b*n\n                t.float().to(device),   # 1\n                edge_index.long().to(device) if edge_index is not None else None,   # 2, E\n            )\n\n            x0_pred_prob_u = x0_pred_u.reshape((1, xt.shape[0], -1, 2)).softmax(dim=-1)\n            output = torch.cat((p_theta[..., 1], x0_pred_prob_u[..., 1]), dim=0)\n\n            return output\n\n# ==========================================\n# File: diffusion/consistency/tsp.py\n# Function/Context: TSPConsistency\n# ==========================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom diffusion.consistency.meta import MetaConsistency\nfrom diffusion.utils.diffusion_schedulers import InferenceSchedule\nfrom diffusion.utils.tsp_utils import TSPEvaluator, batched_two_opt_torch, merge_tours\n\n\nclass TSPConsistency(MetaConsistency):\n    def __init__(\n        self,\n        args,\n        sigma_max=1000,\n        sigma_min=0,\n        weight_schedule=\"uniform\",\n        boundary_func=\"truncate\",\n    ):\n        super(TSPConsistency, self).__init__(\n            sigma_max=sigma_max,\n            sigma_min=sigma_min,\n            weight_schedule=weight_schedule,\n            boundary_func=boundary_func,\n        )\n        self.args = args\n\n    def consistency_losses(self, model, batch):\n        edge_index = None\n        if model.sparse:\n            _, graph_data, point_indicator, edge_indicator, _ = batch\n            route_edge_flags = graph_data.edge_attr\n            points = graph_data.x\n            edge_index = graph_data.edge_index\n            num_edges = edge_index.shape[1]\n            batch_size = point_indicator.shape[0]\n            adj_matrix = route_edge_flags.reshape((batch_size, num_edges // batch_size))\n            t = torch.randint(\n                1,\n                model.diffusion.T + 1,\n                [point_indicator.shape[0]],\n                device=points.device,\n            )\n            t2 = (model.args.alpha * t).int()\n        else:\n            _, points, adj_matrix, _ = batch\n            batch_size = points.shape[0]\n            t = torch.randint(\n                1, model.diffusion.T + 1, [points.shape[0]], device=points.device\n            )\n            t2 = (model.args.alpha * t).int()\n\n        x0 = F.one_hot(\n            adj_matrix.long(), num_classes=2\n        ).float()\n        if model.sparse:\n            x0 = x0.unsqueeze(1)\n\n        x_t = model.diffusion.sample(x0, t.cpu().numpy())\n        x_t2 = model.diffusion.sample(x0, t2.cpu().numpy())\n\n        if model.sparse:\n            t = t.reshape(-1, 1).repeat(1, adj_matrix.shape[1]).reshape(-1)\n            t2 = t2.reshape(-1, 1).repeat(1, adj_matrix.shape[1]).reshape(-1)\n            x_t = x_t.reshape(-1)\n            x_t2 = x_t2.reshape(-1)\n            adj_matrix = adj_matrix.reshape(-1)\n            points = points.reshape(-1, 2)\n            edge_index = edge_index.float().to(adj_matrix.device).reshape(2, -1)\n\n        model_output, denoise = self.denoise(model, points, x_t, t, edge_index, x0)\n        model_output2, denoise2 = self.denoise(model, points, x_t2, t2, edge_index, x0)\n        adj_matrix = adj_matrix.long()\n        loss_func = nn.CrossEntropyLoss()\n        loss = loss_func(denoise, adj_matrix) + loss_func(denoise2, adj_matrix)\n\n        return loss\n\n    def denoise(self, model, points, x_t, t, edge_index, x0):\n        x_t = x_t * 2 - 1\n        x_t = x_t * (1.0 + 0.05 * torch.rand_like(x_t))\n        model_output = model(\n            points, x_t, t, edge_index\n        )\n\n        c_skip, c_out = [\n            self.append_dims(x, model_output.ndim)\n            for x in self.get_scalings_for_boundary_condition(t)\n        ]\n\n        if not model.sparse:\n            x0 = x0.permute(0, 3, 1, 2)\n        else:\n            x0 = x0.reshape((-1, 2))\n        denoise = c_out * model_output + c_skip * x0\n\n        return model_output, denoise\n\n    def consistency_test_step(self, model, batch, batch_idx, split=\"test\"):\n        edge_index = None\n        np_edge_index = None\n        device = batch[-1].device\n        original_edge_index = None\n\n        if not model.sparse:\n            real_batch_idx, points, adj_matrix, gt_tour = batch\n            np_points = points.cpu().numpy()[0]\n            np_gt_tour = gt_tour.cpu().numpy()[0]\n        else:\n            real_batch_idx, graph_data, point_indicator, edge_indicator, gt_tour = batch\n            route_edge_flags = graph_data.edge_attr\n            points = graph_data.x\n            edge_index = graph_data.edge_index\n            original_edge_index = edge_index.clone()\n            num_edges = edge_index.shape[1]\n            batch_size = point_indicator.shape[0]\n            adj_matrix = route_edge_flags.reshape((batch_size, num_edges // batch_size))\n            points = points.reshape((-1, 2))\n            edge_index = edge_index.reshape((2, -1))\n            np_points = points.cpu().numpy()\n            np_gt_tour = gt_tour.cpu().numpy().reshape(-1)\n            np_edge_index = edge_index.cpu().numpy()\n\n        if model.args.parallel_sampling > 1:\n            if not model.sparse:\n                points = points.repeat(model.args.parallel_sampling, 1, 1)\n            else:\n                points = points.repeat(model.args.parallel_sampling, 1)\n                edge_index = model.duplicate_edge_index(\n                    model.args.parallel_sampling, edge_index, np_points.shape[0], device\n                )\n\n        stacked_tours = []\n\n        for _ in range(model.args.sequential_sampling):\n            xt = torch.randn_like(adj_matrix.float())\n            if model.args.parallel_sampling > 1:\n                if not model.sparse:\n                    xt = xt.repeat(model.args.parallel_sampling, 1, 1)\n                else:\n                    xt = xt.repeat(model.args.parallel_sampling, 1)\n                xt = torch.randn_like(xt)\n\n            xt = (xt > 0).long()\n\n            if model.sparse:\n                xt = xt.reshape(-1)\n\n            steps = model.args.inference_diffusion_steps\n            time_schedule = InferenceSchedule(\n                inference_schedule=model.args.inference_schedule,\n                T=model.diffusion.T,\n                inference_T=steps,\n            )\n\n            for i in range(steps):\n                t1, t2 = time_schedule(i)\n                t1 = torch.tensor([t1], device=device).float()\n\n                xt_scale = xt * 2 - 1\n                xt_scale = xt_scale * (\n                    1.0 + 0.05 * torch.rand_like(xt.float(), device=device)\n                )\n                x0_pred = model.forward(\n                    points.float().to(device),\n                    xt_scale,\n                    t1,\n                    edge_index.long().to(device) if edge_index is not None else None,\n                )\n\n                if not model.sparse:\n                    x0_pred = x0_pred.permute(0, 2, 3, 1).contiguous().softmax(-1)\n                else:\n                    x0_pred = x0_pred.reshape((-1, 2)).softmax(\n                        dim=-1\n                    )\n\n                if model.args.use_intermediate:\n                    adj_mat = x0_pred[..., 1].cpu().detach().numpy() + 1e-6\n\n                    tours, merge_iterations = merge_tours(\n                        adj_mat,\n                        np_points,\n                        np_edge_index,\n                        sparse_graph=model.sparse,\n                        parallel_sampling=model.args.parallel_sampling,\n                    )\n\n                    solved_tours, ns = batched_two_opt_torch(\n                        np_points.astype(\"float64\"),\n                        np.array(tours).astype(\"int64\"),\n                        max_iterations=model.args.two_opt_iterations,\n                        device=device,\n                    )\n\n                    stacked_tours.append(solved_tours)\n\n                if not t2.item == 0:\n                    x0 = torch.bernoulli(x0_pred[..., 1].clamp(0, 1))\n                    x0_onehot = F.one_hot(\n                        x0.long(), num_classes=2\n                    ).float()\n                    Q_bar = (\n                        torch.from_numpy(model.diffusion.Q_bar[t2])\n                        .float()\n                        .to(x0_onehot.device)\n                    )\n                    xt_prob = torch.matmul(x0_onehot, Q_bar)\n                    xt = torch.bernoulli(xt_prob[..., 1].clamp(0, 1))\n\n            adj_mat = x0_pred[..., 1].cpu().detach().numpy() + 1e-6\n\n            tours, merge_iterations = merge_tours(\n                adj_mat,\n                np_points,\n                np_edge_index,\n                sparse_graph=model.sparse,\n                parallel_sampling=model.args.parallel_sampling,\n            )\n\n            solved_tours, ns = batched_two_opt_torch(\n                np_points.astype(\"float64\"),\n                np.array(tours).astype(\"int64\"),\n                max_iterations=model.args.two_opt_iterations,\n                device=device,\n            )\n\n            stacked_tours.append(solved_tours)\n\n        tsp_solver = TSPEvaluator(np_points)\n        gt_cost = tsp_solver.evaluate(np_gt_tour)\n\n        solved_tours = np.concatenate(stacked_tours, axis=0)\n\n        all_solved_costs = [\n            tsp_solver.evaluate(solved_tours[i]) for i in range(solved_tours.shape[0])\n        ]\n        best_solved_cost, best_id = np.min(all_solved_costs), np.argmin(\n            all_solved_costs\n        )\n        gap = (best_solved_cost - gt_cost) / gt_cost * 100\n\n        g_best_tour = solved_tours[best_id]\n\n        guided_gap, g_best_solved_cost = -1.0, -1.0\n\n        if model.args.rewrite:\n            g_best_solved_cost = best_solved_cost\n            for _ in range(model.args.rewrite_steps):\n                g_stacked_tours = []\n                g_x0 = model.tour2adj(\n                    g_best_tour,\n                    np_points,\n                    model.sparse,\n                    model.args.sparse_factor,\n                    original_edge_index,\n                )\n\n                g_x0 = g_x0.unsqueeze(0).to(device)\n                if model.args.parallel_sampling > 1:\n                    if not model.sparse:\n                        g_x0 = g_x0.repeat(\n                            model.args.parallel_sampling, 1, 1\n                        )\n                    else:\n                        g_x0 = g_x0.repeat(model.args.parallel_sampling, 1)\n\n                if model.sparse:\n                    g_x0 = g_x0.reshape(-1)\n\n                g_x0_onehot = F.one_hot(\n                    g_x0.long(), num_classes=2\n                ).float()\n                steps_T = int(model.args.diffusion_steps * model.args.rewrite_ratio)\n\n                Q_bar = (\n                    torch.from_numpy(model.diffusion.Q_bar[steps_T])\n                    .float()\n                    .to(g_x0_onehot.device)\n                )\n                g_xt_prob = torch.matmul(g_x0_onehot, Q_bar)\n\n                t = torch.tensor(\n                    [model.args.diffusion_steps * model.args.rewrite_ratio]\n                ).int()\n\n                if model.args.guided:\n                    g_x0 = self.guided_denoise_step(\n                        model, points, g_xt_prob, g_x0, t, device, edge_index\n                    )\n                else:\n                    g_xt = torch.bernoulli(g_xt_prob[..., 1].clamp(0, 1))\n                    g_x0 = self.denoise_step(model, points, g_xt, t, device, edge_index)\n\n                g_adj_mat = g_x0.float().cpu().detach().numpy() + 1e-6\n                if model.args.save_numpy_heatmap:\n                    model.run_save_numpy_heatmap(\n                        g_adj_mat, np_points, real_batch_idx, split\n                    )\n\n                g_tours, g_merge_iterations = merge_tours(\n                    g_adj_mat,\n                    np_points,\n                    np_edge_index,\n                    sparse_graph=model.sparse,\n                    parallel_sampling=(\n                        model.args.parallel_sampling * 2\n                        if model.args.guided\n                        else model.args.parallel_sampling\n                    ),\n                )\n\n                g_solved_tours, g_ns = batched_two_opt_torch(\n                    np_points.astype(\"float64\"),\n                    np.array(g_tours).astype(\"int64\"),\n                    max_iterations=model.args.two_opt_iterations,\n                    device=device,\n                )\n\n                for g_tour in g_solved_tours:\n                    g_stacked_tours.append(g_tour)\n\n                g_solved_tours = np.array(g_stacked_tours)\n\n                g_all_solved_costs = [\n                    tsp_solver.evaluate(g_solved_tours[i])\n                    for i in range(g_solved_tours.shape[0])\n                ]\n                g_best_solved_cost_tmp, g_best_id = np.min(\n                    g_all_solved_costs\n                ), np.argmin(g_all_solved_costs)\n\n                if g_best_solved_cost_tmp < g_best_solved_cost:\n                    g_best_solved_cost = g_best_solved_cost_tmp\n                    g_best_tour = g_solved_tours[g_best_id]\n\n                guided_gap = (g_best_solved_cost - gt_cost) / gt_cost * 100\n\n            metrics = {\n                f\"{split}/rewrite_ratio\": float(model.args.rewrite_ratio),\n                f\"{split}/gap\": gap,\n                f\"{split}/guided_gap\": guided_gap,\n                f\"{split}/gt_cost\": gt_cost,\n                f\"{split}/guided_solved_cost\": g_best_solved_cost,\n            }\n\n# ==========================================\n# File: diffusion/pl_meta_model.py\n# Function/Context: COMetaModel\n# ==========================================\nimport os\nimport numpy as np\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom torch_geometric.data import DataLoader as GraphDataLoader\nfrom pytorch_lightning.utilities import rank_zero_info\n\nfrom diffusion.models.gnn_encoder import GNNEncoder\nfrom diffusion.utils.lr_schedulers import get_schedule_fn\nfrom diffusion.utils.diffusion_schedulers import CategoricalDiffusion\nimport time\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nclass COMetaModel(pl.LightningModule):\n    def __init__(self,\n                 param_args,\n                 node_feature_only=False):\n        super(COMetaModel, self).__init__()\n        self.args = param_args\n        self.diffusion_schedule = self.args.diffusion_schedule\n        self.diffusion_steps = self.args.diffusion_steps\n        self.sparse = self.args.sparse_factor > 0 or node_feature_only\n\n        out_channels = 2\n        self.diffusion = CategoricalDiffusion(\n            T=self.diffusion_steps, schedule=self.diffusion_schedule)\n\n        self.model = GNNEncoder(\n            n_layers=self.args.n_layers,\n            hidden_dim=self.args.hidden_dim,\n            out_channels=out_channels,\n            aggregation=self.args.aggregation,\n            sparse=self.sparse,\n            use_activation_checkpoint=self.args.use_activation_checkpoint,\n            node_feature_only=node_feature_only,\n        )\n        self.num_training_steps_cached = None\n        # self.output_dir = os.path.join('output', time.strftime('%Y-%m-%d-%H-%M-%S',time.localtime(time.time())))\n        # os.makedirs(self.output_dir)\n\n    def test_epoch_end(self, outputs):\n        unmerged_metrics = {}\n        for metrics in outputs:\n            for k, v in metrics.items():\n                if k not in unmerged_metrics:\n                    unmerged_metrics[k] = []\n                unmerged_metrics[k].append(v)\n\n        merged_metrics = {}\n        for k, v in unmerged_metrics.items():\n            merged_metrics[k] = float(np.mean(v))\n        self.logger.log_metrics(merged_metrics, step=self.global_step)\n\n    def get_total_num_training_steps(self) -> int:\n        \"\"\"Total training steps inferred from datamodule and devices.\"\"\"\n        if self.num_training_steps_cached is not None:\n            return self.num_training_steps_cached\n        dataset = self.train_dataloader()\n        if self.trainer.max_steps and self.trainer.max_steps > 0:\n            return self.trainer.max_steps\n\n        dataset_size = (\n            self.trainer.limit_train_batches * len(dataset)\n            if self.trainer.limit_train_batches != 0\n            else len(dataset)\n        )\n\n        num_devices = max(1, self.trainer.num_devices)\n        effective_batch_size = self.trainer.accumulate_grad_batches * num_devices\n        self.num_training_steps_cached = (dataset_size // effective_batch_size) * self.trainer.max_epochs\n        return self.num_training_steps_cached\n\n    def configure_optimizers(self):\n        rank_zero_info('Parameters: %d' % sum([p.numel() for p in self.model.parameters()]))\n        rank_zero_info('Training steps: %d' % self.get_total_num_training_steps())\n\n        if self.args.lr_scheduler == \"constant\":\n            return torch.optim.AdamW(\n                self.model.parameters(), lr=self.args.learning_rate, weight_decay=self.args.weight_decay)\n\n        else:\n            optimizer = torch.optim.AdamW(\n                self.model.parameters(), lr=self.args.learning_rate, weight_decay=self.args.weight_decay)\n            scheduler = get_schedule_fn(self.args.lr_scheduler, self.get_total_num_training_steps())(optimizer)\n\n            return {\n                \"optimizer\": optimizer,\n                \"lr_scheduler\": {\n                    \"scheduler\": scheduler,\n                    \"interval\": \"step\",\n                },\n            }\n\n    def categorical_posterior(self, target_t, t, x0_pred_prob, xt):\n        \"\"\"\n\n        Args:\n            target_t: 1\n            t: 1\n            x0_pred_prob: 1, N, 1, 2\n            xt: N\n\n        Returns: N\n\n        \"\"\"\n        diffusion = self.diffusion\n        if target_t is None:\n            target_t = t - 1\n\n        if target_t > 0:\n            Q_t = np.linalg.inv(diffusion.Q_bar[target_t]) @ diffusion.Q_bar[t]\n            Q_t = torch.from_numpy(Q_t).float().to(x0_pred_prob.device)\n        else:\n            Q_t = torch.eye(2).float().to(x0_pred_prob.device)\n\n        Q_bar_t_source = torch.from_numpy(diffusion.Q_bar[t]).float().to(x0_pred_prob.device)\n        Q_bar_t_target = torch.from_numpy(diffusion.Q_bar[target_t]).float().to(x0_pred_prob.device)\n\n        xt = F.one_hot(xt.long(), num_classes=2).float()\n        xt = xt.reshape(x0_pred_prob.shape)\n\n        x_t_target_prob_part_1 = torch.matmul(xt, Q_t.permute((1, 0)).contiguous())\n        x_t_target_prob_part_2 = Q_bar_t_target[0]\n        x_t_target_prob_part_3 = (Q_bar_t_source[0] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_target_prob = (x_t_target_prob_part_1 * x_t_target_prob_part_2) / x_t_target_prob_part_3\n\n        sum_x_t_target_prob = x_t_target_prob[..., 1] * x0_pred_prob[..., 0]\n        x_t_target_prob_part_2_new = Q_bar_t_target[1]\n        x_t_target_prob_part_3_new = (Q_bar_t_source[1] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_source_prob_new = (x_t_target_prob_part_1 * x_t_target_prob_part_2_new) / x_t_target_prob_part_3_new\n\n        sum_x_t_target_prob += x_t_source_prob_new[..., 1] * x0_pred_prob[..., 1]\n\n        # plt.clf()\n        # sns.heatmap(sum_x_t_target_prob.clamp(0, 1).float().detach().cpu()[0])\n        # plt.savefig('imgs/original_{}.png'.format(target_t[0]))\n\n        if target_t > 0:\n            xt = torch.bernoulli(sum_x_t_target_prob.clamp(0, 1))\n        else:\n            xt = sum_x_t_target_prob.clamp(min=0)\n\n        if self.sparse:\n            xt = xt.reshape(-1)\n        return xt, sum_x_t_target_prob.clamp(0, 1)\n\n    def guided_categorical_posterior(self, target_t, t, x0_pred_prob, xt, grad=None):\n        # xt: b, n, n\n        if grad is None:\n            grad = xt.grad\n        with torch.no_grad():\n            diffusion = self.diffusion\n            if target_t is None:\n                target_t = t - 1\n            else:\n                target_t = target_t.view(1)\n\n            if target_t > 0:\n                Q_t = np.linalg.inv(diffusion.Q_bar[target_t]) @ diffusion.Q_bar[t]\n                Q_t = torch.from_numpy(Q_t).float().to(x0_pred_prob.device)  # [2, 2], transition matrix\n            else:\n                Q_t = torch.eye(2).float().to(x0_pred_prob.device)\n            Q_bar_t_source = torch.from_numpy(diffusion.Q_bar[t]).float().to(x0_pred_prob.device)\n            Q_bar_t_target = torch.from_numpy(diffusion.Q_bar[target_t]).float().to(x0_pred_prob.device)\n\n            xt_grad_zero, xt_grad_one = torch.zeros(xt.shape, device=xt.device).unsqueeze(-1).repeat(1, 1, 1, 2), \\\n                torch.zeros(xt.shape, device=xt.device).unsqueeze(-1).repeat(1, 1, 1, 2)\n            xt_grad_zero[..., 0] = (1 - xt) * grad\n            xt_grad_zero[..., 1] = -xt_grad_zero[..., 0]\n            xt_grad_one[..., 1] = xt * grad\n            xt_grad_one[..., 0] = -xt_grad_one[..., 1]\n            xt_grad = xt_grad_zero + xt_grad_one\n\n            # xt_grad = (\n            #     torch.zeros(xt.shape, device=xt.device).unsqueeze(-1).repeat(1, 1, 1, 2)\n            # )\n            # xt_grad[..., 1] = grad\n            # xt_grad[..., 0] = -grad\n            #\n            # torch.set_printoptions(threshold=np.inf)\n            # print(xt_grad_fake - xt_grad)\n            # input()\n\n            xt = F.one_hot(xt.long(), num_classes=2).float()\n            xt = xt.reshape(x0_pred_prob.shape)  # [b, n, n, 2]\n\n            # q(xt−1|xt,x0=0)pθ(x0=0|xt)\n            x_t_target_prob_part_1 = torch.matmul(xt, Q_t.permute((1, 0)).contiguous())\n            x_t_target_prob_part_2 = Q_bar_t_target[0]\n            x_t_target_prob_part_3 = (Q_bar_t_source[0] * xt).sum(dim=-1, keepdim=True)\n\n            x_t_target_prob = (x_t_target_prob_part_1 * x_t_target_prob_part_2) / x_t_target_prob_part_3  # [b, n, n, 2]\n\n            sum_x_t_target_prob = x_t_target_prob[..., 1] * x0_pred_prob[..., 0]\n\n            # q(xt−1|xt,x0=1)pθ(x0=1|xt)\n            x_t_target_prob_part_2_new = Q_bar_t_target[1]\n            x_t_target_prob_part_3_new = (Q_bar_t_source[1] * xt).sum(dim=-1, keepdim=True)\n\n            x_t_source_prob_new = (x_t_target_prob_part_1 * x_t_target_prob_part_2_new) / x_t_target_prob_part_3_new\n\n            sum_x_t_target_prob += x_t_source_prob_new[..., 1] * x0_pred_prob[..., 1]\n\n            p_theta = torch.cat((1 - sum_x_t_target_prob.unsqueeze(-1), sum_x_t_target_prob.unsqueeze(-1)), dim=-1)\n            p_phi = torch.exp(-xt_grad)\n            if self.sparse:\n                p_phi = p_phi.reshape(p_theta.shape)\n            posterior = (p_theta * p_phi) / torch.sum((p_theta * p_phi), dim=-1, keepdim=True)\n\n            if target_t > 0:\n                xt = torch.bernoulli(posterior[..., 1].clamp(0, 1))\n            else:\n                xt = posterior[..., 1].clamp(min=0)\n            if self.sparse:\n                xt = xt.reshape(-1)\n            return xt\n\n    def duplicate_edge_index(self, parallel_sampling, edge_index, num_nodes, device):\n        \"\"\"Duplicate the edge index (in sparse graphs) for parallel sampling.\"\"\"\n        edge_index = edge_index.reshape((2, 1, -1))\n        edge_index_indent = torch.arange(0, parallel_sampling).view(1, -1, 1).to(device)\n        edge_index_indent = edge_index_indent * num_nodes\n        edge_index = edge_index + edge_index_indent\n        edge_index = edge_index.reshape((2, -1))\n        return edge_index\n\n    def train_dataloader(self):\n        batch_size = self.args.batch_size\n        train_dataloader = GraphDataLoader(\n            self.train_dataset, batch_size=batch_size, shuffle=True,\n            num_workers=self.args.num_workers, pin_memory=True,\n            persistent_workers=True, drop_last=True)\n\n        return train_dataloader\n\n    def test_dataloader(self, batch_size=None):\n        batch_size = 1 if batch_size is None else batch_size\n        print(\"Test dataset size:\", len(self.test_dataset))\n        test_dataloader = GraphDataLoader(self.test_dataset, batch_size=batch_size, shuffle=False)\n        return test_dataloader\n\n    def val_dataloader(self, batch_size=None):\n        batch_size = 1 if batch_size is None else batch_size\n        val_dataset = torch.utils.data.Subset(self.validation_dataset, range(self.args.validation_examples))\n        print(\"Validation dataset size:\", len(val_dataset))\n        val_dataloader = GraphDataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n        return val_dataloader\n\n    def ema_update(self, source_model, target_model, ema):\n        with torch.no_grad():\n            for target_param, source_param in zip(target_model.parameters(), source_model.parameters()):\n                target_param.copy_(target_param * ema + source_param * (1 - ema))\n\n# ==========================================\n# File: diffusion/pl_mis_model.py\n# Function/Context: MISModel\n# ==========================================\nimport os\n\nimport numpy as np\nimport scipy\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom torch_sparse import SparseTensor\nfrom diffusion.co_datasets.mis_dataset import MISDataset\n\nfrom diffusion.utils.diffusion_schedulers import InferenceSchedule\nfrom diffusion.pl_meta_model import COMetaModel\nfrom diffusion.utils.mis_utils import mis_decode_np\nfrom diffusion.consistency import MISConsistency\n\n\nclass MISModel(COMetaModel):\n    def __init__(self, param_args=None, target_model=None, teacher_model=None, load_dataset=True):\n        super(MISModel, self).__init__(param_args=param_args, node_feature_only=True)\n\n        if load_dataset:\n            # data_label_dir = None\n            # if self.args.training_split_label_dir is not None:\n            #     training_data_label_dir = os.path.join(self.args.training_split_label_dir)\n\n            if self.args.training_split:\n                self.train_dataset = MISDataset(\n                    data_file=os.path.join(self.args.training_split),\n                    data_label_dir=self.args.training_split_label_dir,\n                )\n            if self.args.test_split:\n                self.test_dataset = MISDataset(\n                    data_file=os.path.join(self.args.test_split),\n                    data_label_dir=self.args.test_split_label_dir,\n                )\n            if self.args.validation_split:\n                self.validation_dataset = MISDataset(\n                    data_file=os.path.join(self.args.validation_split),\n                    data_label_dir=self.args.validation_split_label_dir,\n                )\n\n        if self.args.consistency:\n            self.consistency_trainer = MISConsistency(self.args, sigma_max=self.diffusion.T, boundary_func=self.args.boundary_func)\n\n    def forward(self, x, t, edge_index):\n        return self.model(x, t, edge_index=edge_index)\n\n    def consistency_training_step(self, batch, batch_idx):\n        loss = self.consistency_trainer.consistency_losses(self, batch)\n        self.log(\"train/loss\", loss)\n        return loss\n\n    def categorical_training_step(self, batch, batch_idx):\n        _, graph_data, point_indicator = batch\n        t = np.random.randint(1, self.diffusion.T + 1, point_indicator.shape[0]).astype(int)\n        node_labels = graph_data.x\n        edge_index = graph_data.edge_index\n\n        # Sample from diffusion\n        node_labels_onehot = F.one_hot(node_labels.long(), num_classes=2).float()\n        node_labels_onehot = node_labels_onehot.unsqueeze(1).unsqueeze(1)\n\n        t = torch.from_numpy(t).long()\n        t = t.repeat_interleave(point_indicator.reshape(-1).cpu(), dim=0).numpy()\n\n        # print(t.shape)\n        # print(node_labels_onehot.shape)\n        xt = self.diffusion.sample(node_labels_onehot, t)\n        xt = xt * 2 - 1\n        xt = xt * (1.0 + 0.05 * torch.rand_like(xt))\n\n        t = torch.from_numpy(t).float()\n        t = t.reshape(-1)  # N\n        xt = xt.reshape(-1)  # N\n        edge_index = edge_index.to(node_labels.device).reshape(2, -1)  # 2, E\n\n        # Denoise\n        x0_pred = self.forward(\n            xt.float().to(node_labels.device),\n            t.float().to(node_labels.device),\n            edge_index,\n        )  # N, 2\n\n        loss_func = nn.CrossEntropyLoss()\n        loss = loss_func(x0_pred, node_labels)\n        self.log(\"train/loss\", loss)\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        if self.args.consistency:\n            return self.consistency_training_step(batch, batch_idx)\n        else:\n            return self.categorical_training_step(batch, batch_idx)\n\n    def categorical_denoise_step(self, xt, t, device, edge_index=None, target_t=None):\n        \"\"\"\n\n        Args:\n            xt: B*N\n            t: B*N OR B\n            device:\n            edge_index: E, 2\n            target_t: B*N OR B\n\n        Returns:\n\n        \"\"\"\n        xt_scale = xt * 2 - 1\n        xt_scale = xt_scale * (1.0 + 0.05 * torch.rand_like(xt.float(), device=device))\n        with torch.no_grad():\n            x0_pred = self.forward(\n                xt_scale,\n                t.float().to(device),\n                edge_index.long().to(device) if edge_index is not None else None,\n            )\n            x0_pred_prob = x0_pred.reshape((1, xt.shape[0], -1, 2)).softmax(dim=-1)\n            xt, _ = self.categorical_posterior(target_t, t, x0_pred_prob, xt)\n            return xt\n\n    def guided_categorical_denoise_step(self, xt, t, device, edge_index=None, target_t=None):\n        torch.set_grad_enabled(True)\n        xt = xt.float()  # n if sparse\n        xt.requires_grad = True\n        xt_scale = xt * 2 - 1\n        xt_scale = xt_scale * (1.0 + 0.05 * torch.rand_like(xt.float(), device=device))\n        with torch.inference_mode(False):\n            x0_pred = self.forward(\n                xt_scale,\n                t.float().to(device),\n                edge_index.long().to(device) if edge_index is not None else None,\n            )\n\n            x0_pred_prob = x0_pred.reshape((1, xt.shape[0], -1, 2)).softmax(dim=-1)\n            num_nodes = xt.shape[0]\n            adj_matrix = SparseTensor(\n                row=edge_index[0],\n                col=edge_index[1],\n                value=torch.ones_like(edge_index[0].float()),\n                sparse_sizes=(num_nodes, num_nodes),\n            ).to_dense()\n            adj_matrix.fill_diagonal_(0)\n\n            pred_nodes = x0_pred_prob[..., 1].squeeze(0)\n            # cost_est = 1 - pred_nodes / num_nodes\n            f_mis = -pred_nodes.sum()\n            g_mis = adj_matrix @ pred_nodes\n            g_mis = (pred_nodes * g_mis).sum()\n            cost_est = f_mis + 0.5 * g_mis\n            cost_est.requires_grad_(True)\n            cost_est.backward()\n            assert xt.grad is not None\n\n            if self.args.norm is True:\n                xt.grad = nn.functional.normalize(xt.grad, p=2, dim=-1)\n            xt = self.guided_categorical_posterior(target_t, t, x0_pred_prob, xt)\n\n        return xt.detach()\n\n    def test_step(self, batch, batch_idx, split='test'):\n        if self.args.consistency:\n            return self.consistency_trainer.consistency_test_step(self, batch, batch_idx, split)\n        else:\n            return self.categorical_test_step(batch, batch_idx, split)\n\n    def categorical_test_step(self, batch, batch_idx, split='test'):\n        device = batch[-1].device\n\n        real_batch_idx, graph_data, point_indicator = batch\n        node_labels = graph_data.x\n        edge_index = graph_data.edge_index\n\n        stacked_predict_labels = []\n        edge_index = edge_index.to(node_labels.device).reshape(2, -1)\n        edge_index_np = edge_index.cpu().numpy()\n        adj_mat = scipy.sparse.coo_matrix(\n            (np.ones_like(edge_index_np[0]), (edge_index_np[0], edge_index_np[1])),\n        )\n\n        if self.args.parallel_sampling > 1:\n            edge_index = self.duplicate_edge_index(self.args.parallel_sampling, edge_index, node_labels.shape[0],\n                                                   device)\n\n        for _ in range(self.args.sequential_sampling):\n            xt = torch.randn_like(node_labels.float())\n            if self.args.parallel_sampling > 1:\n                xt = xt.repeat(self.args.parallel_sampling, 1, 1)\n                xt = torch.randn_like(xt)\n            # if self.diffusion_type == 'gaussian':\n            #     xt.requires_grad = True\n            # else:\n            xt = (xt > 0).long().reshape(-1)\n\n            batch_size = 1\n            steps = self.args.inference_diffusion_steps\n            time_schedule = InferenceSchedule(inference_schedule=self.args.inference_schedule,\n                                              T=self.diffusion.T, inference_T=steps)\n\n            for i in range(steps):\n                t1, t2 = time_schedule(i)\n                t1 = torch.tensor([t1 for _ in range(batch_size)]).int()\n                t2 = torch.tensor([t2 for _ in range(batch_size)]).int()\n\n                xt = self.categorical_denoise_step(xt, t1, device, edge_index, target_t=t2)\n\n            # if self.diffusion_type == 'gaussian':\n            #     predict_labels = xt.float().cpu().detach().numpy() * 0.5 + 0.5\n            # else:\n            #     predict_labels = xt.float().cpu().detach().numpy() + 1e-6\n            predict_labels = xt.float().cpu().detach().numpy() + 1e-6   # 770,\n\n            stacked_predict_labels.append(predict_labels)\n\n        # import time\n        # b = time.time()\n        predict_labels = np.concatenate(stacked_predict_labels, axis=0)  # 770,\n        all_sampling = self.args.sequential_sampling * self.args.parallel_sampling\n        split_predict_labels = np.split(predict_labels, all_sampling)\n        # print(len(split_predict_labels), split_predict_labels[0].shape)\n        solved_solutions = [mis_decode_np(predict_labels, adj_mat) for predict_labels in split_predict_labels]\n        solved_costs = [solved_solution.sum() for solved_solution in solved_solutions]\n        best_solved_cost = np.max(solved_costs)\n        best_solved_id = np.argmax(solved_costs)\n        # print('pl', time.time() - b)\n        # input()\n\n        gt_cost = node_labels.cpu().numpy().sum()\n\n        gap = (best_solved_cost - gt_cost) / gt_cost * 100\n\n        guided_gap, g_best_solved_cost = -1., -1.\n        if self.args.rewrite:\n            g_best_solution = solved_solutions[best_solved_id]\n            for _ in range(3):\n                g_stacked_predict_labels = []\n                g_x0 = torch.from_numpy(g_best_solution).unsqueeze(0).to(device)\n                g_x0 = F.one_hot(g_x0.long(), num_classes=2).float()\n\n                steps_T = int(self.args.diffusion_steps * self.args.rewrite_ratio)\n                # steps_inf = int(self.args.inference_diffusion_steps * self.args.rewrite_ratio)\n                steps_inf = 10\n\n                time_schedule = InferenceSchedule(inference_schedule=self.args.inference_schedule,\n                                                  T=steps_T, inference_T=steps_inf)\n\n                Q_bar = torch.from_numpy(self.diffusion.Q_bar[steps_T]).float().to(g_x0.device)\n                g_xt_prob = torch.matmul(g_x0, Q_bar)  # [B, N, 2]\n                g_xt = torch.bernoulli(g_xt_prob[..., 1].clamp(0, 1)).to(g_x0.device)  # [B, N]\n\n                if self.args.parallel_sampling > 1:\n                    g_xt = g_xt.repeat(self.args.parallel_sampling, 1, 1)\n                g_xt = g_xt.reshape(-1)\n                # g_xt = (g_xt > 0).long().reshape(-1)\n                for i in range(steps_inf):\n                    t1, t2 = time_schedule(i)\n                    t1 = torch.tensor([t1]).int()\n                    t2 = torch.tensor([t2]).int()\n                    g_xt = self.guided_categorical_denoise_step(g_xt, t1, device, edge_index, target_t=t2)\n\n                g_predict_labels = g_xt.float().cpu().detach().numpy() + 1e-6\n                g_stacked_predict_labels.append(g_predict_labels)\n                g_predict_labels = np.concatenate(g_stacked_predict_labels, axis=0)\n\n                g_split_predict_labels = np.split(g_predict_labels, self.args.parallel_sampling)\n                g_solved_solutions = [mis_decode_np(g_predict_labels, adj_mat) for g_predict_labels in\n                                      g_split_predict_labels]\n                g_solved_costs = [g_solved_solution.sum() for g_solved_solution in g_solved_solutions]\n                g_best_solved_cost = np.max([g_best_solved_cost, np.max(g_solved_costs)])\n                g_best_solved_id = np.argmax(g_solved_costs)\n\n                g_best_solution = g_solved_solutions[g_best_solved_id]\n            # print(\n            #     f'tot_points: {g_x0.shape[-2]}, gt_cost: {gt_cost}, selected_points: {best_solved_cost} -> {g_best_solved_cost}')\n        if self.args.rewrite:\n            metrics = {\n                f\"{split}/gap\": gap,\n                f\"{split}/guided_gap\": guided_gap,\n                f\"{split}/gt_cost\": gt_cost,\n                f\"{split}/guided_solved_cost\": g_best_solved_cost,\n            }\n        else:\n            metrics = {\n                f\"{split}/gap\": gap,\n                f\"{split}/gt_cost\": gt_cost,\n            }\n        for k, v in metrics.items():\n            self.log(k, v, on_epoch=True, sync_dist=True)\n        self.log(f\"{split}/solved_cost\", best_solved_cost, prog_bar=True, on_epoch=True, sync_dist=True)\n\n        return metrics\n\n    def validation_step(self, batch, batch_idx):\n        return self.test_step(batch, batch_idx, split='val')\n\n    def on_save_checkpoint(self, checkpoint):\n        checkpoint['model_state_dict'] = self.model.state_dict()\n\n# ==========================================\n# File: diffusion/pl_tsp_model.py\n# Function/Context: TSPModel\n# ==========================================\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\n\nfrom diffusion.co_datasets.tsp_graph_dataset import TSPGraphDataset\nfrom diffusion.pl_meta_model import COMetaModel\nfrom diffusion.utils.diffusion_schedulers import InferenceSchedule\nfrom diffusion.utils.tsp_utils import TSPEvaluator, batched_two_opt_torch, merge_tours\nfrom diffusion.consistency import TSPConsistency\n\n\nclass TSPModel(COMetaModel):\n    # def __init__(self, param_args=None, target_model=None, teacher_model=None, load_dataset=True):\n    def __init__(self, param_args=None, load_dataset=True):\n        super(TSPModel, self).__init__(param_args=param_args, node_feature_only=False)\n\n        if load_dataset:\n            if self.args.training_split:\n                self.train_dataset = TSPGraphDataset(\n                    data_file=os.path.join(self.args.training_split),\n                    sparse_factor=self.args.sparse_factor,\n                    graph_type=self.args.graph_type,\n                )\n            if self.args.test_split:\n                self.test_dataset = TSPGraphDataset(\n                    data_file=os.path.join(self.args.test_split),\n                    sparse_factor=self.args.sparse_factor,\n                    graph_type=self.args.graph_type,\n                )\n            if self.args.validation_split:\n                self.validation_dataset = TSPGraphDataset(\n                    data_file=os.path.join(self.args.validation_split),\n                    sparse_factor=self.args.sparse_factor,\n                    graph_type=self.args.graph_type,\n                )\n\n        if self.args.consistency:\n            self.consistency_trainer = TSPConsistency(\n                self.args,\n                sigma_max=self.diffusion.T,\n                boundary_func=self.args.boundary_func,\n            )\n\n    def forward(self, x, adj, t, edge_index):\n        return self.model(x, t, adj, edge_index)\n\n    def consistency_training_step(self, batch, batch_idx):\n        loss = self.consistency_trainer.consistency_losses(self, batch)\n        self.log(\"train/loss\", loss)\n        return loss\n\n    def categorical_training_step(self, batch, batch_idx):\n        edge_index = None\n        if not self.sparse:\n            # points: B, N, 2\n            # adj_matrix: B, N, N\n            # t:  B\n            _, points, adj_matrix, _ = batch\n            t = np.random.randint(1, self.diffusion.T + 1, points.shape[0]).astype(int)\n        else:\n            _, graph_data, point_indicator, edge_indicator, _ = batch\n            t = np.random.randint(\n                1, self.diffusion.T + 1, point_indicator.shape[0]\n            ).astype(int)\n            route_edge_flags = graph_data.edge_attr\n            # points: B*N, 2\n            # edge_index: B*E, 2\n            # adj_matrix: B, N*N\n            points = graph_data.x\n            edge_index = graph_data.edge_index\n            num_edges = edge_index.shape[1]\n            batch_size = point_indicator.shape[0]\n            adj_matrix = route_edge_flags.reshape((batch_size, num_edges // batch_size))\n\n        # Sample from diffusion\n        adj_matrix_onehot = F.one_hot(\n            adj_matrix.long(), num_classes=2\n        ).float()  # B, N, N, 2 if not sparse else B, N*N, 2\n\n        if self.sparse:\n            adj_matrix_onehot = adj_matrix_onehot.unsqueeze(1)  # B, 1, N*N, 2\n\n        xt = self.diffusion.sample(\n            adj_matrix_onehot, t\n        )  # B, N, N if not sparse else B, 1, N*k\n        xt = xt * 2 - 1\n        xt = xt * (1.0 + 0.05 * torch.rand_like(xt))\n\n        if self.sparse:\n            t = torch.from_numpy(t).float()\n            t = t.reshape(-1, 1).repeat(1, adj_matrix.shape[1]).reshape(-1)\n            xt = xt.reshape(-1)\n            adj_matrix = adj_matrix.reshape(-1)\n            points = points.reshape(-1, 2)\n            edge_index = edge_index.float().to(adj_matrix.device).reshape(2, -1)\n        else:\n            t = torch.from_numpy(t).float().view(adj_matrix.shape[0])\n\n        # Denoise\n        x0_pred = self.forward(\n            points.float().to(adj_matrix.device),\n            xt.float().to(adj_matrix.device),\n            t.float().to(adj_matrix.device),\n            edge_index,\n        )  # B, 2, N, N\n\n        # Compute loss\n        loss_func = nn.CrossEntropyLoss()\n        loss = loss_func(x0_pred, adj_matrix.long())\n        self.log(\"train/loss\", loss)\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        if self.args.consistency:\n            return self.consistency_training_step(batch, batch_idx)\n        else:\n            return self.categorical_training_step(batch, batch_idx)\n\n    def guided_categorical_denoise_step(\n        self, points, xt, t, device, edge_index=None, target_t=None\n    ):\n        torch.set_grad_enabled(True)\n        xt = xt.float()\n        # b, n, n\n        xt.requires_grad = True\n        xt_scale = xt * 2 - 1\n        xt_scale = xt_scale * (1.0 + 0.05 * torch.rand_like(xt.float(), device=device))\n\n        # [b, 2, n, n]\n        with torch.inference_mode(False):\n            x0_pred = self.forward(\n                points.float().to(device),\n                xt_scale.to(device),\n                t.float().to(device),\n                edge_index.long().to(device) if edge_index is not None else None,\n            )\n\n            if not self.sparse:\n                x0_pred_prob = (\n                    x0_pred.permute((0, 2, 3, 1)).contiguous().softmax(dim=-1)\n                )\n            else:\n                x0_pred_prob = x0_pred.reshape((1, points.shape[0], -1, 2)).softmax(\n                    dim=-1\n                )\n\n            if not self.sparse:\n                dis_matrix = self.points2adj(points)\n                cost_est = (dis_matrix * x0_pred_prob[..., 1]).sum()\n                cost_est.requires_grad_(True)\n                cost_est.backward()\n            else:\n                dis_matrix = torch.sqrt(\n                    torch.sum(\n                        (points[edge_index.T[:, 0]] - points[edge_index.T[:, 1]]) ** 2,\n                        dim=1,\n                    )\n                )\n                dis_matrix = dis_matrix.reshape((1, points.shape[0], -1))\n                cost_est = (dis_matrix * x0_pred_prob[..., 1]).sum()\n                cost_est.requires_grad_(True)\n                cost_est.backward()\n            assert xt.grad is not None\n\n            if self.args.norm is True:\n                xt.grad = nn.functional.normalize(xt.grad, p=2, dim=-1)\n            xt = self.guided_categorical_posterior(target_t, t, x0_pred_prob, xt)\n\n            return xt.detach()\n\n    def test_step(self, batch, batch_idx, split=\"test\"):\n        if self.args.consistency:\n            return self.consistency_trainer.consistency_test_step(\n                self, batch, batch_idx, split\n            )\n        else:\n            return self.categorical_test_step(batch, batch_idx, split)\n\n    def categorical_test_step(self, batch, batch_idx, split=\"test\"):\n        edge_index = None\n        original_edge_index = None\n        np_edge_index = None\n        device = batch[-1].device\n        if not self.sparse:\n            real_batch_idx, points, adj_matrix, gt_tour = batch\n            np_points = points.cpu().numpy()[0]\n            np_gt_tour = gt_tour.cpu().numpy()[0]\n        else:\n            real_batch_idx, graph_data, point_indicator, edge_indicator, gt_tour = batch\n            route_edge_flags = graph_data.edge_attr\n            points = graph_data.x\n            edge_index = graph_data.edge_index\n            num_edges = edge_index.shape[1]\n            batch_size = point_indicator.shape[0]\n            adj_matrix = route_edge_flags.reshape((batch_size, num_edges // batch_size))\n            points = points.reshape((-1, 2))\n            edge_index = edge_index.reshape((2, -1))\n            original_edge_index = edge_index.clone()\n            np_points = points.cpu().numpy()\n            np_gt_tour = gt_tour.cpu().numpy().reshape(-1)\n            np_edge_index = edge_index.cpu().numpy()\n\n        # print(points.shape, edge_index.shape, batch_size, adj_matrix.shape)\n\n        if self.args.parallel_sampling > 1:\n            if not self.sparse:\n                points = points.repeat(self.args.parallel_sampling, 1, 1)\n            else:\n                points = points.repeat(self.args.parallel_sampling, 1)\n                edge_index = self.duplicate_edge_index(\n                    self.args.parallel_sampling, edge_index, np_points.shape[0], device\n                )\n\n        # Initialize with original diffusion\n        stacked_tours = []\n\n        for _ in range(self.args.sequential_sampling):\n            xt = torch.randn_like(adj_matrix.float())\n            if self.args.parallel_sampling > 1:\n                if not self.sparse:\n                    xt = xt.repeat(self.args.parallel_sampling, 1, 1)\n                else:\n                    xt = xt.repeat(self.args.parallel_sampling, 1)  # [B, E]\n                xt = torch.randn_like(xt)\n\n            xt = (xt > 0).long()\n\n            if self.sparse:\n                xt = xt.reshape(-1)  # [E]\n\n            steps = self.args.inference_diffusion_steps\n            time_schedule = InferenceSchedule(\n                inference_schedule=self.args.inference_schedule,\n                T=self.diffusion.T,\n                inference_T=steps,\n            )\n\n            # Diffusion iterations\n            for i in range(steps):\n                t1, t2 = time_schedule(i)\n                t1 = torch.tensor([t1]).int()\n                t2 = torch.tensor([t2]).int()\n\n                # [B, N, N], heatmap score\n                xt, xt_prob = self.categorical_denoise_step(\n                    points, xt, t1, device, edge_index, target_t=t2\n                )\n\n            adj_mat = xt.float().cpu().detach().numpy() + 1e-6  # [B, N, N]\n\n            if self.args.save_numpy_heatmap and not self.args.rewrite:\n                self.run_save_numpy_heatmap(adj_mat, np_points, real_batch_idx, split)\n\n            tours, merge_iterations = merge_tours(  # [B, N+1], list\n                adj_mat,\n                np_points,\n                np_edge_index,\n                sparse_graph=self.sparse,\n                parallel_sampling=self.args.parallel_sampling,\n            )\n\n            # Refine using 2-opt\n            # solver_tours,  [B, N+1] ndarray, the visiting sequence of each city\n            solved_tours, ns = batched_two_opt_torch(\n                np_points.astype(\"float64\"),\n                np.array(tours).astype(\"int64\"),\n                max_iterations=self.args.two_opt_iterations,\n                device=device,\n            )\n            stacked_tours.append(solved_tours)\n\n        solved_tours = np.concatenate(stacked_tours, axis=0)  # [B, N+1] ndarray\n\n        tsp_solver = TSPEvaluator(np_points)  # np_points: [N, 2] ndarray\n        gt_cost = tsp_solver.evaluate(np_gt_tour)  # np_gt_tour: [N+1] ndarray\n\n        total_sampling = self.args.parallel_sampling * self.args.sequential_sampling\n        all_solved_costs = [\n            tsp_solver.evaluate(solved_tours[i]) for i in range(total_sampling)\n        ]\n        best_solved_cost, best_id = np.min(all_solved_costs), np.argmin(\n            all_solved_costs\n        )\n        gap = (best_solved_cost - gt_cost) / gt_cost * 100\n\n        # print(\"gap: {}%\".format((best_solved_cost - gt_cost) / gt_cost * 100))\n\n        # select the best tour\n        g_best_tour = solved_tours[best_id]  # [N+1] ndarray\n\n        guided_gap, g_best_solved_cost = -1.0, -1.0\n\n        # Local Rewrite\n        if self.args.rewrite:\n            g_best_solved_cost = best_solved_cost\n\n            for _ in range(self.args.rewrite_steps):\n                g_stacked_tours = []\n                # optimal adjacent matrix\n                g_x0 = self.tour2adj(\n                    g_best_tour,\n                    np_points,\n                    self.sparse,\n                    self.args.sparse_factor,\n                    original_edge_index,\n                )\n                g_x0 = g_x0.unsqueeze(0).to(device)  # [1, N, N] or [1, N]\n                if self.args.parallel_sampling > 1:\n                    if not self.sparse:\n                        g_x0 = g_x0.repeat(\n                            self.args.parallel_sampling, 1, 1\n                        )  # [1, N ,N] -> [B, N, N]\n                    else:\n                        g_x0 = g_x0.repeat(self.args.parallel_sampling, 1)\n\n                if self.sparse:\n                    g_x0 = g_x0.reshape(-1)\n\n                g_x0_onehot = F.one_hot(\n                    g_x0.long(), num_classes=2\n                ).float()\n\n# ==========================================\n# File: diffusion/utils/diffusion_schedulers.py\n# Function/Context: CategoricalDiffusion\n# ==========================================\nimport math\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\n\nclass CategoricalDiffusion(object):\n    def __init__(self, T, schedule):\n        # Diffusion steps\n        self.T = T\n\n        # Noise schedule\n        if schedule == 'linear':\n            b0 = 1e-4\n            bT = 2e-2\n            self.beta = np.linspace(b0, bT, T)\n        elif schedule == 'cosine':\n            self.alphabar = self.__cos_noise(np.arange(0, T + 1, 1)) / self.__cos_noise(\n                0)  # Generate an extra alpha for bT\n            self.beta = np.clip(1 - (self.alphabar[1:] / self.alphabar[:-1]), None, 0.999)\n\n        beta = self.beta.reshape((-1, 1, 1))\n        eye = np.eye(2).reshape((1, 2, 2))\n        ones = np.ones((2, 2)).reshape((1, 2, 2))\n\n        self.Qs = (1 - beta) * eye + (beta / 2) * ones\n\n        Q_bar = [np.eye(2)]\n        for Q in self.Qs:\n            Q_bar.append(Q_bar[-1] @ Q)\n        self.Q_bar = np.stack(Q_bar, axis=0)\n\n    def __cos_noise(self, t):\n        offset = 0.008\n        return np.cos(math.pi * 0.5 * (t / self.T + offset) / (1 + offset)) ** 2\n\n    def sample(self, x0_onehot, t):\n        # Select noise scales\n        # x0_onehot: N, 1, 1, 2\n        # self.Q_bar: 1001, 2, 2\n        Q_bar = torch.from_numpy(self.Q_bar[t]).float().to(x0_onehot.device)\n\n        xt = torch.matmul(x0_onehot, Q_bar.reshape((Q_bar.shape[0], 1, 2, 2)))\n        return torch.bernoulli(xt[..., 1].clamp(0, 1))\n\n    def consistency_sample(self, x0_onehot, t, t2):\n        \"\"\"\n        Args:\n            x0_onehot: B, N, N, 2\n            t: B\n            t2: B, next time step of t, t2 < t\n        Returns:\n            xt: B, N, N\n            xt2: B, N, N\n        \"\"\"\n        Q_bar_t2 = torch.from_numpy(self.Q_bar[t2]).float().to(x0_onehot.device)\n        Q_bar_t = torch.from_numpy(self.Q_bar[t]).float().to(x0_onehot.device)\n\n        xt2 = torch.matmul(x0_onehot, Q_bar_t2.reshape((Q_bar_t2.shape[0], 1, 2, 2)))\n        xt2 = torch.bernoulli(xt2[..., 1].clamp(0, 1))  # B, N, N\n\n        xt = torch.matmul(F.one_hot(xt2.long(), num_classes=2).float(), (torch.linalg.inv(Q_bar_t2) @ Q_bar_t).reshape((Q_bar_t.shape[0], 1, 2, 2)))\n        xt = torch.bernoulli(xt[..., 1].clamp(0, 1))\n\n        return xt, xt2",
  "description": "Combined Analysis:\n- [diffusion/consistency/mis.py]: This file implements the core optimization logic for Maximum Independent Set (MIS) in the Fast T2T framework. It contains the MISConsistency class which inherits from MetaConsistency and implements three key components: 1) consistency_losses() - training objective that minimizes differences between samples from varying noise levels and optimal solutions, 2) consistency_test_step() - testing procedure with diffusion sampling and gradient-based search (rewrite), 3) guided_denoise_step() - novel gradient search scheme incorporating MIS objective feedback (f_mis + 0.5*g_mis) during testing. The implementation directly maps to the paper's optimization consistency model and gradient search algorithm steps.\n- [diffusion/consistency/tsp.py]: This file implements the core optimization consistency model for TSP as described in the Fast T2T paper. The TSPConsistency class contains:\n1. **consistency_losses**: Implements the optimization consistency training protocol by minimizing differences between samples from varying noise levels (t and t2) and the optimal solution through cross-entropy loss.\n2. **consistency_test_step**: Implements the gradient-based search during testing, including:\n   - Sequential sampling from noisy initial states\n   - Diffusion-based denoising with inference schedule\n   - Local refinement using 2-opt heuristic\n   - Optional rewrite steps that add noise to current best solution and denoise again (gradient search with objective feedback)\n   - Guided denoising when enabled\n3. **denoise**: Helper function that applies boundary conditions and scaling for consistency model predictions.\n\nThe implementation directly maps to the paper's key contributions: learning direct mappings from noise to solutions (consistency training) and gradient search in solution space during testing (rewrite steps).\n- [diffusion/pl_meta_model.py]: This file implements the core neural network model and diffusion-based optimization logic for the Fast T2T framework. The COMetaModel class encapsulates:\n1. The GNN encoder (GNNEncoder) that learns to map problem instances to solution distributions.\n2. The categorical diffusion process (CategoricalDiffusion) for modeling solution space transitions.\n3. Key algorithmic steps: \n   - `categorical_posterior()`: Computes the posterior distribution p(x_{t-1}|x_t) during diffusion sampling (implements the denoising process).\n   - `guided_categorical_posterior()`: Incorporates gradient information from the objective function l(x;G) to guide the sampling toward lower-cost solutions (implements the gradient-based search during testing).\n   - `configure_optimizers()`: Sets up the optimization protocol for training.\n4. The model directly implements the mapping f_θ(x_0|x_t,t,G) described in the paper, where the GNN predicts x_0 from noisy x_t, and the posterior functions enable both standard and guided sampling trajectories.\n5. The code handles both dense (TSP) and sparse (MIS) graph representations via the `sparse` flag.\n6. The `duplicate_edge_index()` helper enables parallel sampling for efficiency.\nThis matches the paper's description of learning direct mappings from noise levels to solutions and using gradient-guided search during testing.\n- [diffusion/pl_mis_model.py]: This file implements the core optimization logic for Maximum Independent Set (MIS) in the Fast T2T framework. Key implementations include:\n1. **Consistency Training**: Uses MISConsistency for optimization consistency training (Fast T2T's direct mapping learning).\n2. **Gradient-Guided Search**: The `guided_categorical_denoise_step` method implements gradient-based search during testing by computing the MIS objective function (f_mis + 0.5*g_mis) and using its gradient to guide denoising.\n3. **Testing Pipeline**: The `categorical_test_step` implements the complete testing procedure with iterative denoising, solution decoding, and optional gradient-guided rewrite steps.\n4. **Objective Function**: The code explicitly computes the MIS objective: f_mis = -pred_nodes.sum() (maximization via negative minimization) and g_mis = (pred_nodes * (adj_matrix @ pred_nodes)).sum() (penalty for adjacent selections).\n5. **Diffusion Integration**: Uses categorical diffusion models for solution space exploration with both standard and guided denoising steps.\n\nThe implementation directly corresponds to the paper's description of learning direct mappings from noise to solutions and using gradient-based search during testing.\n- [diffusion/pl_tsp_model.py]: This file implements the core optimization logic for the TSP problem in the Fast T2T framework. Key implementations include:\n1. **Training Phase**: \n   - `consistency_training_step()`: Implements optimization consistency training protocol that minimizes differences among samples from varying generative trajectories and time steps relative to optimal solutions.\n   - `categorical_training_step()`: Implements standard diffusion training with categorical cross-entropy loss.\n   - `training_step()`: Switches between consistency and categorical training based on configuration.\n\n2. **Testing Phase**:\n   - `guided_categorical_denoise_step()`: Implements the gradient-based search with objective feedback during testing. This computes gradients of the estimated cost w.r.t. the noisy solution and uses them to guide the denoising process.\n   - `categorical_test_step()`: Implements the complete testing pipeline including diffusion sampling, tour merging, 2-opt refinement, and local rewrite with gradient guidance.\n   - `test_step()`: Routes to either consistency or categorical testing.\n\n3. **Mathematical Model Mapping**:\n   - The objective function $l(\\mathbf{x}; G)$ is implemented as TSP tour cost computation.\n   - The constraint $\\mathbf{x} \\in \\Omega$ is handled through categorical adjacency matrix representations and tour merging operations.\n   - The gradient search scheme is implemented via backpropagation through the cost estimate to update noisy solutions.\n\n4. **Algorithm Steps**:\n   - Training: Learns direct mappings $f_\\theta(\\mathbf{x}_{0}|\\mathbf{x}_t,t,G)$ through consistency training.\n   - Testing: Performs iterative denoising with gradient guidance to explore solution space efficiently.\n   - Includes 2-opt local search refinement for improved solution quality.\n\nThis file serves as the main implementation of the TSP-specific optimization model within the Fast T2T framework.\n- [diffusion/utils/diffusion_schedulers.py]: This file implements the core diffusion mechanics for Fast T2T's categorical diffusion model. The CategoricalDiffusion class defines the noise schedule (linear/cosine) and transition matrices (Qs, Q_bar) for the forward diffusion process over binary variables. Key methods: 1) sample() implements the standard forward diffusion p(x_t|x_0) via matrix multiplication with Q_bar[t], 2) consistency_sample() implements the optimization consistency training protocol by generating two noisy samples (xt, xt2) from the same clean solution x0 at different time steps (t, t2) - this enables minimizing differences among samples from varying generative trajectories as described in the paper. The implementation uses categorical diffusion with 2x2 transition matrices for binary decision variables (relevant for TSP/MIS).",
  "dependencies": [
    "np.arange",
    "torch.utils.data",
    "TSPConsistency",
    "matplotlib.pyplot",
    "seaborn",
    "batched_two_opt_torch",
    "time",
    "nn.CrossEntropyLoss",
    "torch_geometric.data.DataLoader",
    "COMetaModel",
    "torch.nn.functional",
    "np.ones",
    "InferenceSchedule",
    "torch.bernoulli",
    "np.stack",
    "pytorch_lightning.utilities.rank_zero_info",
    "diffusion.models.gnn_encoder.GNNEncoder",
    "scipy",
    "math",
    "np.eye",
    "diffusion.consistency.meta.MetaConsistency",
    "os",
    "torch.from_numpy",
    "diffusion.utils.diffusion_schedulers.InferenceSchedule",
    "torch.randint",
    "diffusion.utils.mis_utils.mis_decode_np",
    "diffusion.utils.lr_schedulers.get_schedule_fn",
    "torch",
    "diffusion.utils.diffusion_schedulers.CategoricalDiffusion",
    "TSPGraphDataset",
    "diffusion.co_datasets.mis_dataset.MISDataset",
    "numpy",
    "np.linspace",
    "merge_tours",
    "TSPEvaluator",
    "MetaConsistency",
    "torch.linalg.inv",
    "F.one_hot",
    "torch.nn",
    "diffusion.consistency.MISConsistency",
    "np.clip",
    "torch.matmul",
    "pytorch_lightning",
    "torch_sparse.SparseTensor",
    "diffusion.pl_meta_model.COMetaModel"
  ]
}