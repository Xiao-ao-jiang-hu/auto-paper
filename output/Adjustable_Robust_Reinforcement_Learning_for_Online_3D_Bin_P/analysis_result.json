{
  "paper_id": "Adjustable_Robust_Reinforcement_Learning_for_Online_3D_Bin_P",
  "title": "Adjustable Robust Reinforcement Learning for Online 3D Bin Packing",
  "abstract": "Designing effective policies for the online 3D bin packing problem (3D-BPP) has been a long-standing challenge, primarily due to the unpredictable nature of incoming box sequences and stringent physical constraints. While current deep reinforcement learning (DRL) methods for online 3D-BPP have shown promising results in optimizing average performance over an underlying box sequence distribution, they often fail in real-world settings where some worst-case scenarios can materialize. Standard robust DRL algorithms tend to overly prioritize optimizing the worst-case performance at the expense of performance under normal problem instance distribution. To address these issues, we first introduce a permutation-based attacker to investigate the practical robustness of both DRL-based and heuristic methods proposed for solving online 3D-BPP. Then, we propose an adjustable robust reinforcement learning (AR2L) framework that allows efficient adjustment of robustness weights to achieve the desired balance of the policy's performance in average and worst-case environments. Specifically, we formulate the objective function as a weighted sum of expected and worst-case returns, and derive the lower performance bound by relating to the return under a mixture dynamics. To realize this lower bound, we adopt an iterative procedure that searches for the associated mixture dynamics and improves the corresponding policy. We integrate this procedure into two popular robust adversarial algorithms to develop the exact and approximate AR2L algorithms. Experiments demonstrate that AR2L is versatile in the sense that it improves policy robustness while maintaining an acceptable level of performance for the nominal case.",
  "problem_description_natural": "The online 3D bin packing problem (3D-BPP) involves packing a sequence of cuboid-shaped items of varying sizes into the minimum number of containers (bins) without knowing future items in advance. Items arrive sequentially on a conveyor, and each must be packed immediately after the previous one is placed, respecting physical constraints such as no overlaps, stability, and staying within bin boundaries. The goal is to maximize space utilization (i.e., pack as much volume as possible) while being robust to adversarial permutations of the item sequence.",
  "problem_type": "Combinatorial Optimization Problem (COP)",
  "datasets": [
    "Discrete 3D-BPP dataset",
    "Continuous 3D-BPP dataset"
  ],
  "performance_metrics": [
    "Space utilization rate (Uti.)",
    "Standard deviation of space utilization (Std.)",
    "Average number of packed items (Num.)"
  ],
  "lp_model": {
    "objective": "$\\max \\sum_{i \\in P} w_i h_i d_i$ where $P$ is the set of packed items, normalized by bin volume $S^x S^y S^z$ to maximize space utilization",
    "constraints": [
      "For each item $i \\in P$ with dimensions $(w_i, h_i, d_i)$, placed at position $(x_i, y_i, z_i)$: $0 \\leq x_i \\leq S^x - w_i$, $0 \\leq y_i \\leq S^y - h_i$, $0 \\leq z_i \\leq S^z - d_i$",
      "Non-overlap constraints: For all $i, j \\in P, i \\neq j$, items do not overlap. This can be expressed as at least one of the following holds: $x_i + w_i \\leq x_j$ or $x_j + w_j \\leq x_i$ or $y_i + h_i \\leq y_j$ or $y_j + h_j \\leq y_i$ or $z_i + d_i \\leq z_j$ or $z_j + d_j \\leq z_i$",
      "Stability constraints: Each item must be packed stably, meaning its bottom face is fully supported by other items or the bin floor, as defined in prior work (e.g., Zhao et al., 2022a)"
    ],
    "variables": [
      "$x_i, y_i, z_i$: continuous variables representing the position of item $i$ in the bin if packed",
      "$P$: set of items that are successfully packed, determined sequentially in the online setting"
    ]
  },
  "raw_latex_model": "$$\\begin{aligned} \\text{Maximize} & \\quad \\frac{\\sum_{i \\in P} w_i h_i d_i}{S^x S^y S^z} \\\\ \\text{Subject to} & \\quad \\text{For each item } i \\in P: \\\\ & \\quad 0 \\leq x_i \\leq S^x - w_i, \\quad 0 \\leq y_i \\leq S^y - h_i, \\quad 0 \\leq z_i \\leq S^z - d_i \\\\ & \\quad \\text{Non-overlap: For all } i, j \\in P, i \\neq j: \\\\ & \\quad \\quad (x_i + w_i \\leq x_j) \\lor (x_j + w_j \\leq x_i) \\lor (y_i + h_i \\leq y_j) \\lor (y_j + h_j \\leq y_i) \\lor (z_i + d_i \\leq z_j) \\lor (z_j + d_j \\leq z_i) \\\\ & \\quad \\text{Stability: Each item } i \\in P \\text{ must be supported from below as per physical constraints} \\end{aligned}$$",
  "algorithm_description": "The paper proposes an Adjustable Robust Reinforcement Learning (AR2L) framework to solve online 3D-BPP. It introduces a permutation-based attacker that reorders item sequences to generate worst-case scenarios. AR2L formulates the objective as a weighted sum of expected and worst-case returns (space utilization), derives a lower bound via mixture dynamics, and iteratively improves policies. It integrates with Robust Adversarial Reinforcement Learning (RARL) and Robust $f$-Divergence MDP (RfMDP) to develop exact and approximate AR2L algorithms, implemented using Proximal Policy Optimization (PPO) and transformer networks for policy and attacker models."
}