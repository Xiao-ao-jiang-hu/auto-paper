{
  "file_path": "dcdfg/dcdi/model.py, dcdfg/lowrank_mlp/model.py, dcdfg/lowrank_mlp/module.py, dcdfg/utils/dag_optim.py, dcdfg/utils/gumbel.py, run_perturbseq_linear.py",
  "function_name": "MLPGaussianModel, MLPModuleGaussianModel, MLPModularGaussianModule, GumbelInNOut",
  "code_snippet": "\n\n# ==========================================\n# File: dcdfg/dcdi/model.py\n# Function/Context: MLPGaussianModel\n# ==========================================\nimport numpy as np\nimport pytorch_lightning as pl\nimport torch\n\nfrom dcdfg.dcdi.module import MLPGaussianModule\n\n\nclass MLPGaussianModel(pl.LightningModule):\n    \"\"\"\n    Lightning module that runs augmented lagrangian\n    \"\"\"\n\n    def __init__(\n        self,\n        num_vars,\n        num_layers,\n        hid_dim,\n        lr_init=1e-3,\n        reg_coeff=0.1,\n        constraint_mode=\"exp\",\n    ):\n        super().__init__()\n        self.module = MLPGaussianModule(\n            num_vars, num_layers, hid_dim, constraint_mode=constraint_mode\n        )\n        # augmented lagrangian params\n        # mu: penalty\n        # gamma: multiplier\n        self.mu_init = 1e-8\n        self.gamma_init = 0.0\n        self.omega_gamma = 1e-4\n        self.omega_mu = 0.9\n        self.h_threshold = 1e-7\n        self.mu_mult_factor = 2.0\n\n        # opt params\n        self.save_hyperparameters()\n        self.lr_init = lr_init\n        self.reg_coeff = reg_coeff\n        self.constraint_mode = constraint_mode\n\n        # initialize stuff for learning loop\n        self.aug_lagrangians = []\n        self.not_nlls = []  # Augmented Lagrangrian minus (pseudo) NLL\n        self.nlls = []  # NLL on train\n        self.nlls_val = []  # NLL on validation\n        self.regs = []\n\n        # Augmented Lagrangian stuff\n        self.mu = self.mu_init\n        self.gamma = self.gamma_init\n\n        # bookkeeping for training\n        self.acyclic = 0.0\n        self.aug_lagrangians_val = []\n        self.not_nlls_val = []\n        self.constraint_value = 0.0\n        self.constraints_at_stat = []\n        self.reg_value = 0.0\n        self.internal_checkups = 0.0\n        self.stationary_points = 0.0\n\n    def forward(self, data):\n        return data\n\n    def get_augmented_lagrangian(self, nll, constraint_violation, reg):\n        # compute augmented langrangian\n        return (\n            nll\n            + self.reg_coeff * reg\n            + self.gamma * constraint_violation\n            + 0.5 * self.mu * constraint_violation**2\n        )\n\n    def training_step(self, batch, batch_idx):\n        # get data\n        x, masks, regimes = batch\n\n        # compute loss\n        nll, constraint_violation, reg = self.module.losses(x, masks)\n        aug_lagrangian = self.get_augmented_lagrangian(nll, constraint_violation, reg)\n\n        # logging\n        self.nlls.append(nll.item())\n        self.aug_lagrangians.append(aug_lagrangian.item())\n        self.not_nlls.append(aug_lagrangian.item() - nll.item())\n\n        self.log(\"Train/aug_lagrangian\", aug_lagrangian.detach())\n        self.log(\"Train/nll\", nll.detach())\n        self.log(\"Train/not_nll\", aug_lagrangian.detach() - nll.detach())\n        self.log(\"Aug_lag/mu\", self.mu)\n        self.log(\"Aug_lag/gamma\", self.gamma)\n\n        # return loss\n        return aug_lagrangian\n\n    def validation_step(self, batch, batch_idx):\n        x, masks, regimes = batch\n        nll, constraint_violation, reg = self.module.losses(x, masks)\n        aug_lagrangian = self.get_augmented_lagrangian(nll, constraint_violation, reg)\n        return {\n            \"aug_lagrangian\": aug_lagrangian,\n            \"nll\": nll,\n            \"constraint\": constraint_violation,\n            \"reg\": reg,\n        }\n\n    def validation_epoch_end(self, outputs):\n        agg = {}\n        for k in outputs[0]:\n            agg[k] = torch.stack([dic[k] for dic in outputs]).mean().item()\n        self.aug_lagrangians_val += [agg[\"aug_lagrangian\"]]\n        self.constraint_value = agg[\"constraint\"]\n        self.reg_value = agg[\"reg\"]\n        self.not_nlls_val += [agg[\"aug_lagrangian\"] - agg[\"nll\"]]\n        self.nlls_val += [agg[\"nll\"]]\n        self.regs += [self.reg_value]\n        self.acyclic = self.module.check_acyclicity()\n\n        self.log(\"Val/aug_lagrangian\", agg[\"aug_lagrangian\"])\n        self.log(\"Val/nll\", agg[\"nll\"])\n        self.log(\"Val/not_nll\", agg[\"aug_lagrangian\"] - agg[\"nll\"])\n        self.log(\"Val/acyclic\", float(self.acyclic))\n        self.log(\"Val/constraint_violation\", agg[\"constraint\"])\n        self.log(\"Val/reg_value\", agg[\"reg\"])\n\n    def configure_optimizers(self):\n        return torch.optim.RMSprop(self.module.parameters(), lr=self.lr_init)\n\n    def update_lagrangians(self):\n        self.internal_checkups += 1\n        self.log(\"Monitor/checkup\", self.internal_checkups)\n        # compute delta for gamma to check convergence status\n        delta_gamma = -np.inf\n        if len(self.aug_lagrangians_val) >= 3:\n            t0, t_half, t1 = (\n                self.aug_lagrangians_val[-3],\n                self.aug_lagrangians_val[-2],\n                self.aug_lagrangians_val[-1],\n            )\n            # if the validation loss went up and down, do not update lagrangian and penalty coefficients.\n            if min(t0, t1) < t_half < max(t0, t1):\n                delta_gamma = -np.inf\n            else:\n                delta_gamma = (t1 - t0) / 100\n\n        # if we found a stationary point, but that is not satisfying the acyclicity constraints\n        if self.constraint_value > self.h_threshold or not self.acyclic:\n            if abs(delta_gamma) < self.omega_gamma or delta_gamma > 0:\n                self.stationary_points += 1\n                self.log(\"Monitor/stationary\", self.stationary_points)\n                self.gamma += self.mu * self.constraint_value\n\n                # Did the constraint improve sufficiently?\n                if len(self.constraints_at_stat) > 1:\n                    if (\n                        self.constraint_value\n                        > self.constraints_at_stat[-1] * self.omega_mu\n                    ):\n                        self.mu *= self.mu_mult_factor\n                self.constraints_at_stat.append(self.constraint_value)\n\n                # little hack to make sure the moving average is going down.\n                gap_in_not_nll = (\n                    self.get_augmented_lagrangian(\n                        0.0, self.constraint_value, self.reg_value\n                    )\n                    - self.not_nlls_val[-1]\n                )\n                assert gap_in_not_nll > -1e-2\n                self.aug_lagrangians_val[-1] += gap_in_not_nll\n\n                # reset optimizer\n                self.trainer.optimizers = [self.configure_optimizers()]\n\n        # if we found a stationary point, that satisfies the acyclicity constraints, raise this flag, it will activate patience and terminate training soon\n        else:\n            self.trainer.satisfied_constraints = True\n\n# ==========================================\n# File: dcdfg/lowrank_mlp/model.py\n# Function/Context: MLPModuleGaussianModel\n# ==========================================\nimport numpy as np\nimport pytorch_lightning as pl\nimport torch\n\nfrom dcdfg.lowrank_mlp.module import MLPModularGaussianModule\n\n\nclass MLPModuleGaussianModel(pl.LightningModule):\n    \"\"\"\n    Lightning module that runs augmented lagrangian\n    \"\"\"\n\n    def __init__(\n        self,\n        num_vars,\n        num_layers,\n        num_modules,\n        hid_dim,\n        nonlin=\"leaky_relu\",\n        lr_init=1e-3,\n        reg_coeff=0.1,\n        constraint_mode=\"exp\",\n    ):\n        super().__init__()\n        self.module = MLPModularGaussianModule(\n            num_vars,\n            num_layers,\n            num_modules,\n            hid_dim,\n            nonlin=nonlin,\n            constraint_mode=constraint_mode,\n        )\n        # augmented lagrangian params\n        # mu: penalty\n        # gamma: multiplier\n        self.mu_init = 1e-8\n        self.gamma_init = 0.0\n        self.omega_gamma = 1e-4\n        self.omega_mu = 0.9\n        self.h_threshold = 1e-8\n        self.mu_mult_factor = 2\n        # opt params\n        self.save_hyperparameters()\n        self.hparams[\"name\"] = self.__class__.__name__\n        self.hparams[\"module_name\"] = self.module.__class__.__name__\n\n        self.lr_init = lr_init\n        self.reg_coeff = reg_coeff\n        self.constraint_mode = constraint_mode\n\n        # initialize stuff for learning loop\n        self.aug_lagrangians = []\n        self.not_nlls = []  # Augmented Lagrangrian minus (pseudo) NLL\n        self.nlls = []  # NLL on train\n        self.nlls_val = []  # NLL on validation\n        self.regs = []\n\n        # Augmented Lagrangian stuff\n        self.mu = self.mu_init\n        self.gamma = self.gamma_init\n\n        # bookkeeping for training\n        self.acyclic = 0.0\n        self.aug_lagrangians_val = []\n        self.not_nlls_val = []\n        self.constraint_value = 0.0\n        self.constraints_at_stat = []\n        self.reg_value = 0.0\n        self.internal_checkups = 0.0\n        self.stationary_points = 0.0\n\n    def forward(self, data):\n        x, masks, regimes = data\n        log_likelihood = torch.sum(\n            self.module.log_likelihood(x) * masks, dim=0\n        ) / masks.size(0)\n        return -torch.mean(log_likelihood)\n\n    def get_augmented_lagrangian(self, nll, constraint_violation, reg):\n        # compute augmented langrangian\n        return (\n            nll\n            + self.reg_coeff * reg\n            + self.gamma * constraint_violation\n            + 0.5 * self.mu * constraint_violation**2\n        )\n\n    def training_step(self, batch, batch_idx):\n        # get data\n        x, masks, regimes = batch\n\n        # compute loss\n        nll, constraint_violation, reg = self.module.losses(x, masks)\n        aug_lagrangian = self.get_augmented_lagrangian(nll, constraint_violation, reg)\n\n        # logging\n        self.nlls.append(nll.item())\n        self.aug_lagrangians.append(aug_lagrangian.item())\n        self.not_nlls.append(aug_lagrangian.item() - nll.item())\n\n        self.log(\"Train/aug_lagrangian\", aug_lagrangian.detach())\n        self.log(\"Train/nll\", nll.detach())\n        self.log(\"Train/not_nll\", aug_lagrangian.detach() - nll.detach())\n        self.log(\"Aug_lag/mu\", self.mu)\n        self.log(\"Aug_lag/gamma\", self.gamma)\n\n        # return loss\n        return aug_lagrangian\n\n    def validation_step(self, batch, batch_idx):\n        x, masks, regimes = batch\n        nll, constraint_violation, reg = self.module.losses(x, masks)\n        aug_lagrangian = self.get_augmented_lagrangian(nll, constraint_violation, reg)\n        return {\n            \"aug_lagrangian\": aug_lagrangian,\n            \"nll\": nll,\n            \"constraint\": constraint_violation,\n            \"reg\": reg,\n        }\n\n    def validation_epoch_end(self, outputs):\n        agg = {}\n        for k in outputs[0]:\n            agg[k] = torch.stack([dic[k] for dic in outputs]).mean().item()\n        self.aug_lagrangians_val += [agg[\"aug_lagrangian\"]]\n        self.constraint_value = agg[\"constraint\"]\n        self.reg_value = agg[\"reg\"]\n        self.not_nlls_val += [agg[\"aug_lagrangian\"] - agg[\"nll\"]]\n        self.nlls_val += [agg[\"nll\"]]\n        self.regs += [self.reg_value]\n        # self.acyclic = self.module.check_acyclicity()\n\n        self.log(\"Val/aug_lagrangian\", agg[\"aug_lagrangian\"])\n        self.log(\"Val/nll\", agg[\"nll\"])\n        self.log(\"Val/not_nll\", agg[\"aug_lagrangian\"] - agg[\"nll\"])\n        self.log(\"Val/constraint_violation\", agg[\"constraint\"])\n        self.log(\"Val/reg_value\", agg[\"reg\"])\n\n    def configure_optimizers(self):\n        return torch.optim.RMSprop(self.module.parameters(), lr=self.lr_init)\n\n    def update_lagrangians(self):\n        self.internal_checkups += 1\n        self.log(\"Monitor/checkup\", self.internal_checkups)\n        # compute delta for gamma to check convergence status\n        delta_gamma = -np.inf\n        if len(self.aug_lagrangians_val) >= 3:\n            t0, t_half, t1 = (\n                self.aug_lagrangians_val[-3],\n                self.aug_lagrangians_val[-2],\n                self.aug_lagrangians_val[-1],\n            )\n            # if the validation loss went up and down, do not update lagrangian and penalty coefficients.\n            if min(t0, t1) < t_half < max(t0, t1):\n                delta_gamma = -np.inf\n            else:\n                delta_gamma = (t1 - t0) / 100\n\n        # if we found a stationary point, but that is not satisfying the acyclicity constraints\n        if (\n            self.constraint_value > self.h_threshold\n            and not self.acyclic\n            and self.mu < 1e15\n            or self.stationary_points < 10\n        ):\n            if abs(delta_gamma) < self.omega_gamma or delta_gamma > 0:\n                self.stationary_points += 1\n                self.log(\"Monitor/stationary\", self.stationary_points)\n                self.gamma += self.mu * self.constraint_value\n\n                # Did the constraint improve sufficiently?\n                if len(self.constraints_at_stat) > 1:\n                    if (\n                        self.constraint_value\n                        > self.constraints_at_stat[-1] * self.omega_mu\n                    ):\n                        self.mu *= self.mu_mult_factor\n                self.constraints_at_stat.append(self.constraint_value)\n\n                # little hack to make sure the moving average is going down.\n                gap_in_not_nll = (\n                    self.get_augmented_lagrangian(\n                        0.0, self.constraint_value, self.reg_value\n                    )\n                    - self.not_nlls_val[-1]\n                )\n                assert gap_in_not_nll > -1e-2\n                self.aug_lagrangians_val[-1] += gap_in_not_nll\n\n                # reset optimizer\n                self.trainer.optimizers = [self.configure_optimizers()]\n\n        # if we found a stationary point, that satisfies the acyclicity constraints, raise this flag, it will activate patience and terminate training soon\n        else:\n            self.trainer.satisfied_constraints = True\n\n# ==========================================\n# File: dcdfg/lowrank_mlp/module.py\n# Function/Context: MLPModularGaussianModule\n# ==========================================\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom ..utils.dag_optim import GumbelInNOut, bisect, is_acyclic\n\n\nclass MLPModularGaussianModule(nn.Module):\n    def __init__(\n        self,\n        num_vars,\n        num_layers,\n        num_modules,\n        hid_dim,\n        nonlin=\"leaky_relu\",\n        constraint_mode=\"spectral_radius\",\n    ):\n        super().__init__()\n        self.num_vars = num_vars\n        self.num_layers = num_layers\n        self.num_modules = num_modules\n        self.hid_dim = hid_dim\n        self.nonlin = nonlin\n        self.constraint_mode = constraint_mode\n\n        self.weights_node2module = nn.ParameterList()\n        self.weights_module2node = nn.ParameterList()\n        self.biases_node2module = nn.ParameterList()\n        self.biases_module2node = nn.ParameterList()\n        self.log_stds = nn.Parameter(data=torch.zeros((self.num_vars,)))\n\n        self.gumbel_innout = GumbelInNOut(self.num_vars, self.num_modules)\n        self.zero_weights_ratio = 0.0\n        self.numel_weights = 0\n\n        for weights, biases, num_out_nodes, num_in_nodes in (\n            (\n                self.weights_node2module,\n                self.biases_node2module,\n                self.num_modules,\n                self.num_vars,\n            ),\n        ):\n            for i in range(self.num_layers + 1):\n                in_dim = num_in_nodes if i == 0 else self.hid_dim\n                out_dim = 1 if i == self.num_layers else self.hid_dim\n\n                weights.append(\n                    nn.Parameter(torch.zeros(num_out_nodes, out_dim, in_dim))\n                )\n                biases.append(nn.Parameter(torch.zeros(num_out_nodes, out_dim)))\n                self.numel_weights += self.num_vars * out_dim * in_dim\n\n            with torch.no_grad():\n                for node in range(num_out_nodes):\n                    for i, w in enumerate(weights):\n                        w = w[node]\n                        nn.init.xavier_uniform_(\n                            w, gain=nn.init.calculate_gain(self.nonlin)\n                        )\n                    for i, b in enumerate(biases):\n                        b = b[node]\n                        b.zero_()\n\n            self.weights_module2node.append(\n                nn.Parameter(torch.zeros(self.num_vars, 1, self.num_modules))\n            )\n            self.biases_module2node.append(nn.Parameter(torch.zeros(self.num_vars, 1)))\n            with torch.no_grad():\n                for node in range(num_out_nodes):\n                    nn.init.xavier_uniform_(\n                        self.weights_module2node[0][node],\n                        gain=nn.init.calculate_gain(self.nonlin),\n                    )\n                    self.biases_module2node[0][node].zero_()\n\n        w_adj = self.get_w_adj()\n        self.register_buffer(\"u\", torch.zeros(w_adj.shape[0]))\n        self.register_buffer(\"v\", torch.zeros(w_adj.shape[0]))\n        a, b = -3, 3\n        with torch.no_grad():\n            nn.init.trunc_normal_(self.u, a=a, b=b)\n            nn.init.trunc_normal_(self.v, a=a, b=b)\n\n        self.register_buffer(\"u_v\", torch.zeros(self.num_vars))\n        self.register_buffer(\"u_f\", torch.zeros(self.num_modules))\n        self.register_buffer(\"v_v\", torch.zeros(self.num_vars))\n        self.register_buffer(\"v_f\", torch.zeros(self.num_modules))\n        a, b = -3, 3\n        with torch.no_grad():\n            nn.init.trunc_normal_(self.u_v, a=a, b=b)\n            nn.init.trunc_normal_(self.u_f, a=a, b=b)\n            nn.init.trunc_normal_(self.v_v, a=a, b=b)\n            nn.init.trunc_normal_(self.v_f, a=a, b=b)\n\n        with torch.no_grad():\n            mat = w_adj\n            self.base_radius = self.spectral_radius_adj(mat, n_iter=100)\n            self.constraint_norm = self.compute_dag_constraint(mat).item()\n            if np.isinf(self.constraint_norm):\n                raise ValueError(\"Error: constraint normalization is infinite\")\n\n    def spectral_radius_adj(self, w_adj, n_iter=5):\n        with torch.no_grad():\n            for _ in range(n_iter):\n                self.v = F.normalize(w_adj.T @ self.v, dim=0)\n                self.u = F.normalize(w_adj @ self.u, dim=0)\n        return self.v.T @ w_adj @ self.u / (self.v @ self.u)\n\n    def spectral_radius_block(self, A, B, n_iter=5):\n        with torch.no_grad():\n            for _ in range(n_iter):\n                self.u_f = F.normalize(B @ self.u_v, dim=0)\n                self.u_v = F.normalize(A @ self.u_f, dim=0)\n                self.v_f = F.normalize(A.T @ self.v_v, dim=0)\n                self.v_v = F.normalize(B.T @ self.v_f, dim=0)\n        numerator = self.v_f.T @ B @ self.u_v + self.v_v.T @ A @ self.u_f\n        denominator = self.v_f.T @ self.u_f + self.v_v.T @ self.u_v\n        return numerator / denominator\n\n    def spectral_radius_iteration(self, node2module, module2node, n_iter=5):\n        with torch.no_grad():\n            for _ in range(n_iter):\n                diag_term = self.v * torch.sum(node2module * module2node, 1)\n                self.v = F.normalize(\n                    node2module @ module2node.T @ self.v - diag_term, dim=0\n                )\n                diag_term = self.u * torch.sum(node2module * module2node, 1)\n                self.u = F.normalize(\n                    module2node @ node2module.T @ self.u - diag_term, dim=0\n                )\n        numerator = self.v.T @ node2module @ module2node.T @ self.u\n        numerator -= self.v @ (self.u * torch.sum(node2module * module2node, 1))\n        return numerator / (self.v @ self.u)\n\n    def compute_dag_constraint(self, adj):\n        if self.constraint_mode == \"exp\":\n            return torch.trace(torch.matrix_exp(adj / self.base_radius)) - self.num_vars\n        elif self.constraint_mode == \"spectral_radius\":\n            return self.spectral_radius_adj(adj)\n        elif self.constraint_mode == \"exptrick\":\n            return (\n                torch.trace(\n                    torch.matrix_exp(\n                        self.gumbel_innout.get_proba_modules() / self.base_radius\n                    )\n                )\n                - self.num_modules\n            )\n        elif self.constraint_mode == \"spectraltrick\":\n            return self.compute_dag_constraint_spectral(\n                *self.gumbel_innout.get_proba_()\n            )\n        else:\n            raise ValueError(\n                \"constraint_mode needs to be in ['exp', 'spectral_radius', 'matrix_power'].\"\n            )\n\n    def compute_dag_constraint_power(self, w_adj):\n        d = w_adj.shape[0]\n        return (\n            torch.trace(\n                torch.linalg.matrix_power(\n                    torch.eye(w_adj.shape[0], device=w_adj.device)\n                    + w_adj / self.base_radius,\n                    d,\n                )\n            )\n            - d\n        )\n\n    def compute_dag_constraint_spectral(self, adj_node2module, adj_module2node):\n        return self.spectral_radius_iteration(adj_node2module, adj_module2node)\n\n    def forward(self, x):\n        num_batch = x.size(0)\n        num_zero_weights = 0\n\n        mask_node2module, mask_module2node = self.gumbel_innout(num_batch)\n        mask_module2node = torch.transpose(mask_module2node, 1, 2)\n\n        for weights, biases, mask in (\n            (self.weights_node2module, self.biases_node2module, mask_node2module),\n            (self.weights_module2node, self.biases_module2node, mask_module2node),\n        ):\n            num_layers = len(weights) - 1\n            for layer in range(num_layers + 1):\n                if layer == 0:\n                    x = (\n                        torch.einsum(\"tij,bjt,bj->bti\", weights[layer], mask, x)\n                        + biases[layer]\n                    )\n                else:\n                    x = torch.einsum(\"tij,btj->bti\", weights[layer], x) + biases[layer]\n\n                num_zero_weights += weights[layer].numel() - weights[\n                    layer\n                ].nonzero().size(0)\n\n                if layer != num_layers:\n                    x = (\n                        F.leaky_relu(x)\n                        if self.nonlin == \"leaky_relu\"\n                        else torch.sigmoid(x)\n                    )\n                else:\n                    x = x.squeeze()\n\n        self.zero_weights_ratio = num_zero_weights / float(self.numel_weights)\n\n        return x\n\n    def log_likelihood(self, x):\n        density_params = self.forward(x)\n        stds = torch.sqrt(torch.exp(self.log_stds) + 1e-4)\n        return torch.distributions.Normal(density_params, stds.unsqueeze(0)).log_prob(x)\n\n    def losses(self, x, mask):\n        log_likelihood = torch.sum(self.log_likelihood(x) * mask, dim=0) / mask.size(0)\n        adj = self.get_w_adj()\n        h = (\n            self.compute_dag_constraint(adj)\n        )\n        a, b = self.gumbel_innout.get_proba_()\n        reg = 0.5 * (a.sum() + b.sum()) / a.numel()\n        losses = (-torch.mean(log_likelihood), h, reg)\n        return losses\n\n    def threshold(self):\n        with torch.no_grad():\n            adj = self.gumbel_innout.get_proba_features()\n\n            def acyc(t):\n                return (\n                    float(\n                        is_acyclic(\n                            self.gumbel_innout.get_proba_features(t).cpu().numpy()\n                        )\n                    )\n                    - 0.5\n                )\n\n            threshold = bisect(acyc, 0, 1)\n            assert acyc(threshold) > 0\n            self.weight_mask = self.gumbel_innout.get_proba_features(threshold)\n            print(f\"threshold term-wise:{threshold}\")\n            print(f\"numel:{(self.weight_mask > 0).sum()}\")\n            self.gumbel_innout.freeze_threshold(threshold)\n\n    def check_acyclicity(self):\n        adj = self.get_w_adj()\n        to_keep = (adj > 0.5).type_as(adj)\n        return is_acyclic(to_keep.cpu().numpy())\n\n    def get_w_adj(self):\n        return self.gumbel_innout.get_proba_features()\n\n# ==========================================\n# File: dcdfg/utils/dag_optim.py\n# Function/Context: GumbelInNOut\n# ==========================================\nimport numpy as np\nimport torch\nfrom numba import njit\nfrom tqdm import tqdm\n\nfrom .gumbel import gumbel_sigmoid, gumbel_softmax\n\n\n@njit\ndef _is_acyclic(adjacency):\n    \"\"\"\n    Return true if adjacency is a acyclic\n    :param np.ndarray adjacency: adjacency matrix\n    \"\"\"\n    prod = np.eye(adjacency.shape[0], dtype=adjacency.dtype)\n    for _ in range(1, adjacency.shape[0] + 1):\n        prod = adjacency @ prod\n        if np.trace(prod) != 0:\n            return False\n    return True\n\n\ndef is_acyclic(adjacency):\n    return _is_acyclic(adjacency.astype(float))\n\n\nclass GumbelInNOut(torch.nn.Module):\n    \"\"\"\n    Random matrix M used for encoding egdes between modules and genes.\n    Category:\n    - 0 means no edge\n    - 1 means node2module edge\n    - 2 means module2node edge\n    Can sample a matrix and backpropagate using the\n    Gumbel straigth-through estimator.\n    :param int num_vars: number of variables\n    \"\"\"\n\n    def __init__(self, num_nodes, num_modules):\n        super(GumbelInNOut, self).__init__()\n        self.num_vars = (num_nodes, num_modules)\n        self.log_alpha = torch.nn.Parameter(torch.zeros(num_nodes, num_modules, 3))\n        self.register_buffer(\n            \"freeze_node2module\",\n            torch.zeros((num_nodes, num_modules)),\n        )\n        self.register_buffer(\n            \"freeze_module2node\",\n            torch.zeros((num_nodes, num_modules)),\n        )\n        self.tau = 1\n        self.drawhard = True\n        self.deterministic = False\n        self.reset_parameters()\n\n    def forward(self, bs):\n        if not self.deterministic:\n            design = gumbel_softmax(\n                self.log_alpha, bs, tau=self.tau, hard=self.drawhard\n            )\n            node2module = design[:, :, :, 0]\n            module2node = design[:, :, :, 1]\n        else:\n            node2module = self.freeze_node2module.unsqueeze(0)\n            module2node = self.freeze_module2node.unsqueeze(0)\n        return node2module, module2node\n\n    def freeze_threshold(self, threshold):\n        \"\"\"Returns probability of being assigned into a bucket\"\"\"\n        design = torch.softmax(self.log_alpha / self.tau, -1)\n        node2module = design[:, :, 0]\n        module2node = design[:, :, 1]\n        max_in_out = torch.maximum(node2module, module2node)\n        # zero for low confidence\n        mask_keep = max_in_out >= threshold\n        # track argmax\n        self.freeze_node2module = (node2module == max_in_out) * mask_keep\n        self.freeze_module2node = (module2node == max_in_out) * mask_keep\n        self.deterministic = True\n        print(\"Freeze threshold:\" + str(self.freeze_module2node.device))\n\n    def get_proba_modules(self):\n        \"\"\"Returns probability of being assigned into a bucket\"\"\"\n        design = torch.softmax(self.log_alpha / self.tau, -1)\n        node2module = design[:, :, 0]\n        module2node = design[:, :, 1]\n        mat = module2node.T @ node2module\n        # above is correct except for diagonal values (individual values in the matrix product are corr.)\n        mask_modules = torch.ones(self.num_vars[1], self.num_vars[1]) - torch.eye(\n            self.num_vars[1]\n        )\n        return mat * mask_modules.type_as(mat)\n\n    def get_proba_features(self, threshold=None):\n        \"\"\"Returns probability of being assigned into a bucket\"\"\"\n        design = torch.softmax(self.log_alpha / self.tau, -1)\n        node2module = design[:, :, 0]\n        module2node = design[:, :, 1]\n        if not threshold:\n            # return a differentiable tensor\n            mat = node2module @ module2node.T\n            # above is correct except for diagonal values (individual values in the matrix product are corr.)\n            mask_nodes = torch.ones(self.num_vars[0], self.num_vars[0]) - torch.eye(\n                self.num_vars[0]\n            )\n            return mat * mask_nodes.type_as(mat)\n        else:\n            # here return a matrix without grad\n            # we're thresholding here according to the edge direction confidence\n            max_in_out = torch.maximum(design[:, :, 0], design[:, :, 1])\n            # zero for low confidence\n            mask_keep = design[:, :, 0] + design[:, :, 1] >= threshold\n            # track argmax\n            node2module = (design[:, :, 0] == max_in_out) * mask_keep\n            module2node = (design[:, :, 1] == max_in_out) * mask_keep\n            # that product below has no self cycles\n            return (\n                node2module.type_as(self.log_alpha)\n                @ module2node.type_as(self.log_alpha).T\n            )\n\n    def get_proba_(self):\n        design = torch.softmax(self.log_alpha / self.tau, -1)\n        node2module = design[:, :, 0]\n        module2node = design[:, :, 1]\n        return node2module, module2node\n\n    def reset_parameters(self):\n        torch.nn.init.constant_(self.log_alpha, 1)\n\n# ==========================================\n# File: dcdfg/utils/gumbel.py\n# Function/Context: \n# ==========================================\nimport torch\n\n\ndef gumbel_sigmoid(log_alpha, bs, tau=1, hard=True):\n    shape = tuple([bs] + list(log_alpha.size()))\n    uniform = torch.distributions.Uniform(0, 1).sample(shape).type_as(log_alpha)\n    logistic_noise = torch.log(uniform) - torch.log(1 - uniform)\n    y_soft = torch.sigmoid((log_alpha + logistic_noise) / tau)\n\n    if hard:\n        y_hard = (y_soft > 0.5).type_as(y_soft)\n        # straight through logistic\n        y = y_hard.detach() - y_soft.detach() + y_soft\n    else:\n        y = y_soft\n\n    return y\n\n\ndef gumbel_softmax(log_alpha, bs, tau=1, hard=True):\n    shape = tuple([bs] + list(log_alpha.size()))\n    gumbels = (\n        -torch.empty(\n            shape, memory_format=torch.legacy_contiguous_format, device=log_alpha.device\n        )\n        .exponential_()\n        .log()\n    )  # ~Gumbel(0,1)\n    gumbels = (log_alpha + gumbels) / tau  # ~Gumbel(logits,tau)\n    y_soft = gumbels.softmax(-1)\n\n    if hard:\n        # Straight through.\n        index = y_soft.max(-1, keepdim=True)[1]\n        y_hard = torch.zeros_like(gumbels).scatter_(-1, index, 1.0)\n        ret = y_hard.detach() - y_soft.detach() + y_soft\n    else:\n        # Reparametrization trick.\n        ret = y_soft\n    return ret\n\n# ==========================================\n# File: run_perturbseq_linear.py\n# Function/Context: \n# ==========================================\nimport argparse\nimport os\n\nimport numpy as np\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import EarlyStopping\nfrom pytorch_lightning.loggers import WandbLogger\nfrom torch.utils.data import DataLoader, random_split\n\nimport wandb\nfrom dcdfg.callback import (AugLagrangianCallback, ConditionalEarlyStopping,\n                            CustomProgressBar)\nfrom dcdfg.linear_baseline.model import LinearGaussianModel\nfrom dcdfg.lowrank_linear_baseline.model import LinearModuleGaussianModel\nfrom dcdfg.lowrank_mlp.model import MLPModuleGaussianModel\nfrom dcdfg.perturbseq_data import PerturbSeqDataset\n\n\"\"\"\nUSAGE:\npython -u run_perturbseq_linear.py --data-path control --reg-coeff 0.001 --constraint-mode spectral_radius --lr 0.01 --model linear\n\"\"\"\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n\n    # data\n    parser.add_argument(\n        \"--data-path\", type=str, default=\"control\", help=\"Path to data files\"\n    )\n    parser.add_argument(\n        \"--train-samples\",\n        type=int,\n        default=0.8,\n        help=\"Number of samples used for training (default is 80% of the total size)\",\n    )\n    parser.add_argument(\n        \"--train-batch-size\",\n        type=int,\n        default=64,\n        help=\"number of samples in a minibatch\",\n    )\n    parser.add_argument(\n        \"--num-train-epochs\",\n        type=int,\n        default=600,\n        help=\"number of meta gradient steps\",\n    )\n    parser.add_argument(\n        \"--num-fine-epochs\", type=int, default=50, help=\"number of meta gradient steps\"\n    )\n    parser.add_argument(\"--num-modules\", type=int, default=20, help=\"number of modules\")\n    # optimization\n    parser.add_argument(\n        \"--lr\", type=float, default=1e-3, help=\"learning rate for optim\"\n    )\n    parser.add_argument(\n        \"--reg-coeff\",\n        type=float,\n        default=0.1,\n        help=\"regularization coefficient (lambda)\",\n    )\n    parser.add_argument(\n        \"--constraint-mode\",\n        type=str,\n        default=\"exp\",\n        help=\"technique for acyclicity constraint\",\n    )\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        default=\"linear\",\n        help=\"linear|linearlr|mlplr\",\n    )\n    parser.add_argument(\n        \"--poly\", action=\"store_true\", help=\"Polynomial on linear model\"\n    )\n\n\n    parser.add_argument(\n        \"--data-dir\", type=str, default=\"../perturb-cite-seq/SCP1064/ready/\"\n    )\n    parser.add_argument(\"--num-gpus\", type=int, default=1)\n\n    arg = parser.parse_args()\n\n    # load data and make dataset\n    folder = arg.data_dir\n    file = arg.data_dir + \"/\" + arg.data_path + \"_gene_filtered_adata.h5ad\"\n\n    train_dataset = PerturbSeqDataset(\n        file, number_genes=1000, fraction_regimes_to_ignore=0.2\n    )\n    regimes_to_ignore = train_dataset.regimes_to_ignore\n    test_dataset = PerturbSeqDataset(\n        file, number_genes=1000, regimes_to_ignore=regimes_to_ignore, load_ignored=True\n    )\n\n    nb_nodes = test_dataset.dim\n\n    train_size = int(0.8 * len(train_dataset))\n    val_size = len(train_dataset) - train_size\n    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n    if arg.model == \"linear\":\n        # create model\n        model = LinearGaussianModel(\n            nb_nodes,\n            lr_init=arg.lr,\n            reg_coeff=arg.reg_coeff,\n            constraint_mode=arg.constraint_mode,\n            poly=arg.poly,\n        )\n    elif arg.model == \"linearlr\":\n        model = LinearModuleGaussianModel(\n            nb_nodes,\n            arg.num_modules,\n            lr_init=arg.lr,\n            reg_coeff=arg.reg_coeff,\n            constraint_mode=arg.constraint_mode,\n        )\n    elif arg.model == \"mlplr\":\n        model = MLPModuleGaussianModel(\n            nb_nodes,\n            2,\n            arg.num_modules,\n            16,\n            lr_init=arg.lr,\n            reg_coeff=arg.reg_coeff,\n            constraint_mode=arg.constraint_mode,\n        )\n    else:\n        raise ValueError(\"couldn't find model\")\n\n    logger = WandbLogger(project=\"DCDI-train-\" + arg.data_path, log_model=True)\n    # LOG CONFIG\n    model_name = model.__class__.__name__\n    if arg.poly and model_name == \"LinearGaussianModel\":\n        model_name += \"_poly\"\n    logger.experiment.config.update(\n        {\"model_name\": model_name, \"module_name\": model.module.__class__.__name__}\n    )\n\n    # Step 1: augmented lagrangian\n    early_stop_1_callback = ConditionalEarlyStopping(\n        monitor=\"Val/aug_lagrangian\",\n        min_delta=1e-4,\n        patience=5,\n        verbose=True,\n        mode=\"min\",\n    )\n    trainer = pl.Trainer(\n        gpus=arg.num_gpus,\n        max_epochs=arg.num_train_epochs,\n        logger=logger,\n        val_check_interval=1.0,\n        callbacks=[AugLagrangianCallback(), early_stop_1_callback, CustomProgressBar()],\n    )\n    trainer.fit(\n        model,\n        DataLoader(train_dataset, batch_size=arg.train_batch_size, num_workers=4),\n        DataLoader(val_dataset, num_workers=8, batch_size=256),\n    )\n    wandb.log({\"nll_val\": model.nlls_val[-1]})\n    wandb.finish()\n\n    # freeze and prune adjacency\n    model.module.threshold()\n    # WE NEED THIS BECAUSE IF it's exactly a DAG THE POWER ITERATIONS DOESN'T CONVERGE\n    # TODO Just refactor and remove constraint at validation time\n    model.module.constraint_mode = \"exp\"\n    # remove dag constraints: we have a prediction problem now!\n    model.gamma = 0.0\n    model.mu = 0.0\n\n    # Step 2:fine tune weights with frozen model\n    logger = WandbLogger(project=\"DCDI-fine-\" + arg.data_path, log_model=True)\n    model_name = model.__class__.__name__\n    if arg.poly and model_name == \"LinearGaussianModel\":\n        model_name += \"_poly\"\n    logger.experiment.config.update(\n        {\"model_name\": model_name, \"module_name\": model.module.__class__.__name__}\n    )\n\n    early_stop_2_callback = EarlyStopping(\n        monitor=\"Val/nll\", min_delta=1e-6, patience=5, verbose=True, mode=\"min\"\n    )\n    trainer_fine = pl.Trainer(\n        gpus=arg.num_gpus,\n        max_epochs=arg.num_fine_epochs,\n        logger=logger,\n        val_check_interval=1.0,\n        callbacks=[early_stop_2_callback, CustomProgressBar()],\n    )\n    trainer_fine.fit(\n        model,\n        DataLoader(train_dataset, batch_size=arg.train_batch_size),\n        DataLoader(val_dataset, num_workers=2, batch_size=256),\n    )\n\n    # EVAL on held-out data\n    pred = trainer_fine.predict(\n        ckpt_path=\"best\",\n        dataloaders=DataLoader(test_dataset, num_workers=8, batch_size=256),\n    )\n    held_out_nll = np.mean([x.item() for x in pred])\n\n    # Step 3: score adjacency matrix against groundtruth\n    pred_adj = model.module.weight_mask.detach().cpu().numpy()\n    # check integers\n    assert np.equal(np.mod(pred_adj, 1), 0).all()\n    print(\"saved, now evaluating\")\n\n    # Step 4: add valid nll and dump metrics\n    pred = trainer_fine.predict(\n        ckpt_path=\"best\",\n        dataloaders=DataLoader(val_dataset, num_workers=8, batch_size=256),\n    )\n    val_nll = np.mean([x.item() for x in pred])\n\n    acyclic = int(model.module.check_acyclicity())\n    wandb.log(\n        {\n            \"interv_nll\": held_out_nll,\n            \"val nll\": val_nll,\n            \"acyclic\": acyclic,\n            \"n_edges\": pred_adj.sum(),\n        }\n    )",
  "description": "Combined Analysis:\n- [dcdfg/dcdi/model.py]: This file implements the core augmented Lagrangian optimization loop for DCD-FG. It encapsulates the key algorithm steps: 1) Computing the augmented Lagrangian objective combining negative log-likelihood (NLL), regularization, and acyclicity constraint violation with penalty parameters. 2) Performing gradient-based optimization using RMSprop. 3) Dynamically updating Lagrange multiplier (gamma) and penalty parameter (mu) based on constraint satisfaction and stationarity conditions. 4) Monitoring convergence via validation metrics and acyclicity checks. The MLPGaussianModule (imported) handles the specific factor graph parameterization and constraint computation, while this class manages the overall optimization strategy described in the paper.\n- [dcdfg/lowrank_mlp/model.py]: This file implements the core augmented Lagrangian optimization loop for DCD-FG. It directly corresponds to the paper's Algorithm 1 (Augmented Lagrangian method) and the optimization model: Objective = max_{Φ,Θ} S(Φ, Θ) with constraint C(E[M(Φ)]) = 0. The class MLPModuleGaussianModel manages the alternating optimization between the likelihood term (negative log-likelihood) and the acyclicity constraint via penalty parameters (mu, gamma). Key mathematical components implemented: 1) Augmented Lagrangian formulation (get_augmented_lagrangian), 2) Constraint violation monitoring (constraint_value), 3) Adaptive penalty updates (update_lagrangians) with stationary point detection, 4) Gradient-based optimization (configure_optimizers). The actual low-rank factor graph model and constraint computation are delegated to MLPModularGaussianModule, but this file orchestrates the constrained optimization procedure described in the paper.\n- [dcdfg/lowrank_mlp/module.py]: This file implements the core optimization model from the paper. The MLPModularGaussianModule class directly corresponds to the differentiable causal discovery framework with factor graphs (DCD-FG). Key implementations include: 1) Low-rank factorization via bipartite factor graph parameterization (node2module and module2node matrices), 2) Gumbel-softmax relaxation for differentiable edge selection via GumbelInNOut, 3) Multiple acyclicity constraint modes (spectral radius, exponential trace) applied to the half-square graph, 4) Gaussian SEM likelihood with MLP transformations, 5) Augmented Lagrangian components in losses() method. The code matches the mathematical formulation where M(Φ)=[U(Φ),V(Φ)] represents the factor graph adjacency matrices, and the constraint C(E[M(Φ)])=0 ensures acyclicity of the induced variable graph.\n- [dcdfg/utils/dag_optim.py]: This file implements the core differentiable parameterization of the factor graph adjacency matrices (U and V) described in the DCD-FG paper. The GumbelInNOut class uses a 3-category Gumbel-softmax distribution to model edges between variables and latent factors (node2module and module2node), which correspond to matrices U and V in the paper. The induced adjacency matrix over variables (half-square graph) is computed via matrix multiplication in get_proba_features(), matching the constraint M(Φ)=[U(Φ),V(Φ)]. The acyclicity constraint is enforced through the is_acyclic() function that checks the trace of matrix powers. The implementation supports both differentiable sampling (forward()) and deterministic thresholding (freeze_threshold()), aligning with the continuous relaxation and optimization steps in the paper.\n- [dcdfg/utils/gumbel.py]: This file implements the Gumbel-Softmax and Gumbel-Sigmoid tricks, which are essential for the continuous relaxation of discrete adjacency matrices in DCD-FG. The functions enable differentiable sampling from Bernoulli (sigmoid) and categorical (softmax) distributions, supporting the parameterization of factor graph edges U and V with a correlated Gumbel-softmax distribution to avoid self-loops. The 'hard' parameter implements the straight-through estimator, allowing gradients to flow through discrete samples during optimization. These functions are used to sample binary adjacency matrices from log-probabilities (log_alpha) with temperature (tau) controlling the relaxation, directly supporting the differentiable constraint enforcement in the optimization model.\n- [run_perturbseq_linear.py]: This file implements the complete training pipeline for DCD-FG on biological data, including: 1) Data loading with interventional regimes (PerturbSeqDataset), 2) Model selection (linear, low-rank linear, or low-rank MLP factor graphs), 3) Two-stage optimization: augmented Lagrangian method with acyclicity constraints (spectral_radius or exp) followed by fine-tuning with frozen adjacency, 4) Evaluation on held-out interventional data. The code directly implements Algorithm 1 from the paper: Step 1 (augmented Lagrangian optimization with constraint C(M(Φ))=0) and Step 2 (fine-tuning with frozen structure). The low-rank models (linearlr, mlplr) implement the factor graph parameterization M(Φ)=[U(Φ),V(Φ)] with m modules/factors.",
  "dependencies": [
    "gumbel_softmax",
    "dcdfg.lowrank_mlp.module.MLPModularGaussianModule",
    "..utils.dag_optim.bisect",
    "dcdfg.lowrank_mlp.model",
    "torch.nn.functional",
    "gumbel_sigmoid",
    "dcdfg.perturbseq_data",
    "numba",
    "..utils.dag_optim.is_acyclic",
    "dcdfg.callback",
    "is_acyclic",
    "_is_acyclic",
    "..utils.dag_optim.GumbelInNOut",
    "tqdm",
    "dcdfg.linear_baseline.model",
    "dcdfg.dcdi.module.MLPGaussianModule",
    "wandb",
    "os",
    "argparse",
    "numpy",
    "torch.nn",
    "dcdfg.lowrank_linear_baseline.model",
    "torch",
    "pytorch_lightning"
  ]
}