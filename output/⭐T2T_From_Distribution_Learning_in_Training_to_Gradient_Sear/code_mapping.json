{
  "file_path": "diffusion/pl_meta_model.py, diffusion/pl_mis_model.py, diffusion/pl_tsp_model.py",
  "function_name": "COMetaModel.guided_categorical_posterior, MISModel, TSPModel.test_step",
  "code_snippet": "\n\n# ==========================================\n# File: diffusion/pl_meta_model.py\n# Function/Context: COMetaModel.guided_categorical_posterior\n# ==========================================\nimport os\nimport numpy as np\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom torch_geometric.data import DataLoader as GraphDataLoader\nfrom pytorch_lightning.utilities import rank_zero_info\n\nfrom models.gnn_encoder import GNNEncoder\nfrom utils.lr_schedulers import get_schedule_fn\nfrom utils.diffusion_schedulers import CategoricalDiffusion\nimport time\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nclass COMetaModel(pl.LightningModule):\n    def __init__(self,\n                 param_args,\n                 node_feature_only=False):\n        super(COMetaModel, self).__init__()\n        self.args = param_args\n        self.diffusion_schedule = self.args.diffusion_schedule\n        self.diffusion_steps = self.args.diffusion_steps\n        self.sparse = self.args.sparse_factor > 0 or node_feature_only\n\n        out_channels = 2\n        self.diffusion = CategoricalDiffusion(\n            T=self.diffusion_steps, schedule=self.diffusion_schedule)\n\n        self.model = GNNEncoder(\n            n_layers=self.args.n_layers,\n            hidden_dim=self.args.hidden_dim,\n            out_channels=out_channels,\n            aggregation=self.args.aggregation,\n            sparse=self.sparse,\n            use_activation_checkpoint=self.args.use_activation_checkpoint,\n            node_feature_only=node_feature_only,\n        )\n\n    def guided_categorical_posterior(self, target_t, t, x0_pred_prob, xt, grad=None):\n      # xt: b, n, n\n      if grad is None:\n        grad = xt.grad\n      with torch.no_grad():\n        diffusion = self.diffusion\n        if target_t is None:\n          target_t = t - 1\n        else:\n          target_t = torch.from_numpy(target_t).view(1)\n\n        if target_t > 0:\n          Q_t = np.linalg.inv(diffusion.Q_bar[target_t]) @ diffusion.Q_bar[t]\n          Q_t = torch.from_numpy(Q_t).float().to(x0_pred_prob.device)  # [2, 2], transition matrix\n        else:\n          Q_t = torch.eye(2).float().to(x0_pred_prob.device)\n        Q_bar_t_source = torch.from_numpy(diffusion.Q_bar[t]).float().to(x0_pred_prob.device)\n        Q_bar_t_target = torch.from_numpy(diffusion.Q_bar[target_t]).float().to(x0_pred_prob.device)\n\n        xt_grad_zero, xt_grad_one = torch.zeros(xt.shape, device=xt.device).unsqueeze(-1).repeat(1, 1, 1, 2), \\\n          torch.zeros(xt.shape, device=xt.device).unsqueeze(-1).repeat(1, 1, 1, 2)\n        xt_grad_zero[..., 0] = (1 - xt) * grad\n        xt_grad_zero[..., 1] = -xt_grad_zero[..., 0]\n        xt_grad_one[..., 1] = xt * grad\n        xt_grad_one[..., 0] = -xt_grad_one[..., 1]\n        xt_grad = xt_grad_zero + xt_grad_one\n\n        xt = F.one_hot(xt.long(), num_classes=2).float()\n        xt = xt.reshape(x0_pred_prob.shape)  # [b, n, n, 2]\n\n        # q(xt−1|xt,x0=0)pθ(x0=0|xt)\n        x_t_target_prob_part_1 = torch.matmul(xt, Q_t.permute((1, 0)).contiguous())\n        x_t_target_prob_part_2 = Q_bar_t_target[0]\n        x_t_target_prob_part_3 = (Q_bar_t_source[0] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_target_prob = (x_t_target_prob_part_1 * x_t_target_prob_part_2) / x_t_target_prob_part_3  # [b, n, n, 2]\n\n        sum_x_t_target_prob = x_t_target_prob[..., 1] * x0_pred_prob[..., 0]\n\n        # q(xt−1|xt,x0=1)pθ(x0=1|xt)\n        x_t_target_prob_part_2_new = Q_bar_t_target[1]\n        x_t_target_prob_part_3_new = (Q_bar_t_source[1] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_source_prob_new = (x_t_target_prob_part_1 * x_t_target_prob_part_2_new) / x_t_target_prob_part_3_new\n\n        sum_x_t_target_prob += x_t_source_prob_new[..., 1] * x0_pred_prob[..., 1]\n\n        p_theta = torch.cat((1 - sum_x_t_target_prob.unsqueeze(-1), sum_x_t_target_prob.unsqueeze(-1)), dim=-1)\n        p_phi = torch.exp(-xt_grad)\n        if self.sparse:\n          p_phi = p_phi.reshape(p_theta.shape)\n        posterior = (p_theta * p_phi) / torch.sum((p_theta * p_phi), dim=-1, keepdim=True)\n\n        # plt.clf()\n        # sns.heatmap(posterior[..., 1].clamp(0, 1).float().detach().cpu()[0])\n        # plt.savefig('imgs/guided_{}.png'.format(target_t[0]))\n\n        if target_t > 0:\n          xt = torch.bernoulli(posterior[..., 1].clamp(0, 1))\n        else:\n          xt = posterior[..., 1].clamp(min=0)\n        if self.sparse:\n          xt = xt.reshape(-1)\n        return xt\n\n# ==========================================\n# File: diffusion/pl_mis_model.py\n# Function/Context: MISModel\n# ==========================================\nimport os\n\nimport numpy as np\nimport scipy.sparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom torch_sparse import SparseTensor\nfrom co_datasets.mis_dataset import MISDataset\nfrom utils.diffusion_schedulers import InferenceSchedule\nfrom pl_meta_model import COMetaModel\nfrom utils.mis_utils import mis_decode_np\n\n\nclass MISModel(COMetaModel):\n  def __init__(self, param_args=None):\n    super(MISModel, self).__init__(param_args=param_args, node_feature_only=True)\n\n    self.test_dataset = MISDataset(\n      data_file=os.path.join(self.args.storage_path, self.args.test_split),\n    )\n\n    self.validation_dataset = MISDataset(\n      data_file=os.path.join(self.args.storage_path, self.args.validation_split),\n    )\n\n  def forward(self, x, t, edge_index):\n    return self.model(x, t, edge_index=edge_index)\n\n  def categorical_denoise_step(self, xt, t, device, edge_index=None, target_t=None):\n    with torch.no_grad():\n      t = torch.from_numpy(t).view(1)\n      x0_pred = self.forward(\n        xt.float().to(device),\n        t.float().to(device),\n        edge_index.long().to(device) if edge_index is not None else None,\n      )\n      x0_pred_prob = x0_pred.reshape((1, xt.shape[0], -1, 2)).softmax(dim=-1)\n      xt, _ = self.categorical_posterior(target_t, t, x0_pred_prob, xt)\n      return xt\n\n  def guided_categorical_denoise_step(self, xt, t, device, edge_index=None, target_t=None):\n    torch.set_grad_enabled(True)\n    xt = xt.float()  # n if sparse\n    xt.requires_grad = True\n    t = torch.from_numpy(t).view(1)\n\n    with torch.inference_mode(False):\n      x0_pred = self.forward(\n        xt.to(device),\n        t.float().to(device),\n        edge_index.long().to(device) if edge_index is not None else None,\n      )\n\n      x0_pred_prob = x0_pred.reshape((1, xt.shape[0], -1, 2)).softmax(dim=-1)\n      num_nodes = xt.shape[0]\n      adj_matrix = SparseTensor(\n        row=edge_index[0],\n        col=edge_index[1],\n        value=torch.ones_like(edge_index[0].float()),\n        sparse_sizes=(num_nodes, num_nodes),\n      ).to_dense()\n      adj_matrix.fill_diagonal_(0)\n\n      pred_nodes = x0_pred_prob[..., 1].squeeze(0)\n      # cost_est = 1 - pred_nodes / num_nodes\n      f_mis = -pred_nodes.sum()\n      g_mis = adj_matrix @ pred_nodes\n      g_mis = (pred_nodes * g_mis).sum()\n      cost_est = f_mis + 0.5 * g_mis\n      cost_est.requires_grad_(True)\n      cost_est.backward()\n      assert xt.grad is not None\n\n      if self.args.norm is True:\n        xt.grad = nn.functional.normalize(xt.grad, p=2, dim=-1)\n      xt = self.guided_categorical_posterior(target_t, t, x0_pred_prob, xt)\n\n    return xt.detach()\n\n  def test_step(self, batch, batch_idx, draw=False, split='test'):\n    device = batch[-1].device\n\n    real_batch_idx, graph_data, point_indicator = batch\n    node_labels = graph_data.x\n    edge_index = graph_data.edge_index\n\n    stacked_predict_labels = []\n    edge_index = edge_index.to(node_labels.device).reshape(2, -1)\n    edge_index_np = edge_index.cpu().numpy()\n    adj_mat = scipy.sparse.coo_matrix(\n      (np.ones_like(edge_index_np[0]), (edge_index_np[0], edge_index_np[1])),\n    )\n\n    if self.args.parallel_sampling > 1:\n      edge_index = self.duplicate_edge_index(self.args.parallel_sampling, edge_index, node_labels.shape[0], device)\n\n    for _ in range(self.args.sequential_sampling):\n      xt = torch.randn_like(node_labels.float())\n      if self.args.parallel_sampling > 1:\n        xt = xt.repeat(self.args.parallel_sampling, 1, 1)\n        xt = torch.randn_like(xt)\n      xt = (xt > 0).long()\n      xt = xt.reshape(-1)\n\n      batch_size = 1\n      steps = self.args.inference_diffusion_steps\n      time_schedule = InferenceSchedule(inference_schedule=self.args.inference_schedule,\n                                        T=self.diffusion.T, inference_T=steps)\n\n      for i in range(steps):\n        t1, t2 = time_schedule(i)\n        t1 = np.array([t1 for _ in range(batch_size)]).astype(int)\n        t2 = np.array([t2 for _ in range(batch_size)]).astype(int)\n\n        xt = self.categorical_denoise_step(xt, t1, device, edge_index, target_t=t2)\n\n      predict_labels = xt.float().cpu().detach().numpy() + 1e-6\n\n      stacked_predict_labels.append(predict_labels)\n\n    predict_labels = np.concatenate(stacked_predict_labels, axis=0)\n    all_sampling = self.args.sequential_sampling * self.args.parallel_sampling\n\n    splitted_predict_labels = np.split(predict_labels, all_sampling)\n    solved_solutions = [mis_decode_np(predict_labels, adj_mat) for predict_labels in splitted_predict_labels]\n    solved_costs = [solved_solution.sum() for solved_solution in solved_solutions]\n    best_solved_cost = np.max(solved_costs)\n    best_solved_id = np.argmax(solved_costs)\n\n    gt_cost = node_labels.cpu().numpy().sum()\n\n    guided_gap, g_best_solved_cost = -1, -1\n    if self.args.rewrite:\n      g_best_solution = solved_solutions[best_solved_id]\n      for _ in range(self.args.rewrite_steps):\n        g_stacked_predict_labels = []\n        g_x0 = torch.from_numpy(g_best_solution).unsqueeze(0).to(device)\n        g_x0 = F.one_hot(g_x0.long(), num_classes=2).float()\n\n        steps_T = int(self.args.diffusion_steps * self.args.rewrite_ratio)\n        # steps_inf = int(self.args.inference_diffusion_steps * self.args.rewrite_ratio)\n        steps_inf = self.args.inference_steps\n\n        time_schedule = InferenceSchedule(inference_schedule=self.args.inference_schedule,\n                                          T=steps_T, inference_T=steps_inf)\n\n        Q_bar = torch.from_numpy(self.diffusion.Q_bar[steps_T]).float().to(g_x0.device)\n        g_xt_prob = torch.matmul(g_x0, Q_bar)  # [B, N, 2]\n        g_xt = torch.bernoulli(g_xt_prob[..., 1].clamp(0, 1)).to(g_x0.device)  # [B, N]\n        g_xt = g_xt * 2 - 1  # project to [-1, 1]\n        g_xt = g_xt * (1.0 + 0.05 * torch.rand_like(g_xt))  # add noise\n\n        if self.args.parallel_sampling > 1:\n          g_xt = g_xt.repeat(self.args.parallel_sampling, 1, 1)\n\n        g_xt = (g_xt > 0).long().reshape(-1)\n        for i in range(steps_inf):\n          t1, t2 = time_schedule(i)\n          t1 = np.array([t1]).astype(int)\n          t2 = np.array([t2]).astype(int)\n          g_xt = self.guided_categorical_denoise_step(g_xt, t1, device, edge_index, target_t=t2)\n\n        g_predict_labels = g_xt.float().cpu().detach().numpy() + 1e-6\n        g_stacked_predict_labels.append(g_predict_labels)\n        g_predict_labels = np.concatenate(g_stacked_predict_labels, axis=0)\n\n        g_splitted_predict_labels = np.split(g_predict_labels, self.args.parallel_sampling)\n        g_solved_solutions = [mis_decode_np(g_predict_labels, adj_mat) for g_predict_labels in g_splitted_predict_labels]\n        g_solved_costs = [g_solved_solution.sum() for g_solved_solution in g_solved_solutions]\n        g_best_solved_cost = np.max([g_best_solved_cost, np.max(g_solved_costs)])\n        g_best_solved_id = np.argmax(g_solved_costs)\n\n        g_best_solution = g_solved_solutions[g_best_solved_id]\n\n      print(f'tot_points: {g_x0.shape[-2]}, gt_cost: {gt_cost}, selected_points: {best_solved_cost} -> {g_best_solved_cost}')\n\n    metrics = {\n        f\"{split}/rewrite_ratio\": self.args.rewrite_ratio,\n        f\"{split}/norm\": self.args.norm,\n        # f\"{split}/gap\": gap,\n        # f\"{split}/guided_gap\": guided_gap,\n        f\"{split}/gt_cost\": gt_cost,\n        f\"{split}/guided_solved_cost\": g_best_solved_cost,\n    }\n    for k, v in metrics.items():\n        self.log(k, v, on_epoch=True, sync_dist=True)\n    self.log(f\"{split}/solved_cost\", best_solved_cost, prog_bar=True, on_epoch=True, sync_dist=True)\n\n    return metrics\n\n  def validation_step(self, batch, batch_idx):\n    return self.test_step(batch, batch_idx, split='val')\n\n# ==========================================\n# File: diffusion/pl_tsp_model.py\n# Function/Context: TSPModel.test_step\n# ==========================================\n  def test_step(self, batch, batch_idx, split='test'):\n    edge_index = None\n    original_edge_index = None\n    np_edge_index = None\n    device = batch[-1].device\n    if not self.sparse:\n      real_batch_idx, points, adj_matrix, gt_tour = batch\n      np_points = points.cpu().numpy()[0]\n      np_gt_tour = gt_tour.cpu().numpy()[0]\n    else:\n      real_batch_idx, graph_data, point_indicator, edge_indicator, gt_tour = batch\n      route_edge_flags = graph_data.edge_attr\n      points = graph_data.x\n      edge_index = graph_data.edge_index\n      num_edges = edge_index.shape[1]\n      batch_size = point_indicator.shape[0]\n      adj_matrix = route_edge_flags.reshape((batch_size, num_edges // batch_size))\n      points = points.reshape((-1, 2))\n      edge_index = edge_index.reshape((2, -1))\n      original_edge_index = edge_index.clone()\n      np_points = points.cpu().numpy()\n      np_gt_tour = gt_tour.cpu().numpy().reshape(-1)\n      np_edge_index = edge_index.cpu().numpy()\n\n    tsp_solver = TSPEvaluator(np_points)  # np_points: [N, 2] ndarray\n    gt_cost = tsp_solver.evaluate(np_gt_tour)  # np_gt_tour: [N+1] ndarray\n\n    # print(points.shape, edge_index.shape, batch_size, adj_matrix.shape)\n\n    if self.args.parallel_sampling > 1:\n      if not self.sparse:\n        points = points.repeat(self.args.parallel_sampling, 1, 1)\n      else:\n        points = points.repeat(self.args.parallel_sampling, 1)\n        edge_index = self.duplicate_edge_index(self.args.parallel_sampling, edge_index, np_points.shape[0], device)\n\n    # Initialize with original diffusion\n    stacked_tours = []\n    ns, merge_iterations = 0, 0\n\n    for _ in range(self.args.sequential_sampling):\n      xt = torch.randn_like(adj_matrix.float())\n      if self.args.parallel_sampling > 1:\n        if not self.sparse:\n          xt = xt.repeat(self.args.parallel_sampling, 1, 1)\n        else:\n          xt = xt.repeat(self.args.parallel_sampling, 1)  # [B, E]\n        xt = torch.randn_like(xt)\n\n      xt = (xt > 0).long()\n\n      if self.sparse:\n        xt = xt.reshape(-1)  # [E]\n\n      steps = self.args.inference_diffusion_steps\n      time_schedule = InferenceSchedule(inference_schedule=self.args.inference_schedule,\n                                        T=self.diffusion.T, inference_T=steps)\n\n      # Diffusion iterations\n      for i in range(steps):\n        t1, t2 = time_schedule(i)\n        t1 = np.array([t1]).astype(int)\n        t2 = np.array([t2]).astype(int)\n\n        # [B, N, N], heatmap score\n        xt, xt_prob = self.categorical_denoise_step(\n          points, xt, t1, device, edge_index, target_t=t2)\n\n      adj_mat = xt.float().cpu().detach().numpy() + 1e-6  # [B, N, N]\n\n      if self.args.save_numpy_heatmap and not self.args.rewrite:\n        self.run_save_numpy_heatmap(adj_mat, np_points, real_batch_idx, split)\n\n      tours, merge_iterations = merge_tours(  # [B, N+1], list\n          adj_mat, np_points, np_edge_index,\n          sparse_graph=self.sparse,\n          parallel_sampling=self.args.parallel_sampling,\n      )\n\n      # Refine using 2-opt\n      # solver_tours,  [B, N+1] ndarray, the visiting sequence of each city\n      solved_tours, ns = batched_two_opt_torch(\n          np_points.astype(\"float64\"), np.array(tours).astype('int64'),\n          max_iterations=self.args.two_opt_iterations, device=device\n      )\n      stacked_tours.append(solved_tours)\n\n    solved_tours = np.concatenate(stacked_tours, axis=0)  # [B, N+1] ndarray\n\n    tsp_solver = TSPEvaluator(np_points)  # np_points: [N, 2] ndarray\n    gt_cost = tsp_solver.evaluate(np_gt_tour)  # np_gt_tour: [N+1] ndarray\n\n    total_sampling = self.args.parallel_sampling * self.args.sequential_sampling\n    all_solved_costs = [tsp_solver.evaluate(solved_tours[i]) for i in range(total_sampling)]\n    best_solved_cost, best_id = np.min(all_solved_costs), np.argmin(all_solved_costs)\n    gap = (best_solved_cost - gt_cost) / gt_cost * 100\n\n    # print(\"gap: {}%\".format((best_solved_cost - gt_cost) / gt_cost * 100))\n\n    # select the best tour\n    g_best_tour = solved_tours[best_id]  # [N+1] ndarray\n\n    guided_gap, g_ns, g_merge_iterations, g_best_solved_cost = -1, -1, -1, -1\n\n    # Local Rewrite\n    if self.args.rewrite:\n      g_best_solved_cost = best_solved_cost\n\n      for _ in range(self.args.rewrite_steps):\n        g_stacked_tours = []\n        # optimal adjacent matrix\n        g_x0 = self.tour2adj(g_best_tour, np_points, self.sparse, self.args.sparse_factor, original_edge_index)\n        g_x0 = g_x0.unsqueeze(0).to(device)  # [1, N, N] or [1, N]\n        if self.args.parallel_sampling > 1:\n          if not self.sparse:\n            g_x0 = g_x0.repeat(self.args.parallel_sampling, 1, 1)  # [1, N ,N] -> [B, N, N]\n          else:\n            g_x0 = g_x0.repeat(self.args.parallel_sampling, 1)\n\n        if self.sparse:\n          g_x0 = g_x0.reshape(-1)\n\n        g_x0_onehot = F.one_hot(g_x0.long(), num_classes=2).float()  # [B, N, N, 2]\n        # if self.sparse:\n        #   g_x0_onehot = g_x0_onehot.unsqueeze(1)\n\n        steps_T = int(self.args.diffusion_steps * self.args.rewrite_ratio)\n        steps_inf = self.args.inference_steps\n        time_schedule = InferenceSchedule(inference_schedule=self.args.inference_schedule,\n                                          T=steps_T, inference_T=steps_inf)\n\n        # g_xt = self.diffusion.sample(g_x0_onehot, steps_T)\n        Q_bar = torch.from_numpy(self.diffusion.Q_bar[steps_T]).float().to(g_x0_onehot.device)\n        g_xt_prob = torch.matmul(g_x0_onehot, Q_bar)  # [B, N, N, 2]\n\n        # add noise for the steps_T samples, namely rewrite\n        g_xt = torch.bernoulli(g_xt_prob[..., 1].clamp(0, 1))  # [B, N, N]\n        g_xt = g_xt * 2 - 1  # project to [-1, 1]\n        g_xt = g_xt * (1.0 + 0.05 * torch.rand_like(g_xt))  # add noise\n        g_xt = (g_xt > 0).long()\n\n        for i in range(steps_inf):\n          t1, t2 = time_schedule(i)\n          t1 = np.array([t1]).astype(int)\n          t2 = np.array([t2]).astype(int)\n\n          # [1, N, N], denoise, heatmap for edges\n          g_xt = self.guided_categorical_denoise_step(points, g_xt, t1, device, edge_index, target_t=t2)\n\n        g_adj_mat = g_xt.float().cpu().detach().numpy() + 1e-6\n        if self.args.save_numpy_heatmap:\n          self.run_save_numpy_heatmap(g_adj_mat, np_points, real_batch_idx, split)\n\n        g_tours, g_merge_iterations = merge_tours(\n          g_adj_mat, np_points, np_edge_index,\n          sparse_graph=self.sparse,\n          parallel_sampling=self.args.parallel_sampling,\n        )\n\n        # Refine using 2-opt\n        g_solved_tours, g_ns = batched_two_opt_torch(\n            np_points.astype(\"float64\"), np.array(g_tours).astype('int64'),\n            max_iterations=self.args.two_opt_iterations, device=device\n        )\n        g_stacked_tours.append(g_solved_tours)\n\n        g_solved_tours = np.concatenate(g_stacked_tours, axis=0)\n\n        tsp_solver = TSPEvaluator(np_points)  # np_points: [N, 2] ndarray\n        gt_cost = tsp_solver.evaluate(np_gt_tour)  # np_gt_tour: [N+1] ndarray\n\n        g_total_sampling = self.args.parallel_sampling\n        g_all_solved_costs = [tsp_solver.evaluate(g_solved_tours[i]) for i in range(g_total_sampling)]\n        g_best_solved_cost_tmp, g_best_id = np.min(g_all_solved_costs), np.argmin(g_all_solved_costs)\n        g_best_solved_cost = min(g_best_solved_cost, g_best_solved_cost_tmp)\n\n        guided_gap = (g_best_solved_cost - gt_cost) / gt_cost * 100\n\n        # select the best tour\n        g_best_tour = g_solved_tours[g_best_id]\n\n      # print(\"gap: {}% -> {}%\".format(gap, guided_gap))\n\n    metrics = {\n        f\"{split}/rewrite_ratio\": self.args.rewrite_ratio,\n        f\"{split}/norm\": self.args.norm,\n        f\"{split}/inference_step\": self.args.inference_diffusion_steps,\n        f\"{split}/gap\": gap,\n        f\"{split}/guided_gap\": guided_gap,\n        f\"{split}/gt_cost\": gt_cost,\n        f\"{split}/2opt_iterations\": g_ns,\n        f\"{split}/merge_iterations\": g_merge_iterations,\n        f\"{split}/guided_solved_cost\": g_best_solved_cost,\n    }\n\n    for k, v in metrics.items():\n      self.log(k, v, on_epoch=True, sync_dist=True)\n    self.log(f\"{split}/solved_cost\", best_solved_cost, prog_bar=True, on_epoch=True, sync_dist=True)\n    return metrics",
  "description": "Combined Analysis:\n- [diffusion/pl_meta_model.py]: This file implements the core gradient-guided search mechanism of the T2T framework. The 'guided_categorical_posterior' function performs the key algorithm step: during testing, it combines the learned diffusion model's prediction (p_theta) with objective function gradients (p_phi = exp(-gradient)) to compute a modified posterior distribution. This enables gradient-based search within the solution space, aligning with the paper's description of 'conducting a gradient-based search within the solution space during testing.' The method uses the diffusion model's transition matrices (Q_t, Q_bar) to compute the categorical posterior, then modifies it with gradient information from the optimization objective to bias sampling toward lower-cost solutions.\n- [diffusion/pl_mis_model.py]: This file implements the core T2T algorithm for Maximal Independent Set (MIS) as described in the paper. The key components are:\n1. **Diffusion Model**: The forward method implements the diffusion model that predicts clean solutions from noisy inputs.\n2. **Gradient-Guided Search**: The `guided_categorical_denoise_step` method implements the gradient-based search during testing. It computes the MIS objective function (f_mis + 0.5*g_mis) and backpropagates to adjust the solution, aligning with the paper's 'gradient search in testing'.\n3. **Two-Phase Testing**: The `test_step` method implements the complete T2T testing pipeline: (a) Standard diffusion sampling to get initial solutions, (b) Guided rewrite steps that apply gradient-based search to iteratively improve solutions, matching the paper's 'graduated solution improvement'.\n4. **MIS Objective**: The code explicitly implements the MIS objective: maximizing node selection (f_mis = -pred_nodes.sum()) while enforcing constraints via penalty term (g_mis = (pred_nodes * (adj_matrix @ pred_nodes)).sum()).\n5. **Diffusion Schedules**: Uses InferenceSchedule for graduated noise reduction during testing.\nThe implementation directly corresponds to the paper's algorithm steps: using diffusion for solution distribution learning and gradient-guided search for instance-specific optimization.\n- [diffusion/pl_tsp_model.py]: The test_step function implements the core testing (inference) logic of the T2T framework for TSP. It includes two phases: 1) Standard diffusion sampling (categorical_denoise_step) to generate initial candidate tours, followed by 2-opt local search. 2) If rewrite is enabled (self.args.rewrite), it performs the gradient-guided search (guided_categorical_denoise_step) that iteratively improves the best tour found. This matches the paper's description of using diffusion for generative modeling and then gradient-based search for instance-specific improvement. The guided step uses gradient of the cost w.r.t. the diffusion state (via backpropagation) to guide the denoising process, aligning with the T2T's gradient search in testing.",
  "dependencies": [
    "torch.nn.functional.one_hot",
    "torch.utils.data",
    "self.sparse",
    "self.guided_categorical_denoise_step",
    "scipy.sparse",
    "self.args",
    "torch.nn.functional",
    "self.run_save_numpy_heatmap",
    "utils.diffusion_schedulers.CategoricalDiffusion",
    "utils.diffusion_schedulers.InferenceSchedule",
    "co_datasets.mis_dataset.MISDataset",
    "utils.mis_utils.mis_decode_np",
    "utils.tsp_utils.TSPEvaluator",
    "self.diffusion.Q_bar",
    "utils.tsp_utils.batched_two_opt_torch",
    "numpy",
    "self.categorical_denoise_step",
    "self.tour2adj",
    "torch.nn",
    "pl_meta_model.COMetaModel",
    "utils.tsp_utils.merge_tours",
    "torch",
    "torch_sparse.SparseTensor",
    "models.gnn_encoder.GNNEncoder"
  ]
}