{
  "file_path": "all_heatmap/softdist/batch_generate_heatmap.py, default_mcts/code/TSP_Basic_Functions.h, default_mcts/code/TSP_MCTS.h, default_mcts_varying_time/code/TSP.cpp, default_mcts_varying_time/code/TSP_MCTS.h, grid_search/code/TSP_MCTS.h, utsp/Search/code/TSP.cpp, utsp_varying_time/Search/code/TSP.cpp",
  "function_name": "create_heatmap_matrix, Get_Best_Unselected_City, Identify_Candidate_Set, MCTS, Solve_One_Instance, Solve_Instances_In_Batch, main, MCTS, MCTS, MCTS_Init, Get_Simulated_Action_Delta, Back_Propagation, Simulation, Execute_Best_Action, Solve_One_Instance, Solve_Instances_In_Batch, main, Solve_One_Instance, Solve_Instances_In_Batch, main",
  "code_snippet": "\n\n# ==========================================\n# File: all_heatmap/softdist/batch_generate_heatmap.py\n# Function/Context: create_heatmap_matrix\n# ==========================================\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport os\nimport time\nimport fire\nfrom multiprocessing import Pool\n\ndef create_heatmap_matrix(batch_coords, t, device=\"cuda:0\"):\n    batch_coords = torch.tensor(batch_coords, device=device).float()\n\n    start_time = time.time()\n\n    coord_diff = batch_coords[:, :, None, :] - batch_coords[:, None, :, :]\n    distance_matrix = torch.sqrt(torch.sum(coord_diff ** 2, dim=-1))\n    eye = torch.eye(distance_matrix.size(1), device=device).unsqueeze(0)\n    distance_matrix = torch.where(eye == 1, torch.tensor(float('inf'), dtype=torch.float, device=device), distance_matrix)\n    heatmap = F.softmax(- distance_matrix / t, dim=2)\n\n    end_time = time.time()\n\n    elapsed_time = end_time - start_time\n    print(f\"Heatmap generation took {elapsed_time} seconds\")\n\n    return heatmap.cpu().numpy()\n\ndef read_tsp_file(file_path, N):\n    with open(file_path, 'r') as file:\n        lines = file.readlines()\n    data = []\n    for line in lines:\n        parts = line.strip().split(\" output \")\n        coords_flat = np.array(parts[0].split(), dtype=np.float32)\n        data.append(coords_flat[:2*N])\n    data = np.array(data).reshape(-1, N, 2)\n    return data\n\ndef write_heatmap_to_file(args):\n    heatmap_matrix, output_file, N = args\n    with open(output_file, 'w') as out_file:\n        out_file.write(f\"{N}\\n\")\n        for row in heatmap_matrix:\n            out_file.write(' '.join(map(str, row)) + '\\n')\n\ndef is_power_of_two(n):\n    return (n != 0) and (n & (n - 1) == 0)\n\ndef process_batch(batch_coords, temperature, N, batch_size, device):\n    for i in range(0, len(batch_coords), batch_size):\n        batch = batch_coords[i:i+batch_size]\n        heatmap_matrices = create_heatmap_matrix(batch, temperature, device)\n        \n        args = [(heatmap_matrix, f\"./heatmap/tsp{N}/heatmaptsp{N}_{i+j}.txt\", N) \n                for j, heatmap_matrix in enumerate(heatmap_matrices)]\n        \n        with Pool() as pool:\n            pool.map(write_heatmap_to_file, args)\n\ndef process_tsp_data(N, temperature, device=\"cuda:0\"):\n    file_path = f\"../../default_mcts/tsp{N}_test_concorde.txt\"\n    batch_coords = read_tsp_file(file_path, N)\n    \n    os.makedirs(f\"./heatmap/tsp{N}\", exist_ok=True)\n    \n    try:\n        process_batch(batch_coords, temperature, N, len(batch_coords), device)\n        print(\"Processed in a single batch.\")\n\n    except RuntimeError as e:\n        print(f\"Error occurred: {e}. Please enter a valid batch size (must be a power of two and less than or equal to {len(batch_coords)}):\")\n        \n        while True:\n            try:\n                batch_size = int(input(\"Enter batch size: \"))\n                if not is_power_of_two(batch_size) or batch_size > len(batch_coords):\n                    raise ValueError\n                \n                process_batch(batch_coords, temperature, N, batch_size, device)\n                break\n\n            except ValueError:\n                print(\"Invalid batch size. It must be a power of two and less than or equal to the total number of batches.\")\n            except RuntimeError as e:\n                print(f\"Error occurred again: {e}. Please enter a smaller batch size:\")\n\ndef main(N, temperature):\n    process_tsp_data(N, temperature)\n\nif __name__ == \"__main__\":\n    fire.Fire(main)\n\n# ==========================================\n# File: default_mcts/code/TSP_Basic_Functions.h\n# Function/Context: Get_Best_Unselected_City, Identify_Candidate_Set\n# ==========================================\n// Modified for ICML\n// Return the unselected city neareast to Cur_City\nint Get_Best_Unselected_City(int Cur_City)\n{\n\tint Best_Unselected_City=Null;\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t{\n\t\tif(i==Cur_City || If_City_Selected[i] || Get_Distance(Cur_City,i) >= Inf_Cost )\n\t\t\tcontinue;\n\n\t\tif(Best_Unselected_City == Null || Edge_Heatmap[Cur_City][i] > Edge_Heatmap[Cur_City][Best_Unselected_City])\n\t\t\tBest_Unselected_City=i;\n\t}\n\n\tif(Edge_Heatmap[Cur_City][Best_Unselected_City] >= 0.0001)\n\t\treturn Best_Unselected_City;\n\telse\n\t\treturn Null;\n}\n\n// Modified for ICML\n// Identify a set of candidate neighbors for each city, stored in Candidate_Num[] and Candidate[][]\nvoid Identify_Candidate_Set()\n{\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t{\n\t\tCandidate_Num[i]=0;\n\n\t\tfor(int j=0;j<Virtual_City_Num;j++)\n\t\t\tIf_City_Selected[j]=false;\n\n\t\twhile(true)\n\t\t{\n\t\t\tint Best_Unselected_City=Get_Best_Unselected_City(i);\n\t\t\tif(Best_Unselected_City != Null && Candidate_Num[i] < Max_Candidate_Num)\n\t\t\t{\n\t\t\t\tCandidate[i][Candidate_Num[i]++]=Best_Unselected_City;\n\t\t\t\tIf_City_Selected[Best_Unselected_City]=true;\n\t\t\t}\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\t}\n}\n\n// Fetch the distance (already stored in Distance[][]) between two cities\nDistance_Type Get_Distance(int First_City,int Second_City)\n{\n\treturn Distance[First_City][Second_City];\n}\n\n# ==========================================\n# File: default_mcts/code/TSP_MCTS.h\n# Function/Context: MCTS\n# ==========================================\n// Initialize the parameters used in MCTS\nvoid MCTS_Init()\n{\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t\tfor(int j=0;j<Virtual_City_Num;j++)\n\t\t{\n\t\t\t//Weight[i][j]=1;\n\t\t\tWeight[i][j]=Edge_Heatmap[i][j]*100;\n\t\t\tChosen_Times[i][j]=0;\n\t\t}\n\n\t/*\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t\tfor(int j=0;j<Virtual_City_Num;j++)\n\t\t\tWeight[i][j]+=Edge_Heatmap[i][j]*100;\n\t*/\n\n\tTotal_Simulation_Times=0;\n}\n\n//Get the average weight of all the edge relative to Cur_City\ndouble Get_Avg_Weight(int Cur_City)\n{\n\tdouble Total_Weight=0;\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t{\n\t\tif(i==Cur_City)\n\t\t\tcontinue;\n\n\t\tTotal_Weight+=Weight[Cur_City][i];\n\t}\n\n\treturn Total_Weight/(Virtual_City_Num-1);\n}\n\n//Estimate the potential of each edge by upper bound confidence function\ndouble Get_Potential(int First_City, int Second_City)\n{\n\tdouble Potential=Weight[First_City][Second_City]/Avg_Weight+Alpha*sqrt( log(Total_Simulation_Times+1) / ( log(2.718)*(Chosen_Times[First_City][Second_City]+1) ) );\n\n\treturn Potential;\n}\n\n// Indentify the promising cities as candidates which are possible to connect to Cur_City\nvoid Identify_Promising_City(int Cur_City, int Begin_City)\n{\n\tPromising_City_Num=0;\n\tfor(int i=0;i<Candidate_Num[Cur_City];i++)\n\t{\n\t\tint Temp_City = Candidate[Cur_City][i];\n\t\tif(Temp_City == Begin_City)\n\t\t\tcontinue;\n\t\tif(Temp_City == All_Node[Cur_City].Next_City)\n\t\t\tcontinue;\n\t\tif(Get_Potential(Cur_City, Temp_City) < 1)\n\t\t\tcontinue;\n\n\t\tPromising_City[Promising_City_Num++]=Temp_City;\n\t}\n}\n\n// Set the probability (stored in Probabilistic[]) of selecting each candidate city (proportion to the potential of the corresponding edge)\nbool Get_Probabilistic(int Cur_City)\n{\n\tif(Promising_City_Num==0)\n\t\treturn false;\n\n\tdouble Total_Potential=0;\n\tfor(int i=0;i<Promising_City_Num;i++)\n\t\tTotal_Potential+=Get_Potential(Cur_City, Promising_City[i]);\n\n\tProbabilistic[0]=(int)(1000*Get_Potential(Cur_City, Promising_City[0])/Total_Potential);\n\tfor(int i=1;i<Promising_City_Num-1;i++)\n\t\tProbabilistic[i]=Probabilistic[i-1]+(int)(1000*Get_Potential(Cur_City, Promising_City[i])/Total_Potential);\n\tProbabilistic[Promising_City_Num-1]=1000;\n\n\treturn true;\n}\n\n// Probabilistically choose a city, controled by the values stored in Probabilistic[]\nint Probabilistic_Get_City_To_Connect()\n{\n\tint Random_Num=Get_Random_Int(1000);\n\tfor(int i=0;i<Promising_City_Num;i++)\n\t\tif(Random_Num < Probabilistic[i])\n\t\t\treturn Promising_City[i];\n\n\treturn Null;\n}\n\n// The whole process of choosing a city (a_{i+1} in the paper) to connect Cur_City (b_i in the paper)\nint Choose_City_To_Connect(int Cur_City, int Begin_City)\n{\n\tAvg_Weight=Get_Avg_Weight(Cur_City);\n\tIdentify_Promising_City(Cur_City, Begin_City);\n\tGet_Probabilistic(Cur_City);\n\n\treturn Probabilistic_Get_City_To_Connect();\n}\n\n// Generate an action starting form Begin_City (corresponding to a_1 in the paper), return the delta value\nDistance_Type Get_Simulated_Action_Delta(int Begin_City)\n{\n\t// Store the current solution to Solution[]\n\tif(Convert_All_Node_To_Solution()==false)\n\t\treturn -Inf_Cost;\n\n\tint Next_City=All_Node[Begin_City].Next_City;   // a_1=Begin city, b_1=Next_City\n\n\t// Break edge (a_1,b_1)\n\tAll_Node[Begin_City].Next_City=Null;\n\tAll_Node[Next_City].Pre_City=Null;\n\n\t// The elements of an action is stored in City_Sequence[], where a_{i+1}=City_Sequence[2*i], b_{i+1}=City_Sequence[2*i+1]\n\tCity_Sequence[0]=Begin_City;\n\tCity_Sequence[1]=Next_City;\n\n\tGain[0]=Get_Distance(Begin_City,Next_City);                // Gain[i] stores the delta (before connecting to a_1) at the (i+1)th iteration\n\tReal_Gain[0]=Gain[0]-Get_Distance(Next_City,Begin_City);   // Real_Gain[i] stores the delta (after connecting to a_1) at the (i+1)th iteration\n\tPair_City_Num=1;                                            // Pair_City_Num indicates the depth (k in the paper) of the action\n\n\tbool If_Changed=false;\n\tint Cur_City=Next_City;     // b_i = Cur_City (1 <= i <= k)\n\twhile(true)\n\t{\n\t\tint Next_City_To_Connect=Choose_City_To_Connect(Cur_City,Begin_City); //  Probabilistically choose one city as a_{i+1}\n\t\tif(Next_City_To_Connect == Null)\n\t\t\tbreak;\n\n\t\t//Update the chosen times, used in MCTS\n\t\tChosen_Times[Cur_City][Next_City_To_Connect] ++;\n\t\tChosen_Times[Next_City_To_Connect][Cur_City] ++;\n\n\t\tint Next_City_To_Disconnect=All_Node[Next_City_To_Connect].Pre_City;   // Determine b_{i+1}\n\n\t\t// Update City_Sequence[], Gain[], Real_Gain[] and Pair_City_Num\n\t\tCity_Sequence[2*Pair_City_Num]=Next_City_To_Connect;\n\t\tCity_Sequence[2*Pair_City_Num+1]=Next_City_To_Disconnect;\n\t\tGain[Pair_City_Num]=Gain[Pair_City_Num-1]-Get_Distance(Cur_City,Next_City_To_Connect)+Get_Distance(Next_City_To_Connect,Next_City_To_Disconnect);\n\t\tReal_Gain[Pair_City_Num]=Gain[Pair_City_Num]-Get_Distance(Next_City_To_Disconnect,Begin_City);\n\t\tPair_City_Num++;\n\n\t\t// Reverse the cities between b_i and b_{i+1}\n\t\tReverse_Sub_Path(Cur_City,Next_City_To_Disconnect);\n\t\tAll_Node[Cur_City].Next_City=Next_City_To_Connect;\n\t\tAll_Node[Next_City_To_Connect].Pre_City=Cur_City;\n\t\tAll_Node[Next_City_To_Disconnect].Pre_City=Null;\n\t\tIf_Changed=true;\n\n\t\t// Turns to the next iteration\n\t\tCur_City=Next_City_To_Disconnect;\n\n\t\t// Close the loop is meeting an improving action, or the depth reaches its upper bound\n\t\tif(Real_Gain[Pair_City_Num-1] > 0 || Pair_City_Num > Max_Depth)\n\t\t\tbreak;\n\t}\n\n\t// Restore the solution before simulation\n\tif(If_Changed)\n\t\tConvert_Solution_To_All_Node();\n\telse\n\t{\n\t\tAll_Node[Begin_City].Next_City=Next_City;\n\t\tAll_Node[Next_City].Pre_City=Begin_City;\n\t}\n\n\t// Identify the best depth of the simulated action\n\tint Max_Real_Gain=-Inf_Cost;\n\tint Best_Index=1;\n\tfor(int i=1;i<Pair_City_Num;i++)\n\t\tif(Real_Gain[i] > Max_Real_Gain)\n\t\t{\n\t\t\tMax_Real_Gain=Real_Gain[i];\n\t\t\tBest_Index=i;\n\t\t}\n\n\tPair_City_Num=Best_Index+1;\n\n\treturn Max_Real_Gain;\n}\n\n// If the delta of an action is greater than zero, use the information of this action (stored in City_Sequence[]) to update the parameters by back propagation\nvoid Back_Propagation(Distance_Type Before_Simulation_Distance, Distance_Type Action_Delta)\n{\n\tfor(int i=0;i<Pair_City_Num;i++)\n\t{\n\t\tint First_City=City_Sequence[2*i];\n\t\tint Second_City=City_Sequence[2*i+1];\n\t\tint Third_City;\n\t\tif(i<Pair_City_Num-1)\n\t\t\tThird_City=City_Sequence[2*i+2];\n\t\telse\n\t\t\tThird_City=City_Sequence[0];\n\n\t\tif(Action_Delta >0)\n\t\t{\n\t\t\tdouble Increase_Rate=Beta*(pow(2.718, (double) (Action_Delta) / (double)(Before_Simulation_Distance) )-1);\n\t\t\tWeight[Second_City][Third_City] += Increase_Rate;\n\t\t\tWeight[Third_City][Second_City] += Increase_Rate;\n\t\t}\n\t}\n}\n\n// Sampling at most Max_Simulation_Times actions\nDistance_Type Simulation(int Max_Simulation_Times)\n{\n\tDistance_Type Best_Action_Delta = -Inf_Cost;\n\tfor(int i=0;i<Max_Simulation_Times;i++)\n\t{\n\t\tint Begin_City=Get_Random_Int(Virtual_City_Num);\n\t\tDistance_Type Action_Delta=Get_Simulated_Action_Delta(Begin_City);\n\t\tTotal_Simulation_Times++;\n\n\t\t//Store the action with the best delta, stored in Temp_City_Sequence[] and Temp_Pair_Num\n\t\tif(Action_Delta > Best_Action_Delta)\n\t\t{\n\t\t\tBest_Action_Delta = Action_Delta;\n\n\t\t\tTemp_Pair_Num = Pair_City_Num;\n\t\t\tfor(int j=0;j<2*Pair_City_Num;j++)\n\t\t\t\tTemp_City_Sequence[j]=City_Sequence[j];\n\t\t}\n\n\t\tif(Best_Action_Delta >0)\n\t\t\tbreak;\n\t}\n\n\t// Restore the action with the best delta\n\tPair_City_Num=Temp_Pair_Num;\n\tfor(int i=0;i<2*Pair_City_Num;i++)\n\t\tCity_Sequence[i]=Temp_City_Sequence[i];\n\n\treturn Best_Action_Delta;\n}\n\n//Execute the best action stored in City_Sequence[] with depth Pair_City_Num\nbool Execute_Best_Action()\n{\n\tint Begin_City=City_Sequence[0];\n\tint Cur_City=City_Sequence[1];\n\tAll_Node[Begin_City].Next_City=Null;\n\tAll_Node[Cur_City].Pre_City=Null;\n\tfor(int i=1;i<Pair_City_Num;i++)\n\t{\n\t\tint Next_City_To_Connect=City_Sequence[2*i];\n\t\tint Next_City_To_Disconnect=City_Sequence[2*i+1];\n\n\t\tReverse_Sub_Path(Cur_City,Next_City_To_Disconnect);\n\n\t\tAll_Node[Cur_City].Next_City=Next_City_To_Connect;\n\t\tAll_Node[Next_City_To_Connect].Pre_City=Cur_City;\n\t\tAll_Node[Next_City_To_Disconnect].Pre_City=Null;\n\n\t\tCur_City=Next_City_To_Disconnect;\n\t}\n\n\tAll_Node[Begin_City].Next_City=Cur_City;\n\tAll_Node[Cur_City].Pre_City=Begin_City;\n\n\tif(Check_Solution_Feasible()==false)\n\t{\n\t\tprintf(\"\\nError! The solution after applying action from %d is unfeasible\\n\",Begin_City+1);\n\t\tPrint_TSP_Tour(Begin_City);\n\t\tgetchar();\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n// Process of the MCTS\nvoid MCTS()\n{\n\t//while(true)\n\twhile(((double)clock()-Current_Instance_Begin_Time) /CLOCKS_PER_SEC<Param_T*Virtual_City_Num)\n\t{\n\t\tDistance_Type Before_Simulation_Distance = Get_Solution_Total_Distance();\n\n\t\t//Simulate a number of (controled by Param_H) actions\n\t\tDistance_Type Best_Delta=Simulation(Param_H*Virtual_City_Num);\n\n\t\t// Use the information of the best action to update the parameters of MCTS by back propagation\n\t\tBack_Propagation(Before_Simulation_Distance,Best_Delta);\n\n\t\tif(Best_Delta > 0)\n\t\t{\n\t\t\t// Select the best action to execute\n\t\t\tExecute_Best_Action();\n\n\t\t\t// Store the best found solution to Struct_Node *Best_All_Node\n\t\t\tDistance_Type Cur_Solution_Total_Distance=Get_Solution_Total_Distance();\n\t\t\tif(Cur_Solution_Total_Distance < Current_Instance_Best_Distance)\n\t\t\t{\n\t\t\t\tCurrent_Instance_Best_Distance = Cur_Solution_Total_Distance;\n\t\t\t\tStore_Best_Solution();\n\t\t\t}\n\t\t}\n\t\telse\n\t\t\tbreak;      // The MCTS terminates if no improving action is found among the sampling pool\n\t}\n}\n\n# ==========================================\n# File: default_mcts_varying_time/code/TSP.cpp\n# Function/Context: Solve_One_Instance, Solve_Instances_In_Batch, main\n# ==========================================\n#include \"TSP_IO.h\"\n#include \"TSP_Basic_Functions.h\"\n#include \"TSP_Init.h\"\n#include \"TSP_2Opt.h\"\n#include \"TSP_MCTS.h\"\n#include \"TSP_Markov_Decision.h\"\n\n// For TSP20-50-100-200-500-1000 instances\nvoid Solve_One_Instance(int Inst_Index)\n{\n\tCurrent_Instance_Begin_Time=(double)clock();\n\tCurrent_Instance_Best_Distance=Inf_Cost;\n\n\t// Input\n\tFetch_Stored_Instance_Info(Inst_Index);\n\n\t//Pre-processing\n\tCalculate_All_Pair_Distance();\n\n  \tSet_Heapmap_Fine_Name(Inst_Index);\n  \tRead_Heatmap();\n\n  \tIdentify_Candidate_Set();\n\n\t//Search by MDP\n\tMarkov_Decision_Process();\n\n\tdouble Stored_Solution_Double_Distance=Get_Stored_Solution_Double_Distance(Inst_Index);\n\tdouble Current_Solution_Double_Distance=Get_Current_Solution_Double_Distance();\n\n\tif(Stored_Solution_Double_Distance/Magnify_Rate-Current_Solution_Double_Distance/Magnify_Rate > 0.000001)\n\t\tBeat_Best_Known_Times++;\n\telse if(Current_Solution_Double_Distance/Magnify_Rate-Stored_Solution_Double_Distance/Magnify_Rate > 0.000001)\n\t\tMiss_Best_Known_Times++;\n\telse\n\t\tMatch_Best_Known_Times++;\n\n\tSum_Opt_Distance+=Stored_Solution_Double_Distance/Magnify_Rate;\n\tSum_My_Distance+=Current_Solution_Double_Distance/Magnify_Rate;\n\tSum_Gap += (Current_Solution_Double_Distance-Stored_Solution_Double_Distance)/Stored_Solution_Double_Distance;\n\n\tprintf(\"\\nInst_Index:%d Concorde Distance:%f, MCTS Distance:%f Improve:%f Time:%.2f Seconds\\n\", Inst_Index+1, Stored_Solution_Double_Distance/Magnify_Rate,\n\t\t\tCurrent_Solution_Double_Distance/Magnify_Rate, Stored_Solution_Double_Distance/Magnify_Rate-Current_Solution_Double_Distance/Magnify_Rate, ((double)clock()-Current_Instance_Begin_Time)/CLOCKS_PER_SEC);\n\n\tFILE *fp;\n\tfp=fopen(Statistics_File_Name, \"a+\");\n\tfprintf(fp,\"\\nInst_Index:%d \\t City_Num:%d \\t Concorde:%f \\t MCTS:%f Improve:%f \\t Time:%.2f Seconds\\n\",Inst_Index+1, Virtual_City_Num, Stored_Solution_Double_Distance/Magnify_Rate,\n\t\t\tCurrent_Solution_Double_Distance/Magnify_Rate, Stored_Solution_Double_Distance/Magnify_Rate-Current_Solution_Double_Distance/Magnify_Rate, ((double)clock()-Current_Instance_Begin_Time)/CLOCKS_PER_SEC);\n\n\tfprintf(fp,\"Solution: \");\n\tint Cur_City=Start_City;\n\tdo\n\t{\n\t\tfprintf(fp,\"%d \",Cur_City+1);\n\t\tCur_City=All_Node[Cur_City].Next_City;\n\t}while(Cur_City != Null && Cur_City != Start_City);\n\n\tfprintf(fp,\"\\n\");\n\tfclose(fp);\n\n\tRelease_Memory(Virtual_City_Num);\n}\n\nbool Solve_Instances_In_Batch()\n{\n\tifstream FIC;\n\tFIC.open(Input_File_Name);\n\n\tif(FIC.fail())\n\t{\n    \tcout << \"\\n\\nError! Fail to open file\"<<Input_File_Name<<endl;\n    \tgetchar();\n    \treturn false;\n\t}\n  \telse\n    \tcout << \"\\n\\nBegin to read instances information from \"<<Input_File_Name<<endl;\n\n\n \tdouble Temp_X;\n \tdouble Temp_Y;\n \tint Temp_City;\n \tchar Temp_String[100];\n\n  \tfor(int i=0;i<Total_Instance_Num;i++)\n  \t{\n  \t\tfor(int j=0;j<Temp_City_Num;j++)\n  \t\t{\n\t\t\tFIC>>Temp_X;\n\t\t\tFIC>>Temp_Y;\n\t\t\tStored_Coordinates_X[i][j]=Temp_X;\n\t\t\tStored_Coordinates_Y[i][j]=Temp_Y;\n\t\t}\n\n\t\tFIC>>&Temp_String[0];\n\n\t\tfor(int j=0;j<Temp_City_Num;j++)\n  \t\t{\n\t\t\tFIC>>Temp_City;\n\t\t\tStored_Opt_Solution[i][j]=Temp_City-1;\n\t\t}\n\n\t\tFIC>>Temp_City;\n\t}\n  \tFIC.close();\n\n  \tcout <<\"\\nRead instances finished. Begin to search.\"<<endl;\n\n\tif((Index_In_Batch+1)*Inst_Num_Per_Batch < Total_Instance_Num)\n\t\tTest_Inst_Num=Inst_Num_Per_Batch;\n\telse\n\t\tTest_Inst_Num=Total_Instance_Num-Index_In_Batch*Inst_Num_Per_Batch;\n\tcout<<\"\\nNumber of instances in current batch: \" <<Test_Inst_Num <<endl;\n\n\tFILE *fp;\n\tfp=fopen(Statistics_File_Name, \"w+\");\n\tfprintf(fp,\"Number_of_Instances_In_Current_Batch: %d\\n\",Test_Inst_Num);\n\tfclose(fp);\n\n\n  \tfor(int i=Index_In_Batch*Inst_Num_Per_Batch;i<(Index_In_Batch+1)*Inst_Num_Per_Batch && i<Total_Instance_Num;i++)\n\t \tSolve_One_Instance(i);\n\n  \treturn true;\n}\n\nint main(int argc, char ** argv)\n{\n\tdouble Overall_Begin_Time=(double)clock();\n\n\tsrand(Random_Seed);\n\n\tIndex_In_Batch=atoi(argv[1]);\n\tStatistics_File_Name=argv[2];\n\tInput_File_Name=argv[3];\n\tTemp_City_Num=atoi(argv[4]);\n\tInst_Num_Per_Batch=atoi(argv[5]);\n\tParam_T = atof(argv[6]);\n\tprintf(\"Param_T: %f\\n\", Param_T);\n\n\n\tSolve_Instances_In_Batch();\n\n\tFILE *fp;\n\tfp=fopen(Statistics_File_Name, \"a+\");\n\tfprintf(fp,\"\\n\\nAvg_Concorde_Distance: %f Avg_MCTS_Distance: %f Avg_Gap: %f Total_Time: %.2f Seconds \\n Beat_Best_Known_Times: %d Match_Best_Known_Times: %d Miss_Best_Known_Times: %d \\n\",\n\t\t\tSum_Opt_Distance/Test_Inst_Num,Sum_My_Distance/Test_Inst_Num, Sum_Gap/Test_Inst_Num, ((double)clock()-Overall_Begin_Time)/CLOCKS_PER_SEC, Beat_Best_Known_Times, Match_Best_Known_Times, Miss_Best_Known_Times);\n\tfclose(fp);\n\n\tprintf(\"\\n\\nAvg_Concorde_Distance: %f Avg_MCTS_Distance: %f Avg_Gap: %f Total_Time: %.2f Seconds \\n Beat_Best_Known_Times: %d Match_Best_Known_Times: %d Miss_Best_Known_Times: %d \\n\",\n\t\t\tSum_Opt_Distance/Test_Inst_Num,Sum_My_Distance/Test_Inst_Num, Sum_Gap/Test_Inst_Num, ((double)clock()-Overall_Begin_Time)/CLOCKS_PER_SEC, Beat_Best_Known_Times, Match_Best_Known_Times, Miss_Best_Known_Times);\n\tgetchar();\n\n\treturn 0;\n}\n\n# ==========================================\n# File: default_mcts_varying_time/code/TSP_MCTS.h\n# Function/Context: MCTS\n# ==========================================\n// Initialize the parameters used in MCTS\nvoid MCTS_Init()\n{\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t\tfor(int j=0;j<Virtual_City_Num;j++)\n\t\t{\n\t\t\t//Weight[i][j]=1;\n\t\t\tWeight[i][j]=Edge_Heatmap[i][j]*100;\n\t\t\tChosen_Times[i][j]=0;\n\t\t}\n\n\t/*\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t\tfor(int j=0;j<Virtual_City_Num;j++)\n\t\t\tWeight[i][j]+=Edge_Heatmap[i][j]*100;\n\t*/\n\n\tTotal_Simulation_Times=0;\n}\n\n//Get the average weight of all the edge relative to Cur_City\ndouble Get_Avg_Weight(int Cur_City)\n{\n\tdouble Total_Weight=0;\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t{\n\t\tif(i==Cur_City)\n\t\t\tcontinue;\n\n\t\tTotal_Weight+=Weight[Cur_City][i];\n\t}\n\n\treturn Total_Weight/(Virtual_City_Num-1);\n}\n\n//Estimate the potential of each edge by upper bound confidence function\ndouble Get_Potential(int First_City, int Second_City)\n{\n\tdouble Potential=Weight[First_City][Second_City]/Avg_Weight+Alpha*sqrt( log(Total_Simulation_Times+1) / ( log(2.718)*(Chosen_Times[First_City][Second_City]+1) ) );\n\n\treturn Potential;\n}\n\n// Indentify the promising cities as candidates which are possible to connect to Cur_City\nvoid Identify_Promising_City(int Cur_City, int Begin_City)\n{\n\tPromising_City_Num=0;\n\tfor(int i=0;i<Candidate_Num[Cur_City];i++)\n\t{\n\t\tint Temp_City = Candidate[Cur_City][i];\n\t\tif(Temp_City == Begin_City)\n\t\t\tcontinue;\n\t\tif(Temp_City == All_Node[Cur_City].Next_City)\n\t\t\tcontinue;\n\t\tif(Get_Potential(Cur_City, Temp_City) < 1)\n\t\t\tcontinue;\n\n\t\tPromising_City[Promising_City_Num++]=Temp_City;\n\t}\n}\n\n// Set the probability (stored in Probabilistic[]) of selecting each candidate city (proportion to the potential of the corresponding edge)\nbool Get_Probabilistic(int Cur_City)\n{\n\tif(Promising_City_Num==0)\n\t\treturn false;\n\n\tdouble Total_Potential=0;\n\tfor(int i=0;i<Promising_City_Num;i++)\n\t\tTotal_Potential+=Get_Potential(Cur_City, Promising_City[i]);\n\n\tProbabilistic[0]=(int)(1000*Get_Potential(Cur_City, Promising_City[0])/Total_Potential);\n\tfor(int i=1;i<Promising_City_Num-1;i++)\n\t\tProbabilistic[i]=Probabilistic[i-1]+(int)(1000*Get_Potential(Cur_City, Promising_City[i])/Total_Potential);\n\tProbabilistic[Promising_City_Num-1]=1000;\n\n\treturn true;\n}\n\n// Probabilistically choose a city, controled by the values stored in Probabilistic[]\nint Probabilistic_Get_City_To_Connect()\n{\n\tint Random_Num=Get_Random_Int(1000);\n\tfor(int i=0;i<Promising_City_Num;i++)\n\t\tif(Random_Num < Probabilistic[i])\n\t\t\treturn Promising_City[i];\n\n\treturn Null;\n}\n\n// The whole process of choosing a city (a_{i+1} in the paper) to connect Cur_City (b_i in the paper)\nint Choose_City_To_Connect(int Cur_City, int Begin_City)\n{\n\tAvg_Weight=Get_Avg_Weight(Cur_City);\n\tIdentify_Promising_City(Cur_City, Begin_City);\n\tGet_Probabilistic(Cur_City);\n\n\treturn Probabilistic_Get_City_To_Connect();\n}\n\n// Generate an action starting form Begin_City (corresponding to a_1 in the paper), return the delta value\nDistance_Type Get_Simulated_Action_Delta(int Begin_City)\n{\n\t// Store the current solution to Solution[]\n\tif(Convert_All_Node_To_Solution()==false)\n\t\treturn -Inf_Cost;\n\n\tint Next_City=All_Node[Begin_City].Next_City;   // a_1=Begin city, b_1=Next_City\n\n\t// Break edge (a_1,b_1)\n\tAll_Node[Begin_City].Next_City=Null;\n\tAll_Node[Next_City].Pre_City=Null;\n\n\t// The elements of an action is stored in City_Sequence[], where a_{i+1}=City_Sequence[2*i], b_{i+1}=City_Sequence[2*i+1]\n\tCity_Sequence[0]=Begin_City;\n\tCity_Sequence[1]=Next_City;\n\n\tGain[0]=Get_Distance(Begin_City,Next_City);                // Gain[i] stores the delta (before connecting to a_1) at the (i+1)th iteration\n\tReal_Gain[0]=Gain[0]-Get_Distance(Next_City,Begin_City);   // Real_Gain[i] stores the delta (after connecting to a_1) at the (i+1)th iteration\n\tPair_City_Num=1;                                            // Pair_City_Num indicates the depth (k in the paper) of the action\n\n\tbool If_Changed=false;\n\tint Cur_City=Next_City;     // b_i = Cur_City (1 <= i <= k)\n\twhile(true)\n\t{\n\t\tint Next_City_To_Connect=Choose_City_To_Connect(Cur_City,Begin_City); //  Probabilistically choose one city as a_{i+1}\n\t\tif(Next_City_To_Connect == Null)\n\t\t\tbreak;\n\n\t\t//Update the chosen times, used in MCTS\n\t\tChosen_Times[Cur_City][Next_City_To_Connect] ++;\n\t\tChosen_Times[Next_City_To_Connect][Cur_City] ++;\n\n\t\tint Next_City_To_Disconnect=All_Node[Next_City_To_Connect].Pre_City;   // Determine b_{i+1}\n\n\t\t// Update City_Sequence[], Gain[], Real_Gain[] and Pair_City_Num\n\t\tCity_Sequence[2*Pair_City_Num]=Next_City_To_Connect;\n\t\tCity_Sequence[2*Pair_City_Num+1]=Next_City_To_Disconnect;\n\t\tGain[Pair_City_Num]=Gain[Pair_City_Num-1]-Get_Distance(Cur_City,Next_City_To_Connect)+Get_Distance(Next_City_To_Connect,Next_City_To_Disconnect);\n\t\tReal_Gain[Pair_City_Num]=Gain[Pair_City_Num]-Get_Distance(Next_City_To_Disconnect,Begin_City);\n\t\tPair_City_Num++;\n\n\t\t// Reverse the cities between b_i and b_{i+1}\n\t\tReverse_Sub_Path(Cur_City,Next_City_To_Disconnect);\n\t\tAll_Node[Cur_City].Next_City=Next_City_To_Connect;\n\t\tAll_Node[Next_City_To_Connect].Pre_City=Cur_City;\n\t\tAll_Node[Next_City_To_Disconnect].Pre_City=Null;\n\t\tIf_Changed=true;\n\n\t\t// Turns to the next iteration\n\t\tCur_City=Next_City_To_Disconnect;\n\n\t\t// Close the loop is meeting an improving action, or the depth reaches its upper bound\n\t\tif(Real_Gain[Pair_City_Num-1] > 0 || Pair_City_Num > Max_Depth)\n\t\t\tbreak;\n\t}\n\n\t// Restore the solution before simulation\n\tif(If_Changed)\n\t\tConvert_Solution_To_All_Node();\n\telse\n\t{\n\t\tAll_Node[Begin_City].Next_City=Next_City;\n\t\tAll_Node[Next_City].Pre_City=Begin_City;\n\t}\n\n\t// Identify the best depth of the simulated action\n\tint Max_Real_Gain=-Inf_Cost;\n\tint Best_Index=1;\n\tfor(int i=1;i<Pair_City_Num;i++)\n\t\tif(Real_Gain[i] > Max_Real_Gain)\n\t\t{\n\t\t\tMax_Real_Gain=Real_Gain[i];\n\t\t\tBest_Index=i;\n\t\t}\n\n\tPair_City_Num=Best_Index+1;\n\n\treturn Max_Real_Gain;\n}\n\n// If the delta of an action is greater than zero, use the information of this action (stored in City_Sequence[]) to update the parameters by back propagation\nvoid Back_Propagation(Distance_Type Before_Simulation_Distance, Distance_Type Action_Delta)\n{\n\tfor(int i=0;i<Pair_City_Num;i++)\n\t{\n\t\tint First_City=City_Sequence[2*i];\n\t\tint Second_City=City_Sequence[2*i+1];\n\t\tint Third_City;\n\t\tif(i<Pair_City_Num-1)\n\t\t\tThird_City=City_Sequence[2*i+2];\n\t\telse\n\t\t\tThird_City=City_Sequence[0];\n\n\t\tif(Action_Delta >0)\n\t\t{\n\t\t\tdouble Increase_Rate=Beta*(pow(2.718, (double) (Action_Delta) / (double)(Before_Simulation_Distance) )-1);\n\t\t\tWeight[Second_City][Third_City] += Increase_Rate;\n\t\t\tWeight[Third_City][Second_City] += Increase_Rate;\n\t\t}\n\t}\n}\n\n// Sampling at most Max_Simulation_Times actions\nDistance_Type Simulation(int Max_Simulation_Times)\n{\n\tDistance_Type Best_Action_Delta = -Inf_Cost;\n\tfor(int i=0;i<Max_Simulation_Times;i++)\n\t{\n\t\tint Begin_City=Get_Random_Int(Virtual_City_Num);\n\t\tDistance_Type Action_Delta=Get_Simulated_Action_Delta(Begin_City);\n\t\tTotal_Simulation_Times++;\n\n\t\t//Store the action with the best delta, stored in Temp_City_Sequence[] and Temp_Pair_Num\n\t\tif(Action_Delta > Best_Action_Delta)\n\t\t{\n\t\t\tBest_Action_Delta = Action_Delta;\n\n\t\t\tTemp_Pair_Num = Pair_City_Num;\n\t\t\tfor(int j=0;j<2*Pair_City_Num;j++)\n\t\t\t\tTemp_City_Sequence[j]=City_Sequence[j];\n\t\t}\n\n\t\tif(Best_Action_Delta >0)\n\t\t\tbreak;\n\t}\n\n\t// Restore the action with the best delta\n\tPair_City_Num=Temp_Pair_Num;\n\tfor(int i=0;i<2*Pair_City_Num;i++)\n\t\tCity_Sequence[i]=Temp_City_Sequence[i];\n\n\treturn Best_Action_Delta;\n}\n\n//Execute the best action stored in City_Sequence[] with depth Pair_City_Num\nbool Execute_Best_Action()\n{\n\tint Begin_City=City_Sequence[0];\n\tint Cur_City=City_Sequence[1];\n\tAll_Node[Begin_City].Next_City=Null;\n\tAll_Node[Cur_City].Pre_City=Null;\n\tfor(int i=1;i<Pair_City_Num;i++)\n\t{\n\t\tint Next_City_To_Connect=City_Sequence[2*i];\n\t\tint Next_City_To_Disconnect=City_Sequence[2*i+1];\n\n\t\tReverse_Sub_Path(Cur_City,Next_City_To_Disconnect);\n\n\t\tAll_Node[Cur_City].Next_City=Next_City_To_Connect;\n\t\tAll_Node[Next_City_To_Connect].Pre_City=Cur_City;\n\t\tAll_Node[Next_City_To_Disconnect].Pre_City=Null;\n\n\t\tCur_City=Next_City_To_Disconnect;\n\t}\n\n\tAll_Node[Begin_City].Next_City=Cur_City;\n\tAll_Node[Cur_City].Pre_City=Begin_City;\n\n\tif(Check_Solution_Feasible()==false)\n\t{\n\t\tprintf(\"\\nError! The solution after applying action from %d is unfeasible\\n\",Begin_City+1);\n\t\tPrint_TSP_Tour(Begin_City);\n\t\tgetchar();\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n// Process of the MCTS\nvoid MCTS()\n{\n\t//while(true)\n\twhile(((double)clock()-Current_Instance_Begin_Time) /CLOCKS_PER_SEC<Param_T*Virtual_City_Num)\n\t{\n\t\tDistance_Type Before_Simulation_Distance = Get_Solution_Total_Distance();\n\n\t\t//Simulate a number of (controled by Param_H) actions\n\t\tDistance_Type Best_Delta=Simulation(Param_H*Virtual_City_Num);\n\n\t\t// Use the information of the best action to update the parameters of MCTS by back propagation\n\t\tBack_Propagation(Before_Simulation_Distance,Best_Delta);\n\n\t\tif(Best_Delta > 0)\n\t\t{\n\t\t\t// Select the best action to execute\n\t\t\tExecute_Best_Action();\n\n\t\t\t// Store the best found solution to Struct_Node *Best_All_Node\n\t\t\tDistance_Type Cur_Solution_Total_Distance=Get_Solution_Total_Distance();\n\t\t\tif(Cur_Solution_Total_Distance < Current_Instance_Best_Distance)\n\t\t\t{\n\t\t\t\tCurrent_Instance_Best_Distance = Cur_Solution_Total_Distance;\n\t\t\t\tStore_Best_Solution();\n\t\t\t}\n\t\t}\n\t\telse\n\t\t\tbreak;      // The MCTS terminates if no improving action is found among the sampling pool\n\t}\n}\n\n# ==========================================\n# File: grid_search/code/TSP_MCTS.h\n# Function/Context: MCTS, MCTS_Init, Get_Simulated_Action_Delta, Back_Propagation, Simulation, Execute_Best_Action\n# ==========================================\n// Initialize the parameters used in MCTS\nvoid MCTS_Init()\n{\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t\tfor(int j=0;j<Virtual_City_Num;j++)\n\t\t{\n\t\t\t//Weight[i][j]=1;\n\t\t\tWeight[i][j]=Edge_Heatmap[i][j]*100;\n\t\t\tChosen_Times[i][j]=0;\n\t\t}\n\n\t/*\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t\tfor(int j=0;j<Virtual_City_Num;j++)\n\t\t\tWeight[i][j]+=Edge_Heatmap[i][j]*100;\n\t*/\n\n\tTotal_Simulation_Times=0;\n}\n\n//Get the average weight of all the edge relative to Cur_City\ndouble Get_Avg_Weight(int Cur_City)\n{\n\tdouble Total_Weight=0;\n\tfor(int i=0;i<Virtual_City_Num;i++)\n\t{\n\t\tif(i==Cur_City)\n\t\t\tcontinue;\n\n\t\tTotal_Weight+=Weight[Cur_City][i];\n\t}\n\n\treturn Total_Weight/(Virtual_City_Num-1);\n}\n\n//Estimate the potential of each edge by upper bound confidence function\ndouble Get_Potential(int First_City, int Second_City)\n{\n\tdouble Potential=Weight[First_City][Second_City]/Avg_Weight+Alpha*sqrt( log(Total_Simulation_Times+1) / ( log(2.718)*(Chosen_Times[First_City][Second_City]+1) ) );\n\n\treturn Potential;\n}\n\n// Indentify the promising cities as candidates which are possible to connect to Cur_City\nvoid Identify_Promising_City(int Cur_City, int Begin_City)\n{\n\tPromising_City_Num=0;\n\tfor(int i=0;i<Candidate_Num[Cur_City];i++)\n\t{\n\t\tint Temp_City = Candidate[Cur_City][i];\n\t\tif(Temp_City == Begin_City)\n\t\t\tcontinue;\n\t\tif(Temp_City == All_Node[Cur_City].Next_City)\n\t\t\tcontinue;\n\t\tif(Get_Potential(Cur_City, Temp_City) < 1)\n\t\t\tcontinue;\n\n\t\tPromising_City[Promising_City_Num++]=Temp_City;\n\t}\n}\n\n// Set the probability (stored in Probabilistic[]) of selecting each candidate city (proportion to the potential of the corresponding edge)\nbool Get_Probabilistic(int Cur_City)\n{\n\tif(Promising_City_Num==0)\n\t\treturn false;\n\n\tdouble Total_Potential=0;\n\tfor(int i=0;i<Promising_City_Num;i++)\n\t\tTotal_Potential+=Get_Potential(Cur_City, Promising_City[i]);\n\n\tProbabilistic[0]=(int)(1000*Get_Potential(Cur_City, Promising_City[0])/Total_Potential);\n\tfor(int i=1;i<Promising_City_Num-1;i++)\n\t\tProbabilistic[i]=Probabilistic[i-1]+(int)(1000*Get_Potential(Cur_City, Promising_City[i])/Total_Potential);\n\tProbabilistic[Promising_City_Num-1]=1000;\n\n\treturn true;\n}\n\n// Probabilistically choose a city, controled by the values stored in Probabilistic[]\nint Probabilistic_Get_City_To_Connect()\n{\n\tint Random_Num=Get_Random_Int(1000);\n\tfor(int i=0;i<Promising_City_Num;i++)\n\t\tif(Random_Num < Probabilistic[i])\n\t\t\treturn Promising_City[i];\n\n\treturn Null;\n}\n\n// The whole process of choosing a city (a_{i+1} in the paper) to connect Cur_City (b_i in the paper)\nint Choose_City_To_Connect(int Cur_City, int Begin_City)\n{\n\tAvg_Weight=Get_Avg_Weight(Cur_City);\n\tIdentify_Promising_City(Cur_City, Begin_City);\n\tGet_Probabilistic(Cur_City);\n\n\treturn Probabilistic_Get_City_To_Connect();\n}\n\n// Generate an action starting form Begin_City (corresponding to a_1 in the paper), return the delta value\nDistance_Type Get_Simulated_Action_Delta(int Begin_City)\n{\n\t// Store the current solution to Solution[]\n\tif(Convert_All_Node_To_Solution()==false)\n\t\treturn -Inf_Cost;\n\n\tint Next_City=All_Node[Begin_City].Next_City;   // a_1=Begin city, b_1=Next_City\n\n\t// Break edge (a_1,b_1)\n\tAll_Node[Begin_City].Next_City=Null;\n\tAll_Node[Next_City].Pre_City=Null;\n\n\t// The elements of an action is stored in City_Sequence[], where a_{i+1}=City_Sequence[2*i], b_{i+1}=City_Sequence[2*i+1]\n\tCity_Sequence[0]=Begin_City;\n\tCity_Sequence[1]=Next_City;\n\n\tGain[0]=Get_Distance(Begin_City,Next_City);                // Gain[i] stores the delta (before connecting to a_1) at the (i+1)th iteration\n\tReal_Gain[0]=Gain[0]-Get_Distance(Next_City,Begin_City);   // Real_Gain[i] stores the delta (after connecting to a_1) at the (i+1)th iteration\n\tPair_City_Num=1;                                            // Pair_City_Num indicates the depth (k in the paper) of the action\n\n\tbool If_Changed=false;\n\tint Cur_City=Next_City;     // b_i = Cur_City (1 <= i <= k)\n\twhile(true)\n\t{\n\t\tint Next_City_To_Connect=Choose_City_To_Connect(Cur_City,Begin_City);\t// \tProbabilistically choose one city as a_{i+1}\n\t\tif(Next_City_To_Connect == Null)\n\t\t\tbreak;\n\n\t\t//Update the chosen times, used in MCTS\n\t\tChosen_Times[Cur_City][Next_City_To_Connect] ++;\n\t\tChosen_Times[Next_City_To_Connect][Cur_City] ++;\n\n\t\tint Next_City_To_Disconnect=All_Node[Next_City_To_Connect].Pre_City;   // Determine b_{i+1}\n\n\t\t// Update City_Sequence[], Gain[], Real_Gain[] and Pair_City_Num\n\t\tCity_Sequence[2*Pair_City_Num]=Next_City_To_Connect;\n\t\tCity_Sequence[2*Pair_City_Num+1]=Next_City_To_Disconnect;\n\t\tGain[Pair_City_Num]=Gain[Pair_City_Num-1]-Get_Distance(Cur_City,Next_City_To_Connect)+Get_Distance(Next_City_To_Connect,Next_City_To_Disconnect);\n\t\tReal_Gain[Pair_City_Num]=Gain[Pair_City_Num]-Get_Distance(Next_City_To_Disconnect,Begin_City);\n\t\tPair_City_Num++;\n\n\t\t// Reverse the cities between b_i and b_{i+1}\n\t\tReverse_Sub_Path(Cur_City,Next_City_To_Disconnect);\n\t\tAll_Node[Cur_City].Next_City=Next_City_To_Connect;\n\t\tAll_Node[Next_City_To_Connect].Pre_City=Cur_City;\n\t\tAll_Node[Next_City_To_Disconnect].Pre_City=Null;\n\t\tIf_Changed=true;\n\n\t\t// Turns to the next iteration\n\t\tCur_City=Next_City_To_Disconnect;\n\n\t\t// Close the loop is meeting an improving action, or the depth reaches its upper bound\n\t\tif(Real_Gain[Pair_City_Num-1] > 0 || Pair_City_Num > Max_Depth)\n\t\t\tbreak;\n\t}\n\n\t// Restore the solution before simulation\n\tif(If_Changed)\n\t\tConvert_Solution_To_All_Node();\n\telse\n\t{\n\t\tAll_Node[Begin_City].Next_City=Next_City;\n\t\tAll_Node[Next_City].Pre_City=Begin_City;\n\t}\n\n\t// Identify the best depth of the simulated action\n\tint Max_Real_Gain=-Inf_Cost;\n\tint Best_Index=1;\n\tfor(int i=1;i<Pair_City_Num;i++)\n\t\tif(Real_Gain[i] > Max_Real_Gain)\n\t\t{\n\t\t\tMax_Real_Gain=Real_Gain[i];\n\t\t\tBest_Index=i;\n\t\t}\n\n\tPair_City_Num=Best_Index+1;\n\n\treturn Max_Real_Gain;\n}\n\n// If the delta of an action is greater than zero, use the information of this action (stored in City_Sequence[]) to update the parameters by back propagation\nvoid Back_Propagation(Distance_Type Before_Simulation_Distance, Distance_Type Action_Delta)\n{\n\tfor(int i=0;i<Pair_City_Num;i++)\n\t{\n\t\tint First_City=City_Sequence[2*i];\n\t\tint Second_City=City_Sequence[2*i+1];\n\t\tint Third_City;\n\t\tif(i<Pair_City_Num-1)\n\t\t\tThird_City=City_Sequence[2*i+2];\n\t\telse\n\t\t\tThird_City=City_Sequence[0];\n\n\t\tif(Action_Delta >0)\n\t\t{\n\t\t\tdouble Increase_Rate=Beta*(pow(2.718, (double) (Action_Delta) / (double)(Before_Simulation_Distance) )-1);\n\t\t\tWeight[Second_City][Third_City] += Increase_Rate;\n\t\t\tWeight[Third_City][Second_City] += Increase_Rate;\n\t\t}\n\t}\n}\n\n// Sampling at most Max_Simulation_Times actions\nDistance_Type Simulation(int Max_Simulation_Times)\n{\n\tDistance_Type Best_Action_Delta = -Inf_Cost;\n\tfor(int i=0;i<Max_Simulation_Times;i++)\n\t{\n\t\tint Begin_City=Get_Random_Int(Virtual_City_Num);\n\t\tDistance_Type Action_Delta=Get_Simulated_Action_Delta(Begin_City);\n\t\tTotal_Simulation_Times++;\n\n\t\t//Store the action with the best delta, stored in Temp_City_Sequence[] and Temp_Pair_Num\n\t\tif(Action_Delta > Best_Action_Delta)\n\t\t{\n\t\t\tBest_Action_Delta = Action_Delta;\n\n\t\t\tTemp_Pair_Num = Pair_City_Num;\n\t\t\tfor(int j=0;j<2*Pair_City_Num;j++)\n\t\t\t\tTemp_City_Sequence[j]=City_Sequence[j];\n\t\t}\n\n\t\tif(Best_Action_Delta >0)\n\t\t\tbreak;\n\t}\n\n\t// Restore the action with the best delta\n\tPair_City_Num=Temp_Pair_Num;\n\tfor(int i=0;i<2*Pair_City_Num;i++)\n\t\tCity_Sequence[i]=Temp_City_Sequence[i];\n\n\treturn Best_Action_Delta;\n}\n\n//Execute the best action stored in City_Sequence[] with depth Pair_City_Num\nbool Execute_Best_Action()\n{\n\tint Begin_City=City_Sequence[0];\n\tint Cur_City=City_Sequence[1];\n\tAll_Node[Begin_City].Next_City=Null;\n\tAll_Node[Cur_City].Pre_City=Null;\n\tfor(int i=1;i<Pair_City_Num;i++)\n\t{\n\t\tint Next_City_To_Connect=City_Sequence[2*i];\n\t\tint Next_City_To_Disconnect=City_Sequence[2*i+1];\n\n\t\tReverse_Sub_Path(Cur_City,Next_City_To_Disconnect);\n\n\t\tAll_Node[Cur_City].Next_City=Next_City_To_Connect;\n\t\tAll_Node[Next_City_To_Connect].Pre_City=Cur_City;\n\t\tAll_Node[Next_City_To_Disconnect].Pre_City=Null;\n\n\t\tCur_City=Next_City_To_Disconnect;\n\t}\n\n\tAll_Node[Begin_City].Next_City=Cur_City;\n\tAll_Node[Cur_City].Pre_City=Begin_City;\n\n\tif(Check_Solution_Feasible()==false)\n\t{\n\t\tprintf(\"\\nError! The solution after applying action from %d is unfeasible\\n\",Begin_City+1);\n\t\tPrint_TSP_Tour(Begin_City);\n\t\tgetchar();\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n// Process of the MCTS\nvoid MCTS()\n{\n\t//while(true)\n\twhile(((double)clock()-Current_Instance_Begin_Time) /CLOCKS_PER_SEC<Param_T*Virtual_City_Num)\n\t{\n\t\tDistance_Type Before_Simulation_Distance = Get_Solution_Total_Distance();\n\n\t\t//Simulate a number of (controled by Param_H) actions\n\t\tDistance_Type Best_Delta=Simulation(Param_H*Virtual_City_Num);\n\n\t\t// Use the information of the best action to update the parameters of MCTS by back propagation\n\t\tBack_Propagation(Before_Simulation_Distance,Best_Delta);\n\n\t\tif(Best_Delta > 0)\n\t\t{\n\t\t\t// Select the best action to execute\n\t\t\tExecute_Best_Action();\n\n\t\t\t// Store the best found solution to Struct_Node *Best_All_Node\n\t\t\tDistance_Type Cur_Solution_Total_Distance=Get_Solution_Total_Distance();\n\t\t\tif(Cur_Solution_Total_Distance < Current_Instance_Best_Distance)\n\t\t\t{\n\t\t\t\tCurrent_Instance_Best_Distance = Cur_Solution_Total_Distance;\n\t\t\t\tStore_Best_Solution();\n\t\t\t}\n\t\t}\n\t\telse\n\t\t\tbreak;      // The MCTS terminates if no improving action is found among the sampling pool\n\t}\n}\n\n# ==========================================\n# File: utsp/Search/code/TSP.cpp\n# Function/Context: Solve_One_Instance, Solve_Instances_In_Batch, main\n# ==========================================\n#include \"include/TSP_IO.h\"\n#include \"include/TSP_Basic_Functions.h\"\n#include \"include/TSP_Init.h\"\n#include \"include/TSP_2Opt.h\"\n#include \"include/TSP_MCTS.h\"\n#include \"include/TSP_Markov_Decision.h\"\n\n// For TSP20-50-100 instances\nvoid Solve_One_Instance(int Inst_Index)\n{\t\n\tCurrent_Instance_Begin_Time=(double)clock();  \n\tCurrent_Instance_Best_Distance=Inf_Cost;    \t   \n\t\n\t// Input\t\t\t\n    cout << \"Start Fetch\" << endl;\n\tFetch_Stored_Instance_Info(Inst_Index);\t\n\t\n    cout << \"Start Preprocess\" << endl;\n\t//Pre-processing\t\n\tCalculate_All_Pair_Distance();\t \t\n  \tIdentify_Candidate_Set();    \n\t  \n    cout << \"Start MDP Search\" << endl;\n\t//Search by MDP  \t  \t\t   \t    \n\tMarkov_Decision_Process(Inst_Index);\n\t\t\t\n\tdouble Stored_Solution_Double_Distance=Get_Stored_Solution_Double_Distance(Inst_Index);\n\tdouble Current_Solution_Double_Distance=Get_Current_Solution_Double_Distance();\n\t\t\t\n\tif(Stored_Solution_Double_Distance/Magnify_Rate-Current_Solution_Double_Distance/Magnify_Rate > 0.000001)\n\t\tBeat_Best_Known_Times++;\t\n\telse if(Current_Solution_Double_Distance/Magnify_Rate-Stored_Solution_Double_Distance/Magnify_Rate > 0.000001)\n\t\tMiss_Best_Known_Times++;\n\telse\n\t\tMatch_Best_Known_Times++;\t\n\t\t\t\n\tSum_Opt_Distance+=Stored_Solution_Double_Distance/Magnify_Rate;\n\tSum_My_Distance+=Current_Solution_Double_Distance/Magnify_Rate;\t\n\tSum_Gap += (Current_Solution_Double_Distance-Stored_Solution_Double_Distance)/Stored_Solution_Double_Distance;\n\t\t\n\tprintf(\"\\nInst_Index:%d Concorde Distance:%f, MCTS Distance:%f Improve:%f Time:%.2f Seconds\\n\", Inst_Index+1, Stored_Solution_Double_Distance/Magnify_Rate, \n\t\t\tCurrent_Solution_Double_Distance/Magnify_Rate, Stored_Solution_Double_Distance/Magnify_Rate-Current_Solution_Double_Distance/Magnify_Rate, ((double)clock()-Current_Instance_Begin_Time)/CLOCKS_PER_SEC);\n\t\t\t\n\tFILE *fp;   \n\tfp=fopen(Statistics_File_Name, \"a+\");     \n\tfprintf(fp,\"\\nInst_Index:%d \\t City_Num:%d \\t Concorde:%f \\t MCTS:%f Improve:%f \\t Time:%.2f Seconds\\n\",Inst_Index+1, Virtual_City_Num, Stored_Solution_Double_Distance/1000000,\n\t\t\tCurrent_Solution_Double_Distance/Magnify_Rate, Stored_Solution_Double_Distance/Magnify_Rate-Current_Solution_Double_Distance/Magnify_Rate, ((double)clock()-Current_Instance_Begin_Time)/CLOCKS_PER_SEC); \n\t\n\tfprintf(fp,\"Solution: \");\n\tint Cur_City=Start_City;\n\tdo\n\t{\n\t\tfprintf(fp,\"%d \",Cur_City+1);\n\t\tCur_City=All_Node[Cur_City].Next_City;\t\t\n\t}while(Cur_City != Null && Cur_City != Start_City);\n\t\n\tfprintf(fp,\"\\n\"); \n\tfclose(fp); \t\n\t\t\t\n\tRelease_Memory(Virtual_City_Num);\t\n}\n \nbool Solve_Instances_In_Batch()\n{ \n\tifstream FIC;\n\tFIC.open(Input_File_Name);  \n  \n\tif(FIC.fail())\n\t{\n    \tcout << \"\\n\\nError! Fail to open file\"<<Input_File_Name<<endl;\n    \tgetchar();\n    \treturn false;     \n\t}\n  \telse\n    \tcout << \"\\n\\nBegin to read instances information from \"<<Input_File_Name<<endl;\n    \t    \n  \t\t\t \n \tdouble Temp_X;\n \tdouble Temp_Y;\n \tint Temp_City;\n    int Rec_Index;\n    double Rec_Value;\n \tchar Temp_String[100]; \t\n\n    cout << \"Total Instance Considered: \" << Total_Instance_Num << endl;\n \t\n  \tfor(int i=0;i<Total_Instance_Num;i++)   \n  \t{\n  \t\tfor(int j=0;j<Temp_City_Num;j++)\n  \t\t{\n\t\t\tFIC>>Temp_X;\n\t\t\tFIC>>Temp_Y;\n\t\t\tStored_Coordinates_X[i][j]=Temp_X;\n\t\t\tStored_Coordinates_Y[i][j]=Temp_Y;\t\t\t\n\t\t}\n\t\t\n\t\tFIC>>&Temp_String[0];  \n\t\tfor(int j=0;j<Temp_City_Num;j++)\n  \t\t{\n\t\t\tFIC>>Temp_City;\n\t\t\tStored_Opt_Solution[i][j]=Temp_City-1;\t\t\t\t\t\n\t\t}  \t\n\t\t\n\t\tFIC>>Temp_City;\t\t\t\n        // Here we start reading the recomend cities\n        FIC >> &Temp_String[0];\n        for (int j = 0; j < Temp_City_Num; ++j) {\n            for (int k = 0; k < Rec_Num; ++k) {\n                FIC >> Rec_Index;\n                Stored_Rec[i][j].push_back(Rec_Index - 1);\n            }\n        }\n        FIC >> &Temp_String[0];\n        for (int j = 0; j < Temp_City_Num; ++j) {\n            for (int k = 0; k < Rec_Num; ++k) {\n                FIC >> Rec_Value;\n                Stored_Rec_Value[i][j].push_back(Rec_Value);\n            }\n        }\n\t}      \n  \tFIC.close();  \n  \t\n  \tcout <<\"\\nRead instances finished. Begin to search.\"<<endl;\n\t\n    cout << \"Inst Num Per Batch \" << Inst_Num_Per_Batch << endl;\t\n\tif((Index_In_Batch+1)*Inst_Num_Per_Batch < Total_Instance_Num)\n\t\tTest_Inst_Num=Inst_Num_Per_Batch;\n\telse\n\t\tTest_Inst_Num=Total_Instance_Num-Index_In_Batch*Inst_Num_Per_Batch; \n\tcout<<\"\\nNumber of instances in current batch: \" <<Test_Inst_Num <<endl; \n\t\n\tFILE *fp;   \n\tfp=fopen(Statistics_File_Name, \"w+\");     \n\tfprintf(fp,\"Number_of_Instances_In_Current_Batch: %d\\n\",Test_Inst_Num);  \n\tfclose(fp);   \n\t\n\t\t\t\n  \tfor(int i=Index_In_Batch*Inst_Num_Per_Batch;i<(Index_In_Batch+1)*Inst_Num_Per_Batch && i<Total_Instance_Num;i++)\t   \n\t\tSolve_One_Instance(i);\t  \n        \n  \treturn true;  \n}\n\nint main(int argc, char ** argv)\n{  \t\n\tdouble Overall_Begin_Time=(double)clock();\n\t\n    //srand(Random_Seed); \t\n    srand(time(NULL));\n\n\tIndex_In_Batch=atoi(argv[1]);\n\tStatistics_File_Name=argv[2];\n\tInput_File_Name=argv[3];\n\tTemp_City_Num=atoi(argv[4]);\n    use_rec = atoi(argv[5]);\n    rec_only = atoi(argv[6]);\n\n    Max_Candidate_Num = atoi(argv[7]);\n    Max_Depth = atoi(argv[8]);\n    Alpha = atof(argv[9]);\n    Beta = atof(argv[10]);\n    Param_H = atof(argv[11]);\n    restart = atoi(argv[12]);\n    restart_reconly = atoi(argv[13]);\n\n    cout << \"record some exp parameters here: !!\" << endl;\n    cout << \"Alpha: \" << Alpha << endl;\n    cout << \"Beta: \" << Beta << endl;\n    cout << \"Param_H: \" << Param_H << endl;\n    cout << \"Param_T: \" << Param_T << endl;\n    cout << \"#Candidate Set: \" << Max_Candidate_Num << endl;\n    cout << \"Max Depth \" << Max_Depth << endl;\n    cout << \"rec_only \" << rec_only << endl;\n    cout << \"restart\" << restart << endl;\n    cout << \"restart_reconly\" << restart_reconly << endl;\n\n\tSolve_Instances_In_Batch(); \n  \t\n\tFILE *fp;    \t  \n\tfp=fopen(Statistics_File_Name, \"a+\"); \n\tfprintf(fp,\"\\n\\nIndex_In_Batch: %d, Avg_Concorde_Distance: %f Avg_MCTS_Distance: %f Avg_Gap: %f Total_Time: %.2f Seconds \\n Beat_Best_Known_Times: %d Match_Best_Known_Times: %d Miss_Best_Known_Times: %d \\n\",\n\t\t\tIndex_In_Batch, Sum_Opt_Distance/Test_Inst_Num,Sum_My_Distance/Test_Inst_Num, Sum_Gap/Test_Inst_Num, ((double)clock()-Overall_Begin_Time)/CLOCKS_PER_SEC, Beat_Best_Known_Times, Match_Best_Known_Times, Miss_Best_Known_Times);\n\tfclose(fp);\n\t\n\tprintf(\"\\n\\nIndex_In_Batch: %d, Avg_Concorde_Distance: %f Avg_MCTS_Distance: %f Avg_Gap: %f Total_Time: %.2f Seconds \\n Beat_Best_Known_Times: %d Match_Best_Known_Times: %d Miss_Best_Known_Times: %d \\n\",\n\t\t\tIndex_In_Batch, Sum_Opt_Distance/Test_Inst_Num,Sum_My_Distance/Test_Inst_Num, Sum_Gap/Test_Inst_Num, ((double)clock()-Overall_Begin_Time)/CLOCKS_PER_SEC, Beat_Best_Known_Times, Match_Best_Known_Times, Miss_Best_Known_Times);\n\tgetchar();\n\n\treturn 0;\n}\n\n# ==========================================\n# File: utsp_varying_time/Search/code/TSP.cpp\n# Function/Context: Solve_One_Instance, Solve_Instances_In_Batch, main\n# ==========================================\n#include \"include/TSP_IO.h\"\n#include \"include/TSP_Basic_Functions.h\"\n#include \"include/TSP_Init.h\"\n#include \"include/TSP_2Opt.h\"\n#include \"include/TSP_MCTS.h\"\n#include \"include/TSP_Markov_Decision.h\"\n\n// For TSP20-50-100 instances\nvoid Solve_One_Instance(int Inst_Index)\n{\t\n\tCurrent_Instance_Begin_Time=(double)clock();  \n\tCurrent_Instance_Best_Distance=Inf_Cost;    \t   \n\t\n\t// Input\t\t\t\n    cout << \"Start Fetch\" << endl;\n\tFetch_Stored_Instance_Info(Inst_Index);\t\n\t\n    cout << \"Start Preprocess\" << endl;\n\t//Pre-processing\t\n\tCalculate_All_Pair_Distance();\t \t\n  \tIdentify_Candidate_Set();    \n\t  \n    cout << \"Start MDP Search\" << endl;\n\t//Search by MDP  \t \t\t  \t\t    \n\tMarkov_Decision_Process(Inst_Index);\n\t\t\t\n\tdouble Stored_Solution_Double_Distance=Get_Stored_Solution_Double_Distance(Inst_Index);\n\tdouble Current_Solution_Double_Distance=Get_Current_Solution_Double_Distance();\n\t\t\t\n\tif(Stored_Solution_Double_Distance/Magnify_Rate-Current_Solution_Double_Distance/Magnify_Rate > 0.000001)\n\t\tBeat_Best_Known_Times++;\t\n\telse if(Current_Solution_Double_Distance/Magnify_Rate-Stored_Solution_Double_Distance/Magnify_Rate > 0.000001)\n\t\tMiss_Best_Known_Times++;\n\telse\n\t\tMatch_Best_Known_Times++;\t\n\t\t\t\n\tSum_Opt_Distance+=Stored_Solution_Double_Distance/Magnify_Rate;\n\tSum_My_Distance+=Current_Solution_Double_Distance/Magnify_Rate;\t\n\tSum_Gap += (Current_Solution_Double_Distance-Stored_Solution_Double_Distance)/Stored_Solution_Double_Distance;\n\t\t\n\tprintf(\"\\nInst_Index:%d Concorde Distance:%f, MCTS Distance:%f Improve:%f Time:%.2f Seconds\\n\", Inst_Index+1, Stored_Solution_Double_Distance/Magnify_Rate, \n\t\t\tCurrent_Solution_Double_Distance/Magnify_Rate, Stored_Solution_Double_Distance/Magnify_Rate-Current_Solution_Double_Distance/Magnify_Rate, ((double)clock()-Current_Instance_Begin_Time)/CLOCKS_PER_SEC);\n\t\t\t\n\tFILE *fp;   \n\tfp=fopen(Statistics_File_Name, \"a+\");     \n\tfprintf(fp,\"\\nInst_Index:%d \\t City_Num:%d \\t Concorde:%f \\t MCTS:%f Improve:%f \\t Time:%.2f Seconds\\n\",Inst_Index+1, Virtual_City_Num, Stored_Solution_Double_Distance/1000000,\n\t\t\tCurrent_Solution_Double_Distance/Magnify_Rate, Stored_Solution_Double_Distance/Magnify_Rate-Current_Solution_Double_Distance/Magnify_Rate, ((double)clock()-Current_Instance_Begin_Time)/CLOCKS_PER_SEC); \n\t\n\tfprintf(fp,\"Solution: \");\n\tint Cur_City=Start_City;\n\tdo\n\t{\n\t\tfprintf(fp,\"%d \",Cur_City+1);\n\t\tCur_City=All_Node[Cur_City].Next_City;\t\t\n\t}while(Cur_City != Null && Cur_City != Start_City);\n\t\n\tfprintf(fp,\"\\n\"); \n\tfclose(fp); \t\n\t\t\t\n\tRelease_Memory(Virtual_City_Num);\t\n}\n\nbool Solve_Instances_In_Batch()\n{ \n\tifstream FIC;\n\tFIC.open(Input_File_Name);  \n  \n\tif(FIC.fail())\n\t{\n    \tcout << \"\\n\\nError! Fail to open file\"<<Input_File_Name<<endl;\n    \tgetchar();\n    \treturn false;     \n\t}\n  \telse\n    \tcout << \"\\n\\nBegin to read instances information from \"<<Input_File_Name<<endl;\n    \t    \n  \t\t\t \n \tdouble Temp_X;\n \tdouble Temp_Y;\n \tint Temp_City;\n    int Rec_Index;\n    double Rec_Value;\n \tchar Temp_String[100]; \t\n\n    cout << \"Total Instance Considered: \" << Total_Instance_Num << endl;\n \t\n  \tfor(int i=0;i<Total_Instance_Num;i++)   \n  \t{\n  \t\tfor(int j=0;j<Temp_City_Num;j++)\n  \t\t{\n\t\t\tFIC>>Temp_X;\n\t\t\tFIC>>Temp_Y;\n\t\t\tStored_Coordinates_X[i][j]=Temp_X;\n\t\t\tStored_Coordinates_Y[i][j]=Temp_Y;\t\t\t\n\t\t}\n\t\t\n\t\tFIC>>&Temp_String[0];  \n\t\tfor(int j=0;j<Temp_City_Num;j++)\n  \t\t{\n\t\t\tFIC>>Temp_City;\n\t\t\tStored_Opt_Solution[i][j]=Temp_City-1;\t\t\t\t\t\n\t\t}  \t\n\t\t\n\t\tFIC>>Temp_City;\t\t\t\n        // Here we start reading the recomend cities\n        FIC >> &Temp_String[0];\n        for (int j = 0; j < Temp_City_Num; ++j) {\n            for (int k = 0; k < Rec_Num; ++k) {\n                FIC >> Rec_Index;\n                Stored_Rec[i][j].push_back(Rec_Index - 1);\n            }\n        }\n        FIC >> &Temp_String[0];\n        for (int j = 0; j < Temp_City_Num; ++j) {\n            for (int k = 0; k < Rec_Num; ++k) {\n                FIC >> Rec_Value;\n                Stored_Rec_Value[i][j].push_back(Rec_Value);\n            }\n        }\n\t}      \n  \tFIC.close();  \n  \t\n  \tcout <<\"\\nRead instances finished. Begin to search.\"<<endl;\n\t\n    cout << \"Inst Num Per Batch \" << Inst_Num_Per_Batch << endl;\t\n\tif((Index_In_Batch+1)*Inst_Num_Per_Batch < Total_Instance_Num)\n\t\tTest_Inst_Num=Inst_Num_Per_Batch;\n\telse\n\t\tTest_Inst_Num=Total_Instance_Num-Index_In_Batch*Inst_Num_Per_Batch; \n\tcout<<\"\\nNumber of instances in current batch: \" <<Test_Inst_Num <<endl; \n\t\n\tFILE *fp;   \n\tfp=fopen(Statistics_File_Name, \"w+\");     \n\tfprintf(fp,\"Number_of_Instances_In_Current_Batch: %d\\n\",Test_Inst_Num);  \n\tfclose(fp);   \n\t\n\t\t\t\n  \tfor(int i=Index_In_Batch*Inst_Num_Per_Batch;i<(Index_In_Batch+1)*Inst_Num_Per_Batch && i<Total_Instance_Num;i++)\t   \n\t\tSolve_One_Instance(i);\t  \n        \n  \treturn true;  \n}\n\nint main(int argc, char ** argv)\n{  \t\n\tdouble Overall_Begin_Time=(double)clock();\n\t\n    //srand(Random_Seed); \t\n    srand(time(NULL));\n\n\tIndex_In_Batch=atoi(argv[1]);\n\tStatistics_File_Name=argv[2];\n\tInput_File_Name=argv[3];\n\tTemp_City_Num=atoi(argv[4]);\n\t// Max_City_Num = Temp_City_Num;\n    use_rec = atoi(argv[5]);\n    rec_only = atoi(argv[6]);\n\n    Max_Candidate_Num = atoi(argv[7]);\n    Max_Depth = atoi(argv[8]);\n    Alpha = atof(argv[9]);\n    Beta = atof(argv[10]);\n    Param_H = atof(argv[11]);\n    restart = atoi(argv[12]);\n    restart_reconly = atoi(argv[13]);\n\n\tParam_T = atof(argv[14]);\n\n    cout << \"record some exp parameters here: !!\" << endl;\n    cout << \"Alpha: \" << Alpha << endl;\n    cout << \"Beta: \" << Beta << endl;\n    cout << \"Param_H: \" << Param_H << endl;\n    cout << \"Param_T: \" << Param_T << endl;\n    cout << \"#Candidate Set: \" << Max_Candidate_Num << endl;\n    cout << \"Max Depth \" << Max_Depth << endl;\n    cout << \"rec_only \" << rec_only << endl;\n    cout << \"restart\" << restart << endl;\n    cout << \"restart_reconly\" << restart_reconly << endl;\n\n\tSolve_Instances_In_Batch(); \n  \t\n\tFILE *fp;    \t  \n\tfp=fopen(Statistics_File_Name, \"a+\"); \n\tfprintf(fp,\"\\n\\nIndex_In_Batch: %d, Avg_Concorde_Distance: %f Avg_MCTS_Distance: %f Avg_Gap: %f Total_Time: %.2f Seconds \\n Beat_Best_Known_Times: %d Match_Best_Known_Times: %d Miss_Best_Known_Times: %d \\n\",\n\t\t\tIndex_In_Batch, Sum_Opt_Distance/Test_Inst_Num,Sum_My_Distance/Test_Inst_Num, Sum_Gap/Test_Inst_Num, ((double)clock()-Overall_Begin_Time)/CLOCKS_PER_SEC, Beat_Best_Known_Times, Match_Best_Known_Times, Miss_Best_Known_Times);\n\tfclose(fp);\n\t\n\tprintf(\"\\n\\nIndex_In_Batch: %d, Avg_Concorde_Distance: %f Avg_MCTS_Distance: %f Avg_Gap: %f Total_Time: %.2f Seconds \\n Beat_Best_Known_Times: %d Match_Best_Known_Times: %d Miss_Best_Known_Times: %d \\n\",\n\t\t\tIndex_In_Batch, Sum_Opt_Distance/Test_Inst_Num,Sum_My_Distance/Test_Inst_Num, Sum_Gap/Test_Inst_Num, ((double)clock()-Overall_Begin_Time)/CLOCKS_PER_SEC, Beat_Best_Known_Times, Match_Best_Known_Times, Miss_Best_Known_Times);\n\tgetchar();\n\n\treturn 0;\n}",
  "description": "Combined Analysis:\n- [all_heatmap/softdist/batch_generate_heatmap.py]: This file implements the SoftDist heatmap generation method described in the paper. The core logic is in the 'create_heatmap_matrix' function, which computes Euclidean distance matrices for 2D TSP instances and applies softmax with temperature scaling to create heatmaps. This corresponds to the paper's proposed baseline method that outperforms complex ML approaches. The heatmaps assign probabilities to edges (with self-loops masked as infinity) and are used to guide subsequent MCTS search. The file handles batch processing, I/O operations, and memory management for large-scale TSP instances.\n- [default_mcts/code/TSP_Basic_Functions.h]: This file implements key components of the heatmap-guided MCTS algorithm described in the paper. Specifically, the functions Get_Best_Unselected_City and Identify_Candidate_Set directly utilize the heatmap (Edge_Heatmap) to select candidate edges during search, which aligns with the paper's focus on heatmap-guided post-hoc search. The heatmap provides probabilistic guidance for edge selection, replacing traditional distance-based heuristics. These functions are critical for the candidate generation step within MCTS, enabling the algorithm to prioritize edges with higher heatmap values, thereby integrating the ML-generated heatmap into the optimization process. The code reflects the paper's methodology of using heatmaps as priors to guide k-opt operations in MCTS.\n- [default_mcts/code/TSP_MCTS.h]: This file implements the core Monte Carlo Tree Search (MCTS) algorithm for the Traveling Salesman Problem as described in the paper. The code performs heatmap-guided MCTS with the following key components:\n1. Initializes edge weights using heatmap values (Edge_Heatmap) - representing prior probabilities for edges.\n2. Uses an Upper Confidence Bound (UCB) formula in Get_Potential() to balance exploration and exploitation.\n3. Simulates k-opt style actions through Get_Simulated_Action_Delta(), which breaks and reconnects edges in the tour.\n4. Performs backpropagation to update edge weights based on successful actions.\n5. Executes the best-found action to improve the current tour.\n6. Continues MCTS iterations within a time budget (Param_T*Virtual_City_Num).\nThe implementation directly corresponds to the paper's heatmap-guided MCTS paradigm, using heatmaps as priors to guide the search for optimal tours through k-opt operations.\n- [default_mcts_varying_time/code/TSP.cpp]: This file implements the core pipeline for heatmap-guided MCTS as described in the paper. It orchestrates the complete workflow: 1) Reading TSP instance coordinates and optimal solutions, 2) Calculating Euclidean distances between cities, 3) Loading pre-generated heatmaps (from ML models or SoftDist), 4) Running Markov Decision Process (MCTS) guided by the heatmap, 5) Comparing results against Concorde's optimal solutions. The key function Markov_Decision_Process() encapsulates the MCTS algorithm that uses heatmap priors to guide k-opt operations. The code follows exactly the paper's methodology of using heatmaps as priors for post-hoc search, with performance metrics comparing against classical solvers.\n- [default_mcts_varying_time/code/TSP_MCTS.h]: This file implements the core heatmap-guided Monte Carlo Tree Search (MCTS) algorithm for the Traveling Salesman Problem as described in the paper. The code performs the following key steps: 1) Initializes edge weights from a heatmap (Edge_Heatmap). 2) Uses an Upper Confidence Bound (UCB) formula (Get_Potential) to balance exploration and exploitation during edge selection. 3) Simulates k-opt actions (Get_Simulated_Action_Delta) by probabilistically selecting edges to break and reconnect, guided by the UCB values. 4) Updates edge weights via backpropagation (Back_Propagation) based on action quality. 5) Executes the best found action to improve the tour. 6) Runs the MCTS loop within a time budget (Param_T * n). The implementation directly corresponds to the paper's heatmap-guided MCTS paradigm for TSP, using heatmap values as priors and performing k-opt moves through a tree search strategy.\n- [grid_search/code/TSP_MCTS.h]: This file implements the core heatmap-guided Monte Carlo Tree Search (MCTS) algorithm described in the paper. The implementation includes: 1) Heatmap initialization (Edge_Heatmap  Weight matrix), 2) UCB-like edge potential calculation for exploration-exploitation, 3) Probabilistic k-opt action generation using candidate sets, 4) Simulation of multiple actions to find improving moves, 5) Back-propagation to update edge weights based on action quality, 6) Execution of the best-found k-opt action. The code directly implements the heatmap-guided MCTS paradigm that the paper critically analyzes, showing the complete search procedure including the use of heatmaps as priors, candidate filtering, and iterative improvement through simulated k-opt moves.\n- [utsp/Search/code/TSP.cpp]: This file implements the core driver for the heatmap-guided MCTS algorithm described in the paper. It handles instance loading (including coordinates, optimal solutions, and precomputed heatmaps stored as 'recommendations'), preprocessing (distance calculation, candidate set identification), and invokes the Markov Decision Process (MDP) search (i.e., MCTS) via Markov_Decision_Process(). The main function configures MCTS parameters (Alpha, Beta, Max_Depth, etc.) from command-line arguments, aligning with the paper's focus on tuning MCTS. The code compares results against Concorde's solutions and logs performance metrics, directly supporting the paper's experimental evaluation of heatmap-guided MCTS for TSP.\n- [utsp_varying_time/Search/code/TSP.cpp]: This file implements the main driver for the heatmap-guided MCTS approach described in the paper. It contains the core pipeline: 1) Reading TSP instances with pre-computed heatmaps (Stored_Rec and Stored_Rec_Value), 2) Preprocessing (distance calculation and candidate set identification), 3) Executing the Markov Decision Process (MCTS) search (Markov_Decision_Process), 4) Comparing results against optimal/Concorde solutions. The code demonstrates the post-hoc search paradigm where ML-generated heatmaps guide the MCTS search, which aligns with the paper's examination of neural approaches for TSP. Key parameters like Alpha, Beta, Param_H, Max_Depth control the MCTS behavior and heatmap utilization.",
  "dependencies": [
    "Distance (global 2D array)",
    "Get_Distance (distance computation)",
    "multiprocessing.Pool",
    "Candidate (global 2D array)",
    "Null (sentinel value)",
    "Edge_Heatmap",
    "Weight matrix (initialized from heatmap)",
    "Param_T, Param_H (MCTS time and simulation parameters)",
    "Max_Depth (k-opt depth limit)",
    "Virtual_City_Num (number of cities)",
    "All_Node (current tour representation)",
    "Candidate and Candidate_Num (precomputed candidate lists)",
    "Param_H",
    "clock() (time measurement)",
    "Candidate_Num",
    "Convert_All_Node_To_Solution",
    "include/TSP_2Opt.h",
    "Convert_All_Node_To_Solution / Convert_Solution_To_All_Node (tour representation conversion)",
    "Null (global constant)",
    "TSP_Init.h",
    "Get_Solution_Total_Distance",
    "Param_T",
    "Convert_Solution_To_All_Node",
    "Get_Solution_Total_Distance (objective calculation)",
    "Store_Best_Solution (solution storage)",
    "clock",
    "include/TSP_Basic_Functions.h",
    "torch.nn.functional",
    "cmath (sqrt)",
    "Print_TSP_Tour",
    "All_Node (current tour structure)",
    "ctime",
    "include/TSP_MCTS.h",
    "os",
    "numpy",
    "Virtual_City_Num (global constant)",
    "TSP_Basic_Functions.h",
    "Alpha",
    "Get_Random_Int (random number generator)",
    "TSP_MCTS.h",
    "Reverse_Sub_Path (path reversal for k-opt)",
    "clock() and CLOCKS_PER_SEC (timing)",
    "Get_Distance",
    "cmath",
    "Get_Distance (distance calculation)",
    "Candidate and Candidate_Num (nearest neighbor candidate sets)",
    "Chosen_Times matrix (edge selection statistics)",
    "fire",
    "fstream",
    "TSP_2Opt.h",
    "Candidate_Num (global array)",
    "time",
    "Null",
    "Weight",
    "include/TSP_Init.h",
    "Candidate",
    "Inf_Cost (large constant)",
    "include/TSP_IO.h",
    "cstdlib (rand)",
    "Check_Solution_Feasible",
    "Edge_Heatmap (global 2D array)",
    "Check_Solution_Feasible (tour validation)",
    "Inf_Cost",
    "include/TSP_Markov_Decision.h",
    "Chosen_Times",
    "CLOCKS_PER_SEC",
    "torch",
    "Virtual_City_Num (problem size)",
    "Store_Best_Solution",
    "Max_Candidate_Num (global constant)",
    "All_Node",
    "Inf_Cost (global constant)",
    "TSP_Markov_Decision.h",
    "Get_Random_Int (random number generation)",
    "If_City_Selected (global array)",
    "cstdlib",
    "Beta",
    "Virtual_City_Num",
    "Max_Depth",
    "Alpha, Beta, Param_H, Param_T (MCTS hyperparameters)",
    "cstdio",
    "Get_Random_Int",
    "Reverse_Sub_Path",
    "Edge_Heatmap (heatmap matrix)",
    "Alpha, Beta (MCTS exploration parameters)",
    "iostream",
    "TSP_IO.h",
    "Reverse_Sub_Path (path reversal helper)",
    "Total_Simulation_Times"
  ]
}