{
  "file_path": "src/dag_ppo_bihyb_model.py, src/ged_ppo_bihyb_model.py, src/hcp_ppo_bihyb_model.py, src/hcp_ppo_single_model.py, utils/dag_graph.py, utils/ged_env.py, utils/tsp_algorithms.py, utils/tsp_env.py",
  "function_name": "ActorNet._act, GraphEncoder, ActorNet, CriticNet, GraphEncoder, ActorNet, CriticNet, ActorNet, DAGraph, GEDenv, TSPEnv.step",
  "code_snippet": "\n\n# ==========================================\n# File: src/dag_ppo_bihyb_model.py\n# Function/Context: ActorNet._act\n# ==========================================\nimport torch\nfrom torch import nn\nfrom src.pyg_graph_models import GCN, GraphAttentionPooling, ResNetBlock\nfrom utils.utils import construct_graph_batch, reverse_pyg_graph\nimport numpy as np\nfrom torch_geometric.utils import to_dense_batch\nfrom torch.distributions import Categorical\n\n\nclass GraphEncoder(torch.nn.Module):\n    def __init__(\n            self,\n            node_feature_dim,\n            node_output_size,\n            batch_norm,\n            one_hot_degree,\n            num_layers=10\n    ):\n        super(GraphEncoder, self).__init__()\n        self.node_feature_dim = node_feature_dim\n        self.node_output_size = node_output_size\n        self.batch_norm = batch_norm\n        self.one_hot_degree = one_hot_degree\n        self.num_layers = num_layers\n\n        one_hot_dim = self.one_hot_degree + 1 if self.one_hot_degree > 0 else 0\n        self.forward_gnn = GCN(self.node_feature_dim + one_hot_dim, self.node_output_size, num_layers=self.num_layers,\n                               batch_norm=self.batch_norm)\n        self.reverse_gnn = GCN(self.node_feature_dim + one_hot_dim, self.node_output_size, num_layers=self.num_layers,\n                               batch_norm=self.batch_norm)\n        self.att = GraphAttentionPooling(self.node_output_size * 2)\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, input_graphs):\n        # construct graph batches\n        batched_graphs = construct_graph_batch(input_graphs, self.one_hot_degree, self.device)\n\n        # forward pass\n        forward_node_feat = self.forward_gnn(batched_graphs)\n\n        # reverse pass\n        reversed_graphs = reverse_pyg_graph(batched_graphs)\n        reverse_node_feat = self.reverse_gnn(reversed_graphs)\n\n        # attention for global features\n        node_feat = torch.cat((forward_node_feat, reverse_node_feat), dim=1)\n        node_feat = node_feat / torch.norm(node_feat, dim=-1, keepdim=True)\n        graph_feat = self.att(node_feat, batched_graphs.batch)\n\n        # transform to dense batch\n        node_feat_reshape, _ = to_dense_batch(node_feat, batched_graphs.batch)\n        state_feat = torch.cat(\n            (node_feat_reshape, graph_feat.unsqueeze(1).expand(-1, node_feat_reshape.shape[1], -1)), dim=-1)\n\n        return state_feat\n\n\nclass ActorNet(torch.nn.Module):\n    def __init__(\n            self,\n            dag_model,\n            state_feature_size,\n            batch_norm,\n    ):\n        super(ActorNet, self).__init__()\n        self.dag_model = dag_model\n        self.state_feature_size = state_feature_size\n        self.batch_norm = batch_norm\n\n        self.act1_resnet = ResNetBlock(self.state_feature_size, 1, batch_norm=self.batch_norm)\n        self.act2_resnet = ResNetBlock(self.state_feature_size * 2, 1, batch_norm=self.batch_norm)\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, input_graph, edge_candidates, known_action=None, greedy_select=False, epsilon=0.0):\n        return self._act(input_graph, edge_candidates, known_action, greedy_select, epsilon)\n\n    def _act(self, state_feat, edge_candidates, known_action=None, greedy_select=False, epsilon=0.0):\n        if known_action is None:\n            known_action = (None, None)\n        # roll-out 2 acts\n        mask1, ready_nodes1 = self._get_mask1(state_feat.shape[0], state_feat.shape[1], edge_candidates)\n        act1, log_prob1, entropy1 = self._select_node(state_feat, mask1, known_action[0])\n        mask2, ready_nodes2 = self._get_mask2(state_feat.shape[0], state_feat.shape[1], edge_candidates, act1)\n        act2, log_prob2, entropy2 = self._select_node(state_feat, mask2, known_action[1], act1)\n        return torch.stack((act1, act2)), torch.stack((log_prob1, log_prob2)), entropy1 + entropy2\n\n    def _select_node(self, state_feat, mask, known_cur_act=None, prev_act=None, greedy_sel_num=0):\n        # neural net prediction\n        if prev_act is None:  # for act 1\n            act_scores = self.act1_resnet(state_feat).squeeze(-1)\n        else:  # for act 2\n            prev_node_feat = state_feat[torch.arange(len(prev_act)), prev_act, :]\n            state_feat = torch.cat(\n                (state_feat, prev_node_feat.unsqueeze(1).expand(-1, state_feat.shape[1], -1)), dim=-1)\n            act_scores = self.act2_resnet(state_feat).squeeze(-1)\n\n        # select action\n        act_probs = nn.functional.softmax(act_scores + mask, dim=1)\n        if greedy_sel_num > 0:\n            argsort_prob = torch.argsort(act_probs, dim=-1, descending=True)\n            acts = argsort_prob[:, :greedy_sel_num]\n            return acts, act_probs[torch.arange(acts.shape[0]).unsqueeze(-1), acts]\n        else:\n            dist = Categorical(probs=act_probs)\n            if known_cur_act is None:\n                act = dist.sample()\n                return act, dist.log_prob(act), dist.entropy()\n            else:\n                return known_cur_act, dist.log_prob(known_cur_act), dist.entropy()\n\n    @staticmethod\n    def _get_act1_candidates(edge_candidates):\n        acts = []\n        for node, candidates in edge_candidates.items():\n            if len(candidates) > 0:\n                acts.append(node)\n        return acts\n\n    def _get_mask1(self, batch_size, num_nodes, edge_candidates):\n        masks = torch.full((batch_size, num_nodes), -float('inf'), device=self.device)\n        ready_nodes = []\n        for b in range(batch_size):\n            ready_nodes.append([])\n            for node, candidates in edge_candidates[b].items():\n                if len(candidates) == 0:\n                    pass\n                else:\n                    masks[b, node] = 0\n                    ready_nodes[b].append(node)\n        return masks, ready_nodes\n\n    def _get_mask2(self, batch_size, num_nodes, edge_candidates, act1):\n        masks = torch.full((batch_size, num_nodes), -float('inf'), device=self.device)\n        ready_nodes = []\n        for b in range(batch_size):\n            ready_nodes.append([])\n            candidates = edge_candidates[b][act1[b].item()]\n            for index in candidates:\n                masks[b, index] = 0.0\n                ready_nodes[b].append(index)\n        return masks, ready_nodes\n\n\nclass CriticNet(torch.nn.Module):\n    def __init__(\n            self,\n            dag_model,\n            state_feature_size,\n            batch_norm,\n    ):\n        super(CriticNet, self).__init__()\n        self.dag_model = dag_model\n        self.state_feature_size = state_feature_size\n        self.batch_norm = batch_norm\n\n        self.critic_resnet = ResNetBlock(self.state_feature_size, 1, batch_norm=self.batch_norm)\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, state_feat):\n        return self._eval(state_feat)\n\n    def _eval(self, state_feat):\n        # get global features\n        state_feat = torch.max(state_feat, dim=1).values\n        state_value = self.critic_resnet(state_feat).squeeze(-1)\n        return state_value\n\n# ==========================================\n# File: src/ged_ppo_bihyb_model.py\n# Function/Context: GraphEncoder, ActorNet, CriticNet\n# ==========================================\nimport torch\nfrom torch import nn\nfrom src.pyg_graph_models import GCN, GraphAttentionPooling, ResNetBlock, TensorNetworkModule\nfrom utils.utils import construct_graph_batch\nimport numpy as np\nfrom torch_geometric.utils import to_dense_batch\nfrom torch.distributions import Categorical\nfrom utils.sinkhorn import Sinkhorn\n\n\nclass GraphEncoder(torch.nn.Module):\n    def __init__(\n            self,\n            node_feature_dim,\n            node_output_size,\n            batch_norm,\n            one_hot_degree,\n            num_layers=10\n    ):\n        super(GraphEncoder, self).__init__()\n        self.node_feature_dim = node_feature_dim\n        self.node_output_size = node_output_size\n        self.batch_norm = batch_norm\n        self.one_hot_degree = one_hot_degree\n        self.num_layers = num_layers\n\n        one_hot_dim = self.one_hot_degree + 1 if self.one_hot_degree > 0 else 0\n        self.siamese_gcn = GCN(self.node_feature_dim + one_hot_dim, self.node_output_size, num_layers=self.num_layers,\n                               batch_norm=self.batch_norm)\n        self.sinkhorn = Sinkhorn(max_iter=20, tau=0.005)\n        self.att = GraphAttentionPooling(self.node_output_size)\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, input_graphs_1, input_graphs_2):\n        # construct graph batches\n        batched_graphs_1 = construct_graph_batch(input_graphs_1, self.one_hot_degree, self.device)\n        batched_graphs_2 = construct_graph_batch(input_graphs_2, self.one_hot_degree, self.device)\n\n        # forward pass\n        batched_node_feat_1 = self.siamese_gcn(batched_graphs_1)\n        batched_node_feat_2 = self.siamese_gcn(batched_graphs_2)\n\n        # compute cross-graph similarity\n        node_feat_1, node_indicator_1 = to_dense_batch(batched_node_feat_1, batched_graphs_1.batch)\n        node_feat_2, node_indicator_2 = to_dense_batch(batched_node_feat_2, batched_graphs_2.batch)\n        num_nodes_1 = node_indicator_1.sum(-1)\n        num_nodes_2 = node_indicator_2.sum(-1)\n        sim_mat = torch.bmm(node_feat_1, node_feat_2.transpose(1, 2))\n        sim_mat = self.sinkhorn(sim_mat, num_nodes_1, num_nodes_2)\n\n        # compute cross-graph difference features\n        diff_feat = node_feat_1 - torch.bmm(sim_mat, node_feat_2)\n\n        global_feat_1 = self.att(batched_node_feat_1, batched_graphs_1.batch)\n        global_feat_2 = self.att(batched_node_feat_2, batched_graphs_2.batch)\n\n        return diff_feat, global_feat_1, global_feat_2\n\n\nclass ActorNet(torch.nn.Module):\n    def __init__(\n            self,\n            state_feature_size,\n            batch_norm,\n    ):\n        super(ActorNet, self).__init__()\n        self.state_feature_size = state_feature_size\n        self.batch_norm = batch_norm\n\n        self.act1_resnet = ResNetBlock(self.state_feature_size, 1, batch_norm=self.batch_norm)\n        #self.act2_resnet = ResNetBlock(self.state_feature_size * 2, 1, batch_norm=self.batch_norm)\n        self.act2_query = nn.Linear(self.state_feature_size, self.state_feature_size, bias=False)\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, input_feat, known_action=None):\n        return self._act(input_feat, known_action)\n\n    def _act(self, input_feat, known_action=None):\n        if known_action is None:\n            known_action = (None, None)\n        # roll-out 2 acts\n        act1, log_prob1, entropy1 = self._select_node(input_feat, known_action[0])\n        act2, log_prob2, entropy2 = self._select_node(input_feat, known_action[1], act1)\n        return torch.stack((act1, act2)), torch.stack((log_prob1, log_prob2)), entropy1 + entropy2\n\n    def _select_node(self, state_feat, known_cur_act=None, prev_act=None, greedy_sel_num=0):\n        # neural net prediction\n        if prev_act is None:  # for act 1\n            act_scores = self.act1_resnet(state_feat).squeeze(-1)\n            mask = torch.zeros_like(act_scores)\n        else:  # for act 2\n            prev_node_feat = state_feat[torch.arange(len(prev_act)), prev_act, :]\n            #state_feat = torch.cat(\n            #    (state_feat, prev_node_feat.unsqueeze(1).expand(-1, state_feat.shape[1], -1)), dim=-1)\n            #act_scores = self.act2_resnet(state_feat).squeeze(-1)\n            act_query = torch.tanh(self.act2_query(prev_node_feat))\n            act_scores = (act_query.unsqueeze(1) * state_feat).sum(dim=-1)\n            mask = torch.zeros_like(act_scores)\n            mask[torch.arange(len(prev_act)), prev_act] = -float('inf')\n\n        # select action\n        act_probs = nn.functional.softmax(act_scores + mask, dim=1)\n        if greedy_sel_num > 0:\n            argsort_prob = torch.argsort(act_probs, dim=-1, descending=True)\n            acts = argsort_prob[:, :greedy_sel_num]\n            return acts, act_probs[torch.arange(acts.shape[0]).unsqueeze(-1), acts]\n        else:\n            dist = Categorical(probs=act_probs)\n            if known_cur_act is None:\n                act = dist.sample()\n                return act, dist.log_prob(act), dist.entropy()\n            else:\n                return known_cur_act, dist.log_prob(known_cur_act), dist.entropy()\n\n\nclass CriticNet(torch.nn.Module):\n    def __init__(\n            self,\n            state_feature_size,\n            batch_norm,\n    ):\n        super(CriticNet, self).__init__()\n        self.state_feature_size = state_feature_size\n        self.batch_norm = batch_norm\n        self.tensor_net = TensorNetworkModule(self.state_feature_size, self.state_feature_size)\n        self.scoring_layer = torch.nn.Sequential(\n            torch.nn.Linear(self.state_feature_size, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, 1),\n            torch.nn.Tanh()\n        )\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, global_feat_1, global_feat_2):\n        state_value = self.scoring_layer(self.tensor_net(global_feat_1, global_feat_2)).squeeze(-1)\n        return state_value\n\n# ==========================================\n# File: src/hcp_ppo_bihyb_model.py\n# Function/Context: GraphEncoder, ActorNet, CriticNet\n# ==========================================\nimport torch\nfrom torch import nn\nfrom src.pyg_graph_models import GCN, GraphAttentionPooling, ResNetBlock, TensorNetworkModule\nfrom utils.utils import construct_graph_batch\nfrom torch_geometric.utils import to_dense_batch\nfrom torch.distributions import Categorical\nimport torch_geometric as pyg\n\n\ndef matrix_list_to_graphs(lower_left_matrices, device):\n    graphs = []\n    #edge_candidates = []\n    for b, lower_left_m in enumerate(lower_left_matrices):\n        edge_indices = [[], []]\n        edge_attrs = [] ###############################\n        x = torch.ones(len(lower_left_m), 1)\n        #edge_cand = {x: set() for x in range(len(lower_left_m))}\n        for row, cols in enumerate(lower_left_m):\n            for col, weight in enumerate(cols):\n                if weight == 0 or weight >= 2:\n                    pass\n                else:\n                    edge_indices[0].append(row)\n                    edge_indices[1].append(col)\n                    edge_attrs.append(weight)  #######################\n                    x[row] += weight\n                    x[col] += weight\n                    #edge_cand[row].add(col)\n                    #edge_cand[col].add(row)\n        edge_indices = torch.tensor(edge_indices)\n        edge_attrs = torch.Tensor(edge_attrs).to(device)  ####################\n        #x = (x) / torch.std(x)\n        # graphs.append(pyg.data.Data(x=x, edge_index=edge_indices)) #, edge_attrs=edge_attrs)) ############################\n        graphs.append(pyg.data.Data(x=x, edge_index=edge_indices, edge_attrs=edge_attrs))  ##########################\n        #edge_candidates.append(edge_cand)\n    return graphs #, edge_candidates\n\n\nclass GraphEncoder(torch.nn.Module):\n    def __init__(\n            self,\n            node_feature_dim,\n            node_output_size,\n            batch_norm,\n            one_hot_degree,\n            num_layers=10\n    ):\n        super(GraphEncoder, self).__init__()\n        self.node_feature_dim = node_feature_dim\n        self.node_output_size = node_output_size\n        self.one_hot_degree = one_hot_degree\n        self.batch_norm = batch_norm\n        self.num_layers = num_layers\n\n        one_hot_dim = self.one_hot_degree + 1 if self.one_hot_degree > 0 else 0\n        self.siamese_gcn = GCN(self.node_feature_dim + one_hot_dim, self.node_output_size, num_layers=self.num_layers,\n                               batch_norm=self.batch_norm)\n        self.att = GraphAttentionPooling(self.node_output_size)\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, inp_lower_matrix):\n        # construct graph batches\n        batched_graphs = construct_graph_batch(matrix_list_to_graphs(inp_lower_matrix, self.device),\n                                               self.one_hot_degree, self.device)\n\n        # forward pass\n        batched_node_feat = self.siamese_gcn(batched_graphs)\n        node_feat_reshape, _ = to_dense_batch(batched_node_feat, batched_graphs.batch)\n        graph_feat = self.att(batched_node_feat, batched_graphs.batch)\n        state_feat = torch.cat(\n            (node_feat_reshape, graph_feat.unsqueeze(1).expand(-1, node_feat_reshape.shape[1], -1)), dim=-1)\n\n        return state_feat\n\n\nclass ActorNet(torch.nn.Module):\n    def __init__(\n            self,\n            state_feature_size,\n            batch_norm,\n    ):\n        super(ActorNet, self).__init__()\n        self.state_feature_size = state_feature_size\n        self.batch_norm = batch_norm\n\n        self.act1_resnet = ResNetBlock(self.state_feature_size, 1, batch_norm=self.batch_norm)\n        #self.act2_resnet = ResNetBlock(self.state_feature_size * 2, 1, batch_norm=self.batch_norm)\n        self.act2_query = nn.Linear(self.state_feature_size, self.state_feature_size, bias=False)\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, input_feat, edge_candidates, known_action=None):\n        return self._act(input_feat, edge_candidates, known_action)\n\n    def _act(self, input_feat, edge_candidates, known_action=None):\n        if known_action is None:\n            known_action = (None, None)\n        # roll-out 2 acts\n        mask1, ready_nodes1 = self._get_mask1(input_feat.shape[0], input_feat.shape[1], edge_candidates)\n        act1, log_prob1, entropy1 = self._select_node(input_feat, mask1, known_action[0])\n        mask2, ready_nodes2 = self._get_mask2(input_feat.shape[0], input_feat.shape[1], edge_candidates, act1)\n        act2, log_prob2, entropy2 = self._select_node(input_feat, mask2, known_action[1], act1)\n        return torch.stack((act1, act2)), torch.stack((log_prob1, log_prob2)), entropy1 + entropy2\n\n    def _select_node(self, state_feat, mask, known_cur_act=None, prev_act=None, greedy_sel_num=0):\n        # neural net prediction\n        if prev_act is None:  # for act 1\n            act_scores = self.act1_resnet(state_feat).squeeze(-1)\n        else:  # for act 2\n            prev_node_feat = state_feat[torch.arange(len(prev_act)), prev_act, :]\n            #state_feat = torch.cat(\n            #    (state_feat, prev_node_feat.unsqueeze(1).expand(-1, state_feat.shape[1], -1)), dim=-1)\n            #act_scores = self.act2_resnet(state_feat).squeeze(-1)\n            act_query = torch.tanh(self.act2_query(prev_node_feat))\n            act_scores = (act_query.unsqueeze(1) * state_feat).sum(dim=-1)\n\n        # select action\n        act_probs = nn.functional.softmax(act_scores + mask, dim=1)\n        if greedy_sel_num > 0:\n            argsort_prob = torch.argsort(act_probs, dim=-1, descending=True)\n            acts = argsort_prob[:, :greedy_sel_num]\n            return acts, act_probs[torch.arange(acts.shape[0]).unsqueeze(-1), acts]\n        else:\n            dist = Categorical(probs=act_probs)\n            if known_cur_act is None:\n                act = dist.sample()\n                return act, dist.log_prob(act), dist.entropy()\n            else:\n                return known_cur_act, dist.log_prob(known_cur_act), dist.entropy()\n\n    def _get_mask1(self, batch_size, num_nodes, edge_candidates):\n        masks = torch.full((batch_size, num_nodes), -float('inf'), device=self.device)\n        ready_nodes = []\n        for b in range(batch_size):\n            ready_nodes.append([])\n            for node, candidates in edge_candidates[b].items():\n                if len(candidates) == 0:\n                    pass\n                else:\n                    masks[b, node] = 0\n                    ready_nodes[b].append(node)\n        return masks, ready_nodes\n\n    def _get_mask2(self, batch_size, num_nodes, edge_candidates, act1):\n        masks = torch.full((batch_size, num_nodes), -float('inf'), device=self.device)\n        ready_nodes = []\n        for b in range(batch_size):\n            ready_nodes.append([])\n            candidates = edge_candidates[b][act1[b].item()]\n            for index in candidates:\n                masks[b, index] = 0.0\n                ready_nodes[b].append(index)\n        return masks, ready_nodes\n\n\nclass CriticNet(torch.nn.Module):\n    def __init__(\n            self,\n            state_feature_size,\n            batch_norm,\n    ):\n        super(CriticNet, self).__init__()\n        self.state_feature_size = state_feature_size\n        self.batch_norm = batch_norm\n\n        self.critic_resnet = ResNetBlock(self.state_feature_size, 1, batch_norm=self.batch_norm)\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, state_feat):\n        return self._eval(state_feat)\n\n    def _eval(self, state_feat):\n        # get global features\n        state_feat = torch.max(state_feat, dim=1).values\n        state_value = self.critic_resnet(state_feat).squeeze(-1)\n        return state_value\n\n# ==========================================\n# File: src/hcp_ppo_single_model.py\n# Function/Context: ActorNet\n# ==========================================\nimport torch\nfrom torch import nn\nfrom src.pyg_graph_models import ResNetBlock\nfrom torch.distributions import Categorical\n\nfrom src.hcp_ppo_bihyb_model import GraphEncoder, CriticNet\n\n\nclass ActorNet(torch.nn.Module):\n    def __init__(\n            self,\n            state_feature_size,\n            batch_norm,\n    ):\n        super(ActorNet, self).__init__()\n        self.state_feature_size = state_feature_size\n        self.batch_norm = batch_norm\n\n        self.act_query = nn.Linear(self.state_feature_size, self.state_feature_size, bias=False)\n\n    @property\n    def device(self):\n        return next(self.parameters()).device\n\n    def forward(self, input_feat, node_candidates, prev_act, known_action=None):\n        return self._act(input_feat, node_candidates, prev_act, known_action)\n\n    def _act(self, input_feat, node_candidates, prev_act, known_action=None):\n        mask, ready_nodes = self._get_mask(input_feat.shape[0], input_feat.shape[1], node_candidates)\n        act, log_prob, entropy = self._select_node(input_feat, mask, prev_act, known_action)\n        return act, log_prob, entropy\n\n    def _select_node(self, state_feat, mask, prev_act, known_cur_act=None, greedy_sel_num=0):\n        # neural net prediction\n        prev_node_feat = state_feat[torch.arange(len(prev_act)), prev_act, :]\n        act_query = torch.tanh(self.act_query(prev_node_feat))\n        act_scores = (act_query.unsqueeze(1) * state_feat).sum(dim=-1)\n        # select action\n        act_probs = nn.functional.softmax(act_scores + mask, dim=1)\n        if greedy_sel_num > 0:\n            argsort_prob = torch.argsort(act_probs, dim=-1, descending=True)\n            acts = argsort_prob[:, :greedy_sel_num]\n            return acts, act_probs[torch.arange(acts.shape[0]).unsqueeze(-1), acts]\n        else:\n            dist = Categorical(probs=act_probs)\n            if known_cur_act is None:\n                act = dist.sample()\n                return act, dist.log_prob(act), dist.entropy()\n            else:\n                return known_cur_act, dist.log_prob(known_cur_act), dist.entropy()\n\n    def _get_mask(self, batch_size, num_nodes, node_candidates):\n        masks = torch.full((batch_size, num_nodes), -float('inf'), device=self.device)\n        ready_nodes = []\n        for b in range(batch_size):\n            ready_nodes.append([])\n            for node in node_candidates[b]:\n                masks[b, node] = 0\n                ready_nodes[b].append(node)\n        return masks, ready_nodes\n\n# ==========================================\n# File: utils/dag_graph.py\n# Function/Context: DAGraph\n# ==========================================\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport networkx as nx\nimport numpy as np\nimport random\nimport torch\n\nfrom queue import PriorityQueue\n\n\nclass DAGraph(object):\n    def __init__(self, resource_dim, feature_dim, scheduler_type='sjf'):\n        self.feature_dim = feature_dim\n        self.resource_dim = resource_dim\n        self.scheduler_type = scheduler_type\n        self.resource_limits = np.array([1.0] * resource_dim)\n\n    def step(self, input_graph, act, prev_greedy):\n        new_graph = input_graph.copy()\n        if isinstance(act, torch.Tensor):\n            act = (act[0].item(), act[1].item())\n        new_graph.add_edge(act[1], act[0],\n                           features=[0.0] * self.feature_dim)\n        assert nx.is_directed_acyclic_graph(new_graph)\n        new_greedy = self.makespan_time(new_graph, self.scheduler_type)\n        reward = prev_greedy - new_greedy\n        edge_candidates = self.get_edge_candidates(new_graph)\n        done = all([len(x) == 0 for x in edge_candidates.values()])\n        return reward, new_graph, new_greedy, edge_candidates, done\n\n    def makespan_time(self, dag_graph, scheduler_type='sft'):\n        if scheduler_type == 'sft':\n            return self.shortest_first_time(dag_graph)\n        elif scheduler_type == 'cp':\n            return self.critical_path_scheduling(dag_graph)\n        elif scheduler_type == 'ts':\n            return self.tetris_scheduling(dag_graph)\n\n    def shortest_first_time(self, graph, print_solution=False):\n        dep_map, _, features_map = self.get_dependency_nodes(graph)\n        run_queue = PriorityQueue()\n        used_resource = [0.0] * self.resource_dim\n        wallclock = 0.0\n        while not wallclock or not run_queue.empty():\n            # peek finished jobs from run_queue\n            current_time = None\n            processed = []\n            while not run_queue.empty():\n                completion_time, spend, resource, node = run_queue.get()\n                if current_time is None:\n                    current_time = completion_time\n                    assert wallclock <= current_time\n                    wallclock = current_time\n                if completion_time == current_time:\n                    used_resource = np.subtract(used_resource, resource)\n                    dep_map = self.remove_dependency(dep_map, node)\n                    processed.append(node)\n                elif completion_time > current_time:\n                    run_queue.put((completion_time, spend, resource, node))\n                    break\n                else:\n                    raise Exception('SJF: finish_time less than current_time')\n\n            # schedule ready nodes to run in shortest-first order\n            ready_nodes = self.get_ready_nodes(dep_map)\n            combos = sorted([(features_map[node]['features'], node)\n                             for node in ready_nodes])\n            run_nodes = set([q[-1] for q in run_queue.queue])\n            for features, node in combos:\n                spend, resource = features[0], features[1:(1 + self.resource_dim)]\n                if node not in run_nodes:\n                    to_resource = np.add(used_resource, resource)\n                    if np.all(to_resource <= self.resource_limits):\n                        used_resource = to_resource\n                        completion_time = wallclock + spend\n                        run_queue.put((completion_time, spend, resource, node))\n            if print_solution:\n                print('wallclock {} processed {} queued {}'.format(\n                    current_time, processed, run_queue.queue))\n        return wallclock\n\n    def get_dependency_nodes(self, graph):\n        parents = {}\n        children = {}\n        features = {}\n        for node, data in graph.nodes(data=True):\n            parents[node] = set()\n            children[node] = set()\n            features[node] = data\n        for from_node, to_node in graph.edges(data=False):\n            parents[from_node].add(to_node)\n            children[to_node].add(from_node)\n        return parents, children, features\n\n    def get_edge_candidates(self, graph):\n        \"\"\"Candidates are node pairs that are not on any paths.\n        This is not a bottle neck yet, but there is no need to repetitively call\n        this whole process after adding one single edge.\n        \"\"\"\n        relations_map = {}\n        parents, children, _ = self.get_dependency_nodes(graph)\n        for node in graph.nodes(data=False):\n            relations = set()\n            self.get_relations(parents, node, relations)\n            self.get_relations(children, node, relations)\n            relations_map[node] = relations\n\n        edge_candidates = {}\n        num_nodes = len(graph.nodes())\n        for i in range(num_nodes):\n            edge_candidates[i] = set(range(num_nodes)) - \\\n                                 set([i]) - relations_map[i]\n        return edge_candidates\n\n    def get_relations(self, relation_map, node, relations):\n        relates = relation_map[node]\n        while relates:\n            next_list = set()\n            for relate in relates:\n                relations.add(relate)\n                next_list = next_list.union(relation_map[relate])\n            relates = next_list\n\n    def get_ready_nodes(self, dependency_nodes):\n        ready_nodes = []\n        for node, dep_nodes in dependency_nodes.items():\n            if len(dep_nodes) == 0:\n                ready_nodes.append(node)\n        return ready_nodes\n\n    def remove_dependency(self, dependency_map, remove_node):\n        dependency_map.pop(remove_node)\n        for node, dep_nodes in dependency_map.items():\n            if remove_node in dep_nodes:\n                dep_nodes.remove(remove_node)\n        return dependency_map\n\n# ==========================================\n# File: utils/ged_env.py\n# Function/Context: GEDenv\n# ==========================================\nimport torch\nimport scipy.optimize as opt\nimport numpy as np\nimport random\nimport os\nfrom multiprocessing import Pool\nfrom torch_geometric.utils import to_dense_batch, to_dense_adj, degree\nfrom torch_geometric.transforms import OneHotDegree\nimport torch_geometric as pyg\nfrom utils.sinkhorn import Sinkhorn\nfrom a_star import a_star\nimport time\n\nVERY_LARGE_INT = 65536\n\n\nclass GEDenv(object):\n    def __init__(self, solver_type='hungarian', dataset='AIDS700nef'):\n        self.solver_type = solver_type\n        self.dataset = dataset\n        self.process_dataset()\n        self.available_solvers = ('hungarian', 'ipfp', 'rrwm', 'beam')\n        assert solver_type in self.available_solvers\n\n    def step(self, graph_1, graph_2, ori_k, act, prev_solution):\n        new_graph_1 = graph_1.clone()\n        assert isinstance(act, torch.Tensor)\n        act = act.unsqueeze(1)\n        edge_index_bool = new_graph_1.edge_index == act\n        edge_index_bool_rev = new_graph_1.edge_index == act.flip(dims=(0,))\n        found_bool = torch.logical_or(torch.logical_and(edge_index_bool[0], edge_index_bool[1]),\n                                      torch.logical_and(edge_index_bool_rev[0], edge_index_bool_rev[1]))\n        if torch.any(found_bool):  # delete edge\n            new_graph_1.edge_index = new_graph_1.edge_index[:, ~found_bool]\n        else:  # add edge\n            new_graph_1.edge_index = torch.cat((new_graph_1.edge_index, act, act.flip(dims=(0,))), dim=1)\n        new_solution, _, __ = self.solve_feasible_ged(new_graph_1, graph_2, self.solver_type, ori_k=ori_k)\n        reward = prev_solution - new_solution\n        return reward, new_graph_1, new_solution\n\n    def solve_feasible_ged(self, graph_1, graph_2, solver_type, ori_k=None):\n        k = self.construct_k(graph_1, graph_2).squeeze(0)\n        prev_time = time.time()\n        if ori_k is None:\n            ori_k = k\n        if solver_type == 'hungarian':\n            x = hungarian_ged(k, graph_1.num_nodes, graph_2.num_nodes)\n        elif solver_type == 'ipfp':\n            x = ipfp_ged(k, graph_1.num_nodes, graph_2.num_nodes)\n        elif solver_type == 'beam':\n            x = astar_ged(k, graph_1.num_nodes, graph_2.num_nodes)\n        elif solver_type == 'rrwm':\n            x = rrwm_ged(k, graph_1.num_nodes, graph_2.num_nodes)\n        elif solver_type == 'ga':\n            x = ga_ged(k, graph_1.num_nodes, graph_2.num_nodes)\n        else:\n            raise NotImplementedError(f'{solver_type} is not implemented.')\n        comp_time = time.time() - prev_time\n        return self.comp_ged(x, ori_k), ori_k, comp_time\n\n    def construct_k(self, graph_1, graph_2):\n        if isinstance(graph_1, pyg.data.Data):\n            graph_1 = pyg.data.Batch.from_data_list([graph_1])\n        if isinstance(graph_2, pyg.data.Data):\n            graph_2 = pyg.data.Batch.from_data_list([graph_2])\n        assert graph_1.num_graphs == graph_2.num_graphs\n        device = graph_1.x.device\n\n        edge_index_1 = graph_1.edge_index\n        edge_index_2 = graph_2.edge_index\n        if hasattr(graph_1, 'edge_attr') and hasattr(graph_2, 'edge_attr'):\n            edge_attr_1 = graph_1.edge_attr\n            edge_attr_2 = graph_2.edge_attr\n        else:\n            edge_attr_1 = None\n            edge_attr_2 = None\n        node_1 = graph_1.x\n        node_2 = graph_2.x\n        batch_1 = graph_1.batch if hasattr(graph_1, 'batch') else torch.tensor((), dtype=torch.long).new_zeros(\n            graph_1.num_nodes)\n        batch_2 = graph_2.batch if hasattr(graph_2, 'batch') else torch.tensor((), dtype=torch.long).new_zeros(\n            graph_2.num_nodes)\n\n        batch_num = graph_1.num_graphs\n\n        ns_1 = torch.bincount(graph_1.batch)\n        ns_2 = torch.bincount(graph_2.batch)\n\n        adj_1 = to_dense_adj(edge_index_1, batch=batch_1, edge_attr=edge_attr_1)\n        dummy_adj_1 = torch.zeros(adj_1.shape[0], adj_1.shape[1] + 1, adj_1.shape[2] + 1, device=device)\n        dummy_adj_1[:, :-1, :-1] = adj_1\n        adj_2 = to_dense_adj(edge_index_2, batch=batch_2, edge_attr=edge_attr_2)\n        dummy_adj_2 = torch.zeros(adj_2.shape[0], adj_2.shape[1] + 1, adj_2.shape[2] + 1, device=device)\n        dummy_adj_2[:, :-1, :-1] = adj_2\n\n        node_1, _ = to_dense_batch(node_1, batch=batch_1)\n        node_2, _ = to_dense_batch(node_2, batch=batch_2)\n\n        dummy_node_1 = torch.zeros(adj_1.shape[0], node_1.shape[1] + 1, node_1.shape[-1], device=device)\n        dummy_node_1[:, :-1, :] = node_1\n        dummy_node_2 = torch.zeros(adj_2.shape[0], node_2.shape[1] + 1, node_2.shape[-1], device=device)\n        dummy_node_2[:, :-1, :] = node_2\n\n        k_diag = self.node_metric(dummy_node_1, dummy_node_2)\n\n        mask_1 = torch.zeros_like(dummy_adj_1)\n        mask_2 = torch.zeros_like(dummy_adj_2)\n        for b in range(batch_num):\n            mask_1[b, :ns_1[b] + 1, :ns_1[b] + 1] = 1\n            mask_1[b, :ns_1[b], :ns_1[b]] -= torch.eye(ns_1[b], device=mask_1.device)\n            mask_2[b, :ns_2[b] + 1, :ns_2[b] + 1] = 1\n            mask_2[b, :ns_2[b], :ns_2[b]] -= torch.eye(ns_2[b], device=mask_2.device)\n\n        a1 = dummy_adj_1.reshape(batch_num, -1, 1)\n        a2 = dummy_adj_2.reshape(batch_num, 1, -1)\n        m1 = mask_1.reshape(batch_num, -1, 1)\n        m2 = mask_2.reshape(batch_num, 1, -1)\n        k = torch.abs(a1 - a2) * torch.bmm(m1, m2)\n        #k[torch.logical_not(torch.bmm(m1, m2).to(dtype=torch.bool))] = VERY_LARGE_INT\n        k = k.reshape(batch_num, dummy_adj_1.shape[1], dummy_adj_1.shape[2], dummy_adj_2.shape[1], dummy_adj_2.shape[2])\n        k = k.permute([0, 1, 3, 2, 4])\n        k = k.reshape(batch_num, dummy_adj_1.shape[1] * dummy_adj_2.shape[1],\n                      dummy_adj_1.shape[2] * dummy_adj_2.shape[2])\n\n        for b in range(batch_num):\n            k_diag_view = torch.diagonal(k[b])\n            k_diag_view[:] = k_diag[b].reshape(-1)\n\n        return k\n\n    def node_metric(self, node1, node2):\n        if self.dataset in ['AIDS700nef', 'AIDS-20', 'AIDS-20-30', 'AIDS-30-50', 'AIDS-50-100']:\n            node1, node2 = node1[:, :, :self.ori_feature_dim], node2[:, :, :self.ori_feature_dim]\n            encoding = torch.sum(torch.abs(node1.unsqueeze(2) - node2.unsqueeze(1)), dim=-1).to(dtype=torch.long)\n            mapping = torch.Tensor([0, 1, 1])\n        elif self.dataset in ['CMU', 'Willow']:\n            assert self.ori_feature_dim == 0\n            encoding = torch.sum(torch.abs(node1.unsqueeze(2) - node2.unsqueeze(1)), dim=-1).to(dtype=torch.long)\n            mapping = torch.Tensor([0, VERY_LARGE_INT, 0])\n        else:\n            assert self.ori_feature_dim == 0\n            encoding = torch.sum(torch.abs(node1.unsqueeze(2) - node2.unsqueeze(1)), dim=-1).to(dtype=torch.long)\n            mapping = torch.Tensor([0, 1, 0])\n        return mapping[encoding]\n\n    @staticmethod\n    def comp_ged(_x, _k):\n        if len(_x.shape) == 3 and len(_k.shape) == 3:\n            _batch = _x.shape[0]\n            return torch.bmm(torch.bmm(_x.reshape(_batch, 1, -1), _k), _x.reshape(_batch, -1, 1)).view(_batch)\n        elif len(_x.shape) == 2 and len(_k.shape) == 2:\n            return torch.mm(torch.mm(_x.reshape( 1, -1), _k), _x.reshape( -1, 1)).view(1)\n        else:\n            raise ValueError('Input dimensions not supported.')\n\n\ndef ipfp_ged(k, n1, n2, max_iter=100):\n    assert len(k.shape) == 2\n    v = hungarian_ged(k, n1, n2)\n    #v = torch.ones(n1 + 1, n2 + 1, dtype=k.dtype, device=k.device) / (n1 + 1) / (n2 + 1)\n    last_v = v\n    best_binary_sol = v\n    n1, n2 = torch.tensor([n1], device=k.device), torch.tensor([n2], device=k.device)\n\n    #k_diag = torch.diag(k)\n    #k_offdiag = k - torch.diag(k_diag)\n    best_upper_bound = float('inf')\n\n    for i in range(max_iter):\n        cost = torch.mm(k, v.view(-1, 1)).reshape(n1+1, n2+1)\n        binary_sol = hungarian_lap(cost, n1, n2)[0]\n        upper_bound = GEDenv.comp_ged(binary_sol, k)\n        if upper_bound < best_upper_bound:\n            best_binary_sol = binary_sol\n            best_upper_bound = upper_bound\n        alpha = torch.mm(torch.mm(v.view(1, -1), k), (binary_sol - v).view(-1, 1)) #+ \\\n                #torch.mm(k_diag.view(1, -1), (binary_sol - v).view(-1, 1))\n        beta = GEDenv.comp_ged(binary_sol - v, k)\n        t0 = - alpha / beta\n        if beta <= 0 or t0 >= 1:\n            v = binary_sol\n        else:\n            v = v + t0 * (binary_sol - v)\n        last_v_sol = GEDenv.comp_ged(last_v, k)\n        if torch.abs(last_v_sol - torch.mm(cost.view(1, -1), binary_sol.view(-1, 1))) / last_v_sol < 1e-3:\n            break\n        last_v = v\n\n    pred_x = best_binary_sol\n    return pred_x\n\n\ndef astar_ged(k, n1, n2, beamwidth=1):\n    x_pred, tree_size = a_star(\n        k.unsqueeze(0), np.array([n1]), np.array([n2]),\n        heuristic_prediction_hun,\n        beam_width=beamwidth,\n        trust_fact=1.,\n        no_pred_size=0,\n    )\n    return x_pred.squeeze(0)\n\n\ndef hungarian_ged(k, n1, n2):\n    x, _ = heuristic_prediction_hun(k, n1, n2)\n    return x\n\n\ndef heuristic_prediction_hun(k, n1, n2, partial_pmat=None):\n    assert len(k.shape) == 2\n    k_prime = k.reshape(-1, n1+1, n2+1)\n    node_costs = torch.empty(k_prime.shape[0], device=k.device)\n    for i in range(k_prime.shape[0]):\n        _, node_costs[i] = hungarian_lap(k_prime[i], n1, n2)\n\n    node_cost_mat = node_costs.reshape(n1+1, n2+1)\n    if partial_pmat is None:\n        partial_pmat = torch.zeros_like(node_cost_mat)\n    graph_1_mask = ~partial_pmat.sum(dim=-1).to(dtype=torch.bool)\n    graph_2_mask = ~partial_pmat.sum(dim=-2).to(dtype=torch.bool)\n    graph_1_mask[-1] = 1\n    graph_2_mask[-1] = 1\n    node_cost_mat = node_cost_mat[graph_1_mask, :]\n    node_cost_mat = node_cost_mat[:, graph_2_mask]\n\n    x, lb = hungarian_lap(node_cost_mat, torch.sum(graph_1_mask[:-1]), torch.sum(graph_2_mask[:-1]))\n    return x, lb\n\n\ndef hungarian_lap(node_cost_mat, n1, n2):\n    assert node_cost_mat.shape[-2] == n1+1\n    assert node_cost_mat.shape[-1] == n2+1\n    row_ind, col_ind = opt.linear_sum_assignment(node_cost_mat.cpu().numpy())\n    x = torch.zeros_like(node_cost_mat)\n    x[row_ind, col_ind] = 1\n    lb = torch.sum(x * node_cost_mat)\n    return x, lb\n\n# ==========================================\n# File: utils/tsp_algorithms.py\n# Function/Context: \n# ==========================================\nimport numpy as np\nimport utils.lkh_wrapper as lkh_wrapper\n\n\ndef get_edge_weight(tsp, city1, city2):\n    weight = tsp.get_weight(*(city1,city2)) if city1 > city2 else tsp.get_weight(*(city2,city1))\n    return weight\n\n\ndef calc_nearest_neighbor_tour_len(tsp):\n    path = calc_nearest_neighbor_tour(tsp)\n    return_path = path.copy()\n    tour_len = 0\n    while(len(path) > 1):\n        start_node = path.pop()\n        next_node  = path[-1]\n        tour_len += get_edge_weight(tsp, start_node, next_node)\n    return return_path, tour_len\n\n\ndef calc_nearest_neighbor_tour(tsp):\n    \"\"\"Construct a tour through all cities in a TSP by following the nearest neighbor heuristic\"\"\"\n    nearest_neighbor_path = [0]\n    current_city          = 0\n    cities_to_travel      = set(range(1, len(list(tsp.get_nodes())) ))\n\n    while cities_to_travel:\n        distance_to_current_city = lambda city: get_edge_weight(tsp, city, current_city)\n        current_city = min(cities_to_travel, key = distance_to_current_city)\n        nearest_neighbor_path.append(current_city)\n        cities_to_travel.remove(current_city)\n    nearest_neighbor_path.append(nearest_neighbor_path[0])\n    \n    return nearest_neighbor_path\n\n\ndef calc_lkh_tour_len(tsp, **lkh_kwargs):\n    lkh_path = calc_lkh_tour(tsp, **lkh_kwargs)\n    return_path = lkh_path.copy()\n    for i in range(len(return_path)):\n        return_path[i] -= 1\n    tour_len = 0\n    while(len(lkh_path) > 1):\n        start_node = lkh_path.pop()\n        next_node  = lkh_path[-1]\n        tour_len += get_edge_weight(tsp, start_node-1, next_node-1)\n    return return_path, tour_len\n\n\ndef calc_lkh_tour(tsp, **lkh_kwargs):\n    solver_path = './LKH-3.0.6/LKH'\n    if 'runs' not in lkh_kwargs:\n        lkh_kwargs['runs'] = 4\n    result = lkh_wrapper.solve(solver_path, problem=tsp, **lkh_kwargs)\n    lkh_path = result[0]\n    lkh_path.append(lkh_path[0])\n    return lkh_path\n\n\ndef calc_furthest_insertion_tour(tsp):\n    \"\"\"Construct a tour through all cities in a TSP by following the furthest insertion heuristic\"\"\"\n    farest_neighbor_path = [0]\n    current_city          = 0\n    cities_to_travel      = set(range(1, len(list(tsp.get_nodes())) ))\n\n    while cities_to_travel:\n        # selection furthest\n        # current_city = min(farest_neighbor_path, key =lambda city_n: max(cities_to_travel, key = lambda city_y: adj[city_n][city_y]))\n        current_city = -1\n        dist_f = 0\n        for c1 in cities_to_travel:\n            dist_s = np.inf\n            for c2 in farest_neighbor_path:\n                dist_s = min(dist_s, get_edge_weight(tsp, c1, c2))\n            if(dist_f < dist_s):\n                dist_f = dist_s\n                current_city = c1\n        # print(current_city)\n        #insertion minimizes cir + crj - cij, and we insert r between i and j\n        if(len(farest_neighbor_path) > 1):\n            insert_length_change = lambda ci: get_edge_weight(tsp,farest_neighbor_path[ci],current_city)+ get_edge_weight(tsp, farest_neighbor_path[ci+1], current_city) - get_edge_weight(tsp, farest_neighbor_path[ci], farest_neighbor_path[ci+1])\n            insert_i = min(list(range(0,len(farest_neighbor_path)-1)), key = insert_length_change)\n            farest_neighbor_path.insert(insert_i,current_city)\n        else:\n            farest_neighbor_path.append(current_city)\n        cities_to_travel.remove(current_city)\n    farest_neighbor_path.append(farest_neighbor_path[0])\n        \n    return farest_neighbor_path\n\n\ndef calc_furthest_insertion_tour_len(tsp):\n    path = calc_furthest_insertion_tour(tsp)\n    return_path = path.copy()\n    tour_len = 0\n    while(len(path) > 1):\n        start_node = path.pop()\n        next_node  = path[-1]\n        tour_len += get_edge_weight(tsp, start_node, next_node)\n    return return_path, tour_len\n\n\ndef get_adj(problem):\n    nodes = list(problem.get_nodes())\n    dim = int(problem.dimension)\n    \n    adj_matrix = np.zeros(dim**2).reshape(dim, dim)\n    for i in range(0,dim):\n        for j in range(i+1,dim):\n            adj_matrix[i][j] = problem.get_weight(*(nodes[i],nodes[j]))\n            # distances.euclidean(start, end)\n    adj_matrix += adj_matrix.T - np.diag(adj_matrix.diagonal()) #+np.inf\n    return adj_matrix\n\n\ndef get_lower_matrix_tsp(problem):\n    nodes = list(problem.get_nodes())\n    dim = int(problem.dimension)\n    \n    adj_matrix = []\n    for i in range(0,dim):\n        matrix_d = []\n        for j in range(0,i+1):\n            if j == i :\n                matrix_d.append(0)\n            else:\n                matrix_d.append(problem.get_weight(*(nodes[i],nodes[j])))\n        adj_matrix.append(matrix_d)\n    return adj_matrix\n\n\ndef get_lower_matrix(problem, feas_weight=1, infeas_weight=10):\n    dim = int(problem.dimension)\n\n    flat_edge_list = []\n    for key in problem.edge_data.keys():\n        flat_edge_list.append(key)\n        flat_edge_list += problem.edge_data[key]\n\n    edge_list = []\n    for i in range(len(flat_edge_list) // 2):\n        edge_list.append((flat_edge_list[i * 2]-1, flat_edge_list[i * 2 + 1]-1))\n\n    adj_matrix = []\n    for i in range(0, dim):\n        matrix_d = []\n        for j in range(0, i + 1):\n            if (i, j) in edge_list or (j, i) in edge_list:\n                matrix_d.append(feas_weight)\n            else:\n                matrix_d.append(infeas_weight)\n        adj_matrix.append(matrix_d)\n    return adj_matrix\n\n\ndef get_edge_dict(problem, adj=None):\n    nodes = list(problem.get_nodes())\n    dim = int(problem.dimension)\n    edge_dict = {}\n    for i in range(dim):\n        for j in range(dim):\n            if i == j:\n                continue\n            if adj is not None and adj[i, j] == 0:\n                continue\n            edge_dict[(i, j)] = problem.get_weight(nodes[i], nodes[j])\n    return edge_dict\n\n\n\ndef get_matrix_hcp(problem):\n    # edge_data = problem.edge_data_format\n    edge_list = problem.edge_data[1]\n    edge_list = np.append(1,edge_list)\n    dim = problem.dimension\n    \n    adj_matrix = (np.ones(dim**2)*2).reshape(dim, dim)\n    for i in range(0,dim):\n        adj_matrix.append(np.ones(i+1)*2)\n    \n    # adj_matrix +=1\n    for i in range(0,len(edge_list),2):\n        c1 = edge_list[i]-1\n        c2 = edge_list[i+1]-1\n        adj_matrix[c2][c1] = 1\n        adj_matrix[c1][c2] = 1\n    return adj_matrix\n\n\ndef solveFarthestInsertion(problem):\n    farest_neighbor_path = [0]\n    distance = get_adj(problem)\n    done          = [0]\n    points      = set(range(1, problem.dimension))\n\n    while points:\n        farthestPoint = None\n        # Find the farthest city to the current cycle\n        for current in done:\n            for point in points:\n                d = distance[current,point]\n                if (farthestPoint is None or d > farthestPoint[1]):\n                    farthestPoint = (point, d)\n        farthestPoint = farthestPoint[0]\n\n        # Find the closest edge of the cycle to the farthest city\n        last = None\n        best = None\n        for current in done:\n            if (last is not None):\n                d1 = distance[last, farthestPoint]\n                d2 = distance[current, farthestPoint]\n                d3 = distance[last, current]\n                d = d1 + d2 - d3\n\n                if (best is None or d < best[2]):\n                    best = (last, current, d)\n            last = current\n\n        if (last is None):\n            last = done[0]\n\n        d1 = distance[last, farthestPoint]\n        d2 = distance[done[0], farthestPoint]\n        d3 = distance[last, done[0]]\n        d = d1 + d2 - d3\n        if (best is None or d < best[2]):\n            best = (last, done[0], d)\n\n        # Connect the farthest city to the cycle\n        done.insert(done.index(best[0]) + 1, farthestPoint)\n        points.remove(farthestPoint)\n    \n    done.append(0)\n\n    tour_len = 0\n    farest_neighbor_path = done.copy()\n    while(len(done) > 1):\n        start_node = done.pop()\n        next_node  = done[-1]\n        tour_len += distance[start_node, next_node]\n    return farest_neighbor_path, tour_len\n\n# ==========================================\n# File: utils/tsp_env.py\n# Function/Context: TSPEnv.step\n# ==========================================\nimport torch\nimport random\nimport os\nimport glob\nimport re\nfrom copy import deepcopy\nimport time\nimport numpy as np\nimport tsplib95\nfrom utils.tsp_algorithms import calc_furthest_insertion_tour_len, calc_lkh_tour_len, calc_nearest_neighbor_tour_len,\\n    get_lower_matrix, solveFarthestInsertion\nfrom tsp_main import parse_tsp\nfrom utils.utils import random_triangulate\n\nVERY_LARGE_INT = 10 # 65536\n\n\nclass TSPEnv(object):\n    def __init__(self, solver_type='nn', min_size=100, max_size=200):\n        self.solver_type = solver_type\n        self.min_size = min_size\n        self.max_size = max_size\n        self.process_dataset()\n        self.available_solvers = ('nn','furthest', 'lkh-fast','lkh-accu')\n        print(self.solver_type)\n        assert solver_type in self.available_solvers\n\n    def step(self, list_lower_matrix, act, prev_solution):\n        new_list_lower_matrix = deepcopy(list_lower_matrix)\n        if isinstance(act, torch.Tensor):\n            act = (act[0].item(), act[1].item())\n        if act[0] >= act[1]:\n            idx0, idx1 = act[0], act[1]\n        else:\n            idx0, idx1 = act[1], act[0]\n        new_list_lower_matrix[idx0][idx1] += VERY_LARGE_INT\n        new_tour, new_solution, _ = self.solve_feasible_tsp(new_list_lower_matrix, self.solver_type)\n        new_edge_candidate = self.edge_candidate_from_tour(new_tour, len(new_list_lower_matrix))\n        reward = prev_solution - new_solution\n        done = new_solution == 0\n        #done = False\n        return reward, new_list_lower_matrix, new_edge_candidate, new_solution, done\n\n    def solve_feasible_tsp(self, lower_left_matrix, solver_type):\n        prev_time = time.time()\n        tsp_inst = tsplib95.parse(parse_tsp(lower_left_matrix))\n        if solver_type == 'nn':\n            tour, length = calc_nearest_neighbor_tour_len(tsp_inst)\n        elif solver_type == 'furthest':\n            tour, length = solveFarthestInsertion(tsp_inst)\n        elif solver_type == 'lkh-fast':\n            tour, length = calc_lkh_tour_len(tsp_inst, move_type=5, runs=5)\n        elif solver_type == 'lkh-accu':\n            tour, length = calc_lkh_tour_len(tsp_inst, move_type=5, runs=10, max_trials=10000)\n        else:\n            raise ValueError(f'{solver_type} is not implemented.')\n        comp_time = time.time() - prev_time\n        return tour, length - tsp_inst.dimension, comp_time\n\n    @staticmethod\n    def edge_candidate_from_tour(tour, num_nodes):\n        assert tour[0] == tour[-1]\n        edge_candidate = {x: set() for x in range(num_nodes)}\n        iter_obj = iter(tour)\n        last_node = next(iter_obj)\n        for node in iter_obj:\n            edge_candidate[last_node].add(node)\n            edge_candidate[node].add(last_node)\n            last_node = node\n        return edge_candidate",
  "description": "Combined Analysis:\n- [src/dag_ppo_bihyb_model.py]: This file implements the neural network components for the upper-level PPO agent in the bi-level optimization framework. Specifically:\n1. GraphEncoder: Encodes input graphs into node-level and graph-level features using bidirectional GCNs with attention pooling.\n2. ActorNet: Implements the policy network that selects actions (edge modifications) through a two-step node selection process with masking to enforce constraints.\n3. CriticNet: Implements the value network for state evaluation.\n\nThe core optimization logic is partially implemented here - specifically the upper-level RL agent's policy and value networks that learn to modify graph structures. However, the complete bi-level optimization loop (including lower-level heuristic solving and reward computation) would be implemented elsewhere, with this file providing the neural network models for the PPO agent.\n- [src/ged_ppo_bihyb_model.py]: This file implements the neural network components for the upper-level PPO agent in the bi-level framework for Graph Edit Distance (GED). The GraphEncoder computes cross-graph similarity and difference features between original and modified graphs. ActorNet implements the policy network that selects node pairs for graph edit operations (edge additions/deletions/modifications). CriticNet provides state-value estimates for PPO training. These components directly implement the upper-level RL agent that learns to modify graph structure (GG') as described in the bi-level optimization framework.\n- [src/hcp_ppo_bihyb_model.py]: This file implements the neural network components for the upper-level PPO agent in the bi-level framework. The GraphEncoder processes input graphs into node and graph features. The ActorNet implements the policy network that selects edge modifications (two nodes) using masked categorical distributions, which corresponds to the upper-level action of modifying graph structure. The CriticNet provides state value estimates for PPO training. The implementation directly supports the Hamiltonian Cycle Problem (HCP) as shown in the paper's Figure 3, where the agent selects edges to add/remove to transform the graph into one where a Hamiltonian cycle exists. The code handles graph representation, action selection with constraints (via masks), and value estimation - all core components of the upper-level RL agent in the bi-level optimization framework.\n- [src/hcp_ppo_single_model.py]: This file implements the actor network for the Proximal Policy Optimization (PPO) agent used in the upper level of the bi-level framework. The ActorNet class defines a policy network that selects discrete actions (nodes) based on state features, previous actions, and candidate nodes, with masking to handle constraints. It uses a linear layer to compute action queries, applies softmax for probability distribution, and samples actions via Categorical distribution, supporting both exploration and greedy selection. This aligns with the RL component of the paper's methodology, where the agent adaptively modifies the graph structure or directly interacts with the problem, though the full bi-level interaction with heuristic solvers is not shown in this file.\n- [utils/dag_graph.py]: This file implements the core bi-level optimization logic for the DAG scheduling problem as described in the paper. The DAGraph class provides:\n1. Upper-level RL environment: The `step()` method modifies the input graph by adding edges (action from RL agent) and computes reward as makespan improvement.\n2. Lower-level heuristic solver: The `makespan_time()` method (with `shortest_first_time()` implementation) solves the scheduling problem on the modified graph using traditional heuristics.\n3. Graph manipulation utilities: Methods for generating DAGs, managing dependencies, and identifying valid edge additions.\n4. The implementation directly corresponds to the bi-level framework where RL learns to modify graph structure (upper-level) while heuristic algorithms solve the optimization problem (lower-level).\n- [utils/ged_env.py]: This file implements the Graph Edit Distance (GED) environment for the bi-level optimization framework. The GEDenv class provides: 1) The 'step' method that implements the upper-level optimization by modifying graph edges (adding/deleting) and computing rewards based on GED improvement, 2) The 'solve_feasible_ged' method that implements the lower-level optimization using various heuristic solvers (Hungarian, IPFP, RRWM, beam search), 3) The 'construct_k' method that builds the quadratic cost matrix for GED computation, 4) Helper functions for different GED solvers. This directly implements the bi-level framework where RL modifies the graph structure (upper level) and traditional heuristics solve GED on the modified graph (lower level).\n- [utils/tsp_algorithms.py]: This file implements the lower-level heuristic algorithms for solving combinatorial optimization problems on graphs, specifically for the Traveling Salesman Problem (TSP) and Hamiltonian Cycle Problem (HCP). It contains multiple heuristic solvers (nearest neighbor, furthest insertion, LKH) that are used in the bi-level framework's lower-level optimization. The functions calculate tours and tour lengths, which correspond to solving the optimization problem on a given graph structure (modified by the upper-level RL agent). The file also includes helper functions for graph representation (adjacency matrices, edge dictionaries) that are essential for the heuristic algorithms. This aligns with the paper's bi-level approach where the lower-level uses existing heuristic algorithms to solve the optimization problem on the modified graph G'.\n- [utils/tsp_env.py]: This file implements the bi-level optimization framework for the Hamiltonian Cycle Problem (HCP) transformed to TSP. The step() method executes the core logic: (1) Upper-level action: modifies graph structure by penalizing an edge (adding VERY_LARGE_INT to its weight), effectively removing it from consideration. (2) Lower-level optimization: calls solve_feasible_tsp() which uses traditional TSP heuristics (nearest neighbor, furthest insertion, or LKH) to solve the TSP on the modified graph. (3) Reward calculation: computes improvement in tour length (prev_solution - new_solution). This matches the paper's bi-level formulation where RL agent modifies the graph and heuristic solves the optimization problem on the modified graph.",
  "dependencies": [
    "ActorNet._select_node",
    "utils.tsp_algorithms.get_lower_matrix",
    "utils.utils.random_triangulate",
    "networkx",
    "torch.distributions",
    "tsplib95",
    "utils.tsp_algorithms.calc_nearest_neighbor_tour_len",
    "src.hcp_ppo_bihyb_model.GraphEncoder",
    "src.pyg_graph_models.GraphAttentionPooling",
    "utils.lkh_wrapper",
    "utils.utils.reverse_pyg_graph",
    "multiprocessing.Pool",
    "torch.distributions.Categorical",
    "src.pyg_graph_models.TensorNetworkModule",
    "time",
    "utils.utils.construct_graph_batch",
    "queue.PriorityQueue",
    "copy.deepcopy",
    "utils.sinkhorn.Sinkhorn",
    "re",
    "torch_geometric.utils.to_dense_batch",
    "utils.utils",
    "src.pyg_graph_models.ResNetBlock",
    "src.hcp_ppo_bihyb_model.CriticNet",
    "src.pyg_graph_models",
    "utils.sinkhorn",
    "src.pyg_graph_models.GCN",
    "os",
    "utils.tsp_algorithms.solveFarthestInsertion",
    "a_star",
    "tsp_main.parse_tsp",
    "random",
    "numpy",
    "torch_geometric.utils",
    "glob",
    "utils.tsp_algorithms.calc_furthest_insertion_tour_len",
    "scipy.optimize",
    "torch.nn",
    "torch_geometric",
    "ActorNet._act",
    "torch",
    "utils.tsp_algorithms.calc_lkh_tour_len",
    "ActorNet._get_mask"
  ]
}