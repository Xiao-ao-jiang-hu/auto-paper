{
  "file_path": "attack_utils.py, models/NGM/gnn.py, models/NGM/hypermodel_v2.py, models/NGM/model_v2.py, src/lap_solvers/sinkhorn.py, src/loss_func.py, src/qap_solvers/rrwm.py, src/qap_solvers/spectral_matching.py, train_eval.py",
  "function_name": "AttackBase._main, AttackBase._MaskUpdateClip_loc, AttackBase._intersect_bbox, GNNLayer.forward, HyperGNNLayer.forward, HyperConvLayer.forward, Net.forward, Net.forward, Sinkhorn, OurPermutationLoss, RRWM.forward, SpectralMatching, train_eval_model",
  "code_snippet": "\n\n# ==========================================\n# File: attack_utils.py\n# Function/Context: AttackBase._main, AttackBase._MaskUpdateClip_loc, AttackBase._intersect_bbox\n# ==========================================\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom src.utils.config import cfg\nfrom src.factorize_graph_matching import kronecker_sparse, kronecker_torch\nfrom src.evaluation_metric import *\nfrom src.feature_align import detect_bound\nfrom src.loss_func import GMLoss\nfrom src.utils.data_to_cuda import data_to_cuda\nfrom src.dataset.data_loader import GMDataset, get_dataloader\n\nimport time\nfrom collections import OrderedDict\n\n#from models.NGM.model_v2 import Net\nfrom src.utils.model_sl import load_model\n\ndef clamp(X, lower_limit, upper_limit):\n    return torch.max(torch.min(X, upper_limit), lower_limit)\n\nclass AttackedObject:\n    def __init__(self, att_key=None, eps=None, bs=None, num=2, dtype=torch.float32, device=None):\n        self.att_key = att_key\n        self.eps = eps\n        self.device = device\n        self.dtype = dtype\n        self.bs = bs # batchsize \n        self.delta = None\n        self.max_delta = None\n        self.max_loss = torch.zeros(bs, device=device)\n        self.delta_shape = None\n        self.delta_grads = None\n        self.num = num # N-graph Matching, here we only consider 2-graph matching\n\n    def init_max_delta(self, inputs):\n        self.delta_shape = list(inputs[0].shape)\n        self.delta_shape.insert(0, self.num)\n        self.max_delta = torch.zeros(self.delta_shape, device=self.device)\n\n    def init_delta(self):\n        self.delta = torch.zeros(self.delta_shape, device=self.device)\n        self.delta.uniform_(-self.eps, self.eps)\n        self.delta.requires_grad = True  \n        self.momentum = torch.zeros(self.delta_shape, device=self.device)\n\nclass AttackBase:\n    def __init__(self, att_obj:str, criterion: GMLoss, eps:tuple, iter_num, alpha,  device, inv=False):\n        self.device = device\n\n        self.criterion = criterion\n        self.criterion_name = criterion.name.lower()\n        self.att_obj = att_obj\n        \n        self.epsilon_feat = torch.tensor(int(eps[0])/255., dtype=torch.float32, device=device)\n        self.epsilon_loc  = torch.tensor(eps[1], dtype=torch.float32, device=device)\n        self.eps_dict = {'Ps': self.epsilon_loc, 'images': self.epsilon_feat}\n\n        self.att_key_list = []\n        if 'pos' in att_obj or 'struc' in att_obj:\n            self.att_key_list.append('Ps')\n        if 'pixel' in att_obj:\n            self.att_key_list.append('images')\n        if self.att_key_list == []:\n            assert False, 'Invalid attacked object' + att_obj\n\n        self.attack_iters = iter_num\n        self.alpha        = alpha\n\n        self.restarts = cfg.ATTACK.RESTARTS\n        self.early_stop_ratio = cfg.ATTACK.EARLY_STOP_RATIO\n        self.grad_inv = -1 if inv else 1\n        self.mu = cfg.ATTACK.MU\n        self.bn_eval = cfg.TRAIN.BN_EVAL\n\n    def __call__(self, model, inputs, criterion=None):\n        if criterion == None:\n            return self._main(model, inputs, self.criterion)\n        else:\n            return self._main(model, inputs, criterion)\n\n    def _main(self, model, inputs, criterion):\n        if self.bn_eval:\n            model.eval()\n        att_obj_dict = OrderedDict()\n        batch_size = inputs['batch_size']\n\n        for att_key in self.att_key_list:\n            att_obj_dict[att_key] = AttackedObject(att_key, self.eps_dict[att_key], batch_size, device=self.device)\n            att_obj_dict[att_key].init_max_delta(inputs[att_key])\n\n        for zz in range(self.restarts):\n\n            for att_obj in att_obj_dict.values():\n                att_obj.init_delta()\n\n            for num_iter in range(self.attack_iters):\n                with torch.set_grad_enabled(True):\n                    for att_key, att_obj in att_obj_dict.items():\n                        for i in range(att_obj.num):\n                            inputs[att_key][i] += att_obj.delta[i]\n\n                    pred = model(inputs)\n\n                    for att_key, att_obj in att_obj_dict.items():\n                        for i in range(att_obj.num):\n                            inputs[att_key][i] -= att_obj.delta[i]\n\n                    s_pred, img_pred = pred['ds_mat'], pred['images']\n\n                    # Early Stop when the matching accuracy w.r.t attacked graphs is below the threshold. \n                    precision = matching_precision(pred['perm_mat'], pred['gt_perm_mat'], pred['ns'][0])\n                    index = torch.where(precision >= self.early_stop_ratio)[0]\n                    if len(index) == 0:\n                        break\n\n                    if type(s_pred) is list:\n                        s_pred = s_pred[-1]\n\n                    if self.criterion_name == 'ourloss':\n                        loss = criterion(pred, pred)\n                    else:\n                        loss = criterion(pred)\n\n                    delta_grads = torch.autograd.grad(loss, [att_obj.delta for att_obj in att_obj_dict.values()], create_graph=False)\n                    for i, att_obj in enumerate(att_obj_dict.values()):\n                        att_obj.delta_grads = delta_grads[i]\n\n                    for att_key, att_obj in att_obj_dict.items():\n                        for i in range(att_obj.num):\n                            if att_key == 'Ps':\n                                att_obj.momentum[i]= self._MaskUpdateClip_loc(model, criterion, i, inputs, inputs[att_key][i], inputs['ns'][i], att_obj.delta[i], att_obj.delta_grads[i], index, att_obj.momentum[i])\n                            else:\n                                att_obj.momentum[i] = self._MaskUpdateClip_feat(att_obj.momentum[i], att_obj.delta[i], att_obj.delta_grads[i], index)\n\n                    if 'pos+struc' in self.att_obj:\n                        inputs = GMDataset.collate_batch(inputs, loc_att_mode='both')\n                        inputs = data_to_cuda(inputs)\n                    elif 'struc' in self.att_obj:\n                        inputs = GMDataset.collate_batch(inputs, 'only_struc')\n                        inputs = data_to_cuda(inputs)\n\n            if self.restarts > 1:\n                all_loss = criterion(model(inputs), reduction='none').detach()\n                for att_key, att_obj in att_obj_dict.items():\n                    for i in range(att_obj.num):\n                        att_obj.max_delta[i][all_loss >= att_obj.max_loss] = att_obj.delta.detach()[i][all_loss >= att_obj.max_loss]\n                    att_obj.max_loss = torch.max(att_obj.max_loss, all_loss)\n            else:\n                for att_key, att_obj in att_obj_dict.items():\n                    att_obj.max_delta = att_obj.delta\n                    att_obj.max_loss = 0.\n\n        for att_key, att_obj in att_obj_dict.items():\n            for i in range(att_obj.num):\n                inputs[att_key][i] += att_obj.max_delta[i]\n\n        if self.bn_eval:\n            model.train()\n        return inputs, None\n\n    def _MaskUpdateClip_feat(self, momentum, delta, grad, index):\n            grad = grad.detach()\n            delta = delta.detach()\n            d = delta[index, :, :]\n            g = grad[index, :, :] * self.grad_inv\n\n            # momentum\n            if self.mu != 0:\n                m = momentum[index, :, :]\n                m = self.mu * m + g / torch.mean(torch.abs(g), dim=(1,2,3), keepdim=True)\n                g = m\n                momentum[index, :, :] = m\n\n            d = clamp(d + self.alpha * self.epsilon_feat * torch.sign(g), -self.epsilon_feat, self.epsilon_feat)\n            delta.data[index, :, :] = d\n            grad.zero_()   \n            return momentum\n\n    def _MaskUpdateClip_loc(self, model, criterion, i, inputs, X, ns, delta, grad, index, momentum):\n        \"\"\"\n        index: 1 denotes current delta needs to be updated while 0 means no changes needs to be done;\n        inputs: inputs['Ps'] = X;\n        X: the last perturbed location; \n        delta: X_ori + delta = X;\n        delta_single: delta_new = delta + delta_single;\n        \"\"\"\n        delta = delta.detach()\n        grad =  grad.detach()\n        d = delta[index, :, :]\n        g = grad[index, :, :] * self.grad_inv\n\n        # momentum\n        if self.mu != 0:\n            m = momentum[index, :, :]\n            m = self.mu * m + g / torch.mean(torch.abs(g), dim=(1,2), keepdim=True)\n            g = m\n            momentum[index, :, :] = m\n\n        # Stage one: clip delta in the epsilon-ball;\n        # d = clamp(d + alpha * epsilon * torch.sign(g), -epsilon, epsilon)\n        delta_single = clamp(self.alpha * self.epsilon_loc * torch.sign(g), -self.epsilon_loc-d, self.epsilon_loc-d)\n        # Stage two: clip delta when X+delta crosses the current feature cell; \n        # detect which cell X locates in feature space; \n        bound_X = detect_bound(X[index, :, :], ns, 256, perturb_type='node')\n        # detect which cell X+delta locates in feature space; \n        bound_X_plus = detect_bound((X+delta_single)[index, :, :], ns, 256, perturb_type='node')\n\n        clip_ratio = torch.ones(d.shape[:2], device=self.device)\n        clip_ratio_ori = torch.ones(d.shape[:2], device=self.device)\n        for idx in range(bound_X.shape[0]):\n            for p_idx, bounds in enumerate(bound_X[idx]):                \n                clip_ratio[idx, p_idx] = self._intersect_bbox(bounds, bound_X_plus[idx, p_idx, :])\n\n        bool_idcs_left = torch.zeros((delta_single.shape[0]), device=self.device, dtype=torch.bool)\n        bool_idcs_right = torch.ones((delta_single.shape[0]), device=self.device, dtype=torch.bool)\n        delta_single[bool_idcs_left, :, :] *= clip_ratio.unsqueeze(-1)[bool_idcs_left, :, :]\n        delta_single[bool_idcs_right, :, :] *= clip_ratio_ori.unsqueeze(-1)[bool_idcs_right, :, :]\n\n        delta.data[index, :, :] += delta_single\n        grad.zero_()\n        return momentum\n\n    def _decide_loss(self, model, criterion, i, inputs, delta):\n        \"\"\"\n        compute loss w.r.t input with added perturbation \n        Note that delta is for the 'i' the graph\n        return the loss\n        \"\"\" \n        with torch.no_grad():\n            inputs['Ps'][i] += delta\n            pred = model(inputs)\n            loss = criterion(pred, reduction='none')\n            inputs['Ps'][i] -= delta\n\n        return loss\n\n    def _intersect_bbox(self, bounds, bounds_X_v, out=None, device=None):\n        if device is None:\n            device = bounds.device\n        if out is None:\n            out = torch.tensor(1., dtype=torch.float32, device=device)\n        eps = 1e-6\n        x0, x1, y0, y1, X0, Y0 = bounds\n        _, _, _, _, X_v0, Y_v0 = bounds_X_v\n        X = (X0, Y0)\n        v = (X_v0 - X0, Y_v0 - Y0)\n        k_inter = lambda x, v_x, loc_V: (loc_V - x) / (v_x + eps)\n        x_or_y_inter = lambda y, k, v_y: y + k * v_y\n        if_inter = lambda k, x_or_y, bound_0, bound_1: (k >= -eps) and (k <= 1.+eps) and (x_or_y >= bound_0-eps) and (x_or_y <= bound_1+eps)\n        # check if X + out * v intersects with the bounding box vertically \n        # vector: (x0, 0)\n        k_inter_x0 = k_inter(X[0], v[0], x0)\n        y_inter_x0 = x_or_y_inter(X[1], k_inter_x0, v[1])\n        if if_inter(k_inter_x0, y_inter_x0, y0, y1):\n            out = k_inter_x0\n            return out \n\n        # vector: (x1, 0)\n        k_inter_x1 = k_inter(X[0], v[0], x1)\n        y_inter_x1 = x_or_y_inter(X[1], k_inter_x1, v[1])\n        if if_inter(k_inter_x1, y_inter_x1, y0, y1):\n            out = k_inter_x1\n            return out \n\n        # vector (0, y0)\n        k_inter_y0 = k_inter(X[1], v[1], y0)\n        x_inter_y0 = x_or_y_inter(X[0], k_inter_y0, v[0])\n        if if_inter(k_inter_y0, x_inter_y0, x0, x1):\n            out = k_inter_y0\n            return out \n\n        # vector (0, y1)\n        k_inter_y1 = k_inter(X[1], v[1], y1)\n        x_inter_y1 = x_or_y_inter(X[0], k_inter_y1, v[0])\n        if if_inter(k_inter_y1, x_inter_y1, x0, x1):\n            out = k_inter_y1\n            return out \n\n        return out\n\n# ==========================================\n# File: models/NGM/gnn.py\n# Function/Context: GNNLayer.forward, HyperGNNLayer.forward, HyperConvLayer.forward\n# ==========================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom src.lap_solvers.sinkhorn import Sinkhorn\n\nfrom collections import Iterable\n\nclass GNNLayer(nn.Module):\n    def __init__(self, in_node_features, in_edge_features, out_node_features, out_edge_features,\n                 sk_channel=0, sk_iter=20, sk_tau=0.05, edge_emb=False):\n        super(GNNLayer, self).__init__()\n        self.in_nfeat = in_node_features\n        self.in_efeat = in_edge_features\n        self.out_efeat = out_edge_features\n        self.sk_channel = sk_channel\n        assert out_node_features == out_edge_features + self.sk_channel\n        if self.sk_channel > 0:\n            self.out_nfeat = out_node_features - self.sk_channel\n            self.sk = Sinkhorn(sk_iter, sk_tau)\n            self.classifier = nn.Linear(self.out_nfeat, self.sk_channel)\n        else:\n            self.out_nfeat = out_node_features\n            self.sk = self.classifier = None\n\n        if edge_emb:\n            self.e_func = nn.Sequential(\n                nn.Linear(self.in_efeat + self.in_nfeat, self.out_efeat),\n                nn.ReLU(),\n                nn.Linear(self.out_efeat, self.out_efeat),\n                nn.ReLU()\n            )\n        else:\n            self.e_func = None\n\n        self.n_func = nn.Sequential(\n            nn.Linear(self.in_nfeat, self.out_nfeat),\n            nn.ReLU(),\n            nn.Linear(self.out_nfeat, self.out_nfeat),\n            nn.ReLU(),\n        )\n\n        self.n_self_func = nn.Sequential(\n            nn.Linear(self.in_nfeat, self.out_nfeat),\n            nn.ReLU(),\n            nn.Linear(self.out_nfeat, self.out_nfeat),\n            nn.ReLU()\n        )\n\n    def forward(self, A, W, x, n1=None, n2=None, norm=True):\n        \"\"\"\n        :param A: adjacent matrix in 0/1 (b x n x n)\n        :param W: edge feature tensor (b x n x n x feat_dim)\n        :param x: node feature tensor (b x n x feat_dim)\n        \"\"\"\n        if self.e_func is not None:\n            W1 = torch.mul(A.unsqueeze(-1), x.unsqueeze(1))\n            W2 = torch.cat((W, W1), dim=-1)\n            W_new = self.e_func(W2)\n        else:\n            W_new = W\n\n        if norm is True:\n            A = F.normalize(A, p=1, dim=2)\n\n        x1 = self.n_func(x)\n        x2 = torch.matmul((A.unsqueeze(-1) * W_new).permute(0, 3, 1, 2), x1.unsqueeze(2).permute(0, 3, 1, 2)).squeeze(-1).transpose(1, 2)\n        x2 += self.n_self_func(x)\n\n        if self.classifier is not None:\n            assert n1.max() * n2.max() == x.shape[1]\n            x3 = self.classifier(x2)\n            n1_rep = torch.repeat_interleave(n1, self.sk_channel, dim=0)\n            n2_rep = torch.repeat_interleave(n2, self.sk_channel, dim=0)\n            x4 = x3.permute(0,2,1).reshape(x.shape[0] * self.sk_channel, n2.max(), n1.max()).transpose(1, 2)\n            x5 = self.sk(x4, n1_rep, n2_rep, dummy_row=True).transpose(2, 1).contiguous()\n\n            x6 = x5.reshape(x.shape[0], self.sk_channel, n1.max() * n2.max()).permute(0, 2, 1)\n            x_new = torch.cat((x2, x6), dim=-1)\n        else:\n            x_new = x2\n\n        return W_new, x_new\n\n\nclass HyperGNNLayer(nn.Module):\n    def __init__(self, in_node_features, in_edge_features, out_node_features, out_edge_features, orders=3, eps=1e-10,\n                 sk_channel=False, sk_iter=20, sk_tau=0.05):\n        super(HyperGNNLayer, self).__init__()\n        self.in_nfeat = in_node_features\n        self.in_efeat = in_edge_features\n        self.out_efeat = out_edge_features\n        self.eps = eps\n        self.sk_channel = sk_channel\n        assert out_node_features == out_edge_features + self.sk_channel\n        if self.sk_channel > 0:\n            self.out_nfeat = out_node_features - self.sk_channel\n            self.sk = Sinkhorn(sk_iter, sk_tau)\n            self.classifier = nn.Linear(self.out_nfeat, self.sk_channel)\n        else:\n            self.out_nfeat = out_node_features\n            self.sk = self.classifier = None\n\n        # used by forward_dense\n        self.n_func = nn.Sequential(\n            nn.Linear(self.in_nfeat, self.out_nfeat),\n            nn.ReLU(),\n            nn.Linear(self.out_nfeat, self.out_nfeat),\n            nn.ReLU(),\n        )\n\n        # used by forward_sparse\n        for i in range(2, orders + 1):\n            n_func = nn.Sequential(\n                nn.Linear(self.in_nfeat, self.out_nfeat),\n                nn.ReLU(),\n                nn.Linear(self.out_nfeat, self.out_nfeat),\n                nn.ReLU()\n            )\n            self.add_module('n_func_{}'.format(i), n_func)\n\n        self.n_self_func = nn.Sequential(\n            nn.Linear(self.in_nfeat, self.out_nfeat),\n            nn.ReLU(),\n            nn.Linear(self.out_nfeat, self.out_nfeat),\n            nn.ReLU()\n        )\n\n    def forward(self, A, W, x, n1=None, n2=None, weight=None, norm=True):\n        \"\"\"wrapper function of forward (support dense/sparse)\"\"\"\n        if not isinstance(A, Iterable):\n            A = [A]\n            W = [W]\n\n        W_new = []\n        if weight is None:\n            weight = [1.] * len(A)\n        assert len(weight) == len(A)\n        for i, (_A, _W, w) in enumerate(zip(A, W, weight)):\n            if type(_W) is tuple or (type(_W) is torch.Tensor and _W.is_sparse):\n                _W_new, _x = self.forward_sparse(_A, _W, x, norm)\n            else:\n                _W_new, _x = self.forward_dense(_A, _W, x, norm)\n            if i == 0:\n                x2 = _x * w\n            else:\n                x2 += _x * w\n            W_new.append(_W_new)\n\n        x2 += self.n_self_func(x)\n\n        if self.classifier is not None:\n            assert n1.max() * n2.max() == x.shape[1]\n            x3 = self.classifier(x2)\n            n1_rep = torch.repeat_interleave(n1, self.sk_channel, dim=0)\n            n2_rep = torch.repeat_interleave(n2, self.sk_channel, dim=0)\n            x4 = x3.permute(0,2,1).reshape(x.shape[0] * self.sk_channel, n2.max(), n1.max()).transpose(1, 2)\n            x5 = self.sk(x4, n1_rep, n2_rep, dummy_row=True).transpose(2, 1).contiguous()\n            x6 = x5.reshape(x.shape[0], self.sk_channel, n1.max() * n2.max()).permute(0, 2, 1)\n            x_new = torch.cat((x2, x6), dim=-1)\n        else:\n            x_new = x2\n\n        return W_new, x_new\n\n    def forward_sparse(self, A, W, x, norm=True):\n        \"\"\"\n        :param A: adjacent tensor in 0/1 (b x {n x ... x n})\n        :param W: edge feature tensor (b x {n x ... x n} x feat_dim)\n        :param x: node feature tensor (b x n x feat_dim)\n        \"\"\"\n        order = len(A.shape) - 1\n\n        if type(W) is tuple:\n            W_ind, W_val = W\n        elif type(W) is torch.Tensor and W.is_sparse:\n            W_ind = W._indices()\n            W_val = W._values()\n        else:\n            raise ValueError('Unknown datatype {}'.format(type(W)))\n\n        W_new_val = W_val\n        if norm is True:\n            assert not A.is_sparse, 'sparse normalization is currently not supported'\n            A_sum = torch.sum(A, dim=tuple(range(2, order + 1)), keepdim=True)\n            A = A / A_sum.expand_as(A)\n            A[torch.isnan(A)] = 0\n\n        if not A.is_sparse:\n            A = A.to_sparse()\n\n        assert A._values().shape[0] == W_new_val.shape[0]\n        assert len(W_new_val.shape) == 2\n\n        n_func = getattr(self, 'n_func_{}'.format(order))\n        x1 = n_func(x)\n\n        tp_val = torch.mul(A._values().unsqueeze(-1), W_new_val)\n        for i in range(order - 1):\n            tp_val = x1[W_ind[0, :], W_ind[-1-i, :], :] * tp_val\n\n        assert torch.all(W_ind == A._indices())\n\n        x_new = torch.zeros_like(x1)\n        x_new.index_put_((W_ind[0, :], W_ind[1, :]), tp_val, True)\n\n        return (W_ind, W_new_val), x_new\n\n\n    def forward_dense(self, A, W, x, norm=True):\n        \"\"\"\n        :param A: adjacent tensor in 0/1 (b x {n x ... x n})\n        :param W: edge feature tensor (b x {n x ... x n} x feat_dim)\n        :param x: node feature tensor (b x n x feat_dim)\n        \"\"\"\n        order = len(A.shape) - 1\n        W_new = W\n\n        if norm is True:\n            A_sum = torch.sum(A, dim=tuple(range(2, order + 1)), keepdim=True)\n            A = A / A_sum.expand_as(A)\n            A[torch.isnan(A)] = 0\n\n        x1 = self.n_func(x)\n\n        x_new = torch.mul(A.unsqueeze(-1), W_new)\n        for i in range(order - 1):\n            x1_shape = [x1.shape[0]] + [1] * (order - 1 - i) + list(x1.shape[1:])\n            x_new = torch.sum(torch.mul(x_new, x1.view(*x1_shape)), dim=-2)\n\n        return W_new, x_new\n\n\nclass HyperConvLayer(nn.Module):\n    \"\"\"\n    Hypergarph convolutional layer inspired by \"Dynamic Hypergraph Neural Networks\"\n    \"\"\"\n    def __init__(self, in_node_features, in_edge_features, out_node_features, out_edge_features, eps=0.0001,\n                 sk_channel=False, sk_iter=20, voting_alpha=20):\n        super(HyperConvLayer, self).__init__()\n        self.in_nfeat = in_node_features\n        self.in_efeat = in_edge_features\n        self.out_efeat = out_edge_features\n        self.eps = eps\n        if sk_channel:\n            assert out_node_features == out_edge_features + 1\n            self.out_nfeat = out_node_features - 1\n            self.sk = Sinkhorn(sk_iter, 1 / voting_alpha)\n            self.classifier = nn.Linear(self.out_efeat, 1)\n        else:\n            assert out_node_features == out_edge_features\n            self.out_nfeat = out_node_features\n            self.sk = self.classifier = None\n\n        self.ne_func = nn.Sequential(\n            nn.Linear(self.in_nfeat, self.out_efeat),\n            nn.ReLU())\n\n        self.e_func = nn.Sequential(\n            nn.Linear(self.out_efeat + self.in_efeat, self.out_efeat),\n            nn.ReLU()\n        )\n\n        self.n_func = nn.Sequential(\n            nn.Linear(self.in_nfeat + self.out_efeat, self.out_nfeat),\n            nn.ReLU()\n        )\n\n    def forward(self, H, E, x, n1=None, n2=None, norm=None):\n        \"\"\"\n        :param H: connectivity (b x n x e)\n        :param E: (hyper)edge feature (b x e x f)\n        :param x: node feature (b x n x f)\n        :param n1: number of nodes in graph1\n        :param n2: number of nodes in graph2\n        :param norm: do normalization (only supports dense tensor)\n        :return: new edge feature, new node feature\n        \"\"\"\n        H_node_sum = torch.sum(H, dim=1, keepdim=True)\n        H_node_norm = H / H_node_sum\n        H_node_norm[torch.isnan(H_node_norm)] = 0\n        H_edge_sum = torch.sum(H, dim=2, keepdim=True)\n        H_edge_norm = H / H_edge_sum\n        H_edge_norm[torch.isnan(H_edge_norm)] = 0\n\n        x_to_E = torch.bmm(H_node_norm.transpose(1, 2), self.ne_func(x))\n        new_E = self.e_func(torch.cat((x_to_E, E), dim=-1))\n        E_to_x = torch.bmm(H_edge_norm, new_E)\n        new_x = self.n_func(torch.cat((E_to_x, x), dim=-1))\n\n        if self.classifier is not None:\n            assert n1.max() * n2.max() == x.shape[1]\n            x3 = self.classifier(new_x)\n            x5 = self.sk(x3.view(x.shape[0], n2.max(), n1.max()).transpose(1, 2), n1, n2, dummy_row=True).transpose(2, 1).contiguous()\n\n            new_x = torch.cat((new_x, x5.view(x.shape[0], n1.max() * n2.max(), -1)), dim=-1)\n\n        return new_E, new_x\n\n# ==========================================\n# File: models/NGM/hypermodel_v2.py\n# Function/Context: Net.forward\n# ==========================================\nimport torch\nimport itertools\n\nfrom models.BBGM.affinity_layer import InnerProductWithWeightsAffinity\nfrom models.BBGM.sconv_archs import SiameseSConvOnNodes, SiameseNodeFeaturesToEdgeFeatures\nfrom src.feature_align import feature_align\nfrom src.factorize_graph_matching import construct_aff_mat\nfrom models.NGM.gnn import HyperGNNLayer\nfrom src.lap_solvers.sinkhorn import Sinkhorn\nfrom src.lap_solvers.hungarian import hungarian\nfrom src.utils.pad_tensor import pad_tensor\nfrom src.utils.sparse import to_sparse\n\nfrom src.utils.config import cfg\n\nfrom src.backbone import *\nCNN = eval(cfg.BACKBONE)\n\n\ndef lexico_iter(lex):\n    return itertools.combinations(lex, 2)\n\n\ndef normalize_over_channels(x):\n    channel_norms = torch.norm(x, dim=1, keepdim=True)\n    return x / channel_norms\n\n\ndef concat_features(embeddings, num_vertices):\n    res = torch.cat([embedding[:, :num_v] for embedding, num_v in zip(embeddings, num_vertices)], dim=-1)\n    return res.transpose(0, 1)\n\n\ndef construct_hyperE(ori_graphs, batch_size, device):\n    nmax = max([g.num_nodes for g in ori_graphs])\n    emax = max([g.hyperedge_index.shape[1] for g in ori_graphs])\n    hyperE = torch.zeros(batch_size, nmax, nmax, nmax, emax, device=device)\n    for b, g in enumerate(ori_graphs):\n        hyperE[b][g.hyperedge_index[0], g.hyperedge_index[1], g.hyperedge_index[2], torch.arange(\n            g.hyperedge_index.shape[1])] = 1\n    return hyperE, nmax, emax\n\n\ndef hyperedge_affinity(attrs1, attrs2):\n    ret_list = []\n    for attr1, attr2 in zip(attrs1, attrs2):\n        X = attr1.unsqueeze(1).expand(attr1.shape[0], attr2.shape[0], attr1.shape[1])\n        Y = attr2.unsqueeze(0).expand(attr1.shape[0], attr2.shape[0], attr2.shape[1])\n        dist = torch.sum(torch.pow(X - Y, 2), dim=-1)\n        dist[torch.isnan(dist)] = float(\"inf\")\n        ret_list.append(torch.exp(- dist / cfg.NGM.SIGMA3))\n    return ret_list\n\n\nclass Net(CNN):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.message_pass_node_features = SiameseSConvOnNodes(input_node_dim=cfg.NGM.FEATURE_CHANNEL * 2)\n        self.build_edge_features_from_node_features = SiameseNodeFeaturesToEdgeFeatures(\n            total_num_nodes=self.message_pass_node_features.num_node_features\n        )\n        self.global_state_dim = cfg.NGM.FEATURE_CHANNEL * 2\n        self.vertex_affinity = InnerProductWithWeightsAffinity(\n            self.global_state_dim, self.message_pass_node_features.num_node_features)\n        self.edge_affinity = InnerProductWithWeightsAffinity(\n            self.global_state_dim, self.build_edge_features_from_node_features.num_edge_features)\n        #self.hyperedge_affinity = InnerProductWithWeightsAffinity(\n        #    self.global_state_dim, self.build_edge_features_from_node_features.num_edge_features)\n\n        self.rescale = cfg.PROBLEM.RESCALE\n        self.tau = cfg.NGM.SK_TAU\n        self.univ_size = cfg.NGM.UNIV_SIZE\n\n        self.sinkhorn = Sinkhorn(max_iter=cfg.NGM.SK_ITER_NUM, tau=self.tau, epsilon=cfg.NGM.SK_EPSILON)\n        self.sinkhorn_mgm = Sinkhorn(max_iter=cfg.NGM.SK_ITER_NUM, epsilon=cfg.NGM.SK_EPSILON, tau=1.)\n        self.gnn_layer = cfg.NGM.GNN_LAYER\n        for i in range(self.gnn_layer):\n            if i == 0:\n                gnn_layer = HyperGNNLayer(\n                    1, 1, cfg.NGM.GNN_FEAT[i] + cfg.NGM.SK_EMB, cfg.NGM.GNN_FEAT[i],\n                    sk_channel=cfg.NGM.SK_EMB, sk_tau=self.tau\n                )\n            else:\n                gnn_layer = HyperGNNLayer(\n                    cfg.NGM.GNN_FEAT[i - 1] + cfg.NGM.SK_EMB, cfg.NGM.GNN_FEAT[i - 1],\n                    cfg.NGM.GNN_FEAT[i] + cfg.NGM.SK_EMB, cfg.NGM.GNN_FEAT[i],\n                    sk_channel=cfg.NGM.SK_EMB, sk_tau=self.tau\n                )\n            self.add_module('gnn_layer_{}'.format(i), gnn_layer)\n        self.classifier = nn.Linear(cfg.NGM.GNN_FEAT[-1] + cfg.NGM.SK_EMB, 1)\n\n    def forward(\n        self,\n        data_dict,\n    ):\n        images = data_dict['images']\n        points = data_dict['Ps']\n        n_points = data_dict['ns']\n        graphs = data_dict['pyg_graphs']\n        batch_size = data_dict['batch_size']\n        num_graphs = len(images)\n\n        if cfg.PROBLEM.TYPE == '2GM' and 'gt_perm_mat' in data_dict:\n            gt_perm_mats = [data_dict['gt_perm_mat']]\n        elif cfg.PROBLEM.TYPE == 'MGM' and 'gt_perm_mat' in data_dict:\n            perm_mat_list = data_dict['gt_perm_mat']\n            gt_perm_mats = [torch.bmm(pm_src, pm_tgt.transpose(1, 2)) for pm_src, pm_tgt in lexico_iter(perm_mat_list)]\n        else:\n            raise ValueError('Ground truth information is required during training.')\n\n        global_list = []\n        orig_graph_list = []\n        for image, p, n_p, graph in zip(images, points, n_points, graphs):\n            # extract feature\n            nodes = self.node_layers(image)\n            edges = self.edge_layers(nodes)\n\n            global_list.append(self.final_layers(edges).reshape((nodes.shape[0], -1)))\n            nodes = normalize_over_channels(nodes)\n            edges = normalize_over_channels(edges)\n\n            # arrange features\n            U = concat_features(feature_align(nodes, p, n_p, self.rescale), n_p)\n            F = concat_features(feature_align(edges, p, n_p, self.rescale), n_p)\n            node_features = torch.cat((U, F), dim=1)\n            graph.x = node_features\n\n            graph = self.message_pass_node_features(graph)\n            orig_graph = self.build_edge_features_from_node_features(graph, hyperedge=True)\n            orig_graph_list.append(orig_graph)\n\n        global_weights_list = [\n            torch.cat([global_src, global_tgt], axis=-1) for global_src, global_tgt in lexico_iter(global_list)\n        ]\n\n        global_weights_list = [normalize_over_channels(g) for g in global_weights_list]\n\n        unary_affs_list = [\n            self.vertex_affinity([item.x for item in g_1], [item.x for item in g_2], global_weights)\n            for (g_1, g_2), global_weights in zip(lexico_iter(orig_graph_list), global_weights_list)\n        ]\n\n        quadratic_affs_list = [\n            self.edge_affinity([item.edge_attr for item in g_1], [item.edge_attr for item in g_2], global_weights)\n            for (g_1, g_2), global_weights in zip(lexico_iter(orig_graph_list), global_weights_list)\n        ]\n\n        quadratic_affs_list = [[0.5 * x for x in quadratic_affs] for quadratic_affs in quadratic_affs_list]\n\n        order3_affs_list = [\n            hyperedge_affinity([item.hyperedge_attr for item in g_1], [item.hyperedge_attr for item in g_2])\n            for (g_1, g_2), global_weights in zip(lexico_iter(orig_graph_list), global_weights_list)\n        ]\n\n        s_list, mgm_s_list, x_list, mgm_x_list, indices = [], [], [], [], []\n\n        for unary_affs, quadratic_affs, order3_affs, (g1, g2), (idx1, idx2) in \\\n            zip(unary_affs_list, quadratic_affs_list, order3_affs_list, lexico_iter(orig_graph_list), lexico_iter(range(num_graphs))):\n            kro_G, kro_H = data_dict['KGHs'] if num_graphs == 2 else data_dict['KGHs']['{},{}'.format(idx1, idx2)]\n            Kp = torch.stack(pad_tensor(unary_affs), dim=0)\n            Ke = torch.stack(pad_tensor(quadratic_affs), dim=0)\n            He = torch.stack(pad_tensor(order3_affs))\n            K = construct_aff_mat(Ke, Kp, kro_G, kro_H)\n\n            # build hyper graph tensor H\n            hyperE1, nmax1, emax1 = construct_hyperE(g1, batch_size, He.device)\n            hyperE2, nmax2, emax2 = construct_hyperE(g2, batch_size, He.device)\n            H = torch.bmm(torch.bmm(\n                hyperE1.reshape(batch_size, -1, emax1), He), hyperE2.reshape(batch_size, -1, emax2).transpose(1, 2))\\\n                .reshape(batch_size, nmax1, nmax1, nmax1, nmax2, nmax2, nmax2).permute(0, 4, 1, 5, 2, 6, 3)\\\n                .reshape(batch_size, nmax1*nmax2, nmax1*nmax2, nmax1*nmax2)\n\n            if num_graphs == 2: data_dict['aff_mat'] = K\n\n            if cfg.NGM.FIRST_ORDER:\n                emb = Kp.transpose(1, 2).contiguous().view(Kp.shape[0], -1, 1)\n            else:\n                emb = torch.ones(K.shape[0], K.shape[1], 1, device=K.device)\n\n            if cfg.NGM.POSITIVE_EDGES:\n                adjs = [(K > 0).to(K.dtype), (H > 0).to(H.dtype)]\n            else:\n                adjs = [(K != 0).to(K.dtype), (H != 0).to(H.dtype)]\n\n            emb_edges = [K.unsqueeze(-1), to_sparse(H.unsqueeze(-1), dense_dim=2)]\n\n            # NGM qap solver\n            for i in range(self.gnn_layer):\n                gnn_layer = getattr(self, 'gnn_layer_{}'.format(i))\n                emb_edges, emb = gnn_layer(adjs, emb_edges, emb, n_points[idx1], n_points[idx2]) #, weight=[1, 0.1])\n\n            v = self.classifier(emb)\n            s = v.view(v.shape[0], points[idx2].shape[1], -1).transpose(1, 2)\n\n            ss = self.sinkhorn(s, n_points[idx1], n_points[idx2], dummy_row=True)\n            x = hungarian(ss, n_points[idx1], n_points[idx2])\n            s_list.append(ss)\n            x_list.append(x)\n            indices.append((idx1, idx2))\n\n        if num_graphs > 2:\n            joint_indices = torch.cat((torch.cumsum(torch.stack([torch.max(np) for np in n_points]), dim=0), torch.zeros((1,), dtype=torch.long, device=K.device)))\n            joint_S = torch.zeros(batch_size, torch.max(joint_indices), torch.max(joint_indices), device=K.device)\n            for idx in range(num_graphs):\n                for b in range(batch_size):\n                    start = joint_indices[idx-1]\n                    joint_S[b, start:start+n_points[idx][b], start:start+n_points[idx][b]] += torch.eye(n_points[idx][b], device=K.device)\n\n            for (idx1, idx2), s in zip(indices, s_list):\n                if idx1 > idx2:\n                    joint_S[:, joint_indices[idx2-1]:joint_indices[idx2], joint_indices[idx1-1]:joint_indices[idx1]] += s.transpose(1, 2)\n                else:\n                    joint_S[:, joint_indices[idx1-1]:joint_indices[idx1], joint_indices[idx2-1]:joint_indices[idx2]] += s\n\n            matching_s = []\n            for b in range(batch_size):\n                e, v = torch.symeig(joint_S[b], eigenvectors=True)\n                diff = e[-self.univ_size:-1] - e[-self.univ_size+1:]\n                if self.training and torch.min(torch.abs(diff)) <= 1e-4:\n                    matching_s.append(joint_S[b])\n                else:\n                    matching_s.append(num_graphs * torch.mm(v[:, -self.univ_size:], v[:, -self.univ_size:].transpose(0, 1)))\n\n            matching_s = torch.stack(matching_s, dim=0)\n\n            for idx1, idx2 in indices:\n                s = matching_s[:, joint_indices[idx1-1]:joint_indices[idx1], joint_indices[idx2-1]:joint_indices[idx2]]\n                s = self.sinkhorn_mgm(torch.log(torch.relu(s)), n_points[idx1], n_points[idx2]) # only perform row/col norm, do not perform exp\n                x = hungarian(s, n_points[idx1], n_points[idx2])\n\n                mgm_s_list.append(s)\n                mgm_x_list.append(x)\n\n        if cfg.PROBLEM.TYPE == '2GM':\n            data_dict.update({\n                'ds_mat': s_list[0],\n                'perm_mat': x_list[0]\n            })\n        elif cfg.PROBLEM.TYPE == 'MGM':\n            data_dict.update({\n                'ds_mat_list': mgm_s_list,\n                'perm_mat_list': mgm_x_list,\n                'graph_indices': indices,\n                'gt_perm_mat_list': gt_perm_mats\n            })\n\n        return data_dict\n\n# ==========================================\n# File: models/NGM/model_v2.py\n# Function/Context: Net.forward\n# ==========================================\nimport torch\nimport itertools\n\nfrom models.BBGM.affinity_layer import InnerProductWithWeightsAffinity\nfrom models.BBGM.sconv_archs import SiameseSConvOnNodes, SiameseNodeFeaturesToEdgeFeatures\nfrom src.feature_align import feature_align\nfrom src.factorize_graph_matching import construct_aff_mat\nfrom src.utils.pad_tensor import pad_tensor\nfrom models.NGM.gnn import GNNLayer\nfrom src.lap_solvers.sinkhorn import Sinkhorn\nfrom src.lap_solvers.hungarian import hungarian\n\nfrom src.utils.config import cfg\n\nfrom src.backbone import *\n#CNN = eval(cfg.BACKBONE)\nCNN = eval('VGG16_bn_final')\n\ndef lexico_iter(lex):\n    return itertools.combinations(lex, 2)\n\ndef normalize_over_channels(x):\n    channel_norms = torch.norm(x, dim=1, keepdim=True)\n    return x / channel_norms\n\ndef concat_features(embeddings, num_vertices):\n    res = torch.cat([embedding[:, :num_v] for embedding, num_v in zip(embeddings, num_vertices)], dim=-1)\n    return res.transpose(0, 1)\n\nclass Net(CNN):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.message_pass_node_features = SiameseSConvOnNodes(input_node_dim=cfg.NGM.FEATURE_CHANNEL * 2)\n        self.build_edge_features_from_node_features = SiameseNodeFeaturesToEdgeFeatures(\n            total_num_nodes=self.message_pass_node_features.num_node_features\n        )\n        self.global_state_dim = cfg.NGM.FEATURE_CHANNEL * 2\n        self.vertex_affinity = InnerProductWithWeightsAffinity(\n            self.global_state_dim, self.message_pass_node_features.num_node_features)\n        self.edge_affinity = InnerProductWithWeightsAffinity(\n            self.global_state_dim,\n            self.build_edge_features_from_node_features.num_edge_features)\n\n        self.rescale = cfg.PROBLEM.RESCALE\n        self.tau = cfg.NGM.SK_TAU\n        self.mgm_tau = cfg.NGM.MGM_SK_TAU\n        self.univ_size = cfg.NGM.UNIV_SIZE\n\n        self.sinkhorn = Sinkhorn(max_iter=cfg.NGM.SK_ITER_NUM, tau=self.tau, epsilon=cfg.NGM.SK_EPSILON)\n        self.sinkhorn_mgm = Sinkhorn(max_iter=cfg.NGM.SK_ITER_NUM, epsilon=cfg.NGM.SK_EPSILON, tau=self.mgm_tau)\n        self.gnn_layer = cfg.NGM.GNN_LAYER\n        for i in range(self.gnn_layer):\n            tau = cfg.NGM.SK_TAU\n            if i == 0:\n                gnn_layer = GNNLayer(1, 1,\n                                     cfg.NGM.GNN_FEAT[i] + cfg.NGM.SK_EMB, cfg.NGM.GNN_FEAT[i],\n                                     sk_channel=cfg.NGM.SK_EMB, sk_tau=tau, edge_emb=cfg.NGM.EDGE_EMB)\n            else:\n                gnn_layer = GNNLayer(cfg.NGM.GNN_FEAT[i - 1] + cfg.NGM.SK_EMB, cfg.NGM.GNN_FEAT[i - 1],\n                                     cfg.NGM.GNN_FEAT[i] + cfg.NGM.SK_EMB, cfg.NGM.GNN_FEAT[i],\n                                     sk_channel=cfg.NGM.SK_EMB, sk_tau=tau, edge_emb=cfg.NGM.EDGE_EMB)\n            self.add_module('gnn_layer_{}'.format(i), gnn_layer)\n        self.classifier = nn.Linear(cfg.NGM.GNN_FEAT[-1] + cfg.NGM.SK_EMB, 1)\n\n    def forward(\n        self,\n        data_dict,\n        forward_mode=cfg.TRAIN.FEAT_ATT_MODE,\n        affinity_mask=cfg.EVAL.AFF_MASK\n    ):\n        images = data_dict['images']\n        images_ori = data_dict['images_ori']\n    \n        points = data_dict['Ps']\n        points_ori = data_dict['Ps_ori']\n\n        n_points = data_dict['ns']\n        graphs = data_dict['pyg_graphs']\n        batch_size = data_dict['batch_size']\n        num_graphs = len(images)\n\n        if cfg.PROBLEM.TYPE == '2GM' and 'gt_perm_mat' in data_dict:\n            gt_perm_mats = [data_dict['gt_perm_mat']]\n        elif cfg.PROBLEM.TYPE == 'MGM' and 'gt_perm_mat' in data_dict:\n            perm_mat_list = data_dict['gt_perm_mat']\n            gt_perm_mats = [torch.bmm(pm_src, pm_tgt.transpose(1, 2)) for pm_src, pm_tgt in lexico_iter(perm_mat_list)]\n        else:\n            raise ValueError('Ground truth information is required during training.')\n\n        global_list = []\n        orig_graph_list = []\n        for image, image_ori, p, p_ori, n_p, graph in zip(images, images_ori, points, points_ori, n_points, graphs):\n            # extract feature\n            if forward_mode == 'both':\n                nodes = self.node_layers(image)\n                edges = self.edge_layers(nodes)\n            elif forward_mode == 'only_nodes':\n                # only perturb node features \n                nodes = self.node_layers(image)\n                with torch.no_grad():\n                    nodes_ori = self.node_layers(image_ori)\n                    edges = self.edge_layers(nodes_ori)\n            elif forward_mode == 'only_edges':\n                # only perturb edge features \n                with torch.no_grad():\n                    nodes = self.node_layers(image_ori)\n                nodes_att = self.node_layers(image)\n                edges = self.edge_layers(nodes_att)\n            else:\n                raise ValueError('Unknown forward_mode. optional: both | only_nodes | only_edges.')\n            global_list.append(self.final_layers(edges).reshape((nodes.shape[0], -1)))\n            nodes = normalize_over_channels(nodes)\n            edges = normalize_over_channels(edges)\n\n            # arrange features\n            if forward_mode == 'both':\n                U = concat_features(feature_align(nodes, p, n_p, self.rescale), n_p)\n                F = concat_features(feature_align(edges, p, n_p, self.rescale), n_p)\n            elif forward_mode == 'only_nodes':\n                U = concat_features(feature_align(nodes, p, n_p, self.rescale), n_p)\n                F = concat_features(feature_align(edges, p_ori, n_p, self.rescale), n_p)\n            elif forward_mode == 'only_edges':\n                U = concat_features(feature_align(nodes, p_ori, n_p, self.rescale), n_p)\n                F = concat_features(feature_align(edges, p, n_p, self.rescale), n_p)\n            else:\n                raise ValueError('Unknown forward_mode. optional: both | only_nodes | only_edges.')\n\n            node_features = torch.cat((U, F), dim=1)\n            graph.x = node_features\n\n            graph = self.message_pass_node_features(graph)\n            orig_graph = self.build_edge_features_from_node_features(graph)\n            orig_graph_list.append(orig_graph)\n\n        global_weights_list = [\n            torch.cat([global_src, global_tgt], axis=-1) for global_src, global_tgt in lexico_iter(global_list)\n        ]\n\n        global_weights_list = [normalize_over_channels(g) for g in global_weights_list]\n\n        unary_affs_list = [\n            self.vertex_affinity([item.x for item in g_1], [item.x for item in g_2], global_weights)\n            for (g_1, g_2), global_weights in zip(lexico_iter(orig_graph_list), global_weights_list)\n        ]\n\n        quadratic_affs_list = [\n            self.edge_affinity([item.edge_attr for item in g_1], [item.edge_attr for item in g_2], global_weights)\n            for (g_1, g_2), global_weights in zip(lexico_iter(orig_graph_list), global_weights_list)\n        ]\n\n        quadratic_affs_list = [[0.5 * x for x in quadratic_affs] for quadratic_affs in quadratic_affs_list]\n\n        s_list, mgm_s_list, x_list, mgm_x_list, indices = [], [], [], [], []\n\n        for unary_affs, quadratic_affs, (idx1, idx2) in zip(unary_affs_list, quadratic_affs_list, lexico_iter(range(num_graphs))):\n            kro_G, kro_H = data_dict['KGHs'] if num_graphs == 2 else data_dict['KGHs']['{},{}'.format(idx1, idx2)]\n            Kp = torch.stack(pad_tensor(unary_affs), dim=0)\n            Ke = torch.stack(pad_tensor(quadratic_affs), dim=0)\n            K = construct_aff_mat(Ke, Kp, kro_G, kro_H)\n            if affinity_mask:\n                mask = torch.eye(*K.shape[1:], dtype=K.dtype, device=K.device )\n                mask = (torch.ones_like(mask, dtype=K.dtype, device=K.device) - mask ).detach()\n                K = K * mask\n\n            if num_graphs == 2: data_dict['aff_mat'] = K\n\n            if cfg.NGM.FIRST_ORDER:\n                emb = Kp.transpose(1, 2).contiguous().view(Kp.shape[0], -1, 1)\n            else:\n                emb = torch.ones(K.shape[0], K.shape[1], 1, device=K.device)\n\n            if cfg.NGM.POSITIVE_EDGES:\n                A = (K > 0).to(K.dtype)\n            else:\n                A = (K != 0).to(K.dtype)\n\n            emb_K = K.unsqueeze(-1)\n\n            # NGM qap solver\n            for i in range(self.gnn_layer):\n                gnn_layer = getattr(self, 'gnn_layer_{}'.format(i))\n                emb_K, emb = gnn_layer(A, emb_K, emb, n_points[idx1], n_points[idx2])\n\n            v = self.classifier(emb)\n            s = v.view(v.shape[0], points[idx2].shape[1], -1).transpose(1, 2)\n\n            ss = self.sinkhorn(s, n_points[idx1], n_points[idx2], dummy_row=True)\n            x = hungarian(ss, n_points[idx1], n_points[idx2])\n            s_list.append(ss)\n            x_list.append(x)\n            indices.append((idx1, idx2))\n\n        if num_graphs > 2:\n            joint_indices = torch.cat((torch.cumsum(torch.stack([torch.max(np) for np in n_points]), dim=0), torch.zeros((1,), dtype=torch.long, device=K.device)))\n            joint_S = torch.zeros(batch_size, torch.max(joint_indices), torch.max(joint_indices), device=K.device)\n            for idx in range(num_graphs):\n                for b in range(batch_size):\n                    start = joint_indices[idx-1]\n                    joint_S[b, start:start+n_points[idx][b], start:start+n_points[idx][b]] += torch.eye(n_points[idx][b], device=K.device)\n\n            for (idx1, idx2), s in zip(indices, s_list):\n                if idx1 > idx2:\n                    joint_S[:, joint_indices[idx2-1]:joint_indices[idx2], joint_indices[idx1-1]:joint_indices[idx1]] += s.transpose(1, 2)\n                else:\n                    joint_S[:, joint_indices[idx1-1]:joint_indices[idx1], joint_indices[idx2-1]:joint_indices[idx2]] += s\n\n            matching_s = []\n            for b in range(batch_size):\n                e, v = torch.symeig(joint_S[b], eigenvectors=True)\n                diff = e[-self.univ_size:-1] - e[-self.univ_size+1:]\n                if self.training and torch.min(torch.abs(diff)) <= 1e-4:\n                    matching_s.append(joint_S[b])\n                else:\n                    matching_s.append(num_graphs * torch.mm(v[:, -self.univ_size:], v[:, -self.univ_size:].transpose(0, 1)))\n\n            matching_s = torch.stack(matching_s, dim=0)\n\n            for idx1, idx2 in indices:\n                s = matching_s[:, joint_indices[idx1-1]:joint_indices[idx1], joint_indices[idx2-1]:joint_indices[idx2]]\n                s = self.sinkhorn_mgm(torch.log(torch.relu(s)), n_points[idx1], n_points[idx2]) # only perform row/col norm, do not perform exp\n                x = hungarian(s, n_points[idx1], n_points[idx2])\n\n                mgm_s_list.append(s)\n                mgm_x_list.append(x)\n\n        if cfg.PROBLEM.TYPE == '2GM':\n            data_dict.update({\n                'ds_mat': s_list[0],\n                'perm_mat': x_list[0]\n            })\n        elif cfg.PROBLEM.TYPE == 'MGM':\n            data_dict.update({\n                'ds_mat_list': mgm_s_list,\n                'perm_mat_list': mgm_x_list,\n                'graph_indices': indices,\n                'gt_perm_mat_list': gt_perm_mats\n            })\n\n        return data_dict\n\n# ==========================================\n# File: src/lap_solvers/sinkhorn.py\n# Function/Context: Sinkhorn\n# ==========================================\nimport torch\nimport torch.nn as nn\nfrom torch import Tensor\n\n\nclass Sinkhorn(nn.Module):\n    r\"\"\"\n    Sinkhorn algorithm turns the input matrix into a bi-stochastic matrix.\n\n    Sinkhorn algorithm firstly applies an ``exp`` function with temperature :math:`\\tau`:\n\n    .. math::\n        \\mathbf{S}_{i,j} = \\exp \\left(\\frac{\\mathbf{s}_{i,j}}{\\tau}\\right)\n\n    And then turns the matrix into doubly-stochastic matrix by iterative row- and column-wise normalization:\n\n    .. math::\n        \\mathbf{S} &= \\mathbf{S} \\oslash (\\mathbf{1}_{n_2} \\mathbf{1}_{n_2}^\\top \\cdot \\mathbf{S}) \\\\\n        \\mathbf{S} &= \\mathbf{S} \\oslash (\\mathbf{S} \\cdot \\mathbf{1}_{n_2} \\mathbf{1}_{n_2}^\\top)\n\n    where :math:`\\oslash` means element-wise division, :math:`\\mathbf{1}_n` means a column-vector with length :math:`n`\n    whose elements are all :math:`1`\\ s.\n\n    :param max_iter: maximum iterations (default: ``10``)\n    :param tau: the hyper parameter :math:`\\tau` controlling the temperature (default: ``1``)\n    :param epsilon: a small number for numerical stability (default: ``1e-4``)\n    :param log_forward: apply log-scale computation for better numerical stability (default: ``True``)\n    :param batched_operation: apply batched_operation for better efficiency (but may cause issues for back-propagation,\n     default: ``False``)\n\n    .. note::\n        ``tau`` is an important hyper parameter to be set for Sinkhorn algorithm. ``tau`` controls the distance between\n        the predicted doubly-stochastic matrix, and the discrete permutation matrix computed by Hungarian algorithm (see\n        :func:`~src.lap_solvers.hungarian.hungarian`). Given a small ``tau``, Sinkhorn performs more closely to\n        Hungarian, at the cost of slower convergence speed and reduced numerical stability.\n\n    .. note::\n        We recommend setting ``log_forward=True`` because it is more numerically stable. It provides more precise\n        gradient in back propagation and helps the model to converge better and faster.\n\n    .. warning::\n        If you set ``log_forward=False``, this function behaves a little bit differently: it does not include the\n        ``exp`` part.\n\n    .. note::\n        Setting ``batched_operation=True`` may be preferred when you are doing inference with this module and do not\n        need the gradient.\n    \"\"\"\n    def __init__(self, max_iter: int=10, tau: float=1., epsilon: float=1e-4,\n                 log_forward: bool=True, batched_operation: bool=False):\n        super(Sinkhorn, self).__init__()\n        self.max_iter = max_iter\n        self.tau = tau\n        self.epsilon = epsilon\n        self.log_forward = log_forward\n        if not log_forward:\n            print('Warning: Sinkhorn algorithm without log forward is deprecated because log_forward is more stable.')\n        self.batched_operation = batched_operation # batched operation may cause instability in backward computation,\n                                                   # but will boost computation.\n\n    def forward(self, s: Tensor, nrows: Tensor=None, ncols: Tensor=None, dummy_row: bool=False) -> Tensor:\n        r\"\"\"\n        :param s: :math:`(b\\times n_1 \\times n_2)` input 3d tensor. :math:`b`: batch size\n        :param nrows: :math:`(b)` number of objects in dim1\n        :param ncols: :math:`(b)` number of objects in dim2\n        :param dummy_row: whether to add dummy rows (rows whose elements are all 0) to pad the matrix to square matrix.\n         default: ``False``\n        :return: :math:`(b\\times n_1 \\times n_2)` the computed doubly-stochastic matrix\n\n        .. note::\n            We support batched instances with different number of nodes, therefore ``nrows`` and ``ncols`` are\n            required to specify the exact number of objects of each dimension in the batch. If not specified, we assume\n            the batched matrices are not padded.\n\n        .. note::\n            The original Sinkhorn algorithm only works for square matrices. To handle cases where the graphs to be\n            matched have different number of nodes, it is a common practice to add dummy rows to construct a square\n            matrix. After the row and column normalizations, the padded rows are discarded.\n\n        .. note::\n            We assume row number <= column number. If not, the input matrix will be transposed.\n        \"\"\"\n        if self.log_forward:\n            return self.forward_log(s, nrows, ncols, dummy_row)\n        else:\n            return self.forward_ori(s, nrows, ncols, dummy_row) # deprecated\n\n    def forward_log(self, s, nrows=None, ncols=None, dummy_row=False):\n        \"\"\"Compute sinkhorn with row/column normalization in the log space.\"\"\"\n        if len(s.shape) == 2:\n            s = s.unsqueeze(0)\n            matrix_input = True\n        elif len(s.shape) == 3:\n            matrix_input = False\n        else:\n            raise ValueError('input data shape not understood.')\n\n        batch_size = s.shape[0]\n\n        if s.shape[2] >= s.shape[1]:\n            transposed = False\n        else:\n            s = s.transpose(1, 2)\n            transposed = True\n\n        if nrows is None:\n            nrows = [s.shape[1] for _ in range(batch_size)]\n        if ncols is None:\n            ncols = [s.shape[2] for _ in range(batch_size)]\n\n        # operations are performed on log_s\n        s = s / self.tau\n\n        if dummy_row:\n            assert s.shape[2] >= s.shape[1]\n            dummy_shape = list(s.shape)\n            dummy_shape[1] = s.shape[2] - s.shape[1]\n            ori_nrows = nrows\n            nrows = ncols\n            s = torch.cat((s, torch.full(dummy_shape, -float('inf')).to(s.device)), dim=1)\n            for b in range(batch_size):\n                s[b, ori_nrows[b]:nrows[b], :ncols[b]] = -100\n                s[b, nrows[b]:, :] = -float('inf')\n                s[b, :, ncols[b]:] = -float('inf')\n\n        if self.batched_operation:\n            log_s = s\n\n            for i in range(self.max_iter):\n                if i % 2 == 0:\n                    log_sum = torch.logsumexp(log_s, 2, keepdim=True)\n                    log_s = log_s - log_sum\n                    log_s[torch.isnan(log_s)] = -float('inf')\n                else:\n                    log_sum = torch.logsumexp(log_s, 1, keepdim=True)\n                    log_s = log_s - log_sum\n                    log_s[torch.isnan(log_s)] = -float('inf')\n\n                # ret_log_s[b, row_slice, col_slice] = log_s\n\n            if dummy_row and dummy_shape[1] > 0:\n                log_s = log_s[:, :-dummy_shape[1]]\n                for b in range(batch_size):\n                    log_s[b, ori_nrows[b]:nrows[b], :ncols[b]] = -float('inf')\n\n            if matrix_input:\n                log_s.squeeze_(0)\n\n            return torch.exp(log_s)\n        else:\n            ret_log_s = torch.full((batch_size, s.shape[1], s.shape[2]), -float('inf'), device=s.device, dtype=s.dtype)\n\n            for b in range(batch_size):\n                row_slice = slice(0, nrows[b])\n                col_slice = slice(0, ncols[b])\n                log_s = s[b, row_slice, col_slice]\n\n                for i in range(self.max_iter):\n                    if i % 2 == 0:\n                        log_sum = torch.logsumexp(log_s, 1, keepdim=True)\n                        log_s = log_s - log_sum\n                    else:\n                        log_sum = torch.logsumexp(log_s, 0, keepdim=True)\n                        log_s = log_s - log_sum\n\n                ret_log_s[b, row_slice, col_slice] = log_s\n\n            if dummy_row:\n                if dummy_shape[1] > 0:\n                    ret_log_s = ret_log_s[:, :-dummy_shape[1]]\n                for b in range(batch_size):\n                    ret_log_s[b, ori_nrows[b]:nrows[b], :ncols[b]] = -float('inf')\n\n            if transposed:\n                ret_log_s = ret_log_s.transpose(1, 2)\n            if matrix_input:\n                ret_log_s.squeeze_(0)\n\n            return torch.exp(ret_log_s)\n\n        # ret_log_s = torch.full((batch_size, s.shape[1], s.shape[2]), -float('inf'), device=s.device, dtype=s.dtype)\n\n        # for b in range(batch_size):\n        #    row_slice = slice(0, nrows[b])\n        #    col_slice = slice(0, ncols[b])\n        #    log_s = s[b, row_slice, col_slice]\n\n    def forward_ori(self, s, nrows=None, ncols=None, dummy_row=False):\n        r\"\"\"\n        Computing sinkhorn with row/column normalization.\n\n        .. warning::\n            This function is deprecated because :meth:`~src.lap_solvers.sinkhorn.Sinkhorn.forward_log` is more\n            numerically stable.\n        \"\"\"\n        if len(s.shape) == 2:\n            s = s.unsqueeze(0)\n            matrix_input = True\n        elif len(s.shape) == 3:\n            matrix_input = False\n        else:\n            raise ValueError('input data shape not understood.')\n\n        batch_size = s.shape[0]\n\n        #s = s.to(dtype=dtype)\n\n        if nrows is None:\n            nrows = [s.shape[1] for _ in range(batch_size)]\n        if ncols is None:\n            ncols = [s.shape[2] for _ in range(batch_size)]\n\n        # tau scaling\n        ret_s = torch.zeros_like(s)\n        for b, n in enumerate(nrows):\n            ret_s[b, 0:n, 0:ncols[b]] = \\\n                nn.functional.softmax(s[b, 0:n, 0:ncols[b]] / self.tau, dim=-1)\n        s = ret_s\n\n        # add dummy elements\n        if dummy_row:\n            dummy_shape = list(s.shape)\n            dummy_shape[1] = s.shape[2] - s.shape[1]\n            #s = torch.cat((s, torch.full(dummy_shape, self.epsilon * 10).to(s.device)), dim=1)\n            #nrows = nrows + dummy_shape[1] # non in-place\n            s = torch.cat((s, torch.full(dummy_shape, 0.).to(s.device)), dim=1)\n            ori_nrows = nrows\n            nrows = ncols\n            for b in range(batch_size):\n                s[b, ori_nrows[b]:nrows[b], :ncols[b]] = self.epsilon\n\n        row_norm_ones = torch.zeros(batch_size, s.shape[1], s.shape[1], device=s.device, dtype=s.dtype)  # size: row x row\n        col_norm_ones = torch.zeros(batch_size, s.shape[2], s.shape[2], device=s.device, dtype=s.dtype)  # size: col x col\n        for b in range(batch_size):\n            row_slice = slice(0, nrows[b])\n            col_slice = slice(0, ncols[b])\n            row_norm_ones[b, row_slice, row_slice] = 1\n            col_norm_ones[b, col_slice, col_slice] = 1\n\n        s += self.epsilon\n\n        for i in range(self.max_iter):\n            if i % 2 == 0:\n                # column norm\n                #ones = torch.ones(batch_size, s.shape[1], s.shape[1], device=s.device)\n                sum = torch.sum(torch.mul(s.unsqueeze(3), col_norm_ones.unsqueeze(1)), dim=2)\n            else:\n                # row norm\n                # ones = torch.ones(batch_size, s.shape[2], s.shape[2], device=s.device)\n                sum = torch.sum(torch.mul(row_norm_ones.unsqueeze(3), s.unsqueeze(1)), dim=2)\n\n            tmp = torch.zeros_like(s)\n            for b in range(batch_size):\n                row_slice = slice(0, nrows[b] if nrows is not None else s.shape[2])\n                col_slice = slice(0, ncols[b] if ncols is not None else s.shape[1])\n                tmp[b, row_slice, col_slice] = 1 / sum[b, row_slice, col_slice]\n            s = s * tmp\n\n        if dummy_row:\n            if dummy_shape[1] > 0:\n                s = s[:, :-dummy_shape[1]]\n            for b in range(batch_size):\n                s[b, ori_nrows[b]:nrows[b], :ncols[b]] = 0\n\n        if matrix_input:\n            s.squeeze_(0)\n\n        return s\n\n# ==========================================\n# File: src/loss_func.py\n# Function/Context: OurPermutationLoss\n# ==========================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom src.lap_solvers.hungarian import hungarian\nfrom src.displacement_layer import Displacement\nfrom torch import Tensor\nfrom src.utils.config import cfg\n\nfrom src.evaluation_metric import objective_score\n\nclass GMLoss:\n    def __init__(self, name, problem_type):\n        if name.lower() == 'offset':\n            self.criterion = OffsetLoss(norm=cfg.TRAIN.RLOSS_NORM)\n        elif name.lower() == 'perm':\n            self.criterion = PermutationLoss()\n        elif name.lower() == 'ce':\n            self.criterion = CrossEntropyLoss()\n        elif name.lower() == 'focal':\n            self.criterion = FocalLoss(gamma=0.)\n        elif name.lower() == 'hung':\n            self.criterion = PermutationLossHung()\n        elif name.lower() == 'hamming':\n            self.criterion = HammingLoss()\n        elif name.lower() == 'ourloss':\n            self.criterion = OurPermutationLoss(reg_level=cfg.TRAIN.REG_LEVEL, reg_ratio=cfg.TRAIN.REG_RATIO)\n        elif name.lower() == 'cw':\n            self.criterion = CWLoss()\n        else:\n            raise ValueError('Unknown loss function {}'.format(name))\n\n        self.name = name\n        self.problem_type = problem_type\n\n    def __call__(self, outputs, outputs_att=None, device=None, reduction='mean'):\n        if self.problem_type == '2GM':\n            if self.name == 'offset': \n                d_gt, grad_mask = displacement(outputs['gt_perm_mat'], *outputs['Ps'], outputs['ns'][0])\n                d_pred, _ = displacement(outputs['ds_mat'], *outputs['Ps'], outputs['ns'][0])\n                loss = self.criterion(d_pred, d_gt, grad_mask)\n            elif self.name in ['perm', 'ce', 'soft_perm', 'cw']:\n                loss = self.criterion(outputs['ds_mat'], outputs['gt_perm_mat'], *outputs['ns'], reduction=reduction)\n            elif self.name == 'hung':\n                loss = self.criterion(outputs['ds_mat'], outputs['gt_perm_mat'], *outputs['ns'])\n            elif self.name == 'hamming':\n                loss = self.criterion(outputs['perm_mat'], outputs['gt_perm_mat'])\n            elif self.name == 'plain':\n                loss = torch.sum(outputs['loss'])\n            elif self.name == 'ourloss':\n                if outputs_att == None:\n                    outputs_att = self.outputs_att\n                loss = self.criterion(outputs['ds_mat'], outputs['perm_mat'], outputs_att['perm_mat'], outputs['gt_perm_mat'], *outputs['ns'], reduction=reduction)\n            else:\n                raise ValueError('Unsupported loss function {} for problem type {}'.format(self.name, cfg.PROBLEM.TYPE))\n\n        elif self.problem_type in ['MGM', 'MGMC']:\n            assert 'ds_mat_list' in outputs\n            assert 'graph_indices' in outputs\n            assert 'perm_mat_list' in outputs\n            assert 'gt_perm_mat_list' in outputs\n\n            if self.name in ['perm', 'ce' 'hung']:\n                loss = torch.zeros(1, device=device)\n                ns = outputs['ns']\n                for s_pred, x_gt, (idx_src, idx_tgt) in \\\n                        zip(outputs['ds_mat_list'], outputs['gt_perm_mat_list'], outputs['graph_indices']):\n                    l = criterion(s_pred, x_gt, ns[idx_src], ns[idx_tgt])\n                    loss += l\n                loss /= len(outputs['ds_mat_list'])\n            elif cfg.TRAIN.LOSS_FUNC == 'plain':\n                loss = torch.sum(outputs['loss'])\n            else:\n                raise ValueError('Unsupported loss function {} for problem type {}'.format(cfg.TRAIN.LOSS_FUNC, cfg.PROBLEM.TYPE))\n\n        return loss\n\n    def get_criterion(self):\n        return self.criterion\n\n    def update_outputs_att(self, outputs_att):\n        self.outputs_att = outputs_att\n\n\nclass OurPermutationLoss(nn.Module):\n    def __init__(self, reg_level=1, reg_ratio=0.1):\n        super(OurPermutationLoss, self).__init__()\n        self.reg_level = reg_level\n        self.reg_ratio = reg_ratio\n    def forward(self, pred_dsmat: Tensor, pred_perm: Tensor, pred_perm_att: Tensor, gt_perm: Tensor, src_ns: Tensor, tgt_ns: Tensor, reduction='mean') -> Tensor:\n        r\"\"\"\n        :param pred_dsmat: :math:`(b\\times n_1 \\times n_2)` predicted doubly-stochastic matrix :math:`(\\mathbf{S})`\n        :param gt_perm: :math:`(b\\times n_1 \\times n_2)` ground truth permutation matrix :math:`(\\mathbf{X}^{gt})`\n        :param src_ns: :math:`(b)` number of exact pairs in the first graph (also known as source graph).\n        :param tgt_ns: :math:`(b)` number of exact pairs in the second graph (also known as target graph).\n        :return: :math:`(1)` averaged permutation loss\n        .. note::\n            We support batched instances with different number of nodes, therefore ``src_ns`` and ``tgt_ns`` are\n            required to specify the exact number of nodes of each instance in the batch.\n        \"\"\"\n        batch_num = pred_dsmat.shape[0]\n        pred_dsmat = pred_dsmat.to(dtype=torch.float32)\n        try:\n            assert torch.all((pred_dsmat >= 0) * (pred_dsmat <= 1))\n            assert torch.all((gt_perm >= 0) * (gt_perm <= 1))\n        except AssertionError as err:\n            print(pred_dsmat)\n            raise err\n\n        if reduction == 'mean':\n            loss = torch.tensor(0.).to(pred_dsmat.device)\n        elif reduction == 'none':\n            loss = torch.zeros(batch_num).to(pred_dsmat.device)\n        else:\n            raise ValueError('Need use an appropriate way to compute the final loss. optional: mean|none')\n        n_sum = torch.zeros_like(loss)\n        \n        with torch.no_grad():\n            sim_batch = self.dig_similarity(pred_perm_att, gt_perm, src_ns, tgt_ns)\n\n        for b in range(batch_num):\n            batch_slice = [b, slice(src_ns[b]), slice(tgt_ns[b])]\n            cur_pred_dsmat = pred_dsmat[batch_slice]\n            cur_gt_perm = gt_perm[batch_slice]\n            # 1. mask the current pred perm via gt_perm \n            cur_mask = cur_gt_perm.detach().clone()\n            # 2. filter out the similar keypoints using sim_array \n            cur_sim_array = sim_batch[b]\n            for i in range(src_ns[b]):\n                num_sim_kps = len(cur_sim_array[i])\n                if num_sim_kps == 0: # current i gets matched correctly \n                    cur_mask[i, :] = 0.\n                else:\n                    # num_sim_kps = len(cur_sim_array[i])\n                    max_sim_kps = min(num_sim_kps, self.reg_level)\n                    sim_kps = [cur_sim_array[i][j] for j in range(max_sim_kps)]\n                    cur_mask[i, sim_kps] = -1\n            # 3. build the margin regularization loss(element wise multiplication)\n            reg_loss = cur_pred_dsmat * cur_mask\n            # reduction way: 'mean'(by default): first sum the loss all together, then average loss row by row; \n            # 'none': average values together and output batch-size loss\n            if reduction == 'mean':\n                loss -= self.reg_ratio * reg_loss.sum()\n                loss += F.binary_cross_entropy(\n                    cur_pred_dsmat,\n                    cur_gt_perm,\n                    reduction='sum')\n                n_sum += src_ns[b].to(n_sum.dtype).to(pred_dsmat.device)\n            elif reduction == 'none':\n                loss[b] -= self.reg_ratio * reg_loss.mean()\n                loss[b] += F.binary_cross_entropy(\n                    cur_pred_dsmat,\n                    cur_gt_perm,\n                    reduction='mean')\n        if reduction == 'mean':\n            return loss / n_sum\n        elif reduction == 'none':\n            return loss\n\n    def dig_similarity(self, pred_perm_att: Tensor, gt_perm: Tensor, src_ns: Tensor, tgt_ns: Tensor) -> Tensor:\n        # 1. mask the correctly matched pair \n        # 2. DFS to dig out the semantically similary keypoint groups (pairwise, triple, etc.)\n        batch_num = pred_perm_att.shape[0]\n        sim_batch = [[None] for _ in range(batch_num)]\n        # TODO: optimize the func time cost later \n        pred_perm_att = pred_perm_att.detach().cpu()\n        gt_perm = gt_perm.detach().cpu()\n\n        def dfs(i, depth, visited, pred_perm, sim_loop=None):\n            visited[i] = True\n            next_i = pred_perm[i]\n            if sim_loop is None and depth == 0:\n                sim_loop = [i]\n            if visited[next_i] or next_i == i:\n                return sim_loop\n            sim_loop.append(next_i.item())\n            return dfs(next_i, depth+1, visited, pred_perm, sim_loop)\n        # The main logic: \n        # 1. Map the matched G2 node index back to G1; \n        # 2. Perform DFS to find the sim loop on G1; (semantically ambiguous nodes)\n        # 3. Map the G1 node index in the sim loop back to G2;\n        for b in range(batch_num):\n            batch_slice = [b, slice(src_ns[b]), slice(tgt_ns[b])]\n            sim_array = [[None] for _ in range(src_ns[b])]\n            sim_loop_array = []\n            visited = [False for _ in range(tgt_ns[b])]\n            cur_pred_perm_att = pred_perm_att[batch_slice]\n            cur_gt_perm = gt_perm[batch_slice]\n            col_index_gt = torch.nonzero(cur_gt_perm, as_tuple=True)[1]\n            col_index_pred = torch.nonzero(cur_pred_perm_att, as_tuple=True)[1]\n            col_index_gt_t = torch.nonzero(torch.t(cur_gt_perm), as_tuple=True)[1]\n            # map the matched node index of g2 back to g1\n            matching_on_g1 = [col_index_gt_t[i] for i in col_index_pred]\n            for i in range(src_ns[b]):\n                if not visited[i]:\n                    sim_loop = dfs(i, 0, visited, matching_on_g1)\n                    sim_loop_array.append(sim_loop)\n            # decode sim_loop to similarity pair\n            gt_mapping_g1_to_g2 = lambda index_g1, gt_mapping: [gt_mapping[i].item() for i in index_g1]\n            for sim_loop in sim_loop_array:\n                for loc, i in enumerate(sim_loop):\n                    if loc == 0: sim_array[i] = gt_mapping_g1_to_g2(sim_loop[loc+1:], col_index_gt)\n                    elif loc == len(sim_loop)-1: sim_array[i] = gt_mapping_g1_to_g2(sim_loop[:loc], col_index_gt)\n                    else:\n                        tmp_loop = sim_loop[loc+1:]\n                        tmp_loop.extend(sim_loop[:loc])\n                        sim_array[i] = gt_mapping_g1_to_g2(tmp_loop, col_index_gt)\n            sim_batch[b] = sim_array\n        return sim_batch\n\n# ==========================================\n# File: src/qap_solvers/rrwm.py\n# Function/Context: RRWM.forward\n# ==========================================\nimport torch\nimport torch.nn as nn\n\nfrom src.lap_solvers.sinkhorn import Sinkhorn as Sinkhorn\n\n\nclass RRWM(nn.Module):\n    \"\"\"\n    RRWM solver for graph matching (QAP), implemented by power iteration with Sinkhorn reweighted jumps.\n    Parameter: maximum iteration max_iter\n    Input: input matrix M\n           maximum size of source graph num_src\n           sizes of source graph in batch ns_src\n           sizes of target graph in batch ns_tgt\n           (optional) initialization vector v0. If not specified, v0 will be initialized with all 1.\n    Output: computed eigenvector v\n    \"\"\"\n    def __init__(self, max_iter=50, sk_iter=20, alpha=0.2, beta=30):\n        super(RRWM, self).__init__()\n        self.max_iter = max_iter\n        self.alpha = alpha\n        self.beta = beta\n        self.sk = Sinkhorn(max_iter=sk_iter,log_forward=False)\n\n    def forward(self, M, num_src, ns_src, ns_tgt, v0=None):\n        d = M.sum(dim=2, keepdim=True)\n        dmax = d.max(dim=1, keepdim=True).values\n        M = M / (dmax + d.min() * 1e-5)\n\n        batch_num = M.shape[0]\n        mn = M.shape[1]\n        if v0 is None:\n            v0 = torch.zeros(batch_num, num_src, mn // num_src, dtype=M.dtype, device=M.device)\n            for b in range(batch_num):\n                v0[b, 0:ns_src[b], 0:ns_tgt[b]] = torch.tensor(1.) / (ns_src[b] * ns_tgt[b])\n\n            v0 = v0.transpose(1, 2).reshape(batch_num, mn, 1)\n\n        v = v0\n        for i in range(self.max_iter):\n            v = torch.bmm(M, v)\n            last_v = v\n            n = torch.norm(v, p=1, dim=1, keepdim=True)\n            v = v / n\n            s = v.view(batch_num, -1, num_src).transpose(1, 2)\n            s = torch.exp(self.beta * s / s.max(dim=1, keepdim=True).values.max(dim=2, keepdim=True).values)\n\n            v = self.alpha * self.sk(s, ns_src, ns_tgt).transpose(1, 2).reshape(batch_num, mn, 1) + (1 - self.alpha) * v\n            n = torch.norm(v, p=1, dim=1, keepdim=True)\n            v = torch.matmul(v, 1 / n)\n\n            if torch.norm(v - last_v) < 1e-5:\n                break\n\n        return v.view(batch_num, -1)\n\n# ==========================================\n# File: src/qap_solvers/spectral_matching.py\n# Function/Context: SpectralMatching\n# ==========================================\nimport torch\nimport torch.nn as nn\nfrom src.utils.sparse import sbmm\n\n\nclass SpectralMatching(nn.Module):\n    \"\"\"\n    Spectral Graph Matching solver.\n    Also known as Power Iteration layer, which computes the leading eigenvector of input matrix.\n    For every iteration,\n        v_k+1 = M * v_k / ||M * v_k||_2\n    Parameter: maximum iteration max_iter\n    Input: input matrix M\n           (optional) initialization vector v0. If not specified, v0 will be initialized with all 1.\n    Output: computed eigenvector v\n    \"\"\"\n    def __init__(self, max_iter=50, stop_thresh=2e-7):\n        super(SpectralMatching, self).__init__()\n        self.max_iter = max_iter\n        self.stop_thresh = stop_thresh\n\n    def forward(self, M, v0=None, **kwargs):\n        batch_num = M.shape[0]\n        mn = M.shape[1]\n        if v0 is None:\n            v0 = torch.ones(batch_num, mn, 1, dtype=M.dtype, device=M.device)\n\n        v = vlast = v0\n        for i in range(self.max_iter):\n            if M.is_sparse:\n                v = sbmm(M, v)\n            else:\n                v = torch.bmm(M, v)\n            n = torch.norm(v, p=2, dim=1)\n            v = torch.matmul(v, (1 / n).view(batch_num, 1, 1))\n            if torch.norm(v - vlast) < self.stop_thresh:\n                return v.view(batch_num, -1)\n            vlast = v\n\n        return v.view(batch_num, -1)\n\n# ==========================================\n# File: train_eval.py\n# Function/Context: train_eval_model\n# ==========================================\nimport torch.optim as optim\nimport time\nimport xlwt\nfrom datetime import datetime\nfrom pathlib import Path\nfrom copy import deepcopy\nfrom tensorboardX import SummaryWriter\n\nfrom src.dataset.data_loader import GMDataset, get_dataloader\nfrom src.build_graphs import build_graphs\nfrom src.displacement_layer import Displacement\nfrom src.loss_func import *\nfrom src.evaluation_metric import matching_recall\nfrom src.parallel import DataParallel\nfrom src.utils.model_sl import load_model, save_model\nfrom eval import eval_model, eval_util, evaluation\nfrom src.utils.data_to_cuda import data_to_cuda, cuda_copy\n\nfrom src.utils.config import cfg\n\nfrom attack_utils import AttackGM\n\ndef train_eval_model(model,\n                     criterion,\n                     optimizer,\n                     dataloader,\n                     tfboard_writer,\n                     num_epochs=25,\n                     start_epoch=0,\n                     attacks=None,\n                     xls_wb=None,\n                     criterion_burnin=None):\n    print('Start training...')\n\n    since = time.time()\n    dataset_size = len(dataloader['train'].dataset)\n    displacement = Displacement()\n\n    device = next(model.parameters()).device\n    print('model on device: {}'.format(device))\n\n    checkpoint_path = Path(cfg.OUTPUT_PATH) / 'params'\n    if not checkpoint_path.exists():\n        checkpoint_path.mkdir(parents=True)\n\n    model_path, optim_path = '',''\n    if start_epoch > 0:\n        model_path = str(checkpoint_path / 'params_{:04}.pt'.format(start_epoch))\n        optim_path = str(checkpoint_path / 'optim_{:04}.pt'.format(start_epoch))\n    if len(cfg.PRETRAINED_PATH) > 0:\n        model_path = cfg.PRETRAINED_PATH\n    if len(model_path) > 0:\n        print('Loading model parameters from {}'.format(model_path))\n        load_model(model, model_path, strict=False)\n    if len(optim_path) > 0:\n        print('Loading optimizer state from {}'.format(optim_path))\n        optimizer.load_state_dict(torch.load(optim_path))\n\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n                                               milestones=cfg.TRAIN.LR_STEP,\n                                               gamma=cfg.TRAIN.LR_DECAY,\n                                               last_epoch=cfg.TRAIN.START_EPOCH - 1)\n\n    for epoch in range(start_epoch, num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        if epoch == cfg.TRAIN.BURN_IN_PERIOD:\n            print('BURN-IN PERIOD ENDS.')\n        print('-' * 10)\n\n        model.train()  # Set model to training mode\n\n        print('lr = ' + ', '.join(['{:.2e}'.format(x['lr']) for x in optimizer.param_groups]))\n\n        epoch_loss = 0.0\n        running_loss = 0.0\n        running_since = time.time()\n        iter_num = 0\n\n        # Iterate over data.\n        for inputs in dataloader['train']:\n            if model.module.device != torch.device('cpu'):\n                inputs = data_to_cuda(inputs)\n            # start_time = time.time()\n            iter_num = iter_num + 1\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            with torch.set_grad_enabled(True):\n                # forward\n                inputs_att = dict()\n                inputs_att = cuda_copy(inputs, inputs_att)\n                if epoch < cfg.TRAIN.BURN_IN_PERIOD:\n                    inputs_att, _ = attacks[0](model, inputs_att)\n                else:\n                    inputs_att, _ = attacks[1](model, inputs_att)\n\n                outputs_att = model(inputs_att)\n                    \n\n                if cfg.PROBLEM.TYPE == '2GM':\n                    assert 'ds_mat' in outputs_att\n                    assert 'perm_mat' in outputs_att\n                    assert 'gt_perm_mat' in outputs_att\n                    # compute loss\n\n                    if cfg.TRAIN.LOSS_FUNC == 'ourloss':\n                        loss = criterion(outputs_att, outputs_att)\n                    else:\n                        loss = criterion(outputs_att)\n\n                    # compute accuracy\n                    acc = matching_recall(outputs_att['perm_mat'], outputs_att['gt_perm_mat'], outputs_att['ns'][0])\n\n                else:\n                    raise ValueError('Unknown problem type {}'.format(cfg.PROBLEM.TYPE))\n\n                # backward + optimize\n                loss.backward()\n                optimizer.step()\n                \n                batch_num = inputs['batch_size']\n\n                # tfboard writer\n                loss_dict = dict()\n                loss_dict['loss'] = loss.item()\n                tfboard_writer.add_scalars('loss', loss_dict, epoch * cfg.TRAIN.EPOCH_ITERS + iter_num)\n\n                accdict = dict()\n                accdict['matching accuracy'] = torch.mean(acc)\n                tfboard_writer.add_scalars(\n                    'training accuracy',\n                    accdict,\n                    epoch * cfg.TRAIN.EPOCH_ITERS + iter_num\n                )\n\n                # statistics\n                running_loss += loss.item() * batch_num\n                epoch_loss += loss.item() * batch_num\n\n                if iter_num % cfg.STATISTIC_STEP == 0:\n                    running_speed = cfg.STATISTIC_STEP * batch_num / (time.time() - running_since)\n                    print('Epoch {:<4} Iteration {:<4} {:>4.2f}sample/s Loss={:<8.4f} Training Acc={:<8.2f}'\n                          .format(epoch, iter_num, running_speed, running_loss / cfg.STATISTIC_STEP / batch_num, torch.mean(acc)))\n                    tfboard_writer.add_scalars(\n                        'speed',\n                        {'speed': running_speed},\n                        epoch * cfg.TRAIN.EPOCH_ITERS + iter_num\n                    )\n\n                    tfboard_writer.add_scalars(\n                        'learning rate',\n                        {'lr_{}'.format(i): x['lr'] for i, x in enumerate(optimizer.param_groups)},\n                        epoch * cfg.TRAIN.EPOCH_ITERS + iter_num\n                    )\n\n                    running_loss = 0.0\n                    running_since = time.time()\n\n        epoch_loss = epoch_loss / dataset_size\n\n        print('Epoch {:<4} Loss: {:.4f} \\n'.format(epoch, epoch_loss))\n        # Eval Clean Accuracy every n epochs\n        if epoch == 0 or (epoch + 1) % cfg.EVAL.NUM_EPOCH == 0:\n            xls_sheet = xls_wb.add_sheet('epoch{}'.format(epoch + 1))\n            accs = eval_model(model, dataloader['test'], xls_sheet=xls_sheet)\n            acc_dict = {\"{}\".format(cls): single_acc for cls, single_acc in zip(dataloader['test'].dataset.classes, accs)}\n            acc_dict['average'] = torch.mean(accs)\n            tfboard_writer.add_scalars(\n                'Eval acc',\n                acc_dict,\n                (epoch + 1) * cfg.TRAIN.EPOCH_ITERS\n            )\n\n            if epoch > 0:\n                save_model(model, str(checkpoint_path / 'params_{:04}.pt'.format(epoch + 1)))\n                torch.save(optimizer.state_dict(), str(checkpoint_path / 'optim_{:04}.pt'.format(epoch + 1)))\n\n        scheduler.step()\n\n    # Eval Robustness in the final epoch \n    eval_util(model, xls_wb, dataloader)\n    wb.save(wb.__save_path)\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'\n          .format(time_elapsed // 3600, (time_elapsed // 60) % 60, time_elapsed % 60))\n\n    return model\n\n\nif __name__ == '__main__':\n    from src.utils.dup_stdout_manager import DupStdoutFileManager\n    from src.utils.parse_args import parse_args\n    from src.utils.print_easydict import print_easydict\n    from src.utils.count_model_params import count_parameters\n\n    args = parse_args('Deep learning of graph matching training & evaluation code.')\n\n    import importlib\n    mod = importlib.import_module(cfg.MODULE)\n    Net = mod.Net\n\n    torch.manual_seed(cfg.RANDOM_SEED)\n    torch.cuda.manual_seed(cfg.RANDOM_SEED)\n\n    dataset_len = {'train': cfg.TRAIN.EPOCH_ITERS * cfg.BATCH_SIZE, 'test': cfg.EVAL.SAMPLES}\n    image_dataset = {\n        x: GMDataset(cfg.DATASET_FULL_NAME,\n                     sets=x,\n                     problem=cfg.PROBLEM.TYPE,\n                     length=dataset_len[x],\n                     cls=cfg.TRAIN.CLASS if x == 'train' else cfg.EVAL.CLASS,\n                     obj_resize=cfg.PROBLEM.RESCALE)\n        for x in ('train', 'test')}\n    dataloader = {x: get_dataloader(image_dataset[x], fix_seed=(x == 'test'))\n        for x in ('train', 'test')}\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    model = Net()\n    model = model.to(device)\n\n    criterion_train = GMLoss(cfg.TRAIN.LOSS_FUNC.lower(), cfg.PROBLEM.TYPE)\n\n    if cfg.TRAIN.SYNC_MINMAX:\n        criterion_att = GMLoss(cfg.TRAIN.LOSS_FUNC.lower(), cfg.PROBLEM.TYPE)\n    else:\n        if criterion_train.name == 'hamming':        \n            criterion_att = GMLoss('hamming', cfg.PROBLEM.TYPE)\n        else:\n            criterion_att = GMLoss(cfg.ATTACK.LOSS_FUNC.lower(), cfg.PROBLEM.TYPE)\n\n    if cfg.TRAIN.MODE == 'eval': \n        pass\n    elif cfg.TRAIN.MODE == 'at':\n        attack1 = AttackGM(cfg.ATTACK.OBJ_TYPE, cfg.ATTACK.TYPE, \n                            criterion=criterion_att, \n                            eps=(cfg.ATTACK.EPSILON_FEATURE, cfg.ATTACK.EPSILON_LOCALITY), \n                            iter_num=cfg.ATTACK.STEP, \n                            alpha=cfg.ATTACK.ALPHA, \n                            device=device, \n                            inv=False)\n        attacks = [attack1, attack1]\n    elif cfg.TRAIN.MODE == '2step':\n        attack_warm = AttackGM(cfg.ATTACK2.OBJ_TYPE, cfg.ATTACK2.TYPE, \n                                criterion=criterion_att, \n                                eps=(cfg.ATTACK.EPSILON_FEATURE, cfg.ATTACK.EPSILON_LOCALITY), \n                                iter_num=cfg.ATTACK2.STEP, \n                                alpha=cfg.ATTACK.ALPHA, \n                                device=device, \n                                inv=False)\n        attack1     = AttackGM(cfg.ATTACK.OBJ_TYPE, cfg.ATTACK.TYPE, \n                                criterion=criterion_att, \n                                eps=(cfg.ATTACK.EPSILON_FEATURE, cfg.ATTACK.EPSILON_LOCALITY), \n                                iter_num=cfg.ATTACK.STEP, \n                                alpha=cfg.ATTACK.ALPHA, \n                                device=device, \n                                inv=False)\n        attacks = [attack_warm, attack1]\n    else:\n        raise NotImplementedError\n\n    if cfg.TRAIN.SEPARATE_BACKBONE_LR:\n        backbone_ids = [id(item) for item in model.backbone_params]\n        other_params = [param for param in model.parameters() if id(param) not in backbone_ids]\n\n        model_params = [\n            {'params': other_params},\n            {'params': model.backbone_params, 'lr': cfg.TRAIN.BACKBONE_LR}\n        ]\n    else:\n        model_params = model.parameters()\n\n    if cfg.TRAIN.OPTIMIZER.lower() == 'sgd':\n        optimizer = optim.SGD(model_params, lr=cfg.TRAIN.LR, momentum=cfg.TRAIN.MOMENTUM, nesterov=True)\n    elif cfg.TRAIN.OPTIMIZER.lower() == 'adam':\n        optimizer = optim.Adam(model_params, lr=cfg.TRAIN.LR)\n    else:\n        raise ValueError('Unknown optimizer {}'.format(cfg.TRAIN.OPTIMIZER))\n\n    if cfg.FP16:\n        try:\n            from apex import amp\n        except ImportError:\n            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to enable FP16.\")\n        model, optimizer = amp.initialize(model, optimizer)\n\n    model = DataParallel(model, device_ids=cfg.GPUS)\n\n    if not Path(cfg.OUTPUT_PATH).exists():\n        Path(cfg.OUTPUT_PATH).mkdir(parents=True)\n\n    now_time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n    tfboardwriter = SummaryWriter(logdir=str(Path(cfg.OUTPUT_PATH) / 'tensorboard' / 'training_{}'.format(now_time)))\n    wb = xlwt.Workbook()\n    wb.__save_path = str(Path(cfg.OUTPUT_PATH) / ( now_time + '.xls'))\n\n    with DupStdoutFileManager(str(Path(cfg.OUTPUT_PATH) / (now_time + '.log'))) as _:\n        print_easydict(cfg)\n        print('Number of parameters: {:.2f}M'.format(count_parameters(model) / 1e6))\n        if cfg.TRAIN.MODE == 'eval':\n            evaluation(model, wb, dataloader)\n        else:\n            model = train_eval_model(model, criterion_train,  optimizer, dataloader, tfboardwriter,\n                                    attacks=attacks,\n                                    num_epochs=cfg.TRAIN.NUM_EPOCHS,\n                                    start_epoch=cfg.TRAIN.START_EPOCH,\n                                    xls_wb=wb\n                                    )\n        \n    wb.save(wb.__save_path)",
  "description": "Combined Analysis:\n- [attack_utils.py]: This file implements the core adversarial attack optimization for graph matching models as described in the paper. The AttackBase class performs iterative gradient-based attacks (PGD with momentum) on keypoint locations ('Ps') and image pixels ('images') to maximize the matching loss. Key mathematical components include: 1) Gradient ascent with momentum () to maximize loss, 2) L norm projection via clamping to enforce perturbation bounds (_loc for locations, _feat for pixels), 3) Geometric constraints via _intersect_bbox to keep perturbed keypoints within their original feature grid cells (ensuring structural locality), 4) Early stopping based on matching precision threshold. The attack directly optimizes the adversarial objective max_ L(f(x+), y) subject to ||||_  , where f is the graph matching model, L is the matching loss (e.g., permutation loss), and  is the joint perturbation on both structural (keypoints) and appearance (pixel) features.\n- [models/NGM/gnn.py]: This file implements the core GNN architecture for the NGMv2 model, which solves the Quadratic Assignment Problem (QAP) for graph matching. The key components are:\n1. GNNLayer, HyperGNNLayer, and HyperConvLayer classes that perform message passing on graphs/hypergraphs to compute node and edge embeddings.\n2. Integration of the Sinkhorn algorithm (from src.lap_solvers.sinkhorn) within these layers when sk_channel>0, which enforces the doubly-stochastic constraints of the QAP relaxation.\n3. The forward methods of these layers compute updated node features that include a Sinkhorn-normalized matching score, directly implementing the continuous relaxation of the permutation matrix constraint.\n4. The architecture supports both dense and sparse tensor operations, enabling efficient processing of graph matching problems.\n5. This implementation corresponds to the vertex classification approach on the association graph described in the paper, where GNN layers propagate information and the Sinkhorn layer provides a differentiable approximation to the discrete assignment problem.\n- [models/NGM/hypermodel_v2.py]: This file implements the core NGMv2 model for graph matching, which directly corresponds to the Quadratic Assignment Problem (QAP) formulation described in the paper. The forward method constructs the affinity matrix K (unary, quadratic, and hyperedge terms) from extracted CNN features, then solves the QAP via a hypergraph neural network (HyperGNNLayer) followed by Sinkhorn normalization and Hungarian discretization to obtain a permutation matrix. This matches the paper's algorithmic steps: feature extraction, affinity computation, and QAP solving via vertex classification on the association graph. The code also handles both 2GM (two-graph matching) and MGM (multi-graph matching) scenarios.\n- [models/NGM/model_v2.py]: This file implements the core NGMv2 graph matching model that solves the Quadratic Assignment Problem (QAP) through deep learning. The forward method performs: 1) Feature extraction from images using CNN backbone, 2) Node/edge feature alignment to keypoints, 3) Unary and quadratic affinity computation via inner product layers, 4) Affinity matrix construction using Kronecker product graphs, 5) GNN-based QAP solver with multiple GNN layers that operate on the association graph, 6) Sinkhorn normalization for doubly-stochastic relaxation, and 7) Hungarian algorithm for discrete permutation matrix. The code directly implements Lawler's QAP formulation where the affinity matrix K is constructed from visual features and the optimization is performed via vertex classification on the association graph. It supports both 2-graph matching (2GM) and multi-graph matching (MGM) scenarios, with spectral matching for MGM. The implementation matches the paper's description of using deep graph matching methods to solve QAP end-to-end.\n- [src/lap_solvers/sinkhorn.py]: This file implements the Sinkhorn algorithm, which is a core component for solving the relaxed Quadratic Assignment Problem (QAP) in deep graph matching. The Sinkhorn algorithm converts an input affinity matrix into a doubly-stochastic matrix (continuous relaxation of permutation matrix), satisfying the constraints X1 = 1 and X^T1 = 1. This directly corresponds to the optimization model's constraint relaxation where the discrete permutation matrix constraint is relaxed to continuous doubly-stochastic constraints. The implementation handles batched operations, different graph sizes via dummy rows, and provides both log-space (numerically stable) and original implementations. This is a key algorithmic step in the deep graph matching pipeline described in the paper.\n- [src/loss_func.py]: This file implements the core loss function for the ASAR-GM defense mechanism. The 'OurPermutationLoss' class encapsulates the Appearance Aware Regularizer (AAR) proposed in the paper. It modifies the standard permutation loss (binary cross-entropy) by adding a regularization term that penalizes the model for assigning high probabilities to semantically similar but incorrect keypoints. The regularization is computed by identifying similarity loops (groups of ambiguous keypoints) via DFS and applying a negative mask to their predicted scores. This directly implements the mathematical formulation of the defense strategy to increase separation between appearance-similar keypoints in the embedding space, enhancing robustness against adversarial attacks without sacrificing clean accuracy.\n- [src/qap_solvers/rrwm.py]: This file implements the RRWM (Reweighted Random Walk Matching) algorithm for solving the Quadratic Assignment Problem (QAP) in graph matching. The core logic aligns with the paper's optimization model: it takes an affinity matrix M (corresponding to K in the QAP objective) and computes a continuous assignment vector v through iterative power method with Sinkhorn reweighting. The algorithm approximates the discrete permutation matrix constraint via doubly-stochastic normalization (Sinkhorn operation) and L1 normalization, directly addressing the QAP relaxation used in deep graph matching pipelines. While the paper's primary method uses NGMv2 with vertex classification, RRWM serves as a classical QAP solver that can be integrated into the broader matching framework for comparison or as a component.\n- [src/qap_solvers/spectral_matching.py]: This file implements the Spectral Matching (Power Iteration) algorithm, which is a key component in solving the Quadratic Assignment Problem (QAP) for graph matching. The algorithm computes the leading eigenvector of the input affinity matrix M, corresponding to the relaxed continuous solution of the permutation matrix X. It aligns with the paper's use of deep graph matching methods (like NGMv2) that relax the binary constraint to a continuous doubly-stochastic matrix and solve via spectral techniques. The forward method iteratively applies the power iteration update v_{k+1} = M * v_k / ||M * v_k||_2, which approximates the principal eigenvector of M, thereby addressing the core optimization objective max vec(X)^T K vec(X) under relaxed constraints.\n- [train_eval.py]: This file implements the core adversarial training pipeline for robust deep graph matching. It directly integrates the paper's key contributions: 1) Adversarial attacks on both visual features and keypoint locations via the AttackGM class, 2) Defense through adversarial training with burn-in periods and multi-step attack strategies, and 3) The Appearance Aware Regularizer (AAR) loss via the GMLoss class. The training loop alternates between generating adversarial examples (attacks[0] during burn-in, attacks[1] after) and optimizing the model with the proposed loss. The code handles both standard adversarial training (AT) and two-step attack strategies, aligning with the paper's methodology for improving robustness against joint feature-structure perturbations.",
  "dependencies": [
    "src.evaluation_metric",
    "copy",
    "concat_features",
    "src.dataset.data_loader",
    "src.dataset.data_loader.GMDataset.collate_batch",
    "torch.optim",
    "src.utils.config.cfg",
    "src.feature_align.feature_align",
    "collections.Iterable",
    "models.BBGM.sconv_archs.SiameseNodeFeaturesToEdgeFeatures",
    "src.backbone.VGG16_bn_final",
    "time",
    "normalize_over_channels",
    "src.build_graphs",
    "src.utils.model_sl",
    "src.utils.parse_args",
    "torch.nn.functional",
    "src.lap_solvers.hungarian",
    "src.utils.sparse.sbmm",
    "importlib",
    "pathlib",
    "src.evaluation_metric.matching_precision",
    "src.utils.config",
    "src.utils.data_to_cuda.data_to_cuda",
    "src.utils.sparse.to_sparse",
    "src.utils.dup_stdout_manager",
    "src.loss_func",
    "models.NGM.gnn.HyperGNNLayer",
    "src.backbone.CNN",
    "src.utils.print_easydict",
    "datetime",
    "models.BBGM.sconv_archs.SiameseSConvOnNodes",
    "src.lap_solvers.sinkhorn.Sinkhorn",
    "models.BBGM.affinity_layer.InnerProductWithWeightsAffinity",
    "models.NGM.gnn.GNNLayer",
    "collections.OrderedDict",
    "src.loss_func.GMLoss",
    "tensorboardX",
    "torch.Tensor",
    "numpy",
    "xlwt",
    "src.lap_solvers.hungarian.hungarian",
    "eval",
    "lexico_iter",
    "src.utils.data_to_cuda",
    "attack_utils",
    "src.utils.pad_tensor.pad_tensor",
    "src.displacement_layer",
    "torch.nn",
    "src.parallel",
    "src.utils.count_model_params",
    "torch",
    "src.factorize_graph_matching.construct_aff_mat",
    "src.feature_align.detect_bound",
    "itertools"
  ]
}