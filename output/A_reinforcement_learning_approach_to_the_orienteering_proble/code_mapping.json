{
  "file_path": "inference_optw_rl.py, src/inference_utils.py, src/neural_net.py, src/solution_construction.py, src/train_utils.py",
  "function_name": "main, gr_inference, bs_inference, as_bs_inference, run_single, run_multiple, active_search_train_model, RecPointerNetwork, RunEpisode, BeamSearch, Lookahead, ModelUtils, train_model",
  "code_snippet": "\n\n# ==========================================\n# File: inference_optw_rl.py\n# Function/Context: main\n# ==========================================\nimport os,time\nimport logging\nimport argparse\nimport json\nimport pandas as pd\nimport numpy as np\n\nimport torch\nfrom torch import optim\n\nimport src.inference_utils as iu\nimport src.utils as u\nimport src.sampling_norm_utils as snu\n\nimport src.config as cf\nimport src.problem_config as pcf\n\nfrom src.neural_net import RecPointerNetwork\n\n\n# for logging\nN_DASHES = 40\nSAVE_H_FILE = 'performance_scores.csv'\n\n\n\ndef setup_args_parser():\n    parser = argparse.ArgumentParser(description='test model')\n    parser.add_argument('--instance', help='which instance to run')\n    parser.add_argument('--device', help='device to use (cpu/cuda)', default='cuda')\n    parser.add_argument('--use_checkpoint', help='use checkpoint (see https://pytorch.org/docs/stable/checkpoint.html)', action='store_true')\n    parser.add_argument('--infe_type', help='which inference to run: \\n \\\n                                greedy (gr), \\\n                                beam search (bs) or \\\n                                active search with beam search (as_bs)',\n                                choices=['gr', 'bs', 'as_bs'],\n                                default='bs')\n\n    parser.add_argument('--sample_type', help='how to sample the scores of each point of interest: \\n \\\n                                uniformly sampled (uni_samp), \\\n                                score proportional to each point of interest\\'s duration of visit (corr_samp)' ,\n                                choices=['uni_samp', 'corr_samp'],\n                                default='uni_samp')\n\n    parser.add_argument('--debug', help='debug mode (verbose output and no saving)', action='store_true')\n    parser.add_argument('--saved_model_epoch', help='epoch number which the pre-trained model was saved', default=500000, type=int)\n    parser.add_argument('--model_name', help='model name', default='default', type=str)\n    parser.add_argument('--nprint', help='epoch frequency for printing and saving in training history generated/benchmark instance reward', default=1, type=int)\n    parser.add_argument('--nepocs', help='number of epochs for active search training', default=128, type=int)\n    parser.add_argument('--batch_size', help='traing batch size', default = 32, type=int)\n    parser.add_argument('--max_beam_number', help='-max number of beams in beam search inference', default = 128, type=int)\n    parser.add_argument('--max_grad_norm', help='maximum norm value for gradient value clipping', default=1, type=int)\n    parser.add_argument('--lr', help='learning rate for active search training', default=1e-5, type=float)\n    parser.add_argument('--seed', help='seed random # generators (for reproducibility)', default=2925, type=int)\n    parser.add_argument('--beta', help='entropy term coefficient', default=0.01, type=float)\n    parser.add_argument('--generated', help='run on the generated instances of the validation set\\\n                                             instead of on the benchmark instance', action='store_true')\n\n    return parser\n\n\n\n\ndef parse_args_further(args):\n\n    LOAD_W_DIR_STRING = '{results_path}/{benchmark_instance}/model_w/model_{model_name}_{sample_type}'\n    GENERATED_STRING = '{generated_path}/{benchmark_instance}'\n\n    VAL_SET_PT_FILE = 'inp_val_{sample_type}.pt'\n\n    args.device_name = str(args.device)\n    args.device = torch.device(args.device_name)\n    args.instance_type = u.get_instance_type(args.instance)\n    args.map_location =  {'cpu': args.device_name}\n\n    args.val_dir = GENERATED_STRING.format(generated_path=cf.GENERATED_INSTANCES_PATH,\n                                           benchmark_instance=args.instance)\n\n    args.load_w_dir = LOAD_W_DIR_STRING.format(results_path=cf.RESULTS_PATH,\n                                               model_name=args.model_name,\n                                               sample_type=args.sample_type,\n                                               benchmark_instance = args.instance)\n\n    args.val_set_pt_file = VAL_SET_PT_FILE.format(sample_type=args.sample_type)\n\n    return args\n\n\n\ndef load_saved_args(args):\n\n    with open(args.load_w_dir+'/model_'+args.model_name+'_training_args.txt') as json_file:\n        data = json.load(json_file)\n        args.n_layers = data['n_layers']\n        args.n_heads = data['n_heads']\n        args.ff_dim = data['ff_dim']\n        args.nfeatures = data['nfeatures']\n        args.ndfeatures = data['ndfeatures']\n        args.rnn_hidden = data['rnn_hidden']\n\n    return args\n\n\n\ndef log_args(args):\n    logger.info(N_DASHES*'-')\n    logger.info('Running test_optw_rl.py')\n    logger.info(N_DASHES*'-')\n    logger.info('model name:  %s' % args.model_name)\n    logger.info(N_DASHES*'-')\n    logger.info('device: %s' % args.device_name)\n    logger.info('instance: %s' % args.instance)\n    logger.info('instance type: %s' % args.instance_type)\n    logger.info('infe_type: %s' % args.infe_type)\n    logger.info('use_checkpoint: %s' % args.use_checkpoint)\n    logger.info('sample type: %s' % args.sample_type)\n    logger.info('sample_prof: %s' % args.sample_prof)\n    logger.info('debug mode: %s' % args.debug)\n    logger.info('nprint: %s' % args.nprint)\n    logger.info('nepocs: %s' % args.nepocs)\n    logger.info('seed: %s' % args.seed)\n    logger.info(N_DASHES*'-')\n    logger.info('max square length (Xmax): %s' % args.Xmax)\n    logger.info('batch_size: %s' % args.batch_size)\n    logger.info('max_grad_norm: %s' % args.max_grad_norm)\n    logger.info('learning rate (lr): %s' % args.lr)\n    logger.info('entropy term coefficient (beta): %s' % args.beta)\n    logger.info('hidden size of RNN (hidden): %s' % args.rnn_hidden)\n    logger.info('number of attention layers in the Encoder: %s' % args.n_layers)\n    logger.info('number of features: %s' % args.nfeatures)\n    logger.info('number of dynamic features: %s' % args.ndfeatures)\n    logger.info(N_DASHES*'-')\n    logger.info(args.instance)\n\n\n\nif __name__ == \"__main__\":\n\n    # ---------------------------------\n    #  parse arguments and setup logger\n    # ---------------------------------\n\n    parser = setup_args_parser()\n    args_temp = parser.parse_args()\n\n    args = parse_args_further(args_temp)\n    args = load_saved_args(args)\n\n    logger = u.setup_logger(args.debug)\n    if args.debug:\n        log_args(args)\n\n\n    # seed\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    if str(args.device) in ['cuda', 'cuda:0', 'cuda:1']:\n        torch.cuda.manual_seed(args.seed)\n\n\n    # ---------------------------------\n    #  load data\n    # ---------------------------------\n    inp_real = u.get_real_data(args, phase='inference')\n    raw_data, raw_distm = inp_real[0]\n\n    start_time = raw_data[0, pcf.OPENING_TIME_WINDOW_IDX]\n\n    # get Tmax and Smax\n    norm_dic = {}\n    Tmax, Smax = snu.instance_dependent_norm_const(raw_data)\n    norm_dic = {'Tmax': Tmax, 'Smax': Smax}\n\n    # ---------------------------------\n    # load model\n    # ---------------------------------\n    logger.info('Loading model for instance {instance} ...'.format(instance=args.instance))\n    performance_scores = []\n\n    pointer_net = RecPointerNetwork(args.nfeatures, args.ndfeatures,\n                              args.rnn_hidden, args).to(args.device).eval()\n\n\n    # ---------------------------------\n    # inference\n    # ---------------------------------\n\n    if not args.generated:\n        logger.info('Infering route for benchmark instance...')\n        output =  iu.run_single(raw_data, norm_dic, start_time, raw_distm, args,\n                                pointer_net, which_inf=args.infe_type)\n\n    else:\n        inp_val = u.get_val_data(args, phase='inference')\n        logger.info('Infering routes for {num_inst} generated instances...' \\\n                    .format(num_inst=len(inp_val)))\n        outputs =  iu.run_multiple(inp_val, norm_dic, args, pointer_net,\n                                   which_inf=args.infe_type)\n\n    # ---------------------------------\n    # Log results\n    # ---------------------------------\n    if args.infe_type in ['gr', 'bs', 'as_bs']:\n\n        logger.info(N_DASHES*'-')\n        if not args.generated:\n            logger.info('route: {route}'.format(route=output['route']))\n            logger.info('total score: {total_score}'\\\n                        .format(total_score=int(output['score'])))\n            inference_time_ms = int(1000*output['inf_time'])\n            logger.info('inference time: {inference_time} ms'\\\n                        .format(inference_time=inference_time_ms))\n\n        else:\n            df_out = pd.DataFrame(outputs)\n            average_total_score = round(df_out.score.mean(), 2)\n            average_inf_time_ms = int(1000*df_out.inf_time.mean())\n            logger.info('average total score: {average_total_score}' \\\n                        .format(average_total_score=average_total_score))\n            logger.info('average inference time: {average_inference_time} ms' \\\n                        .format(average_inference_time=average_inf_time_ms))\n        logger.info(N_DASHES*'-')\n\n# ==========================================\n# File: src/inference_utils.py\n# Function/Context: gr_inference, bs_inference, as_bs_inference, run_single, run_multiple, active_search_train_model\n# ==========================================\nfrom tqdm import tnrange, tqdm\nimport time\n\nimport torch\nfrom torch import optim\nimport src.train_utils as tu\nimport src.sampling_norm_utils as snu\nfrom src.solution_construction import RunEpisode, BeamSearch\n\ndef gr_inference(inst_data, norm_dic, start_time, dist_mat, args, run_episode):\n\n    data_scaled = snu.data_scaler(inst_data, norm_dic)\n    binst_data, bdata_scaled = inst_data.unsqueeze(0), data_scaled.unsqueeze(0)\n\n    with torch.no_grad():\n        seq, _ , _, _ = run_episode(binst_data, bdata_scaled, start_time, dist_mat, 'greedy')\n\n    rewards = tu.reward_fn(inst_data, seq, args.device)\n    maxrew, idx_max = torch.max(rewards, 0)\n    score = maxrew.item()\n\n    route =  [act.item() for act in seq]\n    route[-1] = 0\n    return route, score\n\n\ndef bs_inference(inst_data, norm_dic, start_time, dist_mat, args, run_episode):\n\n    data_scaled = snu.data_scaler(inst_data, norm_dic)\n    binst_data, bdata_scaled = inst_data.unsqueeze(0), data_scaled.unsqueeze(0)\n\n    nb = args.max_beam_number\n    with torch.no_grad():\n        seq, _ = run_episode(binst_data, bdata_scaled, start_time, dist_mat, 'greedy', nb)\n\n    seq_list = [ seq[:,k] for k in range(seq.shape[1])]\n    rewards = tu.reward_fn(inst_data, seq_list, args.device)\n    maxrew, idx_max = torch.max(rewards, 0)\n    score = maxrew.item()\n\n    route =  [0] + [val.item() for val in seq[idx_max] if val.item() != 0]\n    route[-1] = 0\n    return route, score\n\n\ndef as_bs_inference(inp_data, norm_dic, args, run_episode, run_episode_bs):\n\n    model_opt = optim.Adam(run_episode.neuralnet.parameters(), lr=args.lr)\n\n    inst_data, start_time, dist_mat = inp_data\n\n    data_scaled = snu.data_scaler(inst_data, norm_dic)\n\n    for epoch in tqdm(range(args.nepocs)):\n\n        active_search_train_model(inst_data, data_scaled, start_time, dist_mat, run_episode, model_opt, args)\n\n    # .. to load your previously training model:\n    run_episode_bs.neuralnet.load_state_dict(run_episode.neuralnet.state_dict())\n    binst_data, bdata_scaled = inst_data.unsqueeze(0), data_scaled.unsqueeze(0)\n\n    with torch.no_grad():  \n        seq, _ = run_episode_bs(binst_data, bdata_scaled, start_time, dist_mat, 'greedy', args.max_beam_number)\n\n    seq_list = [ seq[:,k] for k in range(seq.shape[1])]\n    rewards = tu.reward_fn(inst_data, seq_list, args.device)\n\n    maxreward, idx_max = torch.max(rewards, 0)\n\n    score = maxreward.item()\n\n    route =  [0]+[val.item() for val in seq[idx_max] if val.item() != 0]\n    route[-1] = 0\n\n    return route, score\n\ndef run_single(inst_data, norm_dic, start_time, dist_mat, args, model,\n               which_inf=None):\n\n\n    saved_model_path = args.load_w_dir +'/model_' + str(args.saved_model_epoch) + '.pkl'\n    model._load_model_weights(saved_model_path, args.device)\n\n\n    tic = time.time()\n    if which_inf=='bs':\n        run_episode_inf = BeamSearch(model, args).eval()\n        route, score = bs_inference(inst_data, norm_dic, start_time, dist_mat,\n                                    args, run_episode_inf)\n\n    elif which_inf=='gr':\n        run_episode_inf = RunEpisode(model, args).eval()\n        route, score = gr_inference(inst_data, norm_dic, start_time, dist_mat,\n                                    args, run_episode_inf)\n\n    elif which_inf=='as_bs':\n\n        saved_model_path = args.load_w_dir +'/model_' + str(args.saved_model_epoch) + '.pkl'\n        model._load_model_weights(saved_model_path, args.device)\n        run_episode_train = RunEpisode(model, args)\n\n        run_episode_inf = BeamSearch(model, args).eval()\n        inp_data = (inst_data, start_time, dist_mat)\n        route, score = as_bs_inference(inp_data, norm_dic, args,\n                                       run_episode_train, run_episode_inf)\n    toc = time.time()\n\n    output = dict([('score', score), ('route', route), ('inf_time', toc-tic)])\n\n    return output\n\ndef run_multiple(inp_val, norm_dic, args, model, which_inf=None):\n\n    outputs = list()\n    for k, (inst_data, start_time, dist_mat) in enumerate(tqdm(inp_val)):\n        output = run_single(inst_data, norm_dic, start_time, dist_mat, args,\n                               model, which_inf=which_inf)\n        outputs.append(output)\n\n    return outputs\n\ndef active_search_train_model(inst_data, data_scaled, inp_t_init_val, dist_mat, run_episode, model_opt, args):\n\n    run_episode.train()\n\n    binst_data, bdata_scaled = tu.samples2batch(inst_data, data_scaled, args.batch_size)\n\n    actions, log_prob, entropy, step_mask = run_episode(binst_data, bdata_scaled, inp_t_init_val, dist_mat, 'stochastic')\n\n    rewards = tu.reward_fn(inst_data, actions, args.device)\n\n    av_rew = rewards.mean()\n\n    advantage = (rewards - av_rew)\n\n    res = advantage.unsqueeze(1)*log_prob + args.beta*entropy\n\n    loss = -res[step_mask].sum()/args.batch_size\n\n    model_opt.zero_grad()\n    loss.backward(retain_graph=False)\n    torch.nn.utils.clip_grad_norm_(run_episode.neuralnet.parameters(), args.max_grad_norm)\n    model_opt.step()\n\n# ==========================================\n# File: src/neural_net.py\n# Function/Context: RecPointerNetwork\n# ==========================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\n\nimport math\nimport numpy as np\n\n# ------------------------------------------------------------------------------\n# Transformer model from: https://github.com/JayParks/transformer\n# and https://github.com/jadore801120/attention-is-all-you-need-pytorch\n\n\nclass ScaledDotProductAttention(nn.Module):\n    def __init__(self, d_k):\n        super(ScaledDotProductAttention, self).__init__()\n        self.scale_factor = np.sqrt(d_k)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, q, k, v, attn_mask=None):\n        # q: [b_size x len_q x d_k]\n        # k: [b_size x len_k x d_k]\n        # v: [b_size x len_v x d_v] note: (len_k == len_v)\n        attn = torch.bmm(q, k.transpose(1, 2)) / self.scale_factor  # attn: [b_size x len_q x len_k]\n        if attn_mask is not None:\n        #    assert attn_mask.size() == attn.size()\n            attn.data.masked_fill_(attn_mask==0, -1e32)\n\n        attn = self.softmax(attn )\n        outputs = torch.bmm(attn, v) # outputs: [b_size x len_q x d_v]\n        return outputs, attn\n\n\nclass _MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, n_heads):\n        super(_MultiHeadAttention, self).__init__()\n\n        self.d_k = d_model // n_heads\n        self.d_v = d_model // n_heads\n        self.d_model = d_model\n        self.n_heads = n_heads\n\n        self.w_q = nn.Parameter(torch.FloatTensor(n_heads, d_model, self.d_k))\n        self.w_k = nn.Parameter(torch.FloatTensor(n_heads, d_model, self.d_k))\n        self.w_v = nn.Parameter(torch.FloatTensor(n_heads, d_model, self.d_v))\n\n        self.attention = ScaledDotProductAttention(self.d_k)\n\n    def forward(self, q, k, v, attn_mask=None, is_adj=True):\n        (d_k, d_v, d_model, n_heads) = (self.d_k, self.d_v, self.d_model, self.n_heads)\n        b_size = k.size(0)\n\n        q_s = q.repeat(n_heads, 1, 1).view(n_heads, -1, d_model)  # [n_heads x b_size * len_q x d_model]\n        k_s = k.repeat(n_heads, 1, 1).view(n_heads, -1, d_model)  # [n_heads x b_size * len_k x d_model]\n        v_s = v.repeat(n_heads, 1, 1).view(n_heads, -1, d_model)  # [n_heads x b_size * len_v x d_model]\n\n        q_s = torch.bmm(q_s, self.w_q).view(b_size * n_heads, -1, d_k)  # [b_size * n_heads x len_q x d_k]\n        k_s = torch.bmm(k_s, self.w_k).view(b_size * n_heads, -1, d_k)  # [b_size * n_heads x len_k x d_k]\n        v_s = torch.bmm(v_s, self.w_v).view(b_size * n_heads, -1, d_v)  # [b_size * n_heads x len_v x d_v]\n\n        if attn_mask is not None:\n            if is_adj:\n                outputs, attn = self.attention(q_s, k_s, v_s, attn_mask=attn_mask.repeat(n_heads, 1, 1))\n            else:\n                outputs, attn = self.attention(q_s, k_s, v_s, attn_mask=attn_mask.unsqueeze(1).repeat(n_heads, 1, 1))\n        else:\n            outputs, attn = self.attention(q_s, k_s, v_s, attn_mask=None)\n\n        return torch.split(outputs, b_size, dim=0), attn\n\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, n_heads):\n        super(MultiHeadAttention, self).__init__()\n\n        self.d_k = d_model // n_heads\n        self.attention = _MultiHeadAttention(d_model, n_heads)\n        self.proj = nn.Linear(n_heads * self.d_k, d_model)\n        self.layer_norm = nn.LayerNorm(d_model)\n\n    def forward(self, q, k, v, attn_mask = None, is_adj = True):\n        # q: [b_size x len_q x d_model]\n        # k: [b_size x len_k x d_model]\n        # v: [b_size x len_v x d_model] note (len_k == len_v)\n        residual = q\n        # outputs: a list of tensors of shape [b_size x len_q x d_v] (length: n_heads)\n        outputs, attn = self.attention(q, k, v, attn_mask=attn_mask, is_adj=is_adj)\n        # concatenate 'n_heads' multi-head attentions\n        outputs = torch.cat(outputs, dim=-1)\n        # project back to residual size, result_size = [b_size x len_q x d_model]\n        outputs = self.proj(outputs)\n\n        return self.layer_norm(residual + outputs), attn\n\n\nclass PositionwiseFeedForward(nn.Module):\n    \"Implements FFN equation.\"\n    def __init__(self, d_model, d_ff):\n        super(PositionwiseFeedForward, self).__init__()\n        self.w_1 = nn.Linear(d_model, d_ff)\n        self.w_2 = nn.Linear(d_ff, d_model)\n        self.layer_norm = nn.LayerNorm(d_model)\n\n    def forward(self, x):\n        residual = x # inputs: [b_size x len_q x d_model]\n        outputs = self.w_2(F.relu(self.w_1(x)))\n        return self.layer_norm(residual + outputs)\n\n\n#----------- Pointer models common blocks ---------------------\n\nclass Decoder(nn.Module):\n    def __init__(self, hidden_size):\n        super(Decoder, self).__init__()\n\n        self.W1 = nn.Linear(hidden_size, hidden_size, bias=False)\n        self.W2 = nn.Linear(hidden_size, hidden_size)\n        self.V = nn.Parameter(torch.zeros((hidden_size, 1), requires_grad=True))\n\n        self.first_h_0 = nn.Parameter(torch.FloatTensor(1, hidden_size), requires_grad=True)\n        self.first_h_0.data.uniform_(-(1. / math.sqrt(hidden_size)), 1. / math.sqrt(hidden_size))\n\n        self.c0 = nn.Parameter(torch.FloatTensor( 1, hidden_size),requires_grad=True)\n        self.c0.data.uniform_(-(1. / math.sqrt(hidden_size)), 1. / math.sqrt(hidden_size))\n\n        self.hidden_0 = (self.first_h_0, self.c0)\n\n        self.lstm = nn.LSTMCell(hidden_size, hidden_size)\n\n\n    def forward(self, input, hidden, enc_outputs, mask):\n        hidden = self.lstm(input, hidden)\n        w1e = self.W1(enc_outputs)\n        w2h = self.W2(hidden[0]).unsqueeze(1)\n        u = torch.tanh(w1e + w2h)\n        a = u.matmul(self.V)\n        a = 10*torch.tanh(a).squeeze(2)\n\n        policy = F.softmax(a + mask.float().log(), dim=1)\n\n        return policy, hidden\n\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, d_ff, n_heads):\n        super(EncoderLayer, self).__init__()\n\n        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n        self.pos_ffn = PositionwiseFeedForward(d_model, d_ff)\n\n    def forward(self, enc_inp, rec_enc_inp, self_attn_mask):\n        enc_outputs, attn = self.enc_self_attn(enc_inp, rec_enc_inp, enc_inp, attn_mask=self_attn_mask)\n        enc_outputs = self.pos_ffn(enc_outputs)\n\n        return enc_outputs, attn\n\n\nclass Encoder(nn.Module):\n    def __init__(self, features_dim, dfeatures_dim, hidden_size, args):\n        super(Encoder, self).__init__()\n\n        n_heads = args.n_heads # number of heads\n        d_ff = args.ff_dim # feed_forward_hidden\n        n_layers = args.n_layers # number of Layers\n\n        self.L1 = nn.Linear(features_dim, hidden_size//2) # for static features\n        self.L2 = nn.Linear(dfeatures_dim, hidden_size//2) # for dynamic features\n\n        self.layers = nn.ModuleList([EncoderLayer(hidden_size, d_ff, n_heads) for _ in range(n_layers)])\n\n    def forward(self, emb_inp, rec_inp, mask, dummy_arg):\n        for layer in self.layers:\n            emb_inp, _ = layer(emb_inp, rec_inp, mask)\n\n        return emb_inp\n\n\nclass RecPointerNetwork(nn.Module):\n\n    def __init__(self, features_dim, dfeatures_dim, hidden_dim, args):\n        super(RecPointerNetwork, self).__init__()\n\n        self.features_dim = features_dim\n        self.dfeatures_dim = dfeatures_dim\n        self.use_checkpoint = args.use_checkpoint\n        self.hidden_dim = hidden_dim\n        self.decoder = Decoder(hidden_dim)\n        self.encoder = Encoder(features_dim, dfeatures_dim, hidden_dim, args)\n        # see https://discuss.pytorch.org/t/checkpoint-with-no-grad-requiring-inputs-problem/19117/11\n        self.dummy_tensor = torch.ones(1, dtype=torch.float32, requires_grad=True)\n\n        self._initialize_parameters()\n\n    def _initialize_parameters(self):\n        for name, param in self.named_parameters():\n            if len(param.shape) > 1:\n                nn.init.xavier_uniform_(param)\n\n    def _load_model_weights(self, path_string, device):\n        self.load_state_dict(torch.load(path_string, map_location=device))\n\n\n    def forward(self, enc_inputs, enc_hidden, adj_mask, dec_input, dec_hidden, mask, first_step=False):\n        policy, dec_hidden, enc_outputs = self._one_step(enc_inputs, enc_hidden, adj_mask, dec_input, dec_hidden, mask, first_step)\n        return policy, dec_hidden, enc_outputs\n\n    def _one_step(self, enc_inputs, enc_hidden, adj_mask, dec_input, dec_hidden, mask, first_step):\n        if self.use_checkpoint:\n            enc_outputs = checkpoint(self.encoder, enc_inputs, enc_hidden, adj_mask, self.dummy_tensor)\n        else:\n            enc_outputs = self.encoder(enc_inputs, enc_hidden, adj_mask, self.dummy_tensor)\n\n        if first_step:\n            return  None, None, enc_outputs\n        else:\n            policy, dec_hidden = self.decoder(dec_input, dec_hidden, enc_outputs, mask)\n            return policy, dec_hidden, enc_outputs\n\n    def sta_emb(self, sta_inp):\n        return torch.tanh(self.encoder.L1(sta_inp))\n\n    def dyn_emb(self, dyn_inp):\n        return torch.tanh(self.encoder.L2(dyn_inp))\n\n# ==========================================\n# File: src/solution_construction.py\n# Function/Context: RunEpisode, BeamSearch, Lookahead, ModelUtils\n# ==========================================\nimport torch\nimport torch.nn as nn\nfrom torch.utils.checkpoint import checkpoint\nfrom torch.distributions import Categorical\n\nimport sys\n\nfrom src.features_utils import DynamicFeatures\nimport src.problem_config as pcf\n\nourlogzero = sys.float_info.min\n\n\nclass Lookahead():\n    def __init__(self, args):\n        super(Lookahead, self).__init__()\n\n        self.device = args.device\n        self.opening_time_window_idx = pcf.OPENING_TIME_WINDOW_IDX\n        self.closing_time_window_idx = pcf.CLOSING_TIME_WINDOW_IDX\n        self.vis_duration_time_idx = pcf.VIS_DURATION_TIME_IDX\n        self.arrival_time_idx = pcf.ARRIVAL_TIME_IDX\n\n    def adjacency_matrix(self, braw_inputs, mask, dist_mat, pres_act, present_time):\n        # feasible neighborhood for each node\n        maskk = mask.clone()\n        step_batch_size, npoints = mask.shape\n\n        #one step forward update\n        arrivej = dist_mat[pres_act] + present_time\n        farrivej = arrivej.view(step_batch_size, npoints)\n        tw_start = braw_inputs[:, :, self.opening_time_window_idx]\n        waitj = torch.max(torch.FloatTensor([0.0]).to(self.device), tw_start-farrivej)\n        durat = braw_inputs[:, : , self.vis_duration_time_idx]\n\n        fpresent_time = farrivej + waitj + durat\n        fpres_act = torch.arange(0, npoints, device=self.device).expand(step_batch_size, -1)\n\n        # feasible neighborhood for each node\n        adj_mask = maskk.unsqueeze(1).repeat(1, npoints, 1)\n        arrivej = dist_mat.expand(step_batch_size, -1, -1) + fpresent_time.unsqueeze(2)\n        waitj = torch.max(torch.FloatTensor([0.0]).to(self.device), tw_start.unsqueeze(2)-arrivej)\n\n        tw_end = braw_inputs[:, :, self.closing_time_window_idx]\n        ttime = braw_inputs[:, 0, self.arrival_time_idx]\n\n        dlast = dist_mat[:, -1].unsqueeze(0).expand(step_batch_size, -1)\n\n        c1 = arrivej + waitj <= tw_end.unsqueeze(1)\n        c2 = arrivej + waitj + durat.unsqueeze(1) + dlast.unsqueeze(1) <= ttime.unsqueeze(1).unsqueeze(1).expand(-1, npoints, npoints)\n        adj_mask = adj_mask * c1 * c2\n\n        # self-loop\n        idx = torch.arange(0, npoints, device=self.device).expand(step_batch_size, -1)\n        adj_mask[:, idx, idx] = 1\n\n        return adj_mask\n\n\n\nclass ModelUtils():\n    def __init__(self, args):\n        super(ModelUtils, self).__init__()\n\n        self.device = args.device\n        self.opening_time_window_idx = pcf.OPENING_TIME_WINDOW_IDX\n        self.closing_time_window_idx = pcf.CLOSING_TIME_WINDOW_IDX\n        self.vis_duration_time_idx = pcf.VIS_DURATION_TIME_IDX\n        self.arrival_time_idx = pcf.ARRIVAL_TIME_IDX\n\n    def feasibility_control(self, braw_inputs, mask, dist_mat, pres_act, present_time, batch_idx, first_step=False):\n\n        done = False\n        maskk = mask.clone()\n        step_batch_size = batch_idx.shape[0]\n\n        arrivej = dist_mat[pres_act] + present_time\n        waitj = torch.max(torch.FloatTensor([0.0]).to(self.device), braw_inputs[:, :, self.opening_time_window_idx]-arrivej)\n\n        c1 = arrivej + waitj <= braw_inputs[:, :, self.closing_time_window_idx]\n        c2 = arrivej + waitj + braw_inputs[:, :, self.vis_duration_time_idx] + dist_mat[:, -1] <= braw_inputs[0, 0, self.arrival_time_idx]\n\n        if not first_step:\n            maskk[batch_idx, pres_act] = 0\n\n        maskk[batch_idx] = maskk[batch_idx] * c1 * c2\n\n        if maskk[:, -1].any() == 0:\n            done = True\n        return done, maskk\n\n\n    def one_step_update(self, raw_inputs_b, dist_mat, pres_action, future_action, present_time, batch_idx, batch_size):\n\n        present_time_b = torch.zeros(batch_size, 1, device=self.device)\n        pres_actions_b = torch.zeros(batch_size, dtype=torch.int64, device=self.device)\n        step_mask_b = torch.zeros(batch_size, 1, device=self.device, requires_grad=False, dtype=torch.bool)\n\n        arrive_j = dist_mat[pres_action, future_action].unsqueeze(1) + present_time\n        wait_j = torch.max(torch.FloatTensor([0.0]).to(self.device),\n                           raw_inputs_b[batch_idx, future_action, self.opening_time_window_idx].unsqueeze(1)-arrive_j)\n        present_time = arrive_j + wait_j + raw_inputs_b[batch_idx, future_action, self.vis_duration_time_idx].unsqueeze(1)\n\n        present_time_b[batch_idx] = present_time\n\n        pres_actions_b[batch_idx] = future_action\n        step_mask_b[batch_idx] = 1\n\n        return pres_actions_b, present_time_b, step_mask_b\n\n\n\nclass RunEpisode(nn.Module):\n\n    def __init__(self, neuralnet, args):\n        super(RunEpisode, self).__init__()\n\n        self.device = args.device\n        self.neuralnet = neuralnet\n        self.dyn_feat = DynamicFeatures(args)\n        self.lookahead = Lookahead(args)\n        self.mu = ModelUtils(args)\n\n    def forward(self, binputs, bdata_scaled, start_time, dist_mat, infer_type):\n\n        self.batch_size, sequence_size, input_size = binputs.size()\n\n        h_0, c_0 = self.neuralnet.decoder.hidden_0\n\n        dec_hidden = (h_0.expand(self.batch_size, -1), c_0.expand(self.batch_size, -1))\n\n        mask = torch.ones(self.batch_size, sequence_size, device=self.device, requires_grad=False, dtype = torch.uint8)\n\n        bpresent_time = start_time*torch.ones(self.batch_size, 1, device=self.device)\n\n        llog_probs, lactions, lstep_mask, lentropy = [], [], [], []\n\n        bpres_actions = torch.zeros(self.batch_size, dtype=torch.int64, device=self.device)\n\n        batch_idx = torch.arange(0, self.batch_size, device=self.device)\n\n        done, mask = self.mu.feasibility_control(binputs[batch_idx], mask, dist_mat, bpres_actions,\n                                                 bpresent_time, batch_idx, first_step=True)\n\n        adj_mask = self.lookahead.adjacency_matrix(binputs[batch_idx], mask, dist_mat, bpres_actions, bpresent_time)\n\n        # encoder first forward pass\n        bdyn_inputs = self.dyn_feat.make_dynamic_feat(binputs, bpresent_time, bpres_actions, dist_mat, batch_idx)\n        emb1 = self.neuralnet.sta_emb(bdata_scaled)\n        emb2 = self.neuralnet.dyn_emb(bdyn_inputs)\n        enc_inputs = torch.cat((emb1,emb2), dim=2)\n\n        _, _, enc_outputs = self.neuralnet(enc_inputs, enc_inputs, adj_mask, enc_inputs, dec_hidden, mask, first_step=True)\n\n        decoder_input = enc_outputs[batch_idx, bpres_actions]\n\n        done, mask = self.mu.feasibility_control(binputs[batch_idx], mask, dist_mat, bpres_actions, bpresent_time, batch_idx)\n        adj_mask = self.lookahead.adjacency_matrix(binputs[batch_idx], mask, dist_mat, bpres_actions, bpresent_time)\n\n        # encoder/decoder forward pass\n        bdyn_inputs = self.dyn_feat.make_dynamic_feat(binputs, bpresent_time,\n                                                      bpres_actions, dist_mat, batch_idx)\n        emb2 = self.neuralnet.dyn_emb(bdyn_inputs)\n        enc_inputs = torch.cat((emb1,emb2), dim=2)\n\n        policy, dec_hidden, enc_outputs = self.neuralnet(enc_inputs, enc_outputs, adj_mask, decoder_input, dec_hidden, mask)\n\n        lactions.append(bpres_actions)\n\n        # Starting the trip\n        while not done:\n\n            future_actions, log_probs, entropy = self.select_actions(policy, infer_type)\n\n            bpres_actions, bpresent_time, bstep_mask = self.mu.one_step_update(binputs, dist_mat, bpres_actions[batch_idx],\n                                                                               future_actions, bpresent_time[batch_idx],\n                                                                               batch_idx, self.batch_size)\n\n            blog_probs = torch.zeros(self.batch_size, 1, dtype=torch.float32).to(self.device)\n            blog_probs[batch_idx] = log_probs.unsqueeze(1)\n\n            bentropy = torch.zeros(self.batch_size,1,dtype=torch.float32).to(self.device)\n            bentropy[batch_idx] = entropy.unsqueeze(1)\n\n            llog_probs.append(blog_probs)\n            lactions.append(bpres_actions)\n            lstep_mask.append(bstep_mask)\n            lentropy.append(bentropy)\n\n            done, mask = self.mu.feasibility_control(binputs[batch_idx], mask, dist_mat,\n                                                     bpres_actions[batch_idx], bpresent_time[batch_idx],\n                                                     batch_idx)\n\n            if done: break\n            sub_batch_idx = torch.nonzero(mask[batch_idx][:,-1], as_tuple=False).squeeze(1)\n\n            batch_idx = torch.nonzero(mask[:,-1], as_tuple=False).squeeze(1)\n\n            adj_mask = self.lookahead.adjacency_matrix(binputs[batch_idx], mask[batch_idx], dist_mat, bpres_actions[batch_idx], bpresent_time[batch_idx])\n\n            #update decoder input and hidden\n            decoder_input = enc_outputs[sub_batch_idx, bpres_actions[sub_batch_idx]]\n            dec_hidden = (dec_hidden[0][sub_batch_idx], dec_hidden[1][sub_batch_idx])\n\n            # encoder/decoder forward pass\n            bdyn_inputs = self.dyn_feat.make_dynamic_feat(binputs, bpresent_time[batch_idx], bpres_actions[batch_idx], dist_mat, batch_idx)\n            emb2 = self.neuralnet.dyn_emb(bdyn_inputs)\n            enc_inputs = torch.cat((emb1[batch_idx],emb2), dim=2)\n\n            policy, dec_hidden, enc_outputs = self.neuralnet(enc_inputs, enc_outputs[sub_batch_idx], adj_mask, decoder_input, dec_hidden, mask[batch_idx])\n\n        return lactions, torch.cat(llog_probs, dim=1), torch.cat(lentropy, dim=1), torch.cat(lstep_mask, dim=1)\n\n\n    def select_actions(self, policy, infer_type):\n\n        if infer_type == 'stochastic':\n            m = Categorical(policy)\n            act_ind = m.sample()\n            log_select =  m.log_prob(act_ind)\n            poli_entro = m.entropy()\n        elif infer_type == 'greedy':\n            prob, act_ind = torch.max(policy, 1)\n            log_select =  prob.log()\n            poli_entro =  torch.zeros(self.batch_size, requires_grad=False).to(self.device)\n\n        return act_ind, log_select, poli_entro\n\n\n\nclass BeamSearch(nn.Module):\n    def __init__(self, neuralnet, args):\n        super(BeamSearch, self).__init__()\n\n        self.device = args.device\n        self.neuralnet = neuralnet\n        self.dyn_feat = DynamicFeatures(args)\n        self.lookahead = Lookahead(args)\n        self.mu = ModelUtils(args)\n\n    def forward(self, inputs, data_scaled, start_time, dist_mat, infer_type, beam_size):\n        self.beam_size = beam_size\n        _, sequence_size, input_size = inputs.size()\n\n        # first step  - node 0\n        bpresent_time = start_time*torch.ones(1, 1, device=self.device)\n\n        mask = torch.ones(1, sequence_size, device=self.device, requires_grad=False, dtype= torch.uint8)\n        bpres_actions = torch.zeros(1, dtype=torch.int64,device=self.device)\n        beam_idx = torch.arange(0, 1, device=self.device)\n\n        done, mask = self.mu.feasibility_control(inputs.expand(beam_idx.shape[0], -1, -1),\n                                                 mask, dist_mat, bpres_actions, bpresent_time,\n                                                 torch.arange(0, mask.shape[0], device=self.device),\n                                                 first_step=True)\n        adj_mask = self.lookahead.adjacency_matrix(inputs.expand(beam_idx.shape[0], -1, -1),\n                                                   mask, dist_mat, bpres_actions, bpresent_time)\n\n        h_0, c_0 = self.neuralnet.decoder.hidden_0\n        dec_hidden = (h_0.expand(1, -1), c_0.expand(1, -1))\n\n        step = 0\n\n        # encoder first forward pass\n        bdata_scaled = data_scaled.expand(1,-1,-1)\n        sum_log_probs = torch.zeros(1, device=self.device).float()\n\n        bdyn_inputs = self.dyn_feat.make_dynamic_feat(inputs.expand(1,-1,-1), bpresent_time, bpres_actions, dist_mat, beam_idx)\n        emb1 = self.neuralnet.sta_emb(bdata_scaled)\n        emb2 = self.neuralnet.dyn_emb(bdyn_inputs)\n        enc_inputs = torch.cat((emb1, emb2), dim=2)\n\n        _, _, enc_outputs = self.neuralnet(enc_inputs, enc_inputs, adj_mask, enc_inputs, dec_hidden, mask, first_step=True)\n\n        decoder_input = enc_outputs[beam_idx, bpres_actions]\n\n        done, mask = self.mu.feasibility_control(inputs.expand(beam_idx.shape[0], -1, -1),\n                                                 mask, dist_mat, bpres_actions, bpresent_time,\n                                                 torch.arange(0, mask.shape[0], device=self.device))\n        adj_mask = self.lookahead.adjacency_matrix(inputs.expand(beam_idx.shape[0], -1, -1),\n                                                   mask, dist_mat, bpres_actions, bpresent_time)\n\n        # encoder/decoder forward pass\n        bdyn_inputs = self.dyn_feat.make_dynamic_feat(inputs.expand(beam_idx.shape[0], -1, -1), bpresent_time, bpres_actions, dist_mat, beam_idx)\n        emb2 = self.neuralnet.dyn_emb(bdyn_inputs)\n        enc_inputs = torch.cat((emb1,emb2), dim=2)\n\n        policy, dec_hidden, enc_outputs = self.neuralnet(enc_inputs, enc_outputs, adj_mask, decoder_input, dec_hidden, mask)\n\n        future_actions, log_probs, beam_idx = self.select_actions(policy, sum_log_probs, mask, infer_type)\n        # info update\n        h_step = torch.index_select(dec_hidden[0], dim=0, index = beam_idx)\n        c_step = torch.index_select(dec_hidden[1], dim=0, index = beam_idx)\n        dec_hidden = (h_step,c_step)\n\n        mask = torch.index_select(mask, dim=0, index=beam_idx)\n        bpresent_time = torch.index_select(bpresent_time, dim=0, index=beam_idx)\n        bpres_actions = torch.index_select(bpres_actions, dim=0, index=beam_idx)\n        enc_outputs  = torch.index_select(enc_outputs, dim=0, index=beam_idx)\n        sum_log_probs = torch.index_select(sum_log_probs, dim=0, index=beam_idx)\n\n        emb1 = torch.index_select(emb1, dim=0, index=beam_idx)\n\n        # initialize buffers\n        bllog_probs = torch.zeros(bpres_actions.shape[0], sequence_size, device=self.device).float()\n        blactions = torch.zeros(bpres_actions.shape[0], sequence_size, device=self.device).long()\n\n        sum_log_probs += log_probs.squeeze(0).detach()\n\n        blactions[:, step] = bpres_actions\n\n        final_log_probs, final_actions, lstep_mask = [], [], []\n\n        # Starting the trip\n        while not done:\n\n            future_actions = future_actions.squeeze(0)\n\n            beam_size = bpres_actions.shape[0]\n            bpres_actions, bpresent_time, bstep_mask = \\\n                self.mu.one_step_update(inputs.expand(beam_size, -1, -1), dist_mat,\n                                        bpres_actions, future_actions, bpresent_time,\n                                        torch.arange(0,beam_size,device=self.device),\n                                        beam_size)\n\n            bllog_probs[:, step] = log_probs\n            blactions[:, step+1] = bpres_actions\n            step+=1\n\n            done, mask = self.mu.feasibility_control(inputs.expand(beam_idx.shape[0], -1, -1),\n                                                     mask, dist_mat, bpres_actions, bpresent_time,\n                                                     torch.arange(0, mask.shape[0], device=self.device))\n            adj_mask = \n\n# ==========================================\n# File: src/train_utils.py\n# Function/Context: train_model\n# ==========================================\nimport torch\nimport random\n\nfrom src.sampling_norm_utils import sample_new_instance, data_scaler\nimport src.problem_config as pcf\n\n\ndef reward_fn(data, sample_solution, device):\n    \"\"\"\n    Returns:\n        Tensor of shape [batch_size] containing rewards\n    \"\"\"\n\n    batch_size = sample_solution[0].shape[0]\n    tour_reward = torch.zeros(batch_size, device=device)\n\n    for act_id in sample_solution:\n        tour_reward += data[act_id, pcf.REWARD_IDX].squeeze(0)\n\n    return tour_reward\n\n\ndef exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_step=5000):\n    \"\"\"Decay learning rate by a factor of 0.96 every lr_decay_epoch epochs.\n       Lower_bounded at 0.00001\"\"\"\n    lr = init_lr * (0.96**(epoch // lr_decay_step))\n    if lr < 0.00001:\n        lr = 0.00001\n\n    if epoch % lr_decay_step == 0:\n        print('LR is set to {}'.format(lr))\n\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n    return optimizer\n\n\ndef samples2batch(new_data, new_data_scaled, batch_size):\n    bnew_data = new_data.expand(batch_size, -1, -1)\n    bnew_data_scaled = new_data_scaled.expand(batch_size, -1, -1)\n    return bnew_data, bnew_data_scaled\n\n\ndef train_model(raw_data, raw_dist_mat, norm_dic, run_episode, opt, args):\n\n    new_data, start_time, dist_mat = sample_new_instance(raw_data, raw_dist_mat, args)\n    new_data_scaled = data_scaler(new_data, norm_dic[args.instance])\n    bnew_data, bnew_data_scaled = samples2batch(new_data, new_data_scaled, args.batch_size)\n\n    run_episode.train()\n    opt.zero_grad()\n    actions, log_prob, entropy, step_mask = run_episode(bnew_data, bnew_data_scaled, start_time, dist_mat, 'stochastic')\n\n    rewards = reward_fn(new_data, actions, args.device)\n\n    loss = 0\n\n    av_rew = rewards.mean()\n    min_rew = rewards.min()\n    max_rew = rewards.max()\n\n    advantage = (rewards - av_rew) #advantage\n\n    res = advantage.unsqueeze(1)*log_prob + args.beta*entropy\n\n    loss = -res[step_mask].sum()/args.batch_size\n\n    loss.backward(retain_graph=False)\n    torch.nn.utils.clip_grad_norm_(run_episode.neuralnet.parameters(), args.max_grad_norm)\n    opt.step()\n\n    return av_rew.item(), min_rew.item(), max_rew.item(), loss.item()\n\n\ndef test_model(data, start_time, dist_mat, inst, inst_norm_dic, run_episode, device):\n    with torch.no_grad():\n        data_scaled = data_scaler(data, inst_norm_dic[inst])\n        bdata, bdata_scaled = data.unsqueeze(0), data_scaled.unsqueeze(0)\n        actions, log_prob, entropy, step_mask = run_episode(bdata, bdata_scaled, start_time, dist_mat, 'greedy')\n        reward = reward_fn(data, actions, device)\n\n        return reward.item()\n\n\ndef validation(inp_val, run_episode, inst_norm_dic, device):\n    reward_val =  torch.tensor(0.0).to(device)\n    rew_dict = {}\n    for k, (inst_name, data) in enumerate(inp_val):\n        inst_data, start_time, dist_mat = data\n        rew = test_model(inst_data, start_time, dist_mat, inst_name, inst_norm_dic, run_episode, device)\n        reward_val += rew\n        key_str = inst_name + '_' + str(k)\n        rew_dict[key_str] = rew\n\n    return rew_dict, reward_val.item()/len(inp_val)",
  "description": "Combined Analysis:\n- [inference_optw_rl.py]: This file implements the inference phase of the OPTW reinforcement learning algorithm. It loads pre-trained Pointer Network models and performs inference using three methods: greedy selection, beam search, and active search with beam search. The core logic includes: 1) Loading OPTW instance data and normalization constants, 2) Initializing the RecPointerNetwork model with trained weights, 3) Executing inference via run_single() or run_multiple() functions which implement the beam search algorithm (maintaining top-nb partial solutions) and active search fine-tuning (REINFORCE algorithm for 128 epochs). The mathematical optimization model's constraints are enforced during solution construction in the inference utilities.\n- [src/inference_utils.py]: This file implements the inference and active search components of the RL algorithm for OPTW. It provides three inference methods: greedy (gr_inference), beam search (bs_inference), and active search with beam search (as_bs_inference). The active_search_train_model function implements the REINFORCE training step for active search, including advantage computation, entropy regularization, and gradient clipping. The run_single and run_multiple functions orchestrate the inference process, loading model weights and measuring inference time. This directly corresponds to Algorithm Steps 3a (Beam Search) and 3b (Active Search) from the paper description.\n- [src/neural_net.py]: This file implements the core neural network architecture (Pointer Network) described in the paper's algorithm steps. Specifically, it contains:\n1. The RecPointerNetwork class that corresponds to the 'set encoder (Transformer with recursion and graph masked self-attention), a sequence encoder (LSTM), and a pointing mechanism' mentioned in Step 1 of the algorithm.\n2. The encoder uses multi-head self-attention (Transformer blocks) with graph masking (adj_mask parameter) to process static and dynamic features.\n3. The decoder uses an LSTM cell (sequence encoder) with attention mechanism to generate probability distributions over nodes (policy).\n4. The forward method implements the sequential decision process where the model outputs probability distributions for node selection at each step.\n5. The architecture directly supports the REINFORCE algorithm by providing policy outputs (pθ(S|φ)) that can be used to compute gradients for parameter updates.\n6. The model handles both static features (node coordinates, scores, time windows) and dynamic features (remaining time, current position) through separate embedding layers.\n\nThis implementation is the neural component that, when combined with the REINFORCE training loop and beam search inference (implemented elsewhere), forms the complete RL approach to OPTW.\n- [src/solution_construction.py]: This file implements the core solution construction logic for the OPTW problem using a Pointer Network model. It contains:\n1. **Lookahead**: Computes adjacency matrices for feasible next nodes based on time window constraints and global time budget.\n2. **ModelUtils**: Implements feasibility checks (constraints c1 and c2 from the paper) and one-step state updates (arrival time, waiting time, departure time).\n3. **RunEpisode**: Performs sequential solution construction (episode rollout) using the neural network policy, handling dynamic feature updates and constraint satisfaction at each step. This corresponds to the solution construction in the training loop (step 2.ii in the algorithm).\n4. **BeamSearch**: Implements beam search for inference, maintaining a beam of partial solutions and expanding them while respecting constraints. This matches the beam search algorithm described in the paper (step 3.a).\n\nThe code directly encodes the mathematical constraints of the OPTW model (time window and global deadline) and the sequential decision-making process of the reinforcement learning algorithm.\n- [src/train_utils.py]: This file implements the core REINFORCE training loop (Step 2 of the algorithm) for the OPTW problem. The `train_model` function performs a single training epoch: it samples an instance, runs the policy network (`run_episode`) in stochastic mode to generate a batch of solutions, computes the total reward (sum of scores) for each solution using `reward_fn`, calculates the advantage (reward minus baseline), and updates the model parameters using the policy gradient loss with entropy regularization. The `test_model` and `validation` functions handle greedy evaluation on validation instances. The code directly corresponds to the REINFORCE algorithm with a baseline (average reward) and entropy term for exploration, as described in the paper's training loop.",
  "dependencies": [
    "src.utils",
    "Lookahead",
    "tqdm",
    "argparse",
    "BeamSearch",
    "pandas",
    "src.sampling_norm_utils.sample_new_instance",
    "json",
    "numpy",
    "src.sampling_norm_utils.data_scaler",
    "run_episode (Pointer Network model)",
    "time",
    "torch.nn.init",
    "src.features_utils.DynamicFeatures",
    "src.sampling_norm_utils",
    "torch",
    "src.problem_config",
    "torch.nn.functional",
    "torch.distributions.Categorical",
    "src.train_utils",
    "os",
    "optimizer (Adam)",
    "math",
    "checkpoint (from torch.utils.checkpoint)",
    "ModelUtils",
    "torch.nn",
    "optim",
    "src.config",
    "logging",
    "sys",
    "RunEpisode",
    "src.solution_construction",
    "random",
    "RecPointerNetwork",
    "src.inference_utils",
    "torch.utils.checkpoint"
  ]
}