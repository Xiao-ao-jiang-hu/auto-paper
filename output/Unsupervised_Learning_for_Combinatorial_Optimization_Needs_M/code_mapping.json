{
  "file_path": "max_clique/rb200/gnn_model.py, max_clique/rb200/learner_model.py, max_clique/rb200/modules_and_utils.py, max_clique/rb200/train_maml.py, max_clique/twitter/gnn_model.py, max_clique/twitter/learner_model.py, vertex_cover/rb200/gnn_model.py, vertex_cover/rb200/learner_model.py, vertex_cover/rb200/train_maml.py, vertex_cover/twitter/gnn_model.py, vertex_cover/twitter/learner_model.py",
  "function_name": "clique_MPNN, ErdosLoss_clique, Learner, decode_clique_final, main, clique_MPNN, ErdosLoss_clique, Learner.erdosloss_clique, vertex_MPNN, ErdosLoss_vertex, ErdosLoss_vertex_new, Learner.erdosloss_vertex, main, vertex_MPNN, ErdosLoss_vertex, Learner.erdosloss_vertex",
  "code_snippet": "\n\n# ==========================================\n# File: max_clique/rb200/gnn_model.py\n# Function/Context: clique_MPNN, ErdosLoss_clique\n# ==========================================\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn import Linear\nfrom torch import tensor\nfrom torch.optim import Adam\nfrom torch.optim import SGD\nfrom math import ceil\nfrom torch.nn import Linear\nfrom torch.distributions import categorical\nfrom torch.distributions import Bernoulli\nimport torch.nn\nfrom torch_geometric.utils import convert as cnv\nfrom torch_geometric.utils import sparse as sp\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn.inits import uniform\nfrom torch_geometric.nn.inits import glorot, zeros\nfrom torch.nn import Parameter\nfrom torch.nn import Sequential as Seq, Linear, ReLU\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.utils import degree\nfrom torch_geometric.nn import GINConv, GATConv\nfrom torch.nn import Parameter\nfrom torch.nn import Sequential as Seq, Linear, ReLU, LeakyReLU\nfrom torch_geometric.nn import MessagePassing\nfrom torch.nn import Linear, Sequential, ReLU, BatchNorm1d as BN\nfrom torch_geometric.data import Batch \nfrom torch_scatter import scatter_min, scatter_max, scatter_add, scatter_mean\nfrom torch import autograd\nfrom torch_geometric.utils import softmax, add_self_loops, remove_self_loops, segregate_self_loops, remove_isolated_nodes, contains_isolated_nodes, add_remaining_self_loops, dropout_adj\nfrom utils import get_mask\nfrom torch_geometric.nn.norm.graph_size_norm import GraphSizeNorm\n\nclass clique_MPNN(torch.nn.Module):\n    def __init__(self, dataset, num_layers, hidden1, hidden2, deltas):\n        super(clique_MPNN, self).__init__()\n        self.hidden1 = hidden1\n        self.hidden2 = hidden2\n        self.momentum = 0.1\n        self.convs = torch.nn.ModuleList()\n        self.deltas = deltas\n        self.numlayers = num_layers\n        self.heads = 8\n        self.concat = True\n        \n        self.bns = torch.nn.ModuleList()\n        for i in range(num_layers-1):\n            self.bns.append(BN(self.heads*self.hidden1, momentum=self.momentum))\n        self.convs = torch.nn.ModuleList()        \n        for i in range(num_layers - 1):\n                self.convs.append(GINConv(Sequential(\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            BN(self.heads*self.hidden1, momentum=self.momentum),\n        ),train_eps=True))\n        self.bn1 = BN(self.heads*self.hidden1)       \n        self.conv1 = GINConv(Sequential(Linear(self.hidden2,  self.heads*self.hidden1),\n            ReLU(),\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            BN(self.heads*self.hidden1, momentum=self.momentum),\n        ),train_eps=True)\n\n        if self.concat:\n            self.lin1 = Linear(self.heads*self.hidden1, self.hidden1)\n        else:\n            self.lin1 = Linear(self.hidden1, self.hidden1)\n        self.lin2 = Linear(self.hidden1, 1)\n        self.gnorm = GraphSizeNorm()\n\n    def reset_parameters(self):\n        self.conv1.reset_parameters()\n        \n        for conv in self.convs:\n            conv.reset_parameters() \n        for bn in self.bns:\n            bn.reset_parameters()\n        self.bn1.reset_parameters()\n        self.lin1.reset_parameters()\n        self.lin2.reset_parameters()\n\n    def forward(self, x, edge_index, batch, edge_dropout = None, penalty_coefficient = 0.25):\n        num_graphs = batch.max().item() + 1\n        row, col = edge_index     \n        total_num_edges = edge_index.shape[1]\n        N_size = x.shape[0]\n\n        if edge_dropout is not None:\n            edge_index = dropout_adj(edge_index, edge_attr = (torch.ones(edge_index.shape[1], device=device)).long(), p = edge_dropout, force_undirected=True)[0]\n            edge_index = add_remaining_self_loops(edge_index, num_nodes = batch.shape[0])[0]\n                \n        reduced_num_edges = edge_index.shape[1]\n        current_edge_percentage = (reduced_num_edges/total_num_edges)\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n\n        xinit= x.clone()\n        x = x.unsqueeze(-1)\n        mask = get_mask(x,edge_index,1).to(x.dtype)\n        x = F.leaky_relu(self.conv1(x, edge_index))# +x\n        x = x*mask\n        x = self.gnorm(x)\n        x = self.bn1(x)\n        \n            \n        for conv, bn in zip(self.convs, self.bns):\n            if(x.dim()>1):\n                x =  x+F.leaky_relu(conv(x, edge_index))\n                mask = get_mask(mask,edge_index,1).to(x.dtype)\n                x = x*mask\n                x = self.gnorm(x)\n                x = bn(x)\n\n        xpostconvs = x.detach()\n        #\n        x = F.leaky_relu(self.lin1(x)) \n        x = x*mask\n\n        xpostlin1 = x.detach()\n        x = F.leaky_relu(self.lin2(x)) \n        x = x*mask\n\n        #calculate min and max\n        batch_max = scatter_max(x, batch, 0, dim_size= N_size)[0]\n        batch_max = torch.index_select(batch_max, 0, batch)        \n        batch_min = scatter_min(x, batch, 0, dim_size= N_size)[0]\n        batch_min = torch.index_select(batch_min, 0, batch)\n\n        #min-max normalize\n        x = (x-batch_min)/(batch_max+1e-6-batch_min)\n        probs=x\n\n        return probs\n\nclass ErdosLoss_clique(torch.nn.Module):\n    def __init__(self):\n        super(ErdosLoss_clique,self).__init__()\n        #self.penalty = Penalty()\n    def forward(self, probs, edge_index, batch, penalty_coefficient,device):\n        #calculating the terms for the expected distance between clique and graph\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        pairwise_prodsums = torch.zeros(num_graphs, device = device)\n        for graph in range(num_graphs):\n            batch_graph = (batch==graph)\n            pairwise_prodsums[graph] = (torch.conv1d(probs[batch_graph].unsqueeze(-1), probs[batch_graph].unsqueeze(-1))).sum()/2\n        ###calculate loss terms\n        self_sums = scatter_add((probs*probs), batch, 0, dim_size = num_graphs)\n        expected_weight_G = scatter_add(probs[no_loop_row]*probs[no_loop_col], batch[no_loop_row], 0, dim_size = num_graphs)/2.\n        expected_clique_weight = (pairwise_prodsums.unsqueeze(-1) - self_sums)/1.\n        expected_distance = (expected_clique_weight - expected_weight_G)        \n        \n        ###calculate loss\n        expected_loss = (penalty_coefficient)*expected_distance*0.5 - 0.5*expected_weight_G  \n        loss = expected_loss\n\n        retdict = {}\n        retdict[\"output\"] = [probs.squeeze(-1),\"hist\"]   #output\n        retdict[\"losses histogram\"] = [loss.squeeze(-1),\"hist\"]\n        retdict[\"Expected weight(G)\"]= [expected_weight_G.mean(), \"sequence\"]\n        retdict[\"Expected maximum weight\"] = [expected_clique_weight.mean(),\"sequence\"]\n        retdict[\"Expected distance\"]= [expected_distance.mean(), \"sequence\"]\n        retdict[\"loss\"] = [loss.mean().squeeze(),\"sequence\"] #final loss\n        return retdict\n\n# ==========================================\n# File: max_clique/rb200/learner_model.py\n# Function/Context: Learner\n# ==========================================\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport utils\nfrom   torch.nn import functional as F\nfrom torch_geometric.utils import remove_self_loops\nfrom torch_scatter import scatter_add\n\nclass Learner:\n    def __init__(self, model, loss_function, inner_lr=1e-3, outer_lr=1e-2, GPU=-1, inner_alg='gradient', outer_alg='adam'):\n        self.model = model\n        self.use_gpu = GPU\n        if GPU>=0:\n            device = torch.device('cuda:'+str(GPU)if torch.cuda.is_available() else \"cpu\")\n            #self.model.cuda()\n            self.model.to(device)\n        assert outer_alg == 'sgd' or 'adam'\n        #self.inner_opt = torch.optim.SGD(self.model.parameters(), lr=inner_lr)\n        self.inner_opt = torch.optim.Adam(self.model.parameters(), lr=inner_lr, eps=1e-3)\n        if outer_alg == 'adam':\n            self.outer_opt = torch.optim.Adam(self.model.parameters(), lr=outer_lr, eps=1e-3)\n        else:\n            self.outer_opt = torch.optim.SGD(self.model.parameters(), lr=outer_lr)\n        self.loss_function = loss_function\n        assert inner_alg == 'gradient' # sqp unsupported in this version\n        self.inner_alg = inner_alg\n\n    def get_params(self):\n        return torch.cat([param.data.view(-1) for param in self.model.parameters()], 0).clone()\n\n    def set_params(self, param_vals):\n        offset = 0\n        for param in self.model.parameters():\n            param.data.copy_(param_vals[offset:offset + param.nelement()].view(param.size()))\n            offset += param.nelement()\n            \n    def set_outer_lr(self, lr):\n        for param_group in self.outer_opt.param_groups:\n            param_group['lr'] = lr\n            \n    def set_inner_lr(self, lr):\n        for param_group in self.inner_opt.param_groups:\n            param_group['lr'] = lr\n\n    def regularization_loss(self, w_0, lam=0.0):\n        \"\"\"\n        Add a regularization loss onto the weights\n        The proximal term regularizes around the point w_0\n        Strength of regularization is lambda\n        lambda can either be scalar (type float) or ndarray (numpy.ndarray)\n        \"\"\"\n        regu_loss = 0.0\n        offset = 0\n        regu_lam = lam if type(lam) == float or np.float64 else utils.to_tensor(lam)\n        if w_0.dtype == torch.float16:\n            try:\n                regu_lam = regu_lam.half()\n            except:\n                regu_lam = np.float16(regu_lam)\n        for param in self.model.parameters():\n            delta = param.view(-1) - w_0[offset:offset + param.nelement()].view(-1)\n            if type(regu_lam) == float or np.float64:\n                regu_loss += 0.5 * regu_lam * torch.sum(delta ** 2)\n            else:\n                # import ipdb; ipdb.set_trace()\n                param_lam = regu_lam[offset:offset + param.nelement()].view(-1)\n                param_delta = delta * param_lam\n                regu_loss += 0.5 * torch.sum(param_delta ** 2)\n            offset += param.nelement()\n        return regu_loss\n\n    def get_loss(self, x, edge_index, batch, penalty_coefficient, device, return_numpy = False):\n        probs = self.model.forward(x, edge_index, batch)\n        loss_dict = self.erdosloss_clique(probs, edge_index, batch, penalty_coefficient, device)\n        loss = loss_dict['loss'][0]\n        weight = loss_dict['Expected weight(G)'][0].item()\n        distance = loss_dict['Expected distance'][0].item()\n        if return_numpy:\n            loss = utils.to_numpy(loss).ravel()[0]\n        return loss, weight, distance\n\n    def predict(self, x, edge_index, batch, return_numpy = False):\n        utils.to_device(x, self.use_gpu)\n        utils.to_device(edge_index, self.use_gpu)\n        utils.to_device(batch, self.use_gpu)\n        probs = self.model.forward(x, edge_index, batch)\n        if return_numpy:\n            probs = utils.to_numpy(probs)\n        return probs\n\n    def learn_on_data(self, x, edge_index, batch, penalty_coefficient, device, num_steps=10,\n                      add_regularization=False,\n                      w_0=None, lam=0.0):\n        assert self.inner_alg == 'gradient'# or 'sqp' or 'adam' # TODO(Aravind): support sqp and adam \n        train_loss = []\n        if self.inner_alg == 'gradient':\n            for i in range(num_steps):\n                self.inner_opt.zero_grad()\n                tloss = self.get_loss(x, edge_index, batch, penalty_coefficient, device)\n                loss = tloss + self.regularization_loss(w_0, lam) if add_regularization else tloss\n                loss.backward()\n                #torch.nn.utils.clip_grad_norm_(self.model.parameters(),1)\n                self.inner_opt.step()\n                train_loss.append(utils.to_numpy(tloss))\n        return train_loss\n    \n    def learn_task(self, x, edge_index, batch, penalty_coefficient, device, num_steps=10, add_regularization=False, w_0=None, lam=0.0):\n\n        return self.learn_on_data(x, edge_index, batch, penalty_coefficient, device, num_steps, add_regularization, w_0, lam)\n\n    def move_toward_target(self, target, lam=2.0):\n        \"\"\"\n        Move slowly towards the target parameter value\n        Default value for lam assumes learning rate determined by optimizer\n        Useful for implementing Reptile\n        \"\"\"\n        # we can implement this with the regularization loss, but regularize around the target point\n        # and with specific choice of lam=2.0 to preserve the learning rate of inner_opt\n        self.outer_opt.zero_grad()\n        loss = self.regularization_loss(target, lam=lam)\n        loss.backward()\n        self.outer_opt.step()\n\n    def outer_step_with_grad(self, grad, flat_grad=False):\n        \"\"\"\n        Given the gradient, step with the outer optimizer using the gradient.\n        Assumed that the gradient is a tuple/list of size compatible with model.parameters()\n        If flat_grad, then the gradient is a flattened vector\n        \"\"\"\n        check = 0\n        for p in self.model.parameters():\n            check = check + 1 if type(p.grad) == type(None) else check\n        if check > 0:\n            # initialize the grad fields properly\n            dummy_loss = self.regularization_loss(self.get_params())\n            dummy_loss.backward()  # this would initialize required variables\n        if flat_grad:\n            offset = 0\n            grad = utils.to_device(grad, self.use_gpu)\n            for p in self.model.parameters():\n                this_grad = grad[offset:offset + p.nelement()].view(p.size())\n                p.grad.copy_(this_grad)\n                offset += p.nelement()\n        else:\n            for i, p in enumerate(self.model.parameters()):\n                p.grad = grad[i]\n        self.outer_opt.step()\n\n    def matrix_evaluator(self, x, edge_index, batch, lam, penalty_coefficient, device, regu_coef=1.0, lam_damping=10.0):\n        \"\"\"\n        Constructor function that can be given to CG optimizer\n        Works for both type(lam) == float and type(lam) == np.ndarray\n        \"\"\"\n        if type(lam) == np.ndarray:\n            lam = utils.to_device(lam, self.use_gpu)\n        def evaluator(v):\n            hvp = self.hessian_vector_product(x, edge_index, batch, v, penalty_coefficient, device)\n            #hvp = self.hessian_vector_product(task, v, x=x, y=y)\n            Av = (1.0 + regu_coef) * v + hvp / (lam + lam_damping)\n            return Av\n        return evaluator\n\n    def hessian_vector_product(self, x, edge_index, batch, vector, penalty_coefficient, device, params=None):\n        \"\"\"\n        Performs hessian vector product on the train set in task with the provided vector\n        \"\"\"\n        if params is not None:\n            self.set_params(params)\n        tloss = self.get_loss(x, edge_index, batch, penalty_coefficient, device)\n        grad_ft = torch.autograd.grad(tloss, self.model.parameters(), create_graph=True)\n        flat_grad = torch.cat([g.contiguous().view(-1) for g in grad_ft])\n        vec = utils.to_device(vector, self.use_gpu)\n        h = torch.sum(flat_grad * vec)\n        hvp = torch.autograd.grad(h, self.model.parameters())\n        hvp_flat = torch.cat([g.contiguous().view(-1) for g in hvp])\n        return hvp_flat\n    \n    def erdosloss_clique(self, probs, edge_index, batch, penalty_coefficient, device):\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        pairwise_prodsums = torch.zeros(num_graphs, device = str(device))\n        for graph in range(num_graphs):\n            batch_graph = (batch==graph)\n            pairwise_prodsums[graph] = (torch.conv1d(probs[batch_graph].unsqueeze(-1), probs[batch_graph].unsqueeze(-1))).sum()/2\n        ###calculate loss terms\n        self_sums = scatter_add((probs*probs), batch, 0, dim_size = num_graphs)\n        expected_weight_G = scatter_add(probs[no_loop_row]*probs[no_loop_col], batch[no_loop_row], 0, dim_size = num_graphs)/2.\n        expected_clique_weight = (pairwise_prodsums.unsqueeze(-1) - self_sums)/1.\n        expected_distance = (expected_clique_weight - expected_weight_G)       \n        ###calculate loss\n        #import pdb; pdb.set_trace()\n        expected_loss = (penalty_coefficient)*expected_distance*0.5 - 0.5*expected_weight_G  \n        loss = expected_loss\n\n        retdict = {}\n        retdict[\"output\"] = [probs.squeeze(-1),\"hist\"]   #output\n        retdict[\"losses histogram\"] = [loss.squeeze(-1),\"hist\"]\n        retdict[\"Expected weight(G)\"]= [expected_weight_G.mean(), \"sequence\"]\n        retdict[\"Expected maximum weight\"] = [expected_clique_weight.mean(),\"sequence\"]\n        retdict[\"Expected distance\"]= [expected_distance.mean(), \"sequence\"]\n        retdict[\"loss\"] = [loss.mean().squeeze(),\"sequence\"] #final loss\n        return retdict\n\n# ==========================================\n# File: max_clique/rb200/modules_and_utils.py\n# Function/Context: decode_clique_final\n# ==========================================\ndef decode_clique_final(data, probabilities, draw=False, weight_factor = 0.0, clique_number_bounds = None ,fig = None, device = 'cpu'):\n    row, col = data.edge_index\n    sets = probabilities.detach().unsqueeze(-1)\n    batch = data.batch\n    no_loop_index,_ = remove_self_loops(data.edge_index)        \n    no_loop_row, no_loop_col = no_loop_index\n    num_graphs = batch.max().item() + 1\n    total_index = 0\n\n    for graph in range(num_graphs):\n        mark_edges = batch[no_loop_row] == graph\n        nlr_graph, nlc_graph = no_loop_index[:,mark_edges]\n        nlr_graph = nlr_graph - total_index\n        nlc_graph = nlc_graph - total_index\n        nlr_graph = nlr_graph.long()\n        nlc_graph = nlc_graph.long()\n        batch_graph = (batch==graph)\n        graph_probs = sets[batch_graph].detach()\n        sorted_inds = torch.argsort(graph_probs.squeeze(-1), descending=True)\n        pairwise_prodsums = torch.zeros(1, device = device)\n        pairwise_prodsums = (torch.conv1d(graph_probs.unsqueeze(-1), graph_probs.unsqueeze(-1))).sum()/2\n        self_sums = (graph_probs*graph_probs).sum()       \n        num_nodes = batch_graph.float().sum().item()\n   \n        current_set_cardinality = 0\n        \n        for node in range(int(num_nodes)):\n            ind_i = total_index + sorted_inds[node]\n            ind_i = ind_i.long()\n            graph_probs_0 = sets[batch_graph].detach()\n            graph_probs_1 = sets[batch_graph].detach()\n            \n            graph_probs_0[sorted_inds[node]] = 0\n            graph_probs_1[sorted_inds[node]] = 1\n\n            pairwise_prodsums_0 = torch.zeros(1, device = device)\n            pairwise_prodsums_0 = (torch.conv1d(graph_probs_0.unsqueeze(-1),graph_probs_0.unsqueeze(-1))).sum()/2\n\n            self_sums_0 = (graph_probs_0*graph_probs_0).sum()\n            #import pdb; pdb.set_trace()\n            expected_weight_G_0 = (graph_probs_0[nlr_graph]*graph_probs_0[nlc_graph]).sum()/2\n            expected_clique_weight_0 = (pairwise_prodsums_0 - self_sums_0)\n            clique_dist_0 = weight_factor*0.5*(exp\n            ---\n\n# ==========================================\n# File: max_clique/rb200/train_maml.py\n# Function/Context: main\n# ==========================================\nimport numpy as np\nimport torch\nimport random\nimport pickle\nimport argparse\nimport pathlib\n\nfrom tqdm import tqdm\nimport sys\nfrom dataset.rb200_train import RB200_train\nfrom dataset.rb200_val import RB200_val\nfrom learner_model import Learner\nfrom gnn_model import clique_MPNN, ErdosLoss_clique\nfrom utils import DataLog\nimport utils\nimport matplotlib.pyplot as plt\nimport yaml\nfrom pathlib import Path\nfrom torch_geometric.data import DataListLoader, DataLoader, Data\n\nfrom utils import get_diracs, decode_clique_final_speed, solve_gurobi_maxclique\nfrom torch.nn.utils.convert_parameters import (vector_to_parameters, parameters_to_vector)\nfrom torch_geometric.utils import dropout_adj, to_undirected, to_networkx\n\ndef main():\n    \n    logger = DataLog()\n\n    # ===================\n    # hyperparameters\n    # ===================\n    parser = argparse.ArgumentParser(description='Implicit MAML on Omniglot dataset')\n    parser.add_argument('--data_dir', type=str, default='/home/aravind/data/omniglot-py/',\n                        help='location of the dataset')\n    parser.add_argument('--N_way', type=int, default=5, help='number of classes for few shot learning tasks')\n    parser.add_argument('--K_shot', type=int, default=1, help='number of instances for few shot learning tasks')\n    parser.add_argument('--inner_lr', type=float, default=1e-2, help='inner loop learning rate')\n    parser.add_argument('--outer_lr', type=float, default=1e-2, help='outer loop learning rate')\n    parser.add_argument('--n_steps', type=int, default=16, help='number of steps in inner loop')\n    parser.add_argument('--meta_steps', type=int, default=1000, help='number of meta steps')\n    parser.add_argument('--task_mb_size', type=int, default=16)\n    parser.add_argument('--lam', type=float, default=1.0, help='regularization in inner steps')\n    parser.add_argument('--cg_steps', type=int, default=5)\n    parser.add_argument('--cg_damping', type=float, default=1.0)\n    parser.add_argument('--use_gpu', type=int, default=0)\n    parser.add_argument('--num_tasks', type=int, default=20000)\n    parser.add_argument('--save_dir', type=str, default='/tmp')\n    parser.add_argument('--lam_lr', type=float, default=0.0)\n    parser.add_argument('--lam_min', type=float, default=0.0)\n    parser.add_argument('--scalar_lam', type=bool, default=True, help='keep regularization as a scalar or diagonal matrix (vector)')\n    parser.add_argument('--taylor_approx', type=bool, default=False, help='Use Neumann approximation for (I+eps*A)^-1')\n    parser.add_argument('--inner_alg', type=str, default='gradient', help='gradient or sqp for inner solve')\n    parser.add_argument('--load_agent', type=str, default=None)\n    parser.add_argument('--load_tasks', type=str, default=None)\n    parser.add_argument('--seed', type=str, default=None)\n    args = parser.parse_args()\n    logger.log_exp_args(args)\n\n    np.random.seed(int(args.seed))\n    torch.manual_seed(int(args.seed))\n    random.seed(int(args.seed))\n\n    print(\"Generating tasks ...... \")\n    cfg = Path('./dataset/configs/config.yaml')\n    cfg_dict = yaml.safe_load(cfg.open('r'))\n    dataset = RB200_train(cfg_dict['train'])\n    testset = RB200_val(cfg_dict['val'])\n    test_loader = DataLoader(testset, 1, shuffle=False)\n\n    numlayers = 4\n    penalty_coeff = 0.5\n    hidden_1 = 64\n    hidden_2 = 1\n    receptive_field = numlayers + 1\n\n\n    if args.load_agent is None:\n        learner_net = clique_MPNN(dataset, numlayers, hidden_1, hidden_2, 1)\n        fast_net = clique_MPNN(dataset, numlayers, hidden_1, hidden_2, 1)\n        meta_learner = Learner(model=learner_net, loss_function=torch.nn.CrossEntropyLoss(), inner_alg=args.inner_alg,\n                            inner_lr=args.inner_lr, outer_lr=args.outer_lr, GPU=args.use_gpu)\n        fast_learner = Learner(model=fast_net, loss_function=torch.nn.CrossEntropyLoss(), inner_alg=args.inner_alg,\n                            inner_lr=args.inner_lr, outer_lr=args.outer_lr, GPU=args.use_gpu)\n    else:\n        meta_learner = pickle.load(open(args.load_agent, 'rb'))\n        meta_learner.set_params(meta_learner.get_params())\n        fast_learner = pickle.load(open(args.load_agent, 'rb'))\n        fast_learner.set_params(fast_learner.get_params())\n        for learner in [meta_learner, fast_learner]:\n            learner.inner_alg = args.inner_alg\n            learner.inner_lr = args.inner_lr\n            learner.outer_lr = args.outer_lr\n        \n    init_params = meta_learner.get_params()\n    #device = 'cuda' if args.use_gpu is True else 'cpu'\n    device = torch.device('cuda:'+str(args.use_gpu) if torch.cuda.is_available() else 'cpu')\n    lam = torch.tensor(args.lam) if args.scalar_lam is True else torch.ones(init_params.shape[0])*args.lam\n    lam = lam.to(device)\n    pathlib.Path(args.save_dir).mkdir(parents=True, exist_ok=True)\n\n    # ===================\n    # Train\n    # ===================\n    print(\"Training model ......\")\n    losses = np.zeros((args.meta_steps, 2))\n    num_tasks = len(dataset)\n    \n    highest_score = 0\n    lowest_loss = 10000\n\n    for outstep in tqdm(range(args.meta_steps)):\n        if outstep > 10 and outstep % 800 == 0:\n            penalty_coeff = penalty_coeff + 0.5\n        w1_list = []\n        d1_list = []\n        w2_list = []\n        d2_list = []\n        task_mb = np.random.choice(num_tasks, size=args.task_mb_size)\n        w_k = meta_learner.get_params()\n        meta_grad = 0.0\n        lam_grad = 0.0\n        for k in range(args.n_steps):\n            old_parameters = parameters_to_vector(meta_learner.model.parameters())\n            losses_q = torch.tensor([0.0]).to(device)\n            data_index = 0\n            for idx in task_mb:\n                task = dataset[idx] # get task\n                task = task.to(device)\n                #vl_before = meta_learner.get_loss(task['x_val'], task['y_val'], return_numpy = True)\n                tl_before, w1, d1 = meta_learner.get_loss(task['x'], task['edge_index'], task['train_batch'], penalty_coefficient = penalty_coeff, device = device)\n                new_grad = torch.autograd.grad(tl_before, meta_learner.model.parameters(), retain_graph = True, create_graph = True)\n                new_params = parameters_to_vector(meta_learner.model.parameters()) - args.inner_lr * parameters_to_vector(new_grad)\n                vector_to_parameters(new_params, meta_learner.model.parameters())\n                tl_after, w2, d2 = meta_learner.get_loss(task['x'], task['edge_index'], task['train_batch'], penalty_coefficient = penalty_coeff, device = device)\n                tl_after, w2, d2 = tl_before, w1, d1\n                tl_after = tl_after.reshape(-1,1)\n                #vl_after = meta_learner.get_loss(task['x_val'], task['y_val']).reshape(-1, 1)\n                if k == 0:\n                    losses[outstep] += (np.array([tl_before.item(), 0])/args.task_mb_size)\n                if k == args.n_steps - 1:\n                    losses[outstep] += (np.array([0, tl_after.item()])/args.task_mb_size)\n                if data_index == 0:\n                    losses_q = tl_after\n                else:\n                    #import pdb; pdb.set_trace()\n                    losses_q = torch.cat((losses_q, tl_after), 0)\n                #vector_to_parameters(old_parameters, meta_learner.model.parameters())\n                data_index = data_index + 1\n\n                w1_list.append(w1)\n                w2_list.append(w2)\n                d1_list.append(d1)\n                d2_list.append(d2)\n            loss_q = torch.mean(losses_q)\n            meta_learner.outer_opt.zero_grad()\n            loss_q.backward()\n            meta_learner.outer_opt.step()\n            print('loss:'+str(loss_q.item())+' w1:'+str(np.mean(w1_list))+' d1:'+str(np.mean(d1_list))+' w2:'+str(np.mean(w2_list))+' d2:'+str(np.mean(d2_list)))\n            if loss_q.item() < lowest_loss:\n                lowest_loss = loss_q.item()\n                model_path = args.save_dir + '/best_loss.pth'\n                torch.save(meta_learner.model.state_dict(), model_path)\n\n        logger.log_kv('train_pre', losses[outstep,0])\n        logger.log_kv('train_post', losses[outstep,1])\n        \n        if (outstep % 10 == 0 and outstep > 0) or outstep == args.meta_steps-1:\n            smoothed_losses = utils.smooth_vector(losses[:outstep], window_size=10)\n            plt.figure(figsize=(10,6))\n            plt.plot(smoothed_losses)\n            plt.ylim([-70, 300])\n            plt.xlim([0, args.meta_steps])\n            plt.grid(True)\n            plt.legend(['Train pre', 'Train post'], loc=1)\n            plt.savefig(args.save_dir+'/learn_curve.png', dpi=100)\n            plt.clf()\n            plt.close('all')\n\n            #pickle.dump(meta_learner, open(args.save_dir+'/agent.pickle', 'wb'))\n            logger.save_log()\n\n        if (outstep % 50 == 0):\n            checkpoint_file = args.save_dir + '/checkpoint_' + str(outstep) + '.pickle'\n            #pickle.dump(meta_learner, open(checkpoint_file, 'wb'))\n            model_path = args.save_dir + '/model_' + str(outstep) + '.pth'\n            torch.save(meta_learner.model.state_dict(), model_path)\n        if outstep == args.meta_steps-1:\n            checkpoint_file = args.save_dir + '/final_model.pickle'\n            #pickle.dump(meta_learner, open(checkpoint_file, 'wb'))\n            model_path = args.save_dir + '/final_model.pth'\n            torch.save(meta_learner.model.state_dict(), model_path)\n        \n        model_output = np.zeros(len(testset))\n        gt_output = []\n        model_index = -1\n        time_list = []\n        if outstep % 5 == 0:\n            for data in test_loader:\n                model_index = model_index + 1\n                for k in range(1):\n                    # get k different data input\n                    data_prime = get_diracs(data.to(device), 1, sparse = True, effective_volume_range=0.15, receptive_field = receptive_field)\n                    data_prime = data_prime.to(device)\n                    criterion = ErdosLoss_clique()\n                    probs = meta_learner.model(data_prime.x, data_prime.edge_index, data_prime.batch, None, penalty_coeff)\n                    retdict = criterion(probs, data_prime.edge_index, data_prime.batch, penalty_coeff, device)\n                    sets, set_edges, set_cardinality = decode_clique_final_speed(data_prime,(retdict[\"output\"][0]), weight_factor =0.,draw=False, beam = 1)\n                    if set_cardinality.item() > model_output[model_index]:\n                        model_output[model_index] = set_cardinality\n            #tests = test_data_clique\n            ratios = [model_output[i] for i in range(len(model_output))]\n            print(f\"Mean ratio: {(np.array(ratios)).mean()} +/-  {(np.array(ratios)).std()}\")\n            if (np.array(ratios)).mean() > highest_score:\n                highest_score = (np.array(ratios)).mean()\n                model_path = args.save_dir + '/best_model_'+str(outstep)+'.pth'\n                torch.save(meta_learner.model.state_dict(), model_path)\n                print(\"epoch:\"+str(outstep)+\", get best again\")\n\nif __name__ == '__main__':\n    main()\n\n# ==========================================\n# File: max_clique/twitter/gnn_model.py\n# Function/Context: clique_MPNN, ErdosLoss_clique\n# ==========================================\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn import Linear\nfrom torch import tensor\nfrom torch.optim import Adam\nfrom torch.optim import SGD\nfrom math import ceil\nfrom torch.nn import Linear\nfrom torch.distributions import categorical\nfrom torch.distributions import Bernoulli\nimport torch.nn\nfrom torch_geometric.utils import convert as cnv\nfrom torch_geometric.utils import sparse as sp\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn.inits import uniform\nfrom torch_geometric.nn.inits import glorot, zeros\nfrom torch.nn import Parameter\nfrom torch.nn import Sequential as Seq, Linear, ReLU\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.utils import degree\nfrom torch_geometric.nn import GINConv, GATConv\nfrom torch.nn import Parameter\nfrom torch.nn import Sequential as Seq, Linear, ReLU, LeakyReLU\nfrom torch_geometric.nn import MessagePassing\nfrom torch.nn import Linear, Sequential, ReLU, BatchNorm1d as BN\nfrom torch_geometric.data import Batch \nfrom torch_scatter import scatter_min, scatter_max, scatter_add, scatter_mean\nfrom torch import autograd\nfrom torch_geometric.utils import softmax, add_self_loops, remove_self_loops, segregate_self_loops, remove_isolated_nodes, contains_isolated_nodes, add_remaining_self_loops, dropout_adj\nfrom utils import get_mask\nfrom torch_geometric.nn.norm.graph_size_norm import GraphSizeNorm\n\nclass clique_MPNN(torch.nn.Module):\n    def __init__(self, dataset, num_layers, hidden1, hidden2, deltas):\n        super(clique_MPNN, self).__init__()\n        self.hidden1 = hidden1\n        self.hidden2 = hidden2\n        self.momentum = 0.1\n        self.convs = torch.nn.ModuleList()\n        self.deltas = deltas\n        self.numlayers = num_layers\n        self.heads = 8\n        self.concat = True\n        \n        self.bns = torch.nn.ModuleList()\n        for i in range(num_layers-1):\n            self.bns.append(BN(self.heads*self.hidden1, momentum=self.momentum))\n        self.convs = torch.nn.ModuleList()        \n        for i in range(num_layers - 1):\n                self.convs.append(GINConv(Sequential(\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            BN(self.heads*self.hidden1, momentum=self.momentum),\n        ),train_eps=True))\n        self.bn1 = BN(self.heads*self.hidden1)       \n        self.conv1 = GINConv(Sequential(Linear(self.hidden2,  self.heads*self.hidden1),\n            ReLU(),\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            BN(self.heads*self.hidden1, momentum=self.momentum),\n        ),train_eps=True)\n\n        if self.concat:\n            self.lin1 = Linear(self.heads*self.hidden1, self.hidden1)\n        else:\n            self.lin1 = Linear(self.hidden1, self.hidden1)\n        self.lin2 = Linear(self.hidden1, 1)\n        self.gnorm = GraphSizeNorm()\n\n    def reset_parameters(self):\n        self.conv1.reset_parameters()\n        \n        for conv in self.convs:\n            conv.reset_parameters() \n        for bn in self.bns:\n            bn.reset_parameters()\n        self.bn1.reset_parameters()\n        self.lin1.reset_parameters()\n        self.lin2.reset_parameters()\n\n    def forward(self, x, edge_index, batch, edge_dropout = None, penalty_coefficient = 0.25):\n        num_graphs = batch.max().item() + 1\n        row, col = edge_index     \n        total_num_edges = edge_index.shape[1]\n        N_size = x.shape[0]\n\n        if edge_dropout is not None:\n            edge_index = dropout_adj(edge_index, edge_attr = (torch.ones(edge_index.shape[1], device=device)).long(), p = edge_dropout, force_undirected=True)[0]\n            edge_index = add_remaining_self_loops(edge_index, num_nodes = batch.shape[0])[0]\n                \n        reduced_num_edges = edge_index.shape[1]\n        current_edge_percentage = (reduced_num_edges/total_num_edges)\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n\n        xinit= x.clone()\n        x = x.unsqueeze(-1)\n        mask = get_mask(x,edge_index,1).to(x.dtype)\n        x = F.leaky_relu(self.conv1(x, edge_index))# +x\n        x = x*mask\n        x = self.gnorm(x)\n        x = self.bn1(x)\n        \n            \n        for conv, bn in zip(self.convs, self.bns):\n            if(x.dim()>1):\n                x =  x+F.leaky_relu(conv(x, edge_index))\n                mask = get_mask(mask,edge_index,1).to(x.dtype)\n                x = x*mask\n                x = self.gnorm(x)\n                x = bn(x)\n\n        xpostconvs = x.detach()\n        #\n        x = F.leaky_relu(self.lin1(x)) \n        x = x*mask\n\n        xpostlin1 = x.detach()\n        x = F.leaky_relu(self.lin2(x)) \n        x = x*mask\n\n        #calculate min and max\n        batch_max = scatter_max(x, batch, 0, dim_size= N_size)[0]\n        batch_max = torch.index_select(batch_max, 0, batch)        \n        batch_min = scatter_min(x, batch, 0, dim_size= N_size)[0]\n        batch_min = torch.index_select(batch_min, 0, batch)\n\n        #min-max normalize\n        x = (x-batch_min)/(batch_max+1e-6-batch_min)\n        probs=x\n\n        return probs\n\nclass ErdosLoss_clique(torch.nn.Module):\n    def __init__(self):\n        super(ErdosLoss_clique,self).__init__()\n        #self.penalty = Penalty()\n    def forward(self, probs, edge_index, batch, penalty_coefficient,device):\n        #calculating the terms for the expected distance between clique and graph\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        pairwise_prodsums = torch.zeros(num_graphs, device = device)\n        for graph in range(num_graphs):\n            batch_graph = (batch==graph)\n            pairwise_prodsums[graph] = (torch.conv1d(probs[batch_graph].unsqueeze(-1), probs[batch_graph].unsqueeze(-1))).sum()/2\n        ###calculate loss terms\n        self_sums = scatter_add((probs*probs), batch, 0, dim_size = num_graphs)\n        expected_weight_G = scatter_add(probs[no_loop_row]*probs[no_loop_col], batch[no_loop_row], 0, dim_size = num_graphs)/2.\n        expected_clique_weight = (pairwise_prodsums.unsqueeze(-1) - self_sums)/1.\n        expected_distance = (expected_clique_weight - expected_weight_G)        \n        \n        ###calculate loss\n        expected_loss = (penalty_coefficient)*expected_distance*0.5 - 0.5*expected_weight_G  \n        loss = expected_loss\n\n        retdict = {}\n        retdict[\"output\"] = [probs.squeeze(-1),\"hist\"]   #output\n        retdict[\"losses histogram\"] = [loss.squeeze(-1),\"hist\"]\n        retdict[\"Expected weight(G)\"]= [expected_weight_G.mean(), \"sequence\"]\n        retdict[\"Expected maximum weight\"] = [expected_clique_weight.mean(),\"sequence\"]\n        retdict[\"Expected distance\"]= [expected_distance.mean(), \"sequence\"]\n        retdict[\"loss\"] = [loss.mean().squeeze(),\"sequence\"] #final loss\n        return retdict\n\n# ==========================================\n# File: max_clique/twitter/learner_model.py\n# Function/Context: Learner.erdosloss_clique\n# ==========================================\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport utils\nfrom   torch.nn import functional as F\nfrom torch_geometric.utils import remove_self_loops\nfrom torch_scatter import scatter_add\n\nclass Learner:\n    def __init__(self, model, loss_function, inner_lr=1e-3, outer_lr=1e-2, GPU=-1, inner_alg='gradient', outer_alg='adam'):\n        self.model = model\n        self.use_gpu = GPU\n        if GPU>=0:\n            device = torch.device('cuda:'+str(GPU)if torch.cuda.is_available() else \"cpu\")\n            #self.model.cuda()\n            self.model.to(device)\n        assert outer_alg == 'sgd' or 'adam'\n        #self.inner_opt = torch.optim.SGD(self.model.parameters(), lr=inner_lr)\n        self.inner_opt = torch.optim.Adam(self.model.parameters(), lr=inner_lr, eps=1e-3)\n        if outer_alg == 'adam':\n            self.outer_opt = torch.optim.Adam(self.model.parameters(), lr=outer_lr, eps=1e-3)\n        else:\n            self.outer_opt = torch.optim.SGD(self.model.parameters(), lr=outer_lr)\n        self.loss_function = loss_function\n        assert inner_alg == 'gradient' # sqp unsupported in this version\n        self.inner_alg = inner_alg\n\n    def get_params(self):\n        return torch.cat([param.data.view(-1) for param in self.model.parameters()], 0).clone()\n\n    def set_params(self, param_vals):\n        offset = 0\n        for param in self.model.parameters():\n            param.data.copy_(param_vals[offset:offset + param.nelement()].view(param.size()))\n            offset += param.nelement()\n            \n    def set_outer_lr(self, lr):\n        for param_group in self.outer_opt.param_groups:\n            param_group['lr'] = lr\n            \n    def set_inner_lr(self, lr):\n        for param_group in self.inner_opt.param_groups:\n            param_group['lr'] = lr\n\n    def regularization_loss(self, w_0, lam=0.0):\n        \"\"\"\n        Add a regularization loss onto the weights\n        The proximal term regularizes around the point w_0\n        Strength of regularization is lambda\n        lambda can either be scalar (type float) or ndarray (numpy.ndarray)\n        \"\"\"\n        regu_loss = 0.0\n        offset = 0\n        regu_lam = lam if type(lam) == float or np.float64 else utils.to_tensor(lam)\n        if w_0.dtype == torch.float16:\n            try:\n                regu_lam = regu_lam.half()\n            except:\n                regu_lam = np.float16(regu_lam)\n        for param in self.model.parameters():\n            delta = param.view(-1) - w_0[offset:offset + param.nelement()].view(-1)\n            if type(regu_lam) == float or np.float64:\n                regu_loss += 0.5 * regu_lam * torch.sum(delta ** 2)\n            else:\n                # import ipdb; ipdb.set_trace()\n                param_lam = regu_lam[offset:offset + param.nelement()].view(-1)\n                param_delta = delta * param_lam\n                regu_loss += 0.5 * torch.sum(param_delta ** 2)\n            offset += param.nelement()\n        return regu_loss\n\n    def get_loss(self, x, edge_index, batch, penalty_coefficient, device, return_numpy = False):\n        probs = self.model.forward(x, edge_index, batch)\n        loss_dict = self.erdosloss_clique(probs, edge_index, batch, penalty_coefficient, device)\n        loss = loss_dict['loss'][0]\n        weight = loss_dict['Expected weight(G)'][0].item()\n        distance = loss_dict['Expected distance'][0].item()\n        if return_numpy:\n            loss = utils.to_numpy(loss).ravel()[0]\n        return loss, weight, distance\n\n    def predict(self, x, edge_index, batch, return_numpy = False):\n        utils.to_device(x, self.use_gpu)\n        utils.to_device(edge_index, self.use_gpu)\n        utils.to_device(batch, self.use_gpu)\n        probs = self.model.forward(x, edge_index, batch)\n        if return_numpy:\n            probs = utils.to_numpy(probs)\n        return probs\n\n    def learn_on_data(self, x, edge_index, batch, penalty_coefficient, device, num_steps=10,\n                      add_regularization=False,\n                      w_0=None, lam=0.0):\n        assert self.inner_alg == 'gradient'# or 'sqp' or 'adam' # TODO(Aravind): support sqp and adam \n        train_loss = []\n        if self.inner_alg == 'gradient':\n            for i in range(num_steps):\n                self.inner_opt.zero_grad()\n                tloss = self.get_loss(x, edge_index, batch, penalty_coefficient, device)\n                loss = tloss + self.regularization_loss(w_0, lam) if add_regularization else tloss\n                loss.backward()\n                #torch.nn.utils.clip_grad_norm_(self.model.parameters(),1)\n                self.inner_opt.step()\n                train_loss.append(utils.to_numpy(tloss))\n        return train_loss\n    \n    def learn_task(self, x, edge_index, batch, penalty_coefficient, device, num_steps=10, add_regularization=False, w_0=None, lam=0.0):\n\n        return self.learn_on_data(x, edge_index, batch, penalty_coefficient, device, num_steps, add_regularization, w_0, lam)\n\n    def move_toward_target(self, target, lam=2.0):\n        \"\"\"\n        Move slowly towards the target parameter value\n        Default value for lam assumes learning rate determined by optimizer\n        Useful for implementing Reptile\n        \"\"\"\n        # we can implement this with the regularization loss, but regularize around the target point\n        # and with specific choice of lam=2.0 to preserve the learning rate of inner_opt\n        self.outer_opt.zero_grad()\n        loss = self.regularization_loss(target, lam=lam)\n        loss.backward()\n        self.outer_opt.step()\n\n    def outer_step_with_grad(self, grad, flat_grad=False):\n        \"\"\"\n        Given the gradient, step with the outer optimizer using the gradient.\n        Assumed that the gradient is a tuple/list of size compatible with model.parameters()\n        If flat_grad, then the gradient is a flattened vector\n        \"\"\"\n        check = 0\n        for p in self.model.parameters():\n            check = check + 1 if type(p.grad) == type(None) else check\n        if check > 0:\n            # initialize the grad fields properly\n            dummy_loss = self.regularization_loss(self.get_params())\n            dummy_loss.backward()  # this would initialize required variables\n        if flat_grad:\n            offset = 0\n            grad = utils.to_device(grad, self.use_gpu)\n            for p in self.model.parameters():\n                this_grad = grad[offset:offset + p.nelement()].view(p.size())\n                p.grad.copy_(this_grad)\n                offset += p.nelement()\n        else:\n            for i, p in enumerate(self.model.parameters()):\n                p.grad = grad[i]\n        self.outer_opt.step()\n\n    def matrix_evaluator(self, x, edge_index, batch, lam, penalty_coefficient, device, regu_coef=1.0, lam_damping=10.0):\n        \"\"\"\n        Constructor function that can be given to CG optimizer\n        Works for both type(lam) == float and type(lam) == np.ndarray\n        \"\"\"\n        if type(lam) == np.ndarray:\n            lam = utils.to_device(lam, self.use_gpu)\n        def evaluator(v):\n            hvp = self.hessian_vector_product(x, edge_index, batch, v, penalty_coefficient, device)\n            #hvp = self.hessian_vector_product(task, v, x=x, y=y)\n            Av = (1.0 + regu_coef) * v + hvp / (lam + lam_damping)\n            return Av\n        return evaluator\n\n    def hessian_vector_product(self, x, edge_index, batch, vector, penalty_coefficient, device, params=None):\n        \"\"\"\n        Performs hessian vector product on the train set in task with the provided vector\n        \"\"\"\n        if params is not None:\n            self.set_params(params)\n        tloss = self.get_loss(x, edge_index, batch, penalty_coefficient, device)\n        grad_ft = torch.autograd.grad(tloss, self.model.parameters(), create_graph=True)\n        flat_grad = torch.cat([g.contiguous().view(-1) for g in grad_ft])\n        vec = utils.to_device(vector, self.use_gpu)\n        h = torch.sum(flat_grad * vec)\n        hvp = torch.autograd.grad(h, self.model.parameters())\n        hvp_flat = torch.cat([g.contiguous().view(-1) for g in hvp])\n        return hvp_flat\n    \n    def erdosloss_clique(self, probs, edge_index, batch, penalty_coefficient, device):\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        pairwise_prodsums = torch.zeros(num_graphs, device = torch.device(str(device)))\n        for graph in range(num_graphs):\n            batch_graph = (batch==graph)\n            pairwise_prodsums[graph] = (torch.conv1d(probs[batch_graph].unsqueeze(-1), probs[batch_graph].unsqueeze(-1))).sum()/2\n        ###calculate loss terms\n        self_sums = scatter_add((probs*probs), batch, 0, dim_size = num_graphs)\n        expected_weight_G = scatter_add(probs[no_loop_row]*probs[no_loop_col], batch[no_loop_row], 0, dim_size = num_graphs)/2.\n        expected_clique_weight = (pairwise_prodsums.unsqueeze(-1) - self_sums)/1.\n        expected_distance = (expected_clique_weight - expected_weight_G)       \n        ###calculate loss\n        #import pdb; pdb.set_trace()\n        expected_loss = (penalty_coefficient)*expected_distance*0.5 - 0.5*expected_weight_G  \n        loss = expected_loss\n\n        retdict = {}\n        retdict[\"output\"] = [probs.squeeze(-1),\"hist\"]   #output\n        retdict[\"losses histogram\"] = [loss.squeeze(-1),\"hist\"]\n        retdict[\"Expected weight(G)\"]= [expected_weight_G.mean(), \"sequence\"]\n        retdict[\"Expected maximum weight\"] = [expected_clique_weight.mean(),\"sequence\"]\n        retdict[\"Expected distance\"]= [expected_distance.mean(), \"sequence\"]\n        retdict[\"loss\"] = [loss.mean().squeeze(),\"sequence\"] #final loss\n        return retdict\n\n# ==========================================\n# File: vertex_cover/rb200/gnn_model.py\n# Function/Context: vertex_MPNN, ErdosLoss_vertex, ErdosLoss_vertex_new\n# ==========================================\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn import Linear\nfrom torch import tensor\nfrom torch.optim import Adam\nfrom torch.optim import SGD\nfrom math import ceil\nfrom torch.nn import Linear\nfrom torch.distributions import categorical\nfrom torch.distributions import Bernoulli\nimport torch.nn\nfrom torch_geometric.utils import convert as cnv\nfrom torch_geometric.utils import sparse as sp\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn.inits import uniform\nfrom torch_geometric.nn.inits import glorot, zeros\nfrom torch.nn import Parameter\nfrom torch.nn import Sequential as Seq, Linear, ReLU\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.utils import degree\nfrom torch_geometric.nn import GINConv, GATConv\nfrom torch.nn import Parameter\nfrom torch.nn import Sequential as Seq, Linear, ReLU, LeakyReLU\nfrom torch_geometric.nn import MessagePassing\nfrom torch.nn import Linear, Sequential, ReLU, BatchNorm1d as BN\nfrom torch_geometric.data import Batch \nfrom torch_scatter import scatter_min, scatter_max, scatter_add, scatter_mean\nfrom torch import autograd\nfrom torch_geometric.utils import softmax, add_self_loops, remove_self_loops, segregate_self_loops, remove_isolated_nodes, contains_isolated_nodes, add_remaining_self_loops, dropout_adj\nfrom utils import get_mask\nfrom torch_geometric.nn.norm.graph_size_norm import GraphSizeNorm\n\n\nclass ErdosLoss_vertex(torch.nn.Module):\n    def __init__(self):\n        super(ErdosLoss_vertex,self).__init__()\n        #self.penalty = Penalty()\n    def forward(self, probs, edge_index, batch, penalty_coefficient, device):\n        #calculating the terms for the vertex covering problem\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        probs_sum = torch.zeros(num_graphs, device = device)\n        #pairwise_prodsums = torch.zeros(num_graphs, device = device)\n        for graph in range(num_graphs):\n            batch_graph = (batch==graph)\n            probs_sum[graph] = probs[batch_graph].unsqueeze(-1).sum()\n        vertex_row = probs[no_loop_row]\n        vertex_col = probs[no_loop_col]\n        expected_distance = (1 - vertex_row) * (1 - vertex_col)\n        expected_distance = expected_distance.sum() / num_graphs\n        expected_weight = probs_sum.mean()\n        loss = penalty_coefficient * expected_distance + expected_weight\n        retdict = {}\n        retdict[\"loss\"] = [loss.squeeze(),\"sequence\"] #final loss\n        retdict[\"Expected weight\"]= [expected_weight, \"sequence\"]\n        retdict[\"Expected distance\"]= [expected_distance, \"sequence\"]\n        return retdict\n\nclass ErdosLoss_vertex_new(torch.nn.Module):\n    def __init__(self):\n        super(ErdosLoss_vertex,self).__init__()\n        #self.penalty = Penalty()\n    def forward(self, probs, edge_index, batch, penalty_coefficient, device):\n        #calculating the terms for the vertex covering problem\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        vertex_row = probs[no_loop_row]\n        vertex_col = probs[no_loop_col]\n        expected_distance = (1 - vertex_row) * (1 - vertex_col)\n        expected_distance = expected_distance.sum() / num_graphs\n        expected_weight = probs.sum() / num_graphs\n        loss = penalty_coefficient * expected_distance + expected_weight\n        return loss\n        \n\n\nclass vertex_MPNN(torch.nn.Module):\n    def __init__(self, dataset, num_layers, hidden1, hidden2, deltas):\n        super(vertex_MPNN, self).__init__()\n        self.hidden1 = hidden1\n        self.hidden2 = hidden2\n        self.momentum = 0.1\n        self.convs = torch.nn.ModuleList()\n        self.deltas = deltas\n        self.numlayers = num_layers\n        self.heads = 8\n        self.concat = True\n        \n        self.bns = torch.nn.ModuleList()\n        for i in range(num_layers-1):\n            self.bns.append(BN(self.heads*self.hidden1, momentum=self.momentum))\n        self.convs = torch.nn.ModuleList()        \n        for i in range(num_layers - 1):\n                self.convs.append(GINConv(Sequential(\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            BN(self.heads*self.hidden1, momentum=self.momentum),\n        ),train_eps=True))\n        self.bn1 = BN(self.heads*self.hidden1)       \n        self.conv1 = GINConv(Sequential(Linear(self.hidden2,  self.heads*self.hidden1),\n            ReLU(),\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            BN(self.heads*self.hidden1, momentum=self.momentum),\n        ),train_eps=True)\n\n        if self.concat:\n            self.lin1 = Linear(self.heads*self.hidden1, self.hidden1)\n        else:\n            self.lin1 = Linear(self.hidden1, self.hidden1)\n        self.lin2 = Linear(self.hidden1, 1)\n        self.gnorm = GraphSizeNorm()\n\n    def reset_parameters(self):\n        self.conv1.reset_parameters()\n        \n        for conv in self.convs:\n            conv.reset_parameters() \n        for bn in self.bns:\n            bn.reset_parameters()\n        self.bn1.reset_parameters()\n        self.lin1.reset_parameters()\n        self.lin2.reset_parameters()\n\n    def forward(self, x, edge_index, batch, edge_dropout = None, penalty_coefficient = 0.25):\n        num_graphs = batch.max().item() + 1\n        row, col = edge_index     \n        total_num_edges = edge_index.shape[1]\n        N_size = x.shape[0]\n\n        if edge_dropout is not None:\n            edge_index = dropout_adj(edge_index, edge_attr = (torch.ones(edge_index.shape[1], device=device)).long(), p = edge_dropout, force_undirected=True)[0]\n            edge_index = add_remaining_self_loops(edge_index, num_nodes = batch.shape[0])[0]\n                \n        reduced_num_edges = edge_index.shape[1]\n        current_edge_percentage = (reduced_num_edges/total_num_edges)\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n\n        xinit= x.clone()\n        x = x.unsqueeze(-1)\n        mask = get_mask(x,edge_index,1).to(x.dtype)\n        x = F.leaky_relu(self.conv1(x, edge_index))# +x\n        x = x*mask\n        x = self.gnorm(x)\n        x = self.bn1(x)\n        \n            \n        for conv, bn in zip(self.convs, self.bns):\n            if(x.dim()>1):\n                x =  x+F.leaky_relu(conv(x, edge_index))\n                mask = get_mask(mask,edge_index,1).to(x.dtype)\n                x = x*mask\n                x = self.gnorm(x)\n                x = bn(x)\n\n        xpostconvs = x.detach()\n        #\n        x = F.leaky_relu(self.lin1(x)) \n        x = x*mask\n\n        xpostlin1 = x.detach()\n        x = F.leaky_relu(self.lin2(x)) \n        x = x*mask\n\n        #calculate min and max\n        batch_max = scatter_max(x, batch, 0, dim_size= N_size)[0]\n        batch_max = torch.index_select(batch_max, 0, batch)        \n        batch_min = scatter_min(x, batch, 0, dim_size= N_size)[0]\n        batch_min = torch.index_select(batch_min, 0, batch)\n\n        #min-max normalize\n        x = (x-batch_min)/(batch_max+1e-6-batch_min)\n        probs=x\n\n        return probs\n\n# ==========================================\n# File: vertex_cover/rb200/learner_model.py\n# Function/Context: Learner.erdosloss_vertex\n# ==========================================\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport utils\nfrom   torch.nn import functional as F\nfrom torch_geometric.utils import remove_self_loops\nfrom torch_scatter import scatter_add\n\nclass Learner:\n    def __init__(self, model, loss_function, inner_lr=1e-3, outer_lr=1e-2, GPU=-1, inner_alg='gradient', outer_alg='adam'):\n        self.model = model\n        self.use_gpu = GPU\n        if GPU>=0:\n            device = torch.device('cuda:'+str(GPU)if torch.cuda.is_available() else \"cpu\")\n            #self.model.cuda()\n            self.model.to(device)\n        assert outer_alg == 'sgd' or 'adam'\n        #self.inner_opt = torch.optim.SGD(self.model.parameters(), lr=inner_lr)\n        self.inner_opt = torch.optim.Adam(self.model.parameters(), lr=inner_lr, eps=1e-3)\n        if outer_alg == 'adam':\n            self.outer_opt = torch.optim.Adam(self.model.parameters(), lr=outer_lr, eps=1e-3)\n        else:\n            self.outer_opt = torch.optim.SGD(self.model.parameters(), lr=outer_lr)\n        self.loss_function = loss_function\n        assert inner_alg == 'gradient' # sqp unsupported in this version\n        self.inner_alg = inner_alg\n\n    def get_params(self):\n        return torch.cat([param.data.view(-1) for param in self.model.parameters()], 0).clone()\n\n    def set_params(self, param_vals):\n        offset = 0\n        for param in self.model.parameters():\n            param.data.copy_(param_vals[offset:offset + param.nelement()].view(param.size()))\n            offset += param.nelement()\n            \n    def set_outer_lr(self, lr):\n        for param_group in self.outer_opt.param_groups:\n            param_group['lr'] = lr\n            \n    def set_inner_lr(self, lr):\n        for param_group in self.inner_opt.param_groups:\n            param_group['lr'] = lr\n\n    def regularization_loss(self, w_0, lam=0.0):\n        \"\"\"\n        Add a regularization loss onto the weights\n        The proximal term regularizes around the point w_0\n        Strength of regularization is lambda\n        lambda can either be scalar (type float) or ndarray (numpy.ndarray)\n        \"\"\"\n        regu_loss = 0.0\n        offset = 0\n        regu_lam = lam if type(lam) == float or np.float64 else utils.to_tensor(lam)\n        if w_0.dtype == torch.float16:\n            try:\n                regu_lam = regu_lam.half()\n            except:\n                regu_lam = np.float16(regu_lam)\n        for param in self.model.parameters():\n            delta = param.view(-1) - w_0[offset:offset + param.nelement()].view(-1)\n            if type(regu_lam) == float or np.float64:\n                regu_loss += 0.5 * regu_lam * torch.sum(delta ** 2)\n            else:\n                # import ipdb; ipdb.set_trace()\n                param_lam = regu_lam[offset:offset + param.nelement()].view(-1)\n                param_delta = delta * param_lam\n                regu_loss += 0.5 * torch.sum(param_delta ** 2)\n            offset += param.nelement()\n        return regu_loss\n\n    def get_loss(self, x, edge_index, batch, penalty_coefficient, device, return_numpy = False):\n        probs = self.model.forward(x, edge_index, batch)\n        loss_dict = self.erdosloss_vertex(probs, edge_index, batch, penalty_coefficient, device)\n        loss = loss_dict['loss'][0]\n        weight = loss_dict['Expected weight'][0].item()\n        distance = loss_dict['Expected distance'][0].item()\n        if return_numpy:\n            loss = utils.to_numpy(loss).ravel()[0]\n        return loss, weight, distance\n\n    def predict(self, x, edge_index, batch, return_numpy = False):\n        utils.to_device(x, self.use_gpu)\n        utils.to_device(edge_index, self.use_gpu)\n        utils.to_device(batch, self.use_gpu)\n        probs = self.model.forward(x, edge_index, batch)\n        if return_numpy:\n            probs = utils.to_numpy(probs)\n        return probs\n\n    def learn_on_data(self, x, edge_index, batch, penalty_coefficient, device, num_steps=10,\n                      add_regularization=False,\n                      w_0=None, lam=0.0):\n        assert self.inner_alg == 'gradient'# or 'sqp' or 'adam' # TODO(Aravind): support sqp and adam \n        train_loss = []\n        if self.inner_alg == 'gradient':\n            for i in range(num_steps):\n                self.inner_opt.zero_grad()\n                tloss = self.get_loss(x, edge_index, batch, penalty_coefficient, device)\n                loss = tloss + self.regularization_loss(w_0, lam) if add_regularization else tloss\n                loss.backward()\n                #torch.nn.utils.clip_grad_norm_(self.model.parameters(),1)\n                self.inner_opt.step()\n                train_loss.append(utils.to_numpy(tloss))\n        return train_loss\n    \n    def learn_task(self, x, edge_index, batch, penalty_coefficient, device, num_steps=10, add_regularization=False, w_0=None, lam=0.0):\n\n        return self.learn_on_data(x, edge_index, batch, penalty_coefficient, device, num_steps, add_regularization, w_0, lam)\n\n    def move_toward_target(self, target, lam=2.0):\n        \"\"\"\n        Move slowly towards the target parameter value\n        Default value for lam assumes learning rate determined by optimizer\n        Useful for implementing Reptile\n        \"\"\"\n        # we can implement this with the regularization loss, but regularize around the target point\n        # and with specific choice of lam=2.0 to preserve the learning rate of inner_opt\n        self.outer_opt.zero_grad()\n        loss = self.regularization_loss(target, lam=lam)\n        loss.backward()\n        self.outer_opt.step()\n\n    def outer_step_with_grad(self, grad, flat_grad=False):\n        \"\"\"\n        Given the gradient, step with the outer optimizer using the gradient.\n        Assumed that the gradient is a tuple/list of size compatible with model.parameters()\n        If flat_grad, then the gradient is a flattened vector\n        \"\"\"\n        check = 0\n        for p in self.model.parameters():\n            check = check + 1 if type(p.grad) == type(None) else check\n        if check > 0:\n            # initialize the grad fields properly\n            dummy_loss = self.regularization_loss(self.get_params())\n            dummy_loss.backward()  # this would initialize required variables\n        if flat_grad:\n            offset = 0\n            grad = utils.to_device(grad, self.use_gpu)\n            for p in self.model.parameters():\n                this_grad = grad[offset:offset + p.nelement()].view(p.size())\n                p.grad.copy_(this_grad)\n                offset += p.nelement()\n        else:\n            for i, p in enumerate(self.model.parameters()):\n                p.grad = grad[i]\n        self.outer_opt.step()\n\n    def matrix_evaluator(self, x, edge_index, batch, lam, penalty_coefficient, device, regu_coef=1.0, lam_damping=10.0):\n        \"\"\"\n        Constructor function that can be given to CG optimizer\n        Works for both type(lam) == float and type(lam) == np.ndarray\n        \"\"\"\n        if type(lam) == np.ndarray:\n            lam = utils.to_device(lam, self.use_gpu)\n        def evaluator(v):\n            hvp = self.hessian_vector_product(x, edge_index, batch, v, penalty_coefficient, device)\n            #hvp = self.hessian_vector_product(task, v, x=x, y=y)\n            Av = (1.0 + regu_coef) * v + hvp / (lam + lam_damping)\n            return Av\n        return evaluator\n\n    def hessian_vector_product(self, x, edge_index, batch, vector, penalty_coefficient, device, params=None):\n        \"\"\"\n        Performs hessian vector product on the train set in task with the provided vector\n        \"\"\"\n        if params is not None:\n            self.set_params(params)\n        tloss = self.get_loss(x, edge_index, batch, penalty_coefficient, device)\n        grad_ft = torch.autograd.grad(tloss, self.model.parameters(), create_graph=True)\n        flat_grad = torch.cat([g.contiguous().view(-1) for g in grad_ft])\n        vec = utils.to_device(vector, self.use_gpu)\n        h = torch.sum(flat_grad * vec)\n        hvp = torch.autograd.grad(h, self.model.parameters())\n        hvp_flat = torch.cat([g.contiguous().view(-1) for g in hvp])\n        return hvp_flat\n    def erdosloss_vertex(self, probs, edge_index, batch, penalty_coefficient, device):\n        #calculating the terms for the vertex covering problem\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        probs_sum = torch.zeros(num_graphs, device = device)\n        #pairwise_prodsums = torch.zeros(num_graphs, device = device)\n        for graph in range(num_graphs):\n            batch_graph = (batch==graph)\n            probs_sum[graph] = probs[batch_graph].unsqueeze(-1).sum()\n        vertex_row = probs[no_loop_row]\n        vertex_col = probs[no_loop_col]\n        expected_distance = (1 - vertex_row) * (1 - vertex_col)\n        expected_distance = expected_distance.sum() / num_graphs\n        expected_weight = probs_sum.mean()\n        loss = penalty_coefficient * expected_distance + expected_weight\n        retdict = {}\n        retdict[\"loss\"] = [loss.squeeze(),\"sequence\"] #final loss\n        retdict[\"Expected weight\"]= [expected_weight, \"sequence\"]\n        retdict[\"Expected distance\"]= [expected_distance, \"sequence\"]\n        return retdict\n\n# ==========================================\n# File: vertex_cover/rb200/train_maml.py\n# Function/Context: main\n# ==========================================\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport random\nimport time as timer\nimport pickle\nimport argparse\nimport pathlib\nfrom tqdm import tqdm\nimport sys\nfrom dataset.rb200_train import RB200_train\nfrom dataset.rb200_val import RB200_val\nfrom learner_model import Learner\nfrom gnn_model import vertex_MPNN\nfrom utils import DataLog\nimport utils\nimport matplotlib.pyplot as plt\nimport yaml\nfrom pathlib import Path\nfrom torch_geometric.data import DataListLoader, DataLoader\nfrom utils import get_diracs\nfrom torch.nn.utils.convert_parameters import (vector_to_parameters, parameters_to_vector)\nfrom test import decode_vertex\nfrom gnn_model import ErdosLoss_vertex\n\ndef main():\n    \n    logger = DataLog()\n\n    # ===================\n    # hyperparameters\n    # ===================\n    parser = argparse.ArgumentParser(description='Implicit MAML on Omniglot dataset')\n    parser.add_argument('--data_dir', type=str, default='/home/aravind/data/omniglot-py/',\n                        help='location of the dataset')\n    parser.add_argument('--N_way', type=int, default=5, help='number of classes for few shot learning tasks')\n    parser.add_argument('--K_shot', type=int, default=1, help='number of instances for few shot learning tasks')\n    parser.add_argument('--inner_lr', type=float, default=1e-2, help='inner loop learning rate')\n    parser.add_argument('--outer_lr', type=float, default=1e-2, help='outer loop learning rate')\n    parser.add_argument('--n_steps', type=int, default=16, help='number of steps in inner loop')\n    parser.add_argument('--meta_steps', type=int, default=1000, help='number of meta steps')\n    parser.add_argument('--task_mb_size', type=int, default=16)\n    parser.add_argument('--lam', type=float, default=1.0, help='regularization in inner steps')\n    parser.add_argument('--cg_steps', type=int, default=5)\n    parser.add_argument('--cg_damping', type=float, default=1.0)\n    parser.add_argument('--use_gpu', type=int, default=0)\n    parser.add_argument('--num_tasks', type=int, default=20000)\n    parser.add_argument('--save_dir', type=str, default='/tmp')\n    parser.add_argument('--lam_lr', type=float, default=0.0)\n    parser.add_argument('--lam_min', type=float, default=0.0)\n    parser.add_argument('--scalar_lam', type=bool, default=True, help='keep regularization as a scalar or diagonal matrix (vector)')\n    parser.add_argument('--taylor_approx', type=bool, default=False, help='Use Neumann approximation for (I+eps*A)^-1')\n    parser.add_argument('--inner_alg', type=str, default='gradient', help='gradient or sqp for inner solve')\n    parser.add_argument('--load_agent', type=str, default=None)\n    parser.add_argument('--load_tasks', type=str, default=None)\n    parser.add_argument('--seed', type=str, default=None)\n    args = parser.parse_args()\n    logger.log_exp_args(args)\n\n    np.random.seed(int(args.seed))\n    torch.manual_seed(int(args.seed))\n    random.seed(int(args.seed))\n\n    print(\"Generating tasks ...... \")\n    cfg = Path('./dataset/configs/config.yaml')\n    cfg_dict = yaml.safe_load(cfg.open('r'))\n    dataset = RB200_train(cfg_dict['train'])\n    testset = RB200_val(cfg_dict['val'])\n    test_loader = DataLoader(testset, 1, shuffle=False)\n\n    numlayers = 4\n    penalty_coeff = 0.5\n    hidden_1 = 64\n    hidden_2 = 1\n    receptive_field = numlayers + 1\n\n\n    if args.load_agent is None:\n        learner_net = vertex_MPNN(dataset, numlayers, hidden_1, hidden_2, 1)\n        fast_net = vertex_MPNN(dataset, numlayers, hidden_1, hidden_2, 1)\n        meta_learner = Learner(model=learner_net, loss_function=torch.nn.CrossEntropyLoss(), inner_alg=args.inner_alg,\n                            inner_lr=args.inner_lr, outer_lr=args.outer_lr, GPU=args.use_gpu)\n        fast_learner = Learner(model=fast_net, loss_function=torch.nn.CrossEntropyLoss(), inner_alg=args.inner_alg,\n                            inner_lr=args.inner_lr, outer_lr=args.outer_lr, GPU=args.use_gpu)\n    else:\n        meta_learner = pickle.load(open(args.load_agent, 'rb'))\n        meta_learner.set_params(meta_learner.get_params())\n        fast_learner = pickle.load(open(args.load_agent, 'rb'))\n        fast_learner.set_params(fast_learner.get_params())\n        for learner in [meta_learner, fast_learner]:\n            learner.inner_alg = args.inner_alg\n            learner.inner_lr = args.inner_lr\n            learner.outer_lr = args.outer_lr\n        \n    init_params = meta_learner.get_params()\n    #device = 'cuda' if args.use_gpu is True else 'cpu'\n    device = torch.device('cuda:'+str(args.use_gpu) if torch.cuda.is_available() else 'cpu')\n    lam = torch.tensor(args.lam) if args.scalar_lam is True else torch.ones(init_params.shape[0])*args.lam\n    lam = lam.to(device)\n    pathlib.Path(args.save_dir).mkdir(parents=True, exist_ok=True)\n\n    # ===================\n    # Train\n    # ===================\n    print(\"Training model ......\")\n    losses = np.zeros((args.meta_steps, 2))\n    num_tasks = len(dataset)\n    lowest_score = 100\n    lowest_loss = 1000\n    for outstep in tqdm(range(args.meta_steps)):\n        if outstep > 10 and outstep%1500 ==0:\n            penalty_coeff = penalty_coeff + 0.\n        w1_list = []\n        d1_list = []\n        w2_list = []\n        d2_list = []\n        task_mb = np.random.choice(num_tasks, size=args.task_mb_size)\n        w_k = meta_learner.get_params()\n        meta_grad = 0.0\n        lam_grad = 0.0\n        for k in range(args.n_steps):\n            old_parameters = parameters_to_vector(meta_learner.model.parameters())\n            losses_q = torch.tensor([0.0]).to(device)\n            data_index = 0\n            for idx in task_mb:\n                task = dataset[idx] # get task\n                task = task.to(device)\n                #vl_before = meta_learner.get_loss(task['x_val'], task['y_val'], return_numpy = True)\n                tl_before, w1, d1 = meta_learner.get_loss(task['x'], task['edge_index'], task['train_batch'], penalty_coefficient = penalty_coeff, device = device)\n                new_grad = torch.autograd.grad(tl_before, meta_learner.model.parameters(), retain_graph = True, create_graph = True)\n                new_params = parameters_to_vector(meta_learner.model.parameters()) - args.inner_lr * parameters_to_vector(new_grad)\n                vector_to_parameters(new_params, meta_learner.model.parameters())\n                tl_after, w2, d2 = meta_learner.get_loss(task['x'], task['edge_index'], task['train_batch'], penalty_coefficient = penalty_coeff, device = device)\n                tl_after = tl_after.reshape(-1,1)\n                #vl_after = meta_learner.get_loss(task['x_val'], task['y_val']).reshape(-1, 1)\n\n                if k == 0:\n                    losses[outstep] += (np.array([tl_before.item(), 0])/args.task_mb_size)\n                if k == args.n_steps - 1:\n                    losses[outstep] += (np.array([0, tl_after.item()])/args.task_mb_size)\n                if data_index == 0:\n                    losses_q = tl_after\n                else:\n                    losses_q = torch.cat((losses_q, tl_after), 0)\n                vector_to_parameters(old_parameters, meta_learner.model.parameters())\n                data_index = data_index + 1\n                \n                w1_list.append(w1)\n                w2_list.append(w2)\n                d1_list.append(d1)\n                d2_list.append(d2)\n            loss_q = torch.mean(losses_q)\n            meta_learner.outer_opt.zero_grad()\n            loss_q.backward()\n            #torch.nn.utils.clip_grad_norm_(meta_learner.model.parameters(),1)\n            meta_learner.outer_opt.step()\n            print('loss:'+str(loss_q.item())+' w1:'+str(np.mean(w1_list))+' d1:'+str(np.mean(d1_list))+' w2:'+str(np.mean(w2_list))+' d2:'+str(np.mean(d2_list)))\n            if loss_q.item() < lowest_loss:\n                lowest_loss = loss_q.item()\n                model_path = args.save_dir + '/best_loss.pth'\n                torch.save(meta_learner.model.state_dict(), model_path)\n\n        logger.log_kv('train_pre', losses[outstep,0])\n        logger.log_kv('train_post', losses[outstep,1])\n        \n        if (outstep % 25 == 0 and outstep > 0) or outstep == args.meta_steps-1:\n            smoothed_losses = utils.smooth_vector(losses[:outstep], window_size=10)\n            plt.figure(figsize=(10,6))\n            plt.plot(smoothed_losses)\n            plt.ylim([-70, 300])\n            plt.xlim([0, args.meta_steps])\n            plt.grid(True)\n            plt.legend(['Train pre', 'Train post'], loc=1)\n            plt.savefig(args.save_dir+'/learn_curve.png', dpi=100)\n            plt.clf()\n            plt.close('all')\n\n            pickle.dump(meta_learner, open(args.save_dir+'/agent.pickle', 'wb'))\n            logger.save_log()\n\n        if (outstep % 50 == 0):\n            checkpoint_file = args.save_dir + '/checkpoint_' + str(outstep) + '.pickle'\n            #pickle.dump(meta_learner, open(checkpoint_file, 'wb'))\n            model_path = args.save_dir + '/model_' + str(outstep) + '.pth'\n            torch.save(meta_learner.model.state_dict(), model_path)\n        if outstep == args.meta_steps-1:\n            checkpoint_file = args.save_dir + '/final_model.pickle'\n            #pickle.dump(meta_learner, open(checkpoint_file, 'wb'))\n            model_path = args.save_dir + '/final_model.pth'\n            torch.save(meta_learner.model.state_dict(), model_path)\n        if outstep % 5 == 0:\n            model_output = np.zeros(len(testset))\n            model_output = model_output + 10000\n            gt_output = []\n            model_index = -1\n            time_list = []\n            testcase_index = -1\n            for data in test_loader:\n                testcase_index = testcase_index = 1\n                if testcase_index<50:\n                    model_index = model_index + 1\n                    for k in range(1):\n                        # get k different data input\n                        data_prime = get_diracs(data.to(device), 1, sparse = True, effective_volume_range=0.15, receptive_field = receptive_field)\n                        data_prime = data_prime.to(device)\n                        criterion = ErdosLoss_vertex()\n                        probs = meta_learner.model(data_prime.x, data_prime.edge_index, data_prime.batch, None, penalty_coeff)\n                        retdict = criterion(probs, data_prime.edge_index, data_prime.batch, penalty_coeff, device)\n                        num_vertex = decode_vertex(data_prime,probs)\n                        if num_vertex.item() < model_output[model_index]:\n                            model_output[model_index] = num_vertex\n                    vertex_num = data.min_cover.item()\n                    gt_output.append(vertex_num)\n                    #print('model_index:'+str(model_index)+\" gt:\"+str(cliqno)+' model:'+str(model_output[model_index])+\"time:\"+str(time_per_data))\n                else:\n                    break\n            ratios = [(model_output[i] - gt_output[i])/gt_output[i] for i in range(len(model_output))]\n            print(f\"Mean ratio: {(np.array(ratios)).mean()} +/-  {(np.array(ratios)).std()}\")\n            if (np.array(ratios)).mean() < lowest_score:\n                lowest_score = (np.array(ratios)).mean()\n                model_path = args.save_dir + '/best_model_'+str(outstep)+'.pth'\n                torch.save(meta_learner.model.state_dict(), model_path)\n                print(\"epoch:\"+str(outstep)+\", get best again\")\n\n\nif __name__ == '__main__':\n    main()\n\n# ==========================================\n# File: vertex_cover/twitter/gnn_model.py\n# Function/Context: vertex_MPNN, ErdosLoss_vertex\n# ==========================================\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn import Linear\nfrom torch import tensor\nfrom torch.optim import Adam\nfrom torch.optim import SGD\nfrom math import ceil\nfrom torch.nn import Linear\nfrom torch.distributions import categorical\nfrom torch.distributions import Bernoulli\nimport torch.nn\nfrom torch_geometric.utils import convert as cnv\nfrom torch_geometric.utils import sparse as sp\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn.inits import uniform\nfrom torch_geometric.nn.inits import glorot, zeros\nfrom torch.nn import Parameter\nfrom torch.nn import Sequential as Seq, Linear, ReLU\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.utils import degree\nfrom torch_geometric.nn import GINConv, GATConv\nfrom torch.nn import Parameter\nfrom torch.nn import Sequential as Seq, Linear, ReLU, LeakyReLU\nfrom torch_geometric.nn import MessagePassing\nfrom torch.nn import Linear, Sequential, ReLU, BatchNorm1d as BN\nfrom torch_geometric.data import Batch \nfrom torch_scatter import scatter_min, scatter_max, scatter_add, scatter_mean\nfrom torch import autograd\nfrom torch_geometric.utils import softmax, add_self_loops, remove_self_loops, segregate_self_loops, remove_isolated_nodes, contains_isolated_nodes, add_remaining_self_loops, dropout_adj\nfrom utils import get_mask\nfrom torch_geometric.nn.norm.graph_size_norm import GraphSizeNorm\n\n\nclass ErdosLoss_vertex(torch.nn.Module):\n    def __init__(self):\n        super(ErdosLoss_vertex,self).__init__()\n        #self.penalty = Penalty()\n    def forward(self, probs, edge_index, batch, penalty_coefficient, device):\n        #calculating the terms for the vertex covering problem\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        probs_sum = torch.zeros(num_graphs, device = device)\n        #pairwise_prodsums = torch.zeros(num_graphs, device = device)\n        for graph in range(num_graphs):\n            batch_graph = (batch==graph)\n            probs_sum[graph] = probs[batch_graph].unsqueeze(-1).sum()\n        vertex_row = probs[no_loop_row]\n        vertex_col = probs[no_loop_col]\n        expected_distance = (1 - vertex_row) * (1 - vertex_col)\n        expected_distance = expected_distance.sum() / num_graphs\n        expected_weight = probs_sum.mean()\n        loss = penalty_coefficient * expected_distance + expected_weight\n        retdict = {}\n        retdict[\"loss\"] = [loss.squeeze(),\"sequence\"] #final loss\n        retdict[\"Expected weight\"]= [expected_weight, \"sequence\"]\n        retdict[\"Expected distance\"]= [expected_distance, \"sequence\"]\n        return retdict\n\nclass ErdosLoss_vertex_new(torch.nn.Module):\n    def __init__(self):\n        super(ErdosLoss_vertex_new,self).__init__()\n        #self.penalty = Penalty()\n    def forward(self, probs, edge_index, batch, penalty_coefficient, device):\n        #calculating the terms for the vertex covering problem\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        vertex_row = probs[no_loop_row]\n        vertex_col = probs[no_loop_col]\n        expected_distance = (1 - vertex_row) * (1 - vertex_col)\n        expected_distance = expected_distance.sum() / num_graphs\n        expected_weight = probs.sum() / num_graphs\n        loss = penalty_coefficient * expected_distance + expected_weight\n        return loss\n        \n\n\nclass vertex_MPNN(torch.nn.Module):\n    def __init__(self, dataset, num_layers, hidden1, hidden2, deltas):\n        super(vertex_MPNN, self).__init__()\n        self.hidden1 = hidden1\n        self.hidden2 = hidden2\n        self.momentum = 0.1\n        self.convs = torch.nn.ModuleList()\n        self.deltas = deltas\n        self.numlayers = num_layers\n        self.heads = 8\n        self.concat = True\n        \n        self.bns = torch.nn.ModuleList()\n        for i in range(num_layers-1):\n            self.bns.append(BN(self.heads*self.hidden1, momentum=self.momentum))\n        self.convs = torch.nn.ModuleList()        \n        for i in range(num_layers - 1):\n                self.convs.append(GINConv(Sequential(\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            BN(self.heads*self.hidden1, momentum=self.momentum),\n        ),train_eps=True))\n        self.bn1 = BN(self.heads*self.hidden1)       \n        self.conv1 = GINConv(Sequential(Linear(self.hidden2,  self.heads*self.hidden1),\n            ReLU(),\n            Linear( self.heads*self.hidden1,  self.heads*self.hidden1),\n            ReLU(),\n            BN(self.heads*self.hidden1, momentum=self.momentum),\n        ),train_eps=True)\n\n        if self.concat:\n            self.lin1 = Linear(self.heads*self.hidden1, self.hidden1)\n        else:\n            self.lin1 = Linear(self.hidden1, self.hidden1)\n        self.lin2 = Linear(self.hidden1, 1)\n        self.gnorm = GraphSizeNorm()\n\n    def reset_parameters(self):\n        self.conv1.reset_parameters()\n        \n        for conv in self.convs:\n            conv.reset_parameters() \n        for bn in self.bns:\n            bn.reset_parameters()\n        self.bn1.reset_parameters()\n        self.lin1.reset_parameters()\n        self.lin2.reset_parameters()\n\n    def forward(self, x, edge_index, batch, edge_dropout = None, penalty_coefficient = 0.25):\n        num_graphs = batch.max().item() + 1\n        row, col = edge_index     \n        total_num_edges = edge_index.shape[1]\n        N_size = x.shape[0]\n\n        if edge_dropout is not None:\n            edge_index = dropout_adj(edge_index, edge_attr = (torch.ones(edge_index.shape[1], device=device)).long(), p = edge_dropout, force_undirected=True)[0]\n            edge_index = add_remaining_self_loops(edge_index, num_nodes = batch.shape[0])[0]\n                \n        reduced_num_edges = edge_index.shape[1]\n        current_edge_percentage = (reduced_num_edges/total_num_edges)\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n\n        xinit= x.clone()\n        x = x.unsqueeze(-1)\n        mask = get_mask(x,edge_index,1).to(x.dtype)\n        x = F.leaky_relu(self.conv1(x, edge_index))# +x\n        x = x*mask\n        x = self.gnorm(x)\n        x = self.bn1(x)\n        \n            \n        for conv, bn in zip(self.convs, self.bns):\n            if(x.dim()>1):\n                x =  x+F.leaky_relu(conv(x, edge_index))\n                mask = get_mask(mask,edge_index,1).to(x.dtype)\n                x = x*mask\n                x = self.gnorm(x)\n                x = bn(x)\n\n        xpostconvs = x.detach()\n        #\n        x = F.leaky_relu(self.lin1(x)) \n        x = x*mask\n\n        xpostlin1 = x.detach()\n        x = F.leaky_relu(self.lin2(x)) \n        x = x*mask\n\n        #calculate min and max\n        batch_max = scatter_max(x, batch, 0, dim_size= N_size)[0]\n        batch_max = torch.index_select(batch_max, 0, batch)        \n        batch_min = scatter_min(x, batch, 0, dim_size= N_size)[0]\n        batch_min = torch.index_select(batch_min, 0, batch)\n\n        #min-max normalize\n        x = (x-batch_min)/(batch_max+1e-6-batch_min)\n        probs=x\n\n        return probs\n\n# ==========================================\n# File: vertex_cover/twitter/learner_model.py\n# Function/Context: Learner.erdosloss_vertex\n# ==========================================\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport utils\nfrom   torch.nn import functional as F\nfrom torch_geometric.utils import remove_self_loops\nfrom torch_scatter import scatter_add\n\nclass Learner:\n    def __init__(self, model, loss_function, inner_lr=1e-3, outer_lr=1e-2, GPU=-1, inner_alg='gradient', outer_alg='adam'):\n        self.model = model\n        self.use_gpu = GPU\n        if GPU>=0:\n            device = torch.device('cuda:'+str(GPU)if torch.cuda.is_available() else \"cpu\")\n            #self.model.cuda()\n            self.model.to(device)\n        assert outer_alg == 'sgd' or 'adam'\n        #self.inner_opt = torch.optim.SGD(self.model.parameters(), lr=inner_lr)\n        self.inner_opt = torch.optim.Adam(self.model.parameters(), lr=inner_lr, eps=1e-3)\n        if outer_alg == 'adam':\n            self.outer_opt = torch.optim.Adam(self.model.parameters(), lr=outer_lr, eps=1e-3)\n        else:\n            self.outer_opt = torch.optim.SGD(self.model.parameters(), lr=outer_lr)\n        self.loss_function = loss_function\n        assert inner_alg == 'gradient' # sqp unsupported in this version\n        self.inner_alg = inner_alg\n\n    def get_params(self):\n        return torch.cat([param.data.view(-1) for param in self.model.parameters()], 0).clone()\n\n    def set_params(self, param_vals):\n        offset = 0\n        for param in self.model.parameters():\n            param.data.copy_(param_vals[offset:offset + param.nelement()].view(param.size()))\n            offset += param.nelement()\n            \n    def set_outer_lr(self, lr):\n        for param_group in self.outer_opt.param_groups:\n            param_group['lr'] = lr\n            \n    def set_inner_lr(self, lr):\n        for param_group in self.inner_opt.param_groups:\n            param_group['lr'] = lr\n\n    def regularization_loss(self, w_0, lam=0.0):\n        \"\"\"\n        Add a regularization loss onto the weights\n        The proximal term regularizes around the point w_0\n        Strength of regularization is lambda\n        lambda can either be scalar (type float) or ndarray (numpy.ndarray)\n        \"\"\"\n        regu_loss = 0.0\n        offset = 0\n        regu_lam = lam if type(lam) == float or np.float64 else utils.to_tensor(lam)\n        if w_0.dtype == torch.float16:\n            try:\n                regu_lam = regu_lam.half()\n            except:\n                regu_lam = np.float16(regu_lam)\n        for param in self.model.parameters():\n            delta = param.view(-1) - w_0[offset:offset + param.nelement()].view(-1)\n            if type(regu_lam) == float or np.float64:\n                regu_loss += 0.5 * regu_lam * torch.sum(delta ** 2)\n            else:\n                # import ipdb; ipdb.set_trace()\n                param_lam = regu_lam[offset:offset + param.nelement()].view(-1)\n                param_delta = delta * param_lam\n                regu_loss += 0.5 * torch.sum(param_delta ** 2)\n            offset += param.nelement()\n        return regu_loss\n\n    def get_loss(self, x, edge_index, batch, penalty_coefficient, device, return_numpy = False):\n        probs = self.model.forward(x, edge_index, batch)\n        loss_dict = self.erdosloss_vertex(probs, edge_index, batch, penalty_coefficient, device)\n        loss = loss_dict['loss'][0]\n        weight = loss_dict['Expected weight'][0].item()\n        distance = loss_dict['Expected distance'][0].item()\n        if return_numpy:\n            loss = utils.to_numpy(loss).ravel()[0]\n        return loss, weight, distance\n\n    def predict(self, x, edge_index, batch, return_numpy = False):\n        utils.to_device(x, self.use_gpu)\n        utils.to_device(edge_index, self.use_gpu)\n        utils.to_device(batch, self.use_gpu)\n        probs = self.model.forward(x, edge_index, batch)\n        if return_numpy:\n            probs = utils.to_numpy(probs)\n        return probs\n\n    def learn_on_data(self, x, edge_index, batch, penalty_coefficient, device, num_steps=10,\n                      add_regularization=False,\n                      w_0=None, lam=0.0):\n        assert self.inner_alg == 'gradient'# or 'sqp' or 'adam' # TODO(Aravind): support sqp and adam \n        train_loss = []\n        if self.inner_alg == 'gradient':\n            for i in range(num_steps):\n                self.inner_opt.zero_grad()\n                tloss = self.get_loss(x, edge_index, batch, penalty_coefficient, device)\n                loss = tloss + self.regularization_loss(w_0, lam) if add_regularization else tloss\n                loss.backward()\n                #torch.nn.utils.clip_grad_norm_(self.model.parameters(),1)\n                self.inner_opt.step()\n                train_loss.append(utils.to_numpy(tloss))\n        return train_loss\n    \n    def learn_task(self, x, edge_index, batch, penalty_coefficient, device, num_steps=10, add_regularization=False, w_0=None, lam=0.0):\n\n        return self.learn_on_data(x, edge_index, batch, penalty_coefficient, device, num_steps, add_regularization, w_0, lam)\n\n    def move_toward_target(self, target, lam=2.0):\n        \"\"\"\n        Move slowly towards the target parameter value\n        Default value for lam assumes learning rate determined by optimizer\n        Useful for implementing Reptile\n        \"\"\"\n        # we can implement this with the regularization loss, but regularize around the target point\n        # and with specific choice of lam=2.0 to preserve the learning rate of inner_opt\n        self.outer_opt.zero_grad()\n        loss = self.regularization_loss(target, lam=lam)\n        loss.backward()\n        self.outer_opt.step()\n\n    def outer_step_with_grad(self, grad, flat_grad=False):\n        \"\"\"\n        Given the gradient, step with the outer optimizer using the gradient.\n        Assumed that the gradient is a tuple/list of size compatible with model.parameters()\n        If flat_grad, then the gradient is a flattened vector\n        \"\"\"\n        check = 0\n        for p in self.model.parameters():\n            check = check + 1 if type(p.grad) == type(None) else check\n        if check > 0:\n            # initialize the grad fields properly\n            dummy_loss = self.regularization_loss(self.get_params())\n            dummy_loss.backward()  # this would initialize required variables\n        if flat_grad:\n            offset = 0\n            grad = utils.to_device(grad, self.use_gpu)\n            for p in self.model.parameters():\n                this_grad = grad[offset:offset + p.nelement()].view(p.size())\n                p.grad.copy_(this_grad)\n                offset += p.nelement()\n        else:\n            for i, p in enumerate(self.model.parameters()):\n                p.grad = grad[i]\n        self.outer_opt.step()\n\n    def matrix_evaluator(self, x, edge_index, batch, lam, penalty_coefficient, device, regu_coef=1.0, lam_damping=10.0):\n        \"\"\"\n        Constructor function that can be given to CG optimizer\n        Works for both type(lam) == float and type(lam) == np.ndarray\n        \"\"\"\n        if type(lam) == np.ndarray:\n            lam = utils.to_device(lam, self.use_gpu)\n        def evaluator(v):\n            hvp = self.hessian_vector_product(x, edge_index, batch, v, penalty_coefficient, device)\n            #hvp = self.hessian_vector_product(task, v, x=x, y=y)\n            Av = (1.0 + regu_coef) * v + hvp / (lam + lam_damping)\n            return Av\n        return evaluator\n\n    def hessian_vector_product(self, x, edge_index, batch, vector, penalty_coefficient, device, params=None):\n        \"\"\"\n        Performs hessian vector product on the train set in task with the provided vector\n        \"\"\"\n        if params is not None:\n            self.set_params(params)\n        tloss = self.get_loss(x, edge_index, batch, penalty_coefficient, device)\n        grad_ft = torch.autograd.grad(tloss, self.model.parameters(), create_graph=True)\n        flat_grad = torch.cat([g.contiguous().view(-1) for g in grad_ft])\n        vec = utils.to_device(vector, self.use_gpu)\n        h = torch.sum(flat_grad * vec)\n        hvp = torch.autograd.grad(h, self.model.parameters())\n        hvp_flat = torch.cat([g.contiguous().view(-1) for g in hvp])\n        return hvp_flat\n    def erdosloss_vertex(self, probs, edge_index, batch, penalty_coefficient, device):\n        #calculating the terms for the vertex covering problem\n        num_graphs = batch.max().item() + 1\n        no_loop_index,_ = remove_self_loops(edge_index)  \n        no_loop_row, no_loop_col = no_loop_index\n        probs_sum = torch.zeros(num_graphs, device = device)\n        #pairwise_prodsums = torch.zeros(num_graphs, device = device)\n        for graph in range(num_graphs):\n            batch_graph = (batch==graph)\n            probs_sum[graph] = probs[batch_graph].unsqueeze(-1).sum()\n        vertex_row = probs[no_loop_row]\n        vertex_col = probs[no_loop_col]\n        expected_distance = (1 - vertex_row) * (1 - vertex_col)\n        expected_distance = expected_distance.sum() / num_graphs\n        expected_weight = probs_sum.mean()\n        loss = penalty_coefficient * expected_distance + expected_weight\n        retdict = {}\n        retdict[\"loss\"] = [loss.squeeze(),\"sequence\"] #final loss\n        retdict[\"Expected weight\"]= [expected_weight, \"sequence\"]\n        retdict[\"Expected distance\"]= [expected_distance, \"sequence\"]\n        return retdict",
  "description": "Combined Analysis:\n- [max_clique/rb200/gnn_model.py]: This file implements the core GNN architecture (clique_MPNN) and unsupervised loss function (ErdosLoss_clique) for the Maximum Clique problem as described in the paper. The clique_MPNN uses GINConv layers to process graph-structured data and outputs node probabilities. The ErdosLoss_clique implements the mathematical formulation that maximizes clique size while penalizing non-edges within the selected set, corresponding to the optimization objective f(X;G) for Maximum Clique. The loss function computes expected clique weight and expected graph weight to guide the model toward valid cliques. This represents the EGN (Efficient Graph Network) component that Meta-EGN builds upon for meta-learning.\n- [max_clique/rb200/learner_model.py]: This file implements the core meta-learning optimization logic for the Maximum Clique (MC) problem as described in the paper. The Learner class encapsulates the MAML-based adaptation framework with inner and outer optimization loops. Key components include:\n1. **Inner Loop Adaptation**: `learn_on_data`/`learn_task` performs gradient steps on individual graph instances using the `erdosloss_clique` loss function, which encodes the MC problem's objective and constraints via continuous relaxation.\n2. **Loss Function**: `erdosloss_clique` computes the expected clique weight and penalizes deviations from feasibility (clique structure), aligning with the paper's unsupervised learning formulation.\n3. **Meta-Learning Mechanics**: Methods like `regularization_loss`, `move_toward_target`, and `outer_step_with_grad` enable Reptile-style or gradient-based meta-updates to learn a generalizable initialization.\n4. **Second-Order Optimization**: `hessian_vector_product` and `matrix_evaluator` support second-order MAML for precise adaptation.\nThe implementation directly corresponds to the Meta-EGN algorithm, where a GNN model is meta-trained to quickly adapt to new graph instances via few-step fine-tuning, ensuring instance-wise optimality rather than averaged performance.\n- [max_clique/rb200/modules_and_utils.py]: The file contains the core decoding algorithm for the Maximum Clique problem. The `decode_clique_final` function implements a greedy derandomization procedure that converts continuous probability outputs from a GNN into discrete binary node selections (clique membership). It processes graphs in batch, sorting nodes by probability and sequentially deciding inclusion based on expected clique weight calculations. This directly maps to the combinatorial optimization objective of maximizing clique size while satisfying feasibility constraints (all selected nodes must be mutually connected). The algorithm uses graph structural information (edge_index) and batch information to compute expected weights and make binary decisions, implementing the key optimization model transformation from continuous relaxations to discrete solutions.\n- [max_clique/rb200/train_maml.py]: This file implements the core MAML (Model-Agnostic Meta-Learning) algorithm for the Max Clique problem as described in the paper. The code trains a meta-learner (graph neural network) that learns good parameter initializations enabling fast adaptation to individual graph instances. Key components: 1) MAML training loop with inner/outer optimization, 2) Task sampling from RB200 dataset, 3) Inner loop gradient updates on individual graphs, 4) Outer loop meta-optimization using accumulated losses, 5) Periodic evaluation on validation set. The implementation directly corresponds to the paper's Meta-EGN framework where unsupervised learning is reframed as meta-learning for combinatorial optimization.\n- [max_clique/twitter/gnn_model.py]: This file implements the core GNN model and unsupervised loss function for the Maximum Clique problem as described in the paper. The clique_MPNN class defines a graph neural network architecture using GINConv layers that outputs node probabilities for clique selection. The ErdosLoss_clique class implements the unsupervised loss function that optimizes the expected clique size while enforcing clique constraints through penalty terms. This directly corresponds to the paper's approach of using unsupervised learning with GNNs for combinatorial optimization, specifically for the max clique problem where the objective is to find the largest complete subgraph. The loss function balances maximizing clique size (through -0.5*expected_weight_G) with enforcing clique constraints (through penalty_coefficient*expected_distance).\n- [max_clique/twitter/learner_model.py]: This file implements the core MAML-based meta-learning framework for combinatorial optimization. The Learner class provides: 1) Inner-loop adaptation via learn_on_data/learn_task (gradient-based optimization on individual instances), 2) Outer-loop meta-optimization via outer_step_with_grad, 3) The specific unsupervised loss function for Maximum Clique (erdosloss_clique) that encodes the combinatorial constraints through expected values. The erdosloss_clique function implements the mathematical formulation where expected_weight_G measures edge coverage, expected_clique_weight measures complete subgraph weight, and expected_distance penalizes deviation from clique feasibility. This directly corresponds to the paper's approach of learning parameter initializations that enable fast adaptation to individual graph instances.\n- [vertex_cover/rb200/gnn_model.py]: This file implements the core optimization model for Minimum Vertex Cover (MVC) using a Graph Neural Network (GNN) approach. The key components are:\n\n1. **Optimization Model Implementation**: The `ErdosLoss_vertex` class implements the unsupervised loss function for MVC, which encodes the optimization objective and constraints:\n   - Objective: Minimize expected weight (sum of selected nodes)\n   - Constraint: Penalize uncovered edges via expected distance term\n   - Mathematical formulation: loss = penalty_coefficient * E[(1-p_u)(1-p_v)] + E[p_i]\n   - This corresponds to the paper's approach of relaxing binary constraints to probabilities\n\n2. **GNN Architecture**: The `vertex_MPNN` class implements a GIN-based graph neural network that:\n   - Processes graph structure through multiple GINConv layers\n   - Uses GraphSizeNorm for normalization\n   - Outputs node probabilities via min-max normalization\n   - Supports edge dropout for regularization\n\n3. **Algorithm Compatibility**: While this file doesn't implement the full Meta-EGN algorithm (which would be in training scripts), it provides the fundamental building blocks:\n   - The GNN model that parameterizes solutions\n   - The loss function that encodes the optimization problem\n   - These components are essential for the meta-learning framework described in the paper\n\n4. **Key Features**:\n   - Handles batched graphs\n   - Uses scatter operations for graph-level computations\n   - Implements probability-based relaxation of binary variables\n   - Provides two loss variants for flexibility\n\nThis implementation directly maps to the paper's formulation of unsupervised learning for combinatorial optimization on graphs, specifically for the Minimum Vertex Cover problem.\n- [vertex_cover/rb200/learner_model.py]: This file implements the core optimization logic for the Minimum Vertex Cover problem using the Meta-EGN framework. The key component is the `erdosloss_vertex` method, which computes the loss function for vertex cover: L =  * (expected uncovered edges) + (expected vertex weight). This corresponds to the paper's formulation where the neural network outputs probabilities for node selection, and the loss encourages covering edges while minimizing selected vertices. The `Learner` class encapsulates the meta-learning logic with inner optimization (task-specific adaptation via `learn_on_data`) and outer optimization (meta-updates via `outer_step_with_grad`), implementing the MAML-style approach described in the paper.\n- [vertex_cover/rb200/train_maml.py]: This file implements the core meta-learning training logic (MAML) for the Minimum Vertex Cover problem as described in the paper. The key components are: 1) Meta-training loop (outer loop) over meta_steps, 2) Task sampling (inner loop) with task_mb_size graphs, 3) Inner loop adaptation using n_steps gradient updates with inner_lr, 4) Outer loop optimization using the post-adaptation loss with outer_lr, 5) Regularization via penalty_coeff for constraint satisfaction, 6) Evaluation on test set using decode_vertex for solution extraction. The implementation follows the Meta-EGN framework where a GNN (vertex_MPNN) is meta-trained to quickly adapt to individual graph instances via few-step fine-tuning.\n- [vertex_cover/twitter/gnn_model.py]: This file implements the core GNN model and loss function for the Minimum Vertex Cover problem within the Meta-EGN framework. The vertex_MPNN class is a Graph Neural Network that processes graph-structured data and outputs node probabilities for inclusion in the vertex cover. The ErdosLoss_vertex class implements the continuous relaxation of the vertex cover objective: it minimizes the expected number of selected vertices (expected_weight) while penalizing uncovered edges via a penalty term (expected_distance). This corresponds to the optimization model where the binary constraint X_i  {0,1} is relaxed to probabilities, and the constraint that every edge must be covered (X_i + X_j  1) is enforced through the penalty term. The model uses GINConv layers with batch normalization and graph size normalization, and outputs normalized probabilities that can be thresholded to obtain binary solutions.\n- [vertex_cover/twitter/learner_model.py]: This file implements the core optimization logic for the Minimum Vertex Cover problem using the Meta-EGN framework. The key components are:\n1. **Learner class**: Implements MAML-style meta-learning with inner/outer optimization loops\n2. **erdosloss_vertex()**: Implements the mathematical formulation of vertex cover as a differentiable loss function:\n   - Expected weight: Sum of node selection probabilities (minimization objective)\n   - Expected distance: Penalty for uncovered edges (1 - p_i)*(1 - p_j) for edge (i,j)\n   - Combined loss: penalty_coefficient * expected_distance + expected_weight\n3. **Inner loop adaptation**: learn_on_data() performs gradient-based adaptation on individual graph instances\n4. **Meta-learning components**: regularization_loss(), outer_step_with_grad(), and hessian_vector_product() support second-order meta-learning updates\n5. **Compatibility**: Directly implements the unsupervised learning formulation where node selection probabilities are optimized to satisfy edge covering constraints while minimizing selected nodes, with meta-learning enabling instance-wise adaptation.",
  "dependencies": [
    "torch_geometric.utils.remove_self_loops",
    "torch.distributions",
    "dataset.rb200_val.RB200_val",
    "pickle",
    "sys",
    "torch.optim",
    "matplotlib.pyplot",
    "pathlib.Path",
    "yaml",
    "time",
    "torch_geometric.data.DataLoader",
    "torch_geometric.utils.to_networkx",
    "torch_scatter.scatter_add",
    "torch.optim.SGD",
    "gnn_model.ErdosLoss_vertex",
    "torch.nn.functional",
    "utils.get_diracs",
    "torch_geometric.utils.to_undirected",
    "pathlib",
    "dataset.rb200_val",
    "torch_geometric.utils.dropout_adj",
    "tqdm",
    "gnn_model.clique_MPNN",
    "utils.get_mask",
    "torch.optim.Adam",
    "utils.decode_clique_final_speed",
    "utils.solve_gurobi_maxclique",
    "utils (custom module)",
    "torch.autograd.grad",
    "torch_geometric.data.DataListLoader",
    "dataset.rb200_train.RB200_train",
    "utils.DataLog",
    "test.decode_vertex",
    "GraphSizeNorm",
    "argparse",
    "gnn_model.vertex_MPNN",
    "random",
    "numpy",
    "torch_geometric.data.Data",
    "dataset.rb200_train",
    "utils",
    "learner_model.Learner",
    "torch.nn.utils.convert_parameters.parameters_to_vector",
    "torch.nn",
    "torch_geometric",
    "gnn_model.ErdosLoss_clique",
    "torch_scatter",
    "torch",
    "torch.nn.utils.convert_parameters.vector_to_parameters"
  ]
}