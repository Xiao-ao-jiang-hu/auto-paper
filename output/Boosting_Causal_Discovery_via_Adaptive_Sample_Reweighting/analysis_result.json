{
  "paper_id": "Boosting_Causal_Discovery_via_Adaptive_Sample_Reweighting",
  "title": "BOOSTING DIFFERENTIABLE CAUSAL DISCOVERY VIA ADAPTIVE SAMPLE REWEIGHTING",
  "abstract": "Under stringent model type and variable distribution assumptions, differentiable score-based causal discovery methods learn a directed acyclic graph (DAG) from observational data by evaluating candidate graphs over an average score function. Despite great success in low-dimensional linear systems, it has been observed that these approaches overly exploit easier-to-fit samples, thus inevitably learning spurious edges. Worse still, the common homogeneity assumption can be easily violated, due to the widespread existence of heterogeneous data in the real world, resulting in performance vulnerability when noise distributions vary. We propose a simple yet effective model-agnostic framework to boost causal discovery performance by dynamically learning the adaptive weights for the Reweighted Score function, ReScore for short, where the weights tailor quantitatively to the importance degree of each sample. Intuitively, we leverage the bilevel optimization scheme to alternately train a standard DAG learner and reweight samples â€” that is, upweight the samples the learner fails to fit and downweight the samples that the learner easily extracts the spurious information from. Extensive experiments on both synthetic and real-world datasets are carried out to validate the effectiveness of ReScore. We observe consistent and significant boosts in structure learning performance. Furthermore, we visualize that ReScore concurrently mitigates the influence of spurious edges and generalizes to heterogeneous data. Finally, we perform the theoretical analysis to guarantee the structure identifiability and the weight adaptive properties of ReScore in linear systems.",
  "problem_description_natural": "The paper addresses limitations in current differentiable score-based causal discovery methods, which use an average score over all samples and assume homogeneous noise distributions. These methods tend to overfit easy samples and fail on heterogeneous data, leading to spurious causal edges. To resolve this, the authors propose ReScore, a bilevel optimization framework that adaptively reweights samples during training: the inner loop learns sample weights that maximize the reweighted score (emphasizing hard-to-fit, informative samples), while the outer loop minimizes this reweighted score plus a DAG constraint to update the causal graph. The goal is to improve causal structure learning by focusing on samples that better reveal true causal relationships and are robust to distribution shifts.",
  "problem_type": "bilevel optimization",
  "datasets": [
    "ER1",
    "ER2",
    "ER4",
    "SF1",
    "SF2",
    "SF4",
    "Sachs"
  ],
  "performance_metrics": [
    "True Positive Rate (TPR)",
    "False Discovery Rate (FDR)",
    "Structural Hamming Distance (SHD)",
    "Structural Intervention Distance (SID)"
  ],
  "lp_model": {
    "objective": "$\\min_{\\mathcal{G}} S(\\mathcal{G}; \\mathbf{X}) = \\mathcal{L}(\\mathcal{G}; \\mathbf{X}) + \\lambda \\mathcal{R}_{\\text{sparse}}(\\mathcal{G})$",
    "constraints": [
      "$H(\\mathcal{G}) = 0$ (differentiable acyclicity constraint, e.g., $H(\\mathcal{G}) = \\text{Tr}(e^{\\mathcal{A} \\odot \\mathcal{A}}) - d$ for adjacency matrix $\\mathcal{A}$)",
      "$\\mathcal{G}$ is a directed acyclic graph (DAG)"
    ],
    "variables": [
      "$\\mathcal{G}$: a directed graph representing the causal structure",
      "$\\mathcal{A}(\\mathcal{G}) \\in \\mathbb{R}^{d \\times d}$ or $B \\in \\mathbb{R}^{d \\times d}$: weighted adjacency matrix where $[\\mathcal{A}]_{ij}$ or $B_{ij}$ indicates the presence or weight of edge from $X_j$ to $X_i$"
    ]
  },
  "raw_latex_model": "$$\\min_{\\mathcal{G}} \\; S(\\mathcal{G}; \\mathbf{X}) \\quad \\text{s.t.} \\quad H(\\mathcal{G}) = 0,$$ where $S(\\mathcal{G}; \\mathbf{X}) = \\mathcal{L}(\\mathcal{G}; \\mathbf{X}) + \\lambda \\mathcal{R}_{\\text{sparse}}(\\mathcal{G})$ is the score function, $\\mathcal{L}(\\mathcal{G}; \\mathbf{X})$ is the goodness-of-fit measure (e.g., least-squares loss), $\\mathcal{R}_{\\text{sparse}}(\\mathcal{G})$ is a sparsity regularization term, and $H(\\mathcal{G}) = 0$ is a differentiable constraint enforcing acyclicity.",
  "algorithm_description": "ReScore is a model-agnostic bilevel optimization framework that boosts differentiable score-based causal discovery methods by learning adaptive sample weights. It alternates between optimizing the DAG learner with reweighted samples (outer loop) and updating the weights based on the learner's errors to upweight informative samples and downweight easy-to-fit samples (inner loop)."
}