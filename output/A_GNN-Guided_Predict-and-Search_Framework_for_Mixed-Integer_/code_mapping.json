{
  "file_path": "PredictAndSearch_GRB.py, PredictAndSearch_SCIP.py",
  "function_name": "",
  "code_snippet": "\n\n# ==========================================\n# File: PredictAndSearch_GRB.py\n# Function/Context: \n# ==========================================\nimport gurobipy\nfrom gurobipy import GRB\nimport argparse\nimport random\nimport os\nimport numpy as np\nimport torch\nfrom helper import get_a_new2\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nrandom.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\n\n#4 public datasets, IS, WA, CA, IP\nTaskName='IS'\nTestNum=100\ndef test_hyperparam(task):\n    '''\n    set the hyperparams\n    k_0, k_1, delta\n    '''\n    if task==\"IP\":\n        return 400,5,1\n    elif task == \"IS\":\n        return 300,300,15\n    elif task == \"WA\":\n        return 0,600,5\n    elif task == \"CA\":\n        return 400,0,10\nk_0,k_1,delta=test_hyperparam(TaskName)\n\n#load pretrained model\nif TaskName==\"IP\":\n    #Add position embedding for IP model, due to the strong symmetry\n    from GCN import GNNPolicy_position as GNNPolicy,postion_get\nelse:\n    from GCN import GNNPolicy\nmodel_name=f'{TaskName}.pth'\npathstr = f'./models/{model_name}'\npolicy = GNNPolicy().to(DEVICE)\nstate = torch.load(pathstr, map_location=torch.device('cuda:0'))\npolicy.load_state_dict(state)\n\nsample_names = sorted(os.listdir(f'./instance/{TaskName}'))\nfor ins_num in range(TestNum):\n    test_ins_name = sample_names[ins_num]\n    ins_name_to_read = f'./instance/{TaskName}/{test_ins_name}'\n\n    #get bipartite graph as input\n    A, v_map, v_nodes, c_nodes, b_vars=get_a_new2(ins_name_to_read)\n    constraint_features = c_nodes.cpu()\n    constraint_features[np.isnan(constraint_features)] = 1 #remove nan value\n    variable_features = v_nodes\n    if TaskName == \"IP\":\n        variable_features = postion_get(variable_features)\n    edge_indices = A._indices()\n    edge_features = A._values().unsqueeze(1)\n    edge_features=torch.ones(edge_features.shape)\n\n    #prediction\n    BD = policy(\n        constraint_features.to(DEVICE),\n        edge_indices.to(DEVICE),\n        edge_features.to(DEVICE),\n        variable_features.to(DEVICE),\n    ).sigmoid().cpu().squeeze()\n\n    #align the variable name betweend the output and the solver\n    all_varname=[]\n    for name in v_map:\n        all_varname.append(name)\n    binary_name=[all_varname[i] for i in b_vars]\n    scores=[]#get a list of (index, VariableName, Prob, -1, type)\n    for i in range(len(v_map)):\n        type=\"C\"\n        if all_varname[i] in binary_name:\n            type='BINARY'\n        scores.append([i, all_varname[i], BD[i].item(), -1, type])\n\n\n    scores.sort(key=lambda x:x[2],reverse=True)\n\n    scores=[x for x in scores if x[4]=='BINARY']#get binary\n\n    fixer=0\n    #fixing variable picked by confidence scores\n    count1=0\n    for i in range(len(scores)):\n        if count1<k_1:\n            scores[i][3] = 1\n            count1+=1\n            fixer += 1\n    scores.sort(key=lambda x: x[2], reverse=False)\n    count0 = 0\n    for i in range(len(scores)):\n        if count0 < k_0:\n            scores[i][3] = 0\n            count0 += 1\n            fixer += 1\n\n\n    print(f'instance: {test_ins_name}, '\n          f'fix {k_0} 0s and '\n          f'fix {k_1} 1s, delta {delta}. ')\n\n\n    #read instance\n    gurobipy.setParam('LogToConsole', 1)  # hideout\n    m = gurobipy.read(ins_name_to_read)\n    m.Params.TimeLimit = 1000\n    m.Params.Threads = 1\n    m.Params.MIPFocus = 1\n    m.Params.LogFile = f'{log_folder}/{test_ins_name}.log'\n\n    # trust region method implemented by adding constraints\n    instance_variabels = m.getVars()\n    instance_variabels.sort(key=lambda v: v.VarName)\n    variabels_map = {}\n    for v in instance_variabels:  # get a dict (variable map), varname:var clasee\n        variabels_map[v.VarName] = v\n    alphas = []\n    for i in range(len(scores)):\n        tar_var = variabels_map[scores[i][1]]  # target variable <-- variable map\n        x_star = scores[i][3]  # 1,0,-1, decide whether need to fix\n        if x_star < 0:\n            continue\n        # tmp_var = m1.addVar(f'alp_{tar_var}', 'C')\n        tmp_var = m.addVar(name=f'alp_{tar_var}', vtype=GRB.CONTINUOUS)\n        alphas.append(tmp_var)\n        m.addConstr(tmp_var >= tar_var - x_star, name=f'alpha_up_{i}')\n        m.addConstr(tmp_var >= x_star - tar_var, name=f'alpha_dowm_{i}')\n    all_tmp = 0\n    for tmp in alphas:\n        all_tmp += tmp\n    m.addConstr(all_tmp <= delta, name=\"sum_alpha\")\n    m.optimize()\n\n# ==========================================\n# File: PredictAndSearch_SCIP.py\n# Function/Context: \n# ==========================================\nimport pyscipopt as scp\nimport argparse\nimport random\nimport numpy as np\nimport os\nimport torch\nfrom helper import get_a_new2\nfrom pyscipopt import SCIP_PARAMSETTING\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nrandom.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\n\n#4 public datasets, IS, WA, CA, IP\nTaskName='IS'\nTestNum=100\ndef test_hyperparam(task):\n    '''\n    set the hyperparams\n    k_0, k_1,delta\n    '''\n    if task==\"IP\":\n        return 400,5,1\n    elif task == \"IS\":\n        return 300,300,15\n    elif task == \"WA\":\n        return 0,600,5\n    elif task == \"CA\":\n        return 400,0,10\nk_0,k_1,delta=test_hyperparam(TaskName)\n\n#set log folder\nsolver='SCIP'\ntest_task = f'{TaskName}_{solver}_Predect&Search'\nif not os.path.isdir(f'./logs'):\n    os.mkdir(f'./logs')\nif not os.path.isdir(f'./logs/{TaskName}'):\n    os.mkdir(f'./logs/{TaskName}')\nif not os.path.isdir(f'./logs/{TaskName}/{test_task}'):\n    os.mkdir(f'./logs/{TaskName}/{test_task}')\nlog_folder=f'./logs/{TaskName}/{test_task}'\n\n\n#load pretrained model\nif TaskName==\"IP\":\n    #Add position embedding for IP model, due to the strong symmetry\n    from GCN import GNNPolicy_position as GNNPolicy,postion_get\nelse:\n    from GCN import GNNPolicy\nmodel_name=f'{TaskName}.pth'\npathstr = f'./models/{model_name}'\npolicy = GNNPolicy().to(DEVICE)\nstate = torch.load(pathstr, map_location=torch.device('cuda:0'))\npolicy.load_state_dict(state)\n\n\nsample_names = sorted(os.listdir(f'./instance/{TaskName}'))\nfor ins_num in range(TestNum):\n    test_ins_name = sample_names[ins_num]\n    ins_name_to_read = f'./instance/{TaskName}/{test_ins_name}'\n\n    #get bipartite graph as input\n    A, v_map, v_nodes, c_nodes, b_vars=get_a_new2(ins_name_to_read)\n    constraint_features = c_nodes.cpu()\n    constraint_features[np.isnan(constraint_features)] = 1 #remove nan value\n    variable_features = v_nodes\n    if TaskName == \"IP\":\n        variable_features = postion_get(variable_features)\n    edge_indices = A._indices()\n    edge_features = A._values().unsqueeze(1)\n    edge_features=torch.ones(edge_features.shape)\n\n    #prediction\n    BD = policy(\n        constraint_features.to(DEVICE),\n        edge_indices.to(DEVICE),\n        edge_features.to(DEVICE),\n        variable_features.to(DEVICE),\n    ).sigmoid().cpu().squeeze()\n\n    #align the variable name betweend the output and the solver\n    all_varname=[]\n    for name in v_map:\n        all_varname.append(name)\n    binary_name=[all_varname[i] for i in b_vars]\n    scores=[]#get a list of (index, VariableName, Prob, -1, type)\n    for i in range(len(v_map)):\n        type=\"C\"\n        if all_varname[i] in binary_name:\n            type='BINARY'\n        scores.append([i, all_varname[i], BD[i].item(), -1, type])\n\n\n    scores.sort(key=lambda x:x[2],reverse=True)\n\n    scores=[x for x in scores if x[4]=='BINARY']#get binary\n\n    fixer=0\n    #fixing variable picked by confidence scores\n    count1=0\n    for i in range(len(scores)):\n        if count1<k_1:\n            scores[i][3] = 1\n            count1+=1\n            fixer += 1\n    scores.sort(key=lambda x: x[2], reverse=False)\n    count0 = 0\n    for i in range(len(scores)):\n        if count0 < k_0:\n            scores[i][3] = 0\n            count0 += 1\n            fixer += 1\n\n\n    print(f'instance: {test_ins_name}, '\n          f'fix {k_0} 0s and '\n          f'fix {k_1} 1s, delta {delta}. ')\n\n    #read instance\n    m1 = scp.Model()\n    m1.setParam('limits/time', 1000)\n    #m1.hideOutput(True)\n    m1.setParam('randomization/randomseedshift', 0)\n    m1.setParam('randomization/lpseed', 0)\n    m1.setParam('randomization/permutationseed', 0)\n    m1.setHeuristics(SCIP_PARAMSETTING.AGGRESSIVE)#MIP focus\n    m1.setLogfile(f'{log_folder}/{test_ins_name}.log')\n    m1.readProblem(ins_name_to_read)\n\n    #trust region method implemented by adding constraints\n    m1_vars = m1.getVars()\n    var_map1 = {}\n    for v in m1_vars:  # get a dict (variable map), varname:var clasee\n        var_map1[v.name] = v\n    alphas = []\n    for i in range(len(scores)):\n        tar_var = var_map1[scores[i][1]]  # target variable <-- variable map\n        x_star = scores[i][3]  # 1,0,-1, decide whether to fix\n        if x_star < 0:\n            continue\n        tmp_var = m1.addVar(f'alp_{tar_var}_{i}', 'C')\n        alphas.append(tmp_var)\n        m1.addCons(tmp_var >= tar_var - x_star, f'alpha_up_{i}')\n        m1.addCons(tmp_var >= x_star - tar_var, f'alpha_down_{i}')\n    m1.addCons(scp.quicksum(ap for ap in alphas) <= delta, 'sum_alpha')\n    m1.optimize()",
  "description": "Combined Analysis:\n- [PredictAndSearch_GRB.py]: This file implements the core predict-and-search algorithm from the paper using Gurobi as the solver. It loads a pre-trained GNN model to predict marginal probabilities for binary variables, selects k0 variables with lowest probabilities (to fix to 0) and k1 variables with highest probabilities (to fix to 1), then adds a trust region constraint using continuous variables α_d to enforce ∑|x_d - x*_d| ≤ Δ. The implementation follows the mathematical model exactly, though it uses continuous α_d variables instead of binary δ_d, which is equivalent for binary x_d since |x_d - x*_d| is 0 or 1. The code includes all key steps: prediction, variable selection, trust region constraint addition, and solving the modified MILP.\n- [PredictAndSearch_SCIP.py]: This file implements the core predict-and-search algorithm from the paper. Key steps implemented: 1) Loads GNN model to predict marginal probabilities (BD) for binary variables. 2) Sorts variables by predicted probabilities and selects k0 smallest (I0) and k1 largest (I1). 3) For each selected variable, adds a continuous variable α and constraints α ≥ |x - x*| (where x* is 0 for I0, 1 for I1). 4) Adds trust region constraint Σα ≤ Δ. 5) Solves the modified MILP using SCIP. The implementation uses continuous α variables instead of binary δ, but mathematically enforces the same trust region via L1-norm constraints on binary variables.",
  "dependencies": [
    "GCN.postion_get",
    "GCN.GNNPolicy_position",
    "gurobipy",
    "GCN.GNNPolicy",
    "pyscipopt",
    "numpy",
    "os",
    "GCN.postion_get (conditional)",
    "argparse",
    "random",
    "helper.get_a_new2",
    "torch"
  ]
}