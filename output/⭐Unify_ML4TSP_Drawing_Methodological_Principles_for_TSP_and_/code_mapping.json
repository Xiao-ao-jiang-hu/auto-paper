{
  "file_path": "ml4tsp-library/ml4tsp/ar/solver/base.py, ml4tsp-library/ml4tsp/nar/decoder/mcts.py, ml4tsp-library/ml4tsp/nar/local_search/mcts.py, ml4tsp-library/ml4tsp/nar/model/diffusion.py, ml4tsp-library/ml4tsp/nar/solver/narsolver.py, models/modelzoo/diffusion/tsp_diffusion.py, models/modelzoo/gnn/tsp_gnn.py, search/mcts.py, search/mcts_solver.py, solvers/solver.py",
  "function_name": "ML4TSPARSolver.solve, ML4TSPNARMCTSDecoder._decode, ML4TSPNARMCTS._local_search, ML4TSPDiffusion, ML4TSPNARSolver, TSPDiffusion, TSPGNN.shared_step, tsp_mcts, tsp_mcts_solver, TSPNARSolver.solve",
  "code_snippet": "\n\n# ==========================================\n# File: ml4tsp-library/ml4tsp/ar/solver/base.py\n# Function/Context: ML4TSPARSolver.solve\n# ==========================================\nimport time\nimport numpy as np\nfrom tqdm import tqdm\nfrom typing import Union\nfrom ml4co_kit import TSPSolver, to_tensor, SOLVER_TYPE, TSPEvaluator, to_numpy\nfrom ml4tsp.ar.model.base import ML4TSPARBaseModel\n\n\nclass ML4TSPARSolver(TSPSolver):\n    def __init__(self, model: ML4TSPARBaseModel):\n        super(ML4TSPARSolver, self).__init__(solver_type=SOLVER_TYPE.ML4TSP, scale=1)\n        self.model = model\n        self.model.env.mode = \"solve\"\n        \n    def solve(\n        self,\n        points: Union[np.ndarray, list] = None,\n        batch_size: int = 1,\n    ) -> np.ndarray:\n        # prepare\n        self.from_data(points=points)\n        \n        # inference\n        inference_start_time = time.time()\n        points = to_tensor(self.points).to(self.model.env.device)\n        batch_points = points.reshape(-1, batch_size, self.nodes_num, 2)\n\n        samples = batch_points.shape[0]\n        solved_tours = list()\n        for idx in tqdm(range(samples), desc=\"Inference\"):          \n            _solved_tours = self.model.solve(points=batch_points[idx])\n            solved_tours.append(_solved_tours)\n        solved_tours = np.array(solved_tours)\n        solved_tours = solved_tours.reshape(-1, self.nodes_num + 1)\n        \n        # select the best\n        per_tours_num = solved_tours.shape[0] // points.shape[0]\n        if per_tours_num > 1:\n            best_tours = list()\n            points = to_numpy(points)\n            solved_tours = solved_tours.reshape(points.shape[0], per_tours_num, -1)\n            # a problem has more than one solved tour\n            for idx in range(points.shape[0]):\n                evaluator = TSPEvaluator(points[idx])\n                _solved_tours = solved_tours[idx]\n                _solved_costs = list()\n                for tour in _solved_tours:\n                    _solved_costs.append(evaluator.evaluate(tour))\n                _id = np.argmin(_solved_costs)\n                best_tours.append(_solved_tours[_id])\n            solved_tours = np.array(best_tours)\n        per_tours_num = 1\n        inference_end_time = time.time()\n        inference_use_time = inference_end_time - inference_start_time\n        print(f\"Inference Time: {inference_use_time}\")\n        \n        # local search\n        if self.model.local_search is not None:\n            local_search_start_time = time.time()\n            solved_tours = self.model.local_search.local_search(\n                solved_tours, points, None, per_tours_num\n            )\n            local_search_end_time = time.time()\n            local_search_use_time = local_search_end_time - local_search_start_time\n            print(f\"Local Search Time: {local_search_use_time}\")\n        self.from_data(tours=solved_tours)\n        return self.tours\n\n# ==========================================\n# File: ml4tsp-library/ml4tsp/nar/decoder/mcts.py\n# Function/Context: ML4TSPNARMCTSDecoder._decode\n# ==========================================\nimport numpy as np\nfrom typing import Union\nfrom ml4co_kit import tsp_mcts_decoder\nfrom scipy.spatial.distance import cdist\nfrom .base import ML4TSPNARDecoder\n\n\nMCTS_TIME_LIMIT_DEFAULT = {\n      50: 0.005,\n     100: 0.020,\n     200: 0.100,\n     500: 1.000,\n    1000: 5.000\n}\n\n\ndef get_nodes_num_for_mcts_time_limit(x: int):\n    if x <= 75:\n        return 50\n    if x <= 150:\n        return 100\n    if x <= 300:\n        return 200\n    if x <= 600:\n        return 500\n    else:\n        return 1000\n\n\nclass ML4TSPNARMCTSDecoder(ML4TSPNARDecoder):\n    def __init__(\n        self,\n        heatmap_delta: float = 1e-14,\n        active_search: bool = False,\n        as_steps: int = 100,\n        as_samples: int = 1000,\n        as_inner_lr: float = 5e-2,\n        time_limit: Union[float, str] = \"auto\",\n        time_multiplier: int = 1, \n        max_depth: int = 10,\n        max_iterations_2opt: int = 5000,\n        mcts_smooth: bool = False,\n        type_2opt: int = 1,\n    ):\n        super(ML4TSPNARMCTSDecoder, self).__init__(\n            heatmap_delta=heatmap_delta, active_search=active_search, \n            as_steps=as_steps, as_samples=as_samples, as_inner_lr=as_inner_lr, \n        )\n\n        self.time_limit = time_limit\n        self.time_multiplier = time_multiplier\n        self.max_depth = max_depth\n        self.max_iterations_2opt = max_iterations_2opt\n        self.mcts_smooth = mcts_smooth\n        self.type_2opt = type_2opt\n    \n    def smooth_heatmap(self, heatmap: np.ndarray, points: np.ndarray) -> np.ndarray:\n        graph = np.array(cdist(points, points))\n        graph = graph / graph.max(axis=1, keepdims=True)\n        new_heatmap = np.exp(np.tan(graph) * np.log(heatmap))\n        np.fill_diagonal(new_heatmap, 1e-14)\n        new_heatmap = new_heatmap / new_heatmap.sum(axis=1, keepdims=True)\n        new_heatmap = new_heatmap * 2\n        return new_heatmap\n    \n    def _decode(self, heatmap: np.ndarray, points: np.ndarray = None) -> np.ndarray:\n        # time_limit\n        change_time_limit = False\n        if self.time_limit == \"auto\":\n            change_time_limit = True\n            x = get_nodes_num_for_mcts_time_limit(self.nodes_num)\n            self.time_limit = MCTS_TIME_LIMIT_DEFAULT[x]\n        self.time_limit *= self.time_multiplier\n        \n        # decoding\n        tours = tsp_mcts_decoder(\n            heatmap=heatmap, points=points, time_limit=self.time_limit, \n            max_depth=self.max_depth, type_2opt=self.type_2opt, \n            max_iterations_2opt=self.max_iterations_2opt\n        )\n\n        # change type\n        if change_time_limit:\n            self.time_limit = \"auto\"\n\n        return tours\n\n# ==========================================\n# File: ml4tsp-library/ml4tsp/nar/local_search/mcts.py\n# Function/Context: ML4TSPNARMCTS._local_search\n# ==========================================\nimport ctypes\nimport numpy as np\nimport scipy.special as ssp\nfrom typing import Union\nfrom scipy.spatial.distance import cdist\nfrom ml4co_kit import tsp_mcts_local_search\nfrom .base import ML4TSPNARLocalSearch\n\n\nMCTS_TIME_LIMIT_DEFAULT = {\n    \"continue\": {\"continue_flag\": True, 50: 0.005, 100: 0.020, 200: 0.100, 500: 1.000, 1000: 5.000},\n    \"fast\": {\"continue_flag\": False, 50: 0.005, 100: 0.020, 200: 0.100, 500: 1.000, 1000: 5.000},\n    \"break\": {\"continue_flag\": False, 50: 0.025, 100: 0.100, 200: 0.500, 500: 2.000, 1000: 10.000},\n}\n\n\ndef get_nodes_num_for_mcts_time_limit(x: int):\n    if x <= 75:\n        return 50\n    if x <= 150:\n        return 100\n    if x <= 300:\n        return 200\n    if x <= 600:\n        return 500\n    else:\n        return 1000\n\n\nclass ML4TSPNARMCTS(ML4TSPNARLocalSearch):\n    def __init__(\n        self,\n        time_limit: Union[float, str] = \"auto\",\n        time_multiplier: int = 1,\n        max_depth: int = 10,\n        max_iterations_2opt: Union[float, str] = \"auto\",\n        mcts_smooth: bool = False,\n        smooth_type: str = \"v1\",\n        smooth_tau: float = 0.01,\n        type_2opt: int = 2,\n        type_mcts: Union[str, int] = \"auto\",\n    ):\n        super().__init__(time_limit=time_limit)\n        self.max_depth = max_depth\n        self.max_iterations_2opt = max_iterations_2opt\n        self.mcts_smooth = mcts_smooth\n        self.smooth_type = smooth_type\n        self.smooth_func_dict = {\n            \"v1\": self.smooth_heatmap,\n            \"v2\": self.smooth_heatmap_v2,\n            \"v3\": self.smooth_heatmap_v3\n        }\n        self.smooth_func = self.smooth_func_dict[self.smooth_type]\n        self.smooth_tau = smooth_tau\n        self.type_2opt = type_2opt\n        self.type_mcts = type_mcts\n        self.time_multiplier = time_multiplier\n        \n    def smooth_heatmap(self, heatmap: np.ndarray, points: np.ndarray) -> np.ndarray:\n        graph = np.array(cdist(points, points))\n        graph = graph / graph.max(axis=1, keepdims=True)\n        new_heatmap = np.exp(np.tan(graph) * np.log(heatmap))\n        np.fill_diagonal(new_heatmap, 1e-14)\n        new_heatmap = new_heatmap / new_heatmap.sum(axis=1, keepdims=True)\n        new_heatmap = new_heatmap * 2\n        return new_heatmap\n    \n    def smooth_heatmap_v2(self, heatmap: np.ndarray, points: np.ndarray) -> np.ndarray:\n        nodes_num = points.shape[-2]\n        sorted_vector = np.sort(heatmap, axis=-1)[:, - nodes_num // 10].reshape(-1, 1)\n        heatmap[(heatmap - sorted_vector) < 0] -= 1e9\n        start = 1.0\n        minimum = 0.0\n        while minimum < 1e-4: # adjust temperature\n            new_heatmap = ssp.softmax(heatmap * start, axis=-1)\n            minimum = new_heatmap[new_heatmap > 0].min()\n            start *= 0.5\n        new_heatmap = new_heatmap / new_heatmap.sum(axis=1, keepdims=True)\n        return new_heatmap\n    \n    def smooth_heatmap_v3(self, heatmap: np.ndarray, points: np.ndarray) -> np.ndarray:\n        graph = 1.0 - np.array(cdist(points, points))\n        new_heatmap = heatmap + self.smooth_tau * graph\n        new_heatmap = new_heatmap / new_heatmap.sum(axis=1, keepdims=True)\n        return new_heatmap\n    \n    def _local_search(\n        self, tour: np.ndarray, points: np.ndarray, heatmap: np.ndarray = None\n    ) -> np.ndarray:\n        # smooth\n        if self.mcts_smooth:\n            heatmap = self.smooth_func(heatmap, points)\n\n        # number of nodes\n        self.nodes_num = heatmap.shape[-1]\n        \n        # continue_flag\n        change_type_mcts = False\n        if self.type_mcts == \"auto\":\n            change_type_mcts= True\n            self.type_mcts = \"break\" if self.nodes_num < 500 else \"continue\"\n        continue_flag = MCTS_TIME_LIMIT_DEFAULT[self.type_mcts][\"continue_flag\"]\n        continue_flag = 1 if continue_flag else 2\n\n        # time_limit\n        change_time_limit = False\n        if self.time_limit == \"auto\":\n            change_time_limit = True\n            x = get_nodes_num_for_mcts_time_limit(self.nodes_num)\n            self.time_limit = MCTS_TIME_LIMIT_DEFAULT[self.type_mcts][x]\n        self.time_limit *= self.time_multiplier\n        \n        # max_iterations_2opt\n        change_max_iterations_2opt = False\n        if self.max_iterations_2opt == \"auto\":\n            change_max_iterations_2opt = True\n            if self.nodes_num < 200:\n                self.max_iterations_2opt = 5000\n            elif self.nodes_num < 500:\n                self.max_iterations_2opt = 50\n            else:\n                self.max_iterations_2opt = 0\n        \n        # real local search\n        mcts_tour = tsp_mcts_local_search(\n            init_tours=tour, heatmap=heatmap, points=points,\n            time_limit=self.time_limit, max_depth=self.max_depth,\n            type_2opt=self.type_2opt, max_iterations_2opt=self.max_iterations_2opt\n        )\n        \n        # change type\n        if change_type_mcts:\n            self.type_mcts = \"auto\"\n        if change_time_limit:\n            self.time_limit = \"auto\"\n        if change_max_iterations_2opt:\n            self.max_iterations_2opt = \"auto\"\n        \n        return mcts_tour\n\n# ==========================================\n# File: ml4tsp-library/ml4tsp/nar/model/diffusion.py\n# Function/Context: ML4TSPDiffusion\n# ==========================================\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch import nn, Tensor\nfrom typing import Union, Tuple\nfrom ..env import ML4TSPNAREnv\nfrom ..decoder import ML4TSPNARDecoder\nfrom ..model.base import ML4TSPNARBaseModel\nfrom ..local_search import ML4TSPNARLocalSearch\nfrom ..encoder.gnn.gnn_encoder import GNNEncoder\nimport math\n\n\nclass ML4TSPDiffusion(ML4TSPNARBaseModel):\n    def __init__(\n        self,\n        env: ML4TSPNAREnv,\n        encoder: GNNEncoder,\n        decoder: Union[ML4TSPNARDecoder, str] = \"greedy\",\n        local_search: Union[ML4TSPNARLocalSearch, str] = None,\n        lr_scheduler: str = \"cosine-decay\",\n        learning_rate: float = 2e-4,\n        weight_decay: float = 1e-4,\n        pretrained: bool = True,\n        pretrained_path: str = None,\n        diffusion_schedule: str=\"linear\",\n        inference_schedule: str=\"cosine\",\n        diffusion_steps: int=1000,\n        inference_diffusion_steps: int=1,\n    ):\n        # super\n        super(ML4TSPDiffusion, self).__init__(\n            env=env,\n            encoder=encoder,\n            decoder=decoder,\n            local_search=local_search,\n            lr_scheduler=lr_scheduler,\n            learning_rate=learning_rate,\n            weight_decay=weight_decay,\n            pretrained=pretrained,\n            pretrained_path=pretrained_path\n        )\n        self.diffusion_schedule = diffusion_schedule\n        self.inference_schedule = inference_schedule\n        self.diffusion_steps = diffusion_steps\n        self.inference_diffusion_steps = inference_diffusion_steps\n        self.diffusion = CategoricalDiffusion(\n            T=self.diffusion_steps, schedule=self.diffusion_schedule)\n    \n    def inference_process(\n        self, points: Tensor, edge_index: Tensor, distmat: Tensor, ground_truth: Tensor\n    ) -> Union[Tensor, Tuple[Tensor, Tensor]]:\n        \n        batch_size = points.shape[0]\n        if self.env.sparse:\n            points = points.reshape(-1, 2)\n            distmat = distmat.reshape(-1)\n            edge_index = edge_index.transpose(1, 0).reshape(2, -1)\n            x_shape = (batch_size, edge_index.shape[1] // batch_size)\n        else:\n            x_shape = (batch_size, points.shape[1], points.shape[1])\n        \n        xt = torch.randn(x_shape).to(points.device)\n        \n        xt = (xt > 0).long()\n        if self.env.sparse:\n            xt = xt.reshape(-1)\n        \n        steps = self.inference_diffusion_steps\n        time_schedule = InferenceSchedule(\n            inference_schedule=self.inference_schedule,\n            T=self.diffusion.T, inference_T=steps\n        )\n        \n        for i in range(steps):\n            t1, t2 = time_schedule(i)\n            t1 = np.array([t1]).astype(int)\n            t2 = np.array([t2]).astype(int)\n        \n            # [B, N, N], heatmap score\n            xt, x0_pred = self.categorical_denoise_step(\n                points, xt, t1, points.device, edge_index, target_t=t2)\n        \n        heatmap = xt.float().cpu().detach().numpy() + 1e-6\n        \n        if self.env.sparse:\n            x0_pred = x0_pred.T.reshape(batch_size, 2, -1)\n            \n        if self.env.mode == \"solve\":\n            return heatmap.reshape(batch_size, -1)\n    \n        # Compute loss\n        loss_func = nn.CrossEntropyLoss()\n        loss = loss_func(x0_pred, ground_truth.long())\n        return loss, heatmap\n    \n    def train_process(\n        self, points: Tensor, edge_index: Tensor, distmat: Tensor, ground_truth: Tensor\n    ) -> Tensor:\n        \n        batch_size = points.shape[0]\n        if self.env.sparse:\n            points = points.reshape(-1, 2)\n            distmat = distmat.reshape(-1)\n            edge_index = edge_index.transpose(1, 0).reshape(2, -1)\n        \n        # Sample from diffusion\n        adj_matrix_onehot = F.one_hot(ground_truth.long(), num_classes=2).float()\n        if self.env.sparse:\n            adj_matrix_onehot = adj_matrix_onehot.unsqueeze(1)\n            \n        np_t = np.random.randint(1, self.diffusion.T + 1, batch_size).astype(int)\n        if self.env.sparse:\n            t = torch.from_numpy(np_t).float().reshape(-1, 1).repeat(1, ground_truth.shape[1]).reshape(-1)\n        else:\n            t = torch.from_numpy(np_t).float().view(ground_truth.shape[0])\n            \n        xt = self.diffusion.sample(adj_matrix_onehot, np_t)\n        xt = xt * 2 - 1\n        xt = xt * (1.0 + 0.05 * torch.rand_like(xt))\n        \n        if self.env.sparse:\n            xt = xt.reshape(-1)\n\n        # x0_pred\n        x0_pred = self.forward(\n            x=points, \n            graph=xt.float().to(ground_truth.device), \n            edge_index=edge_index, \n            timesteps=t.float().to(ground_truth.device)\n        )\n        \n        if self.env.sparse:\n            x0_pred = x0_pred.T.reshape(batch_size, 2, -1)\n        \n        # Compute loss\n        loss_func = nn.CrossEntropyLoss()\n        loss = loss_func(x0_pred, ground_truth.long())\n        \n        return loss\n    \n    def categorical_denoise_step(self, points, xt, t, device, edge_index=None, target_t=None):\n        with torch.no_grad():\n            t = torch.from_numpy(t).view(1)\n\n            ###############################################\n            # scale to [-1, 1]\n            xt_scale = (xt * 2 - 1).float()\n            xt_scale = xt_scale * (1.0 + 0.05 * torch.rand_like(xt_scale))\n            # xt_scale = xt\n            ###############################################\n            x0_pred = self.forward(\n                x=points.float().to(device),\n                graph=xt_scale.float().to(device),\n                timesteps=t.float().to(device),\n                edge_index=edge_index.long().to(device) if edge_index is not None else None,\n            )\n            if not self.env.sparse:\n                x0_pred_prob = x0_pred.permute((0, 2, 3, 1)).contiguous().softmax(dim=-1)\n            else:\n                x0_pred_prob = x0_pred.reshape((1, points.shape[0], -1, 2)).softmax(dim=-1)\n\n            xt = self.categorical_posterior(target_t, t, x0_pred_prob, xt)\n            return xt, x0_pred\n    \n    def categorical_posterior(self, target_t, t, x0_pred_prob, xt):\n        \"\"\"Sample from the categorical posterior for a given time step.\n        See https://arxiv.org/pdf/2107.03006.pdf for details.\n        \"\"\"\n        diffusion = self.diffusion\n        \n        if target_t is None:\n            target_t = t - 1\n        else:\n            target_t = torch.from_numpy(target_t).view(1)\n\n        if target_t > 0:\n            Q_t = np.linalg.inv(diffusion.Q_bar[target_t]) @ diffusion.Q_bar[t]\n            Q_t = torch.from_numpy(Q_t).float().to(x0_pred_prob.device)\n        else:\n            Q_t = torch.eye(2).float().to(x0_pred_prob.device)\n        Q_bar_t_source = torch.from_numpy(diffusion.Q_bar[t]).float().to(x0_pred_prob.device)\n        Q_bar_t_target = torch.from_numpy(diffusion.Q_bar[target_t]).float().to(x0_pred_prob.device)\n\n        xt = F.one_hot(xt.long(), num_classes=2).float()\n        xt = xt.reshape(x0_pred_prob.shape)\n        \n        x_t_target_prob_part_1 = torch.matmul(xt, Q_t.permute((1, 0)).contiguous())\n        x_t_target_prob_part_2 = Q_bar_t_target[0]\n        x_t_target_prob_part_3 = (Q_bar_t_source[0] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_target_prob = (x_t_target_prob_part_1 * x_t_target_prob_part_2) / x_t_target_prob_part_3\n\n        sum_x_t_target_prob = x_t_target_prob[..., 1] * x0_pred_prob[..., 0]\n        x_t_target_prob_part_2_new = Q_bar_t_target[1]\n        x_t_target_prob_part_3_new = (Q_bar_t_source[1] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_source_prob_new = (x_t_target_prob_part_1 * x_t_target_prob_part_2_new) / x_t_target_prob_part_3_new\n\n        sum_x_t_target_prob += x_t_source_prob_new[..., 1] * x0_pred_prob[..., 1]\n\n        if target_t > 0:\n            xt = torch.bernoulli(sum_x_t_target_prob.clamp(0, 1))\n        else:\n            xt = sum_x_t_target_prob.clamp(min=0)\n\n        if self.env.sparse:\n            xt = xt.reshape(-1)\n        return xt\n  \n    @torch.enable_grad() \n    @torch.inference_mode(False)\n    def guided_categorical_denoise_step(self, points, xt, t, device, edge_index=None, target_t=None):            \n        xt = xt.float()  # b, n, n\n        xt.requires_grad = True\n        t = torch.from_numpy(t).view(1)\n        if edge_index is not None: edge_index = edge_index.clone()\n\n        # [b, 2, n, n]\n        # with torch.inference_mode(False):\n        ###############################################\n        # scale to [-1, 1]\n        xt_scale = (xt * 2 - 1)\n        xt_scale = xt_scale * (1.0 + 0.05 * torch.rand_like(xt_scale))\n        # xt_scale = xt\n        ###############################################\n        \n        x0_pred = self.forward(\n            x=points.float().to(device),\n            graph=xt_scale.to(device),\n            timesteps=t.float().to(device),\n            edge_index=edge_index.long().to(device) if edge_index is not None else None,\n        )\n\n        if not self.env.sparse:\n            x0_pred_prob = x0_pred.permute((0, 2, 3, 1)).contiguous().softmax(dim=-1)\n        else:\n            x0_pred_prob = x0_pred.reshape((1, points.shape[0], -1, 2)).softmax(dim=-1)\n\n        if not self.env.sparse:\n            dis_matrix = self.points2adj(points)\n            cost_est = (dis_matrix * x0_pred_prob[..., 1]).sum()\n            cost_est.requires_grad_(True)\n            cost_est.backward()\n        else:\n            dis_matrix = torch.sqrt(torch.sum((points[edge_index.T[:, 0]] - points[edge_index.T[:, 1]]) ** 2, dim=1))\n            dis_matrix = dis_matrix.reshape((1, points.shape[0], -1))\n            cost_est = (dis_matrix * x0_pred_prob[..., 1]).sum()\n            cost_est.requires_grad_(True)\n            cost_est.backward()\n        assert xt.grad is not None\n\n        xt.grad = nn.functional.normalize(xt.grad, p=2, dim=-1)\n        xt = self.guided_categorical_posterior(target_t, t, x0_pred_prob, xt)\n\n        return xt.detach()\n    \n    def guided_categorical_posterior(self, target_t, t, x0_pred_prob, xt, grad=None):\n        # xt: b, n, n\n        if grad is None:\n            grad = xt.grad\n        with torch.no_grad():\n            diffusion = self.diffusion\n        if target_t is None:\n            target_t = t - 1\n        else:\n            target_t = torch.from_numpy(target_t).view(1)\n\n        if target_t > 0:\n            Q_t = np.linalg.inv(diffusion.Q_bar[target_t]) @ diffusion.Q_bar[t]\n            Q_t = torch.from_numpy(Q_t).float().to(x0_pred_prob.device)  # [2, 2], transition matrix\n        else:\n            Q_t = torch.eye(2).float().to(x0_pred_prob.device)\n        Q_bar_t_source = torch.from_numpy(diffusion.Q_bar[t]).float().to(x0_pred_prob.device)\n        Q_bar_t_target = torch.from_numpy(diffusion.Q_bar[target_t]).float().to(x0_pred_prob.device)\n\n        xt_grad_zero, xt_grad_one = torch.zeros(xt.shape, device=xt.device).unsqueeze(-1).repeat(1, 1, 1, 2), \\\n            torch.zeros(xt.shape, device=xt.device).unsqueeze(-1).repeat(1, 1, 1, 2)\n        xt_grad_zero[..., 0] = (1 - xt) * grad\n        xt_grad_zero[..., 1] = -xt_grad_zero[..., 0]\n        xt_grad_one[..., 1] = xt * grad\n        xt_grad_one[..., 0] = -xt_grad_one[..., 1]\n        xt_grad = xt_grad_zero + xt_grad_one\n\n        xt = F.one_hot(xt.long(), num_classes=2).float()\n        xt = xt.reshape(x0_pred_prob.shape)  # [b, n, n, 2]\n\n        # q(xt−1|xt,x0=0)pθ(x0=0|xt)\n        x_t_target_prob_part_1 = torch.matmul(xt, Q_t.permute((1, 0)).contiguous())\n        x_t_target_prob_part_2 = Q_bar_t_target[0]\n        x_t_target_prob_part_3 = (Q_bar_t_source[0] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_target_prob = (x_t_target_prob_part_1 * x_t_target_prob_part_2) / x_t_target_prob_part_3  # [b, n, n, 2]\n\n        sum_x_t_target_prob = x_t_target_prob[..., 1] * x0_pred_prob[..., 0]\n\n        # q(xt−1|xt,x0=1)pθ(x0=1|xt)\n        x_t_target_prob_part_2_new = Q_bar_t_target[1]\n        x_t_target_prob_part_3_new = (Q_bar_t_source[1] * xt).sum(dim=-1, keepdim=True)\n\n        x_t_source_prob_new = (x_t_target_prob_part_1 * x_t_target_prob_part_2_new) / x_t_target_prob_part_3_new\n\n        sum_x_t_target_prob += x_t_source_prob_new[..., 1] * x0_pred_prob[..., 1]\n\n        p_theta = torch.cat((1 - sum_x_t_target_prob.unsqueeze(-1), sum_x_t_target_prob.unsqueeze(-1)), dim=-1)\n        p_phi = torch.exp(-xt_grad)\n        if self.env.sparse:\n            p_phi = p_phi.reshape(p_theta.shape)\n        posterior = (p_theta * p_phi) / torch.sum((p_theta * p_phi), dim=-1, keepdim=True)\n\n        if target_t > 0:\n            xt = torch.bernoulli(posterior[..., 1].clamp(0, 1))\n        else:\n            xt = posterior[..., 1].clamp(min=0)\n        if self.env.sparse:\n            xt = xt.reshape(-1)\n        return xt\n    \n    def points2adj(self, points):\n        \"\"\"\n        return distance matrix\n        Args:\n        points: b, n, 2\n        Returns: b, n, n\n        \"\"\"\n        assert points.dim() == 3\n        return torch.sum((points.unsqueeze(2) - points.unsqueeze(1)) ** 2, dim=-1) ** 0.5\n    \n    \nclass CategoricalDiffusion(object):\n  def __init__(self, T, schedule):\n    # Diffusion steps\n    self.T = T\n\n    # Noise schedule\n    if schedule == 'linear':\n      b0 = 1e-4\n      bT = 2e-2\n      self.beta = np.linspace(b0, bT, T)\n    elif schedule == 'cosine':\n      self.alphabar = self.__cos_noise(np.arange(0, T + 1, 1)) / self.__cos_noise(\n          0)  # Generate an extra alpha for bT\n      self.beta = np.clip(1 - (self.alphabar[1:] / self.alphabar[:-1]), None, 0.999)\n\n    beta = self.beta.reshape((-1, 1, 1))\n    eye = np.eye(2).reshape((1, 2, 2))\n    ones = np.ones((2, 2)).reshape((1, 2, 2))\n\n    self.Qs = (1 - beta) * eye + (beta / 2) * ones\n\n    Q_bar = [np.eye(2)]\n    for Q in self.Qs:\n      Q_bar.append(Q_bar[-1] @ Q)\n    self.Q_bar = np.stack(Q_bar, axis=0)\n\n  def __cos_noise(self, t):\n    offset = 0.008\n    return np.cos(math.pi * 0.5 * (t / self.T + offset) / (1 + offset)) ** 2\n\n  def sample(self, x0_onehot, t):\n    # Select noise scales\n    Q_bar = torch.from_numpy(self.Q_bar[t]).float().to(x0_onehot.device)\n    xt = torch.matmul(x0_onehot, Q_bar.reshape((Q_bar.shape[0], 1, 2, 2)))\n    return torch.bernoulli(xt[..., 1].clamp(0, 1))\n\n\nclass InferenceSchedule(object):\n  def __init__(self, inference_schedule=\"linear\", T=1000, inference_T=1000):\n    self.inference_schedule = inference_schedule\n    self.T = T\n    self.inference_T = inference_T\n\n  def __call__(self, i):\n    assert 0 <= i < self.inference_T\n\n    if self.inference_schedule == \"linear\":\n      t1 = self.T - int((float(i) / self.inference_T) * self.T)\n      t1 = np.clip(t1, 1, self.T)\n\n      t2 = self.T - int((float(i + 1) / self.inference_T) * self.T)\n      t2 = np.clip(t2, 0, self.T - 1)\n      return t1, t2\n    elif self.inference_schedule == \"cosine\":\n      t1 = self.T - int(\n          np.sin((float(i) / self.inference_T) * np.pi / 2) * self.T)\n      t1 = np.clip(t1, 1, self.T)\n\n      t2 = self.T - int(\n          np.sin((float(i + 1) / self.inference_T) * np.pi / 2) * self.T)\n      t2 = np.clip(t2, 0, self.T - 1)\n      return t1, t2\n\n# ==========================================\n# File: ml4tsp-library/ml4tsp/nar/solver/narsolver.py\n# Function/Context: ML4TSPNARSolver\n# ==========================================\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nfrom typing import Union\nfrom ml4co_kit import (\n    TSPSolver, SOLVER_TYPE, Timer, sparse_points, \n    points_to_distmat, to_tensor, iterative_execution\n)\nfrom ..model.base import ML4TSPNARBaseModel\n\n\nclass ML4TSPNARSolver(TSPSolver):\n    def __init__(\n        self, \n        model: ML4TSPNARBaseModel, \n        scale: int = 1, \n        seed: int = 1234,\n        use_softdict: bool = False, # Rethink MCTS for TSP \n        softdict_tau: float = 0.0066\n    ):\n        super(ML4TSPNARSolver, self).__init__(\n            solver_type=SOLVER_TYPE.ML4TSP, scale=scale\n        )\n        self.model = model\n        self.model.set_mode(mode=\"solve\")\n        torch.manual_seed(seed=seed)\n        self.use_softdict = use_softdict\n        self.softdict_tau = softdict_tau\n        \n    def solve(\n        self,\n        points: Union[np.ndarray, list] = None,\n        norm: str = \"EUC_2D\",\n        normalize: bool = False,\n        batch_size: int = 1,\n        show_time: bool = False,\n    ) -> np.ndarray:\n        # preparation\n        self.from_data(points=points, norm=norm, normalize=normalize)\n        self.model.set_nodes_num(self.nodes_num)\n        timer = Timer(apply=show_time)\n        timer.start()\n        \n        # batch process\n        samples_num = self.points.shape[0]\n        iters = samples_num // batch_size\n        batch_points = self.points.reshape(iters, batch_size, self.nodes_num, 2)\n        \n        # solve (core)\n        tours_list = list()\n        for idx in iterative_execution(range, iters, self.solve_msg, show_time):\n            tours_list.append(self._solve(batch_points[idx]))\n            \n        # format\n        tours = np.array(tours_list).reshape(-1, self.nodes_num + 1)\n        self.from_data(tours=tours, ref=False)\n        \n        # show time\n        timer.end()\n        timer.show_time()  \n                  \n        # return\n        return self.tours\n\n    def _solve(self, points: np.ndarray) -> np.ndarray:\n        # utils\n        device = self.model.env.device\n        sparse = self.model.env.sparse\n        sparse_factor = self.model.env.sparse_factor\n        \n        # process data\n        if sparse:\n            points, edge_index = sparse_points(\n                points=points, sparse_factor=sparse_factor, device=device\n            )\n            distmat = points_to_distmat(points, edge_index).to(device)    \n        else:\n            points, edge_index = to_tensor(points).to(device), None\n            distmat = points_to_distmat(points, edge_index).to(device)\n        \n        # softdict\n        if not self.use_softdict:\n            heatmap = self.model.inference_process(\n                points=points, edge_index=edge_index, distmat=distmat, ground_truth=None \n            )\n        else:\n            points = to_tensor(self.points)\n            distance_matrix = points_to_distmat(points)\n            eye = torch.eye(distance_matrix.size(1)).unsqueeze(0)\n            distance_matrix = torch.where(\n                eye == 1, torch.tensor(float('inf'), dtype=torch.float), distance_matrix\n            )\n            heatmap = F.softmax(- distance_matrix / self.softdict_tau, dim=2)\n        per_heatmap_num = len(heatmap) // len(points)\n            \n        # decode\n        solved_tours, heatmap, per_tours_num = self.model.decoder.decode(\n            heatmap=heatmap, points=points, edge_index=edge_index, \n            per_heatmap_num=per_heatmap_num\n        ) # (B, P, N+1) & (B, P, N, N)\n        solved_tours = solved_tours.reshape(-1, self.nodes_num + 1)\n    \n        # local search\n        if self.model.local_search is not None:\n            solved_tours = self.model.local_search.local_search(\n                tours=solved_tours, points=points, heatmap=heatmap, \n                per_tours_num=per_tours_num, per_heatmap_num=per_heatmap_num\n            )\n\n        return solved_tours\n\n# ==========================================\n# File: models/modelzoo/diffusion/tsp_diffusion.py\n# Function/Context: TSPDiffusion\n# ==========================================\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\n\nfrom tqdm import tqdm\nfrom typing import Any, Union\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom torch_geometric.data import Data as GraphData\nfrom torch_sparse import SparseTensor\n\nfrom models.utils.evaluator import TSPEvaluator\nfrom models.utils.active_search import ActiveSearch\nfrom utils.utils import coords_to_distance\nfrom search import tsp_greedy, get_decoding_func, get_local_search_func\nfrom .diffusion_base import MetaDiffusion\nimport pygmtools as pygm\n\nfrom models.utils.diffusion import get_schedule_fn, CategoricalDiffusion, InferenceSchedule\n\n\ntsp_diffusion_path = {\n    50:  'https://huggingface.co/ML4TSPBench/DIFFUSION/resolve/main/tsp50_diffusion.pt?download=true',\n    100: 'https://huggingface.co/ML4TSPBench/DIFFUSION/resolve/main/tsp100_diffusion.pt?download=true',\n    500: 'https://huggingface.co/ML4TSPBench/DIFFUSION/resolve/main/tsp500_diffusion.pt?download=true'\n}\n\n\nclass TSPDiffusion(MetaDiffusion):\n    def __init__(\n        self,\n        num_nodes: int=50,\n        # network\n        network_type: str=\"gnn\",\n        input_dim: int=2,\n        embedding_dim: int=128,\n        hidden_dim: int=256,\n        output_channels: int=2,\n        num_layers: int=12,\n        sparse_factor: int=-1, \n        # train/valid/test\n        train_batch_size: int=64,\n        valid_batch_size: int=1,\n        test_batch_size: int=1,\n        train_file: str=None,\n        valid_file: str=None,\n        test_file: str=None,\n        valid_samples: int=1280,\n        mode: str=None,\n        num_workers: int=0,\n        # parallel/active\n        parallel_sampling: int=1,\n        active_search: bool=False,\n        as_steps: int=500,\n        as_samples: int=1000,\n        gradient_search: bool=False,\n        rewrite_steps: int=3,\n        rewrite_ratio: float=0.25,\n        steps_inf: int=10,\n        # test_step\n        decoding_type: str=\"greedy\",\n        local_search_type: str=None,\n        **kwargs\n    ):\n        super(TSPDiffusion, self).__init__(\n            num_nodes=num_nodes,\n            network_type=network_type,\n            input_dim=input_dim,\n            embedding_dim=embedding_dim,\n            hidden_dim=hidden_dim,\n            output_channels=output_channels,\n            num_layers=num_layers,\n            sparse_factor=sparse_factor,\n            train_batch_size=train_batch_size,\n            valid_batch_size=valid_batch_size,\n            test_batch_size=test_batch_size,\n            train_file=train_file,\n            valid_file=valid_file,\n            test_file=test_file,\n            valid_samples=valid_samples,\n            mode=mode,\n            num_workers=num_workers,\n            **kwargs\n        )\n        self.parallel_sampling = parallel_sampling\n        self.active_search = active_search\n        self.as_steps = as_steps\n        self.as_samples = as_samples\n        self.gradient_search = gradient_search\n        self.rewrite_steps = rewrite_steps\n        self.rewrite_ratio = rewrite_ratio\n        self.steps_inf = steps_inf\n\n        self.test_decoding_type = decoding_type\n        self.test_decoding_kwargs= kwargs\n        self.test_ls_type = local_search_type\n        self.test_ls_kwargs = kwargs\n\n        self.output_channels = output_channels\n\n    def forward(self, x, adj, t, edge_index):\n        h = self.model(x, graph=adj, edge_index=edge_index, timesteps=t)\n        return h # .view(-1, self.output_channels, self.num_nodes, self.num_nodes)\n\n    def shared_step(self, batch: Any, batch_idx: int, phase: str):\n        edge_index = None\n        original_edge_index = None\n        np_edge_index = None\n        device = batch[-1].device\n        if not self.sparse:\n            real_batch_idx, points, adj_matrix, gt_tour = batch\n            points: torch.Tensor\n            gt_tour: torch.Tensor\n            # deal with different mode\n            if phase == 'test':\n                points = points.unsqueeze(dim=0)\n                gt_tour = gt_tour.unsqueeze(dim=0)\n                adj_matrix = adj_matrix.unsqueeze(dim=0)\n            np_points = points.cpu().numpy()[0]\n            np_gt_tour = gt_tour.cpu().numpy()[0]\n            t = np.random.randint(1, self.diffusion.T + 1, points.shape[0]).astype(int)\n        else:\n            real_batch_idx, graph_data, point_indicator, edge_indicator, gt_tour = batch[0:5]\n            t = np.random.randint(1, self.diffusion.T + 1, point_indicator.shape[0]).astype(int)\n            route_edge_flags = graph_data.edge_attr\n            points = graph_data.x\n            edge_index = graph_data.edge_index\n            num_edges = edge_index.shape[1]\n            batch_size = point_indicator.shape[0]\n            adj_matrix = route_edge_flags.reshape((batch_size, num_edges // batch_size))\n        \n        # Sample from diffusion\n        adj_matrix_onehot = F.one_hot(adj_matrix.long(), num_classes=2).float()\n        if self.sparse:\n            adj_matrix_onehot = adj_matrix_onehot.unsqueeze(1)\n\n        xt = self.diffusion.sample(adj_matrix_onehot, t)\n        xt = xt * 2 - 1\n        xt = xt * (1.0 + 0.05 * torch.rand_like(xt))\n\n        if self.sparse:\n            t = torch.from_numpy(t).float()\n            t = t.reshape(-1, 1).repeat(1, adj_matrix.shape[1]).reshape(-1)\n            xt = xt.reshape(-1)\n            adj_matrix = adj_matrix.reshape(-1)\n            points = points.reshape(-1, 2)\n            edge_index = edge_index.to(adj_matrix.device).reshape(2, -1)\n            original_edge_index = edge_index.clone().cpu()\n            np_points = points.cpu().numpy()\n            np_gt_tour = gt_tour.cpu().numpy().reshape(-1)\n            np_edge_index = edge_index.cpu().numpy()\n        else:\n            t = torch.from_numpy(t).float().view(adj_matrix.shape[0])\n\n\n        # Denoise\n        # points = points.unsqueeze(dim=0) if points.ndim == 2 else points\n        # xt = xt.unsqueeze(dim=0) if xt.ndim == 2 else xt\n        x0_pred = self.forward(\n            points.float().to(adj_matrix.device),\n            xt.float().to(adj_matrix.device),\n            t.float().to(adj_matrix.device),\n            edge_index,\n        )\n\n        # Compute loss\n        loss_func = nn.CrossEntropyLoss()\n        loss = loss_func(x0_pred, adj_matrix.long())\n\n        # return loss if current is a training step\n        if phase == \"train\":\n            metrics = {\"train/loss\": loss}\n            for k, v in metrics.items():\n                self.log(k, v, prog_bar=True, on_epoch=True, sync_dist=True)\n            return loss\n        \n        # Solve\n        stacked_tours = []\n      \n        if self.parallel_sampling > 1:\n            if not self.sparse:\n                points = points.repeat(self.parallel_sampling, 1, 1)\n            else:\n                points = points.repeat(self.parallel_sampling, 1)\n                edge_index = self.duplicate_edge_index(edge_index, np_points.shape[0], device)\n\n        xt = torch.randn_like(adj_matrix.float())\n        if self.parallel_sampling > 1:\n            if not self.sparse:\n                xt = xt.repeat(self.parallel_sampling, 1, 1)\n            else:\n                xt = xt.repeat(self.parallel_sampling, 1)  # [B, E]\n            xt = torch.randn_like(xt)\n        xt = (xt > 0).long()\n\n        if self.sparse:\n            xt = xt.reshape(-1)\n\n        steps = self.inference_diffusion_steps\n        time_schedule = InferenceSchedule(inference_schedule=self.inference_schedule,\n                                        T=self.diffusion.T, inference_T=steps)\n        \n        # Diffusion iterations\n        for i in range(steps):\n            t1, t2 = time_schedule(i)\n            t1 = np.array([t1]).astype(int)\n            t2 = np.array([t2]).astype(int)\n\n            # [B, N, N], heatmap score\n            xt = self.categorical_denoise_step(\n                points, xt, t1, device, edge_index, target_t=t2)\n\n        adj_mat = xt\n        \n        # Decoding / solve\n        if phase == \"val\":\n            # Heatmap \n            adj_mat = adj_mat.float().cpu().detach().numpy() + 1e-6\n            solved_tours = tsp_greedy(\n                adj_mat=adj_mat, \n                np_points=np_points, \n                edge_index_np=np_edge_index, \n                sparse_graph=self.sparse, \n                parallel_sampling=self.parallel_sampling,\n                device=gt_tour.device,\n            )\n        else:   \n            # Active search\n            if self.active_search:\n                dist_mat = torch.cdist(points, points)\n                AS = ActiveSearch(dist_mat, self.as_steps, self.as_samples)\n                adj_mat = AS.active_search(adj_mat.clone().detach())\n            adj_mat = adj_mat.float().cpu().detach().numpy() + 1e-6\n\n            # decode\n            decoding_func = get_decoding_func(task=\"tsp\", name=self.test_decoding_type)\n            solved_tours = decoding_func(\n                adj_mat=adj_mat, \n                np_points=np_points, \n                edge_index_np=np_edge_index, \n                sparse_graph=self.sparse, \n                device=gt_tour.device,\n                parallel_sampling=self.parallel_sampling,\n                **self.test_decoding_kwargs\n            )\n\n            # local_search\n            local_search_func = get_local_search_func(task=\"tsp\", name=self.test_ls_type)\n            # if local_search_func is not None:\n            #     solved_tours = local_search_func(\n            #         np_points=np_points, \n            #         tours=solved_tours, \n            #         adj_mat=adj_mat, \n            #         device=gt_tour.device,\n            #         **self.test_ls_kwargs\n            #     )\n\n            if local_search_func is not None:\n                if self.sparse:\n                    if self.parallel_sampling == 1:\n                        sparse_adj_mat = SparseTensor(\n                            row=edge_index[0],\n                            col=edge_index[1],\n                            value=torch.tensor(adj_mat).to(device=edge_index.device)\n                        )\n                        adj_mat = sparse_adj_mat.to_dense().unsqueeze(dim=0).cpu().numpy()\n                    else:\n                        sparse_adj_mat = list()\n                        ps_edge_index = edge_index.reshape(2, self.parallel_sampling, -1).transpose(0, 1)\n                        ps_adj_mat = adj_mat.reshape(self.parallel_sampling, -1)\n                        for idx in range(self.parallel_sampling):\n                            ps_sparse_adj_mat = SparseTensor(\n                                row=ps_edge_index[idx][0] - self.num_nodes*idx,\n                                col=ps_edge_index[idx][1] - self.num_nodes*idx,\n                                value=torch.tensor(ps_adj_mat[idx]).to(device=edge_index.device)\n                            )\n                            sparse_adj_mat.append(ps_sparse_adj_mat.to_dense().unsqueeze(dim=0).cpu().numpy()[0])\n                        adj_mat = np.array(sparse_adj_mat)\n\n                solved_tours = local_search_func(\n                    np_points=np_points, \n                    tours=solved_tours, \n                    adj_mat=adj_mat, \n                    device=gt_tour.device,\n                    **self.test_ls_kwargs\n                )\n            \n        # Check the tours\n        for idx in range(len(solved_tours)):\n            assert sorted(solved_tours[idx][:-1]) == [i for i in range(self.num_nodes)]\n\n        stacked_tours.append(solved_tours)\n        solved_tours = np.concatenate(stacked_tours, axis=0)\n\n        # Caculate the gap\n        tsp_solver = TSPEvaluator(np_points)\n        gt_cost = tsp_solver.evaluate(np_gt_tour)\n        all_solved_costs = [tsp_solver.evaluate(solved_tours[i]) for i in range(self.parallel_sampling)]\n        best_solved_cost, best_id = np.min(all_solved_costs), np.argmin(all_solved_costs)\n        gap = (best_solved_cost - gt_cost) / gt_cost * 100\n\n        # Gradient search\n        if self.gradient_search:\n            # select the best tour\n            g_best_tour = solved_tours[best_id]  # [N+1] ndarray\n            g_best_solved_cost = best_solved_cost\n\n            for _ in range(self.rewrite_steps):\n                g_stacked_tours = []\n                # optimal adjacent matrix\n                g_x0 = self.tour2adj(g_best_tour, np_points, self.sparse, self.sparse_factor, original_edge_index)\n                g_x0 = g_x0.unsqueeze(0).to(device)  # [1, N, N] or [1, N]\n                if self.parallel_sampling > 1:\n                    if not self.sparse:\n                        g_x0 = g_x0.repeat(self.parallel_sampling, 1, 1)  # [1, N ,N] -> [B, N, N]\n                    else:\n                        g_x0 = g_x0.repeat(self.parallel_sampling, 1)\n\n                if self.sparse:\n                    g_x0 = g_x0.reshape(-1)\n\n                g_x0_onehot = F.one_hot(g_x0.long(), num_classes=2).float()  # [B, N, N, 2]\n                steps_T = int(self.diffusion_steps * self.rewrite_ratio)\n                time_schedule = InferenceSchedule(inference_schedule=self.inference_schedule,\n                                                    T=steps_T, inference_T=self.steps_inf)\n                \n                # g_xt = self.diffusion.sample(g_x0_onehot, steps_T)\n                Q_bar = torch.from_numpy(self.diffusion.Q_bar[steps_T]).float().to(g_x0_onehot.device)\n                g_xt_prob = torch.matmul(g_x0_onehot, Q_bar)  # [B, N, N, 2]\n\n                # add noise for the steps_T samples, namely rewrite\n                g_xt = torch.bernoulli(g_xt_prob[..., 1].clamp(0, 1))  # [B, N, N]\n                g_xt = g_xt * 2 - 1  # project to [-1, 1]\n                g_xt = g_xt * (1.0 + 0.05 * torch.rand_like(g_xt))  # add noise\n                g_xt = (g_xt > 0).long()\n\n                for i in range(self.steps_inf):\n                    t1, t2 = time_schedule(i)\n                    t1 = np.array([t1]).astype(int)\n                    t2 = np.array([t2]).astype(int)\n\n                    # [1, N, N], denoise, heatmap for edges\n                    g_xt = self.guided_categorical_denoise_step(points, g_xt, t1, device, edge_index, target_t=t2)\n\n                g_adj_mat = g_xt.float().cpu().detach().numpy() + 1e-6\n\n                # decode\n                decoding_func = get_decoding_func(task=\"tsp\", name=self.test_decoding_type)\n                g_solved_tours = decoding_func(\n                    adj_mat=g_adj_mat, \n                    np_points=np_points, \n                    edge_index_np=np_edge_index, \n                    sparse_graph=self.sparse, \n                    device=gt_tour.device,\n                    parallel_sampling=self.parallel_sampling,\n                    **self.test_decoding_kwargs\n                )\n\n                # local_search\n                local_search_func = get_local_search_func(task=\"tsp\", name=self.test_ls_type)\n                if local_search_func is not None:\n                    if self.sparse:\n                        if self.parallel_sampling == 1:\n                            sparse_g_ad\n\n# ==========================================\n# File: models/modelzoo/gnn/tsp_gnn.py\n# Function/Context: TSPGNN.shared_step\n# ==========================================\nimport numpy as np\nimport torch\nimport time\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\n\nfrom tqdm import tqdm\nfrom typing import Any, Union\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom torch_geometric.data import Data as GraphData\nfrom torch_sparse import SparseTensor\n\nfrom models.utils.evaluator import TSPEvaluator\nfrom models.utils.active_search import ActiveSearch\nfrom utils.utils import coords_to_distance\nfrom search import tsp_greedy, get_decoding_func, get_local_search_func\nfrom .gnn_base import MetaGNN\nimport pygmtools as pygm\n\n\ntsp_gnn_path = {\n    50:  'https://huggingface.co/ML4TSPBench/GNN/resolve/main/tsp50_gnn.pt?download=true',\n    100: 'https://huggingface.co/ML4TSPBench/GNN/resolve/main/tsp100_gnn.pt?download=true',\n    500: 'https://huggingface.co/ML4TSPBench/GNN/resolve/main/tsp500_gnn.pt?download=true',\n}\n\n\nclass TSPGNN(MetaGNN):\n    def __init__(\n        self,\n        num_nodes: int=50,\n        # network\n        network_type: str=\"gnn\",\n        input_dim: int=2,\n        embedding_dim: int=128,\n        hidden_dim: int=256,\n        output_channels: int=2,\n        num_layers: int=12,\n        sparse_factor: int=-1, \n        # train/valid/test\n        train_batch_size: int=64,\n        valid_batch_size: int=1,\n        test_batch_size: int=1,\n        train_file: str=None,\n        valid_file: str=None,\n        test_file: str=None,\n        valid_samples: int=1280,\n        mode: str=None,\n        num_workers: int=0,\n        # parallel/active\n        parallel_sampling: int=1,\n        active_search: bool=False,\n        as_steps: int=100,\n        as_samples: int=1000,\n        inner_lr: float=5e-2,\n        # test_step\n        decoding_type: str=\"greedy\",\n        local_search_type: str=None,\n        **kwargs\n    ):\n        super(TSPGNN, self).__init__(\n            num_nodes=num_nodes,\n            network_type=network_type,\n            input_dim=input_dim,\n            embedding_dim=embedding_dim,\n            hidden_dim=hidden_dim,\n            output_channels=output_channels,\n            num_layers=num_layers,\n            sparse_factor=sparse_factor,\n            train_batch_size=train_batch_size,\n            valid_batch_size=valid_batch_size,\n            test_batch_size=test_batch_size,\n            train_file=train_file,\n            valid_file=valid_file,\n            test_file=test_file,\n            valid_samples=valid_samples,\n            mode=mode,\n            num_workers=num_workers,\n            **kwargs\n        )\n\n        self.parallel_sampling = parallel_sampling\n        self.active_search = active_search\n        self.as_steps = as_steps\n        self.as_samples = as_samples\n        self.inner_lr = inner_lr\n\n        self.test_decoding_type = decoding_type\n        self.test_decoding_kwargs= kwargs\n        self.test_ls_type = local_search_type\n        self.test_ls_kwargs = kwargs\n\n    def shared_step(self, batch: Any, batch_idx: int, phase: str):\n        edge_index = None\n        np_edge_index = None\n        if not self.sparse:\n            _, points, adj_matrix, gt_tour = batch\n            points: torch.Tensor\n            gt_tour: torch.Tensor\n            graph = coords_to_distance(points)\n            # deal with different mode\n            if phase != \"train\":\n                np_points = points.cpu().numpy()[0]\n                np_gt_tour = gt_tour.cpu().numpy()[0]\n        else:\n            graph_data = batch[1]\n            graph_data: GraphData\n            gt_tour = batch[4]\n            gt_tour: torch.Tensor\n            route_edge_flags = graph_data.edge_attr\n            route_edge_flags: torch.Tensor\n            points = graph_data.x\n            edge_index = graph_data.edge_index\n            edge_index: torch.Tensor\n            adj_matrix = route_edge_flags.reshape(-1)\n            graph = coords_to_distance(points, edge_index)\n            if phase != \"train\":\n                np_points = points.cpu().numpy()\n                np_gt_tour = gt_tour.reshape(-1).cpu().numpy()\n                np_edge_index = edge_index.cpu().numpy()\n\n        x0_pred = self.forward(points, graph, edge_index)\n\n        # Caculate loss\n        x0_pred: torch.Tensor\n        adj_matrix: torch.Tensor\n        edge_labels = adj_matrix.cpu().numpy().flatten()\n        edge_cw = compute_class_weight(\"balanced\", classes=np.unique(edge_labels), y=edge_labels)\n        edge_cw = torch.Tensor(edge_cw).to(x0_pred.device) \n        x0 = F.log_softmax(x0_pred, dim=1)\n        loss = nn.NLLLoss(edge_cw)(x0, adj_matrix.long())\n\n        # return loss if current is a training step\n        if phase == \"train\":\n            metrics = {\"train/loss\": loss}\n            for k, v in metrics.items():\n                self.log(k, v, prog_bar=True, on_epoch=True, sync_dist=True)\n            return loss\n        \n        # Gain the heatmap\n        heatmap = F.softmax(x0_pred, dim=1)\n        if not self.sparse:\n            adj_mat = heatmap[:, 1, :, :]\n        else:\n            adj_mat = heatmap[:, 1]    \n\n        # Decoding / solve\n        if phase == \"val\":\n            adj_mat = adj_mat.cpu().numpy()\n            solved_tours = tsp_greedy(\n                adj_mat=adj_mat, \n                np_points=np_points, \n                edge_index_np=np_edge_index, \n                sparse_graph=self.sparse, \n                device=gt_tour.device,\n            )\n        else:\n            # Active search\n            if self.active_search:\n                dist_mat = torch.cdist(points, points)\n                AS = ActiveSearch(dist_mat, self.as_steps, self.as_samples, self.inner_lr)\n                adj_mat = AS.active_search(adj_mat.clone().detach())\n                adj_mat = torch.clamp(adj_mat, min=1e-14)\n            adj_mat = adj_mat.cpu().numpy()\n            \n            # decode\n            begin_time = time.time()\n            decoding_func = get_decoding_func(task=\"tsp\", name=self.test_decoding_type)\n            solved_tours = decoding_func(\n                adj_mat=adj_mat, \n                np_points=np_points, \n                edge_index_np=np_edge_index, \n                sparse_graph=self.sparse, \n                device=gt_tour.device,\n                **self.test_decoding_kwargs\n            )\n            self.decoding_time += (time.time() - begin_time)\n            \n            # local_search\n            local_search_func = get_local_search_func(task=\"tsp\", name=self.test_ls_type)\n            if local_search_func is not None:\n                if self.sparse:\n                    if self.parallel_sampling == 1:\n                        sparse_adj_mat = SparseTensor(\n                            row=edge_index[0],\n                            col=edge_index[1],\n                            value=torch.tensor(adj_mat).to(device=edge_index.device)\n                        )\n                        adj_mat = sparse_adj_mat.to_dense().unsqueeze(dim=0).cpu().numpy()\n                    else:\n                        sparse_adj_mat = list()\n                        ps_edge_index = edge_index.reshape(2, self.parallel_sampling, -1).transpose(0, 1)\n                        ps_adj_mat = adj_mat.reshape(self.parallel_sampling, -1)\n                        for idx in range(self.parallel_sampling):\n                            ps_sparse_adj_mat = SparseTensor(\n                                row=ps_edge_index[idx][0] - self.num_nodes*idx,\n                                col=ps_edge_index[idx][1] - self.num_nodes*idx,\n                                value=torch.tensor(ps_adj_mat[idx]).to(device=edge_index.device)\n                            )\n                            sparse_adj_mat.append(ps_sparse_adj_mat.to_dense().unsqueeze(dim=0).cpu().numpy()[0])\n                        adj_mat = np.array(sparse_adj_mat)\n                \n                solved_tours = local_search_func(\n                    np_points=np_points, \n                    tours=solved_tours, \n                    adj_mat=adj_mat, \n                    device=gt_tour.device,\n                    **self.test_ls_kwargs\n                )\n                \n\n        # Check the tours\n        for idx in range(len(solved_tours)):\n            assert sorted(solved_tours[idx][:-1]) == [i for i in range(self.num_nodes)]\n\n        # Caculate the gap\n        tsp_solver = TSPEvaluator(np_points)\n        gt_cost = tsp_solver.evaluate(np_gt_tour)\n        all_solved_costs = [tsp_solver.evaluate(solved_tours[i]) for i in range(self.parallel_sampling)]\n        best_solved_cost = np.min(all_solved_costs)\n        gap = (best_solved_cost - gt_cost) / gt_cost * 100\n\n        # record the better/worse/match\n        better = 0.0\n        match = 0.0\n        worse = 0.0\n        if gap < -1e-12:\n            better = 1.0\n        elif gap < 1e-12:\n            match = 1.0\n        else:\n            worse = 1.0\n        self.gap_list.append(gap)\n        \n        # Log the loss and gap\n        metrics = {\n            f\"{phase}/loss\": loss,\n            f\"{phase}/gap\": gap,\n            f\"{phase}/better\": better,\n            f\"{phase}/match\": match,\n            f\"{phase}/worse\": worse,\n        }\n\n        if phase == 'test':\n            metrics.update({\n                \"test/gt_cost\": gt_cost,\n                \"test/solved_cost\": best_solved_cost\n            })\n\n        for k, v in metrics.items():\n            self.log(k, v, prog_bar=True, on_epoch=True, sync_dist=True)\n        return metrics\n\n# ==========================================\n# File: search/mcts.py\n# Function/Context: tsp_mcts\n# ==========================================\nimport numpy as np\nfrom ml4co_kit import tsp_mcts_local_search\nfrom .mcts_smooth import smooth_heatmap, smooth_heatmap_v2\n\n\nMCTS_SETTINGS = {\n      50: (0.005, 2, False, 5000),\n     100: (0.020, 2, False, 50),\n     200: (0.100, 1, True, 0),\n     500: (1.000, 1, True, 0),\n    1000: (5.000, 1, True, 0)\n}\n\n\ndef get_nodes_num_for_mcts_time_limit(x: int):\n    if x <= 75:\n        return 50\n    if x <= 150:\n        return 100\n    if x <= 300:\n        return 200\n    if x <= 600:\n        return 500\n    else:\n        return 1000\n    \n\ndef tsp_mcts(\n    np_points:np.ndarray, \n    tours: np.ndarray, \n    adj_mat: np.ndarray, \n    **kwargs\n):\n    '''\n    Output: tours, shape (parallel_sampling, N + 1)\n    '''\n    assert adj_mat is not None, \"adj_mat(heatmap) must be given in mcts.\"\n    # gain the params from the kwargs dict\n    mcts_max_depth = kwargs.get('mcts_max_depth', 10)\n    max_iterations_2opt = kwargs.get('mcts_max_iterations_2opt', None)\n    time_limit = kwargs.get('mcts_time_limit', None)\n    mcts_smooth = kwargs.get('mcts_smooth', False)\n    mcts_smooth_v2 = kwargs.get('mcts_smooth_v2', False)\n    \n    # ensure the dtype of the np.ndarray\n    np_points = np_points.astype(np.float32)\n    adj_mat = adj_mat.astype(np.float32)\n    \n    # dimension modification\n    nodes_num = adj_mat.shape[-1]\n    initial_dim = adj_mat.ndim\n    if adj_mat.ndim == 2:\n        adj_mat = np.expand_dims(adj_mat, axis=0)\n    if np_points.ndim == 2:\n        np_points = np.expand_dims(np_points, axis=0)\n    if np_points.shape[0] != adj_mat.shape[0]:\n        np_points = np_points.repeat(adj_mat.shape[0] / np_points.shape[0], axis=0)\n    tours = np.array(tours)\n    if tours.ndim == 1:\n        tours = np.expand_dims(tours, axis=0)\n    \n    # settings\n    x = get_nodes_num_for_mcts_time_limit(nodes_num)\n    settings = MCTS_SETTINGS[x]\n    _, type_2opt, continue_flag, _ = settings\n    if time_limit is None:\n        time_limit = settings[0]\n    if max_iterations_2opt is None:\n        max_iterations_2opt = settings[3]\n        \n    # mcts local search\n    shortest_tours = list()    \n    for i in range(adj_mat.shape[0]):\n        heatmap = adj_mat[i]\n        if mcts_smooth:\n            heatmap = smooth_heatmap(heatmap)\n        elif mcts_smooth_v2:\n            heatmap = smooth_heatmap_v2(heatmap, np_points[i])\n        nodes_coords = np_points[i]\n        input_tour = np.array(tours[i], dtype=np.int16)\n        tour = tsp_mcts_local_search(\n            init_tours=input_tour, heatmap=heatmap, points=nodes_coords,\n            time_limit=time_limit, max_depth=mcts_max_depth, continue_flag=continue_flag,\n            type_2opt=type_2opt, max_iterations_2opt=max_iterations_2opt\n        )\n        shortest_tours.append(tour)\n        \n    # dimension modification\n    if initial_dim == 2:\n        shortest_tours = shortest_tours[0]\n    return shortest_tours\n\n# ==========================================\n# File: search/mcts_solver.py\n# Function/Context: tsp_mcts_solver\n# ==========================================\nfrom multiprocessing import Pool\nimport numpy as np\nimport scipy.sparse\nimport scipy.spatial\nimport ctypes\nimport numpy as np\nfrom .c_mcts_solver import c_mcts_solver\nfrom typing import Optional\nfrom .mcts_smooth import smooth_heatmap, smooth_heatmap_v2\n\n\ndef _tsp_mcts_solver(\n    adj_mat: np.ndarray, \n    np_points: np.ndarray, \n    kwargs: dict\n):\n    # gain the params from the kwargs dict\n    mcts_max_depth = kwargs.get('mcts_max_depth', 10)\n    mcts_param_t = kwargs.get('mcts_param_t', 0.1)\n    mcts_smooth = kwargs.get('mcts_smooth', False)\n    mcts_smooth_v2 = kwargs.get('mcts_smooth_v2', False)\n    max_iterations_2opt = kwargs.get('max_iterations_2opt', 5000)\n    \n    # dimension modification\n    nodes_num = adj_mat.shape[-1]\n    if adj_mat.ndim == 2:\n        adj_mat = np.expand_dims(adj_mat, axis=0)\n    if np_points.ndim == 2:\n        np_points = np.expand_dims(np_points, axis=0)\n        \n    # mcts solver\n    shortest_tours = list()\n    for i in range(adj_mat.shape[0]):\n        heatmap = adj_mat[i]\n        if mcts_smooth:\n            heatmap = smooth_heatmap(heatmap)\n        elif mcts_smooth_v2:\n            heatmap = smooth_heatmap_v2(heatmap, np_points[i])\n        heatmap = heatmap.reshape(-1)\n        nodes_coords = np_points[i].reshape(-1)\n        tour = c_mcts_solver(\n            heatmap.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),  \n            nodes_coords.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),  \n            nodes_num,\n            mcts_max_depth,\n            ctypes.c_float(mcts_param_t),\n            max_iterations_2opt\n        )\n        tour = np.ctypeslib.as_array(tour, shape=(nodes_num,))\n        tour = tour.tolist()\n        tour.append(tour[0])\n        shortest_tours.append(tour)\n    \n    # dimension modification\n    if adj_mat.shape[0] == 1:\n        shortest_tours = shortest_tours[0]\n    return shortest_tours\n\n\ndef tsp_mcts_solver(\n    adj_mat: np.ndarray, \n    np_points: np.ndarray, \n    edge_index_np: Optional[np.ndarray]=None, \n    sparse_graph=False, \n    parallel_sampling=1,\n    **kwargs\n):\n    '''\n    Output: tours, shape (parallel_sampling, N + 1)\n    Reference: https://github.com/Spider-scnu/TSP\n    '''\n    # ensure the dtype of the np.ndarray\n    np_points = np_points.astype(np.float32)\n    adj_mat = adj_mat.astype(np.float32)\n\n    splitted_adj_mat = np.split(adj_mat, parallel_sampling, axis=0)\n    if not sparse_graph:\n        splitted_adj_mat = [\n            (adj_mat[0] + adj_mat[0].T)/2 for adj_mat in splitted_adj_mat\n        ]\n    else:\n        if edge_index_np is None:\n            raise ValueError(\"edge_index_np should be given if sparse_graph is True\")\n        splitted_adj_mat = [\n            scipy.sparse.coo_matrix(\n                (adj_mat/2, (edge_index_np[0], edge_index_np[1])),\n            ).toarray() + scipy.sparse.coo_matrix(\n                (adj_mat/2, (edge_index_np[1], edge_index_np[0])),\n            ).toarray() for adj_mat in splitted_adj_mat\n        ]\n        \n    splitted_points = [np_points for _ in range(parallel_sampling)]\n    spliited_kwargs = [kwargs for _ in range(parallel_sampling)]\n    \n    if np_points.shape[0] > 1000 and parallel_sampling > 1:\n        with Pool(parallel_sampling) as p:\n            results = p.starmap(\n                _tsp_mcts_solver,\n                zip(splitted_adj_mat, splitted_points, spliited_kwargs),\n            )\n    else:\n        results = [\n            _tsp_mcts_solver(_adj_mat, _np_points, _args) for _adj_mat, _np_points, _args \\\n                in zip(splitted_adj_mat, splitted_points, spliited_kwargs)\n        ]\n        \n    return results\n\n# ==========================================\n# File: solvers/solver.py\n# Function/Context: TSPNARSolver.solve\n# ==========================================\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nimport lkh\nimport time\nimport warnings\nimport tsplib95\nfrom solvers.pyconcorde import TSPSolver as _TSPConcordeSolver\nfrom typing import Union, Any\nfrom pytorch_lightning.utilities import rank_zero_info\nfrom models.modelzoo import TSPNAREncoder, TSPAREncoder, get_nar_model, get_ar_model\nfrom search import get_decoding_func, get_local_search_func\nfrom utils.utils import generate_tsp_file, generate_opt_tour_file, get_data_from_tsp_file, \\\n    sparse_points, get_tour_from_tour_file\nfrom utils.evaluator import TSPEvaluator\nfrom torch_sparse import SparseTensor\n\nwarnings.filterwarnings(\"ignore\")\n\n\nclass TSPSolver:\n    \"\"\"\n    \"\"\"\n    def __init__(self):\n        self.points = None\n        self.ori_points = None\n        self.edge_index = None\n        self.sparse = False\n        self.tours = None\n        self.gt_tours = None\n        self.num_nodes = None\n\n    def check_points_dim(self):\n        if self.points is None:\n            return\n        elif self.points.ndim == 2:\n            self.points = np.expand_dims(self.points, axis=0)\n        self.num_nodes = self.points.shape[1]\n\n    def from_tspfile(self, filename: str):\n        assert filename.endswith(\".tsp\"), f\"file name error\"\n        data = get_data_from_tsp_file(filename)\n        points = data.node_coords\n        if points is None:\n            raise RuntimeError(\"Error in loading {}\".format(filename))\n        points = np.array(points)\n        self.ori_points = points\n        self.points = points.astype(np.float32)\n        self.check_points_dim()\n\n    def from_txt(self, filename: str, load_gt_tours: str=True):\n        assert filename.endswith(\".txt\"), f\"file name error\"\n        with open(filename, 'r') as file:\n            nodes_coords = list()\n            gt_tours = list()\n            for line in file:\n                line = line.strip()\n                if 'output' in line:\n                    split_line = line.split(' output ')\n                    points = split_line[0]\n                    tour = split_line[1]\n                    tour = tour.split(' ')\n                    tour = np.array([int(t) for t in tour])\n                    tour -= 1\n                    gt_tours.append(tour)\n                else:\n                    points = line\n                    load_gt_tours = False\n                points = points.split(' ')\n                points = np.array([[float(points[i]), float(points[i + 1])] for i in range(0, len(points), 2)])\n                nodes_coords.append(points)\n        \n        if load_gt_tours:\n            self.gt_tours = np.array(gt_tours)\n        nodes_coords = np.array(nodes_coords)\n        self.ori_points = nodes_coords\n        self.points = nodes_coords.astype(np.float32)\n        self.check_points_dim()\n\n    def from_data(self, points: np.ndarray):\n        self.points = points.astype(np.float32)\n        self.check_points_dim()\n    \n    def read_gt_tours_from_tspfile(self, filename: str):\n        assert filename.endswith(\".opt.tour\"), f\"file name error\"\n        self.gt_tours = get_tour_from_tour_file(filename)\n    \n    def to_tsp_file(\n        self,\n        tour_filename: str=None,\n        filename: str=None,\n        points: Union[np.ndarray, list]=None,\n        tours: Union[np.ndarray, list]=None,\n\n    ):\n        # points\n        if points is None:\n            points = self.points\n        if type(points) == list:\n            points = np.array(points)\n        # tours\n        if tours is None:\n            tours = self.tours\n        if type(tours) == list:\n            tours = np.array(tours)\n        # generate .tsp file if filename is not none\n        if filename is not None:\n            assert filename.endswith('.tsp')\n            generate_tsp_file(points, filename)\n        # generate .tsp.tour file if tour_filename is not none\n        if tour_filename is not None:\n            assert filename.endswith('.tsp.tour')\n            generate_opt_tour_file(tours, filename)\n            \n    def to_txt(\n        self, \n        filename: str=\"example.txt\",\n        points: Union[np.ndarray, list]=None,\n        tours: Union[np.ndarray, list]=None,\n    ):\n        # points\n        if points is None:\n            points = self.ori_points\n        if type(points) == list:\n            points = np.array(points)\n        # tours\n        if tours is None:\n            tours = self.tours\n        if type(tours) == list:\n            tours = np.array(tours)\n        # write\n        with open(filename, \"w\") as f:\n            for idx, tour in enumerate(tours):\n                f.write(\" \".join(str(x) + str(\" \") + str(y) for x, y in points[idx]))\n                f.write(str(\" \") + str('output') + str(\" \"))\n                f.write(str(\" \").join(str(node_idx + 1) for node_idx in tour))\n                f.write(\"\\n\")\n            f.close()\n\n    def evaluate(self, caculate_gap: bool=False):\n        \"\"\"\n        \"\"\"\n        if caculate_gap and self.gt_tours is None:\n            raise ValueError(\"gt_tours cannot be None, please use TSPLKHSolver to get the gt_tours.\")\n        if self.tours is None:\n            raise ValueError(\"tours cannot be None, please use method 'solve' to solve solution.\")\n        \n        if self.points.ndim == 2:\n            evaluator = TSPEvaluator(self.points)\n            solved_cost = evaluator.evaluate(self.tours)\n            return solved_cost\n        else:\n            cost_total = 0\n            batch = self.points.shape[0]\n            if caculate_gap:\n                gap_list = list()\n            if self.tours.ndim != batch:\n                tours = self.tours.reshape(batch, -1, self.tours.shape[-1])\n                for idx in range(batch):\n                    evaluator = TSPEvaluator(self.points[idx])\n                    solved_tours = tours[idx]\n                    solved_costs = list()\n                    for tour in solved_tours:\n                        solved_costs.append(evaluator.evaluate(tour))\n                    solved_cost = np.min(solved_costs)\n                    cost_total += solved_cost\n                    if caculate_gap:\n                        gt_cost = evaluator.evaluate(self.gt_tours[idx])\n                        gap = (solved_cost - gt_cost) / gt_cost * 100\n                        gap_list.append(gap)\n            else:\n                for idx in range(batch):\n                    evaluator = TSPEvaluator(self.points[idx])\n                    solved_tour = self.tours[idx]\n                    solved_cost = evaluator.evaluate(solved_tour)\n                    cost_total += solved_cost\n                    if caculate_gap:\n                        gt_cost = evaluator.evaluate(self.gt_tours[idx])\n                        gap = (solved_cost - gt_cost) / gt_cost * 100\n                        gap_list.append(gap)\n            cost_avg = cost_total / batch\n            if caculate_gap:\n                gap_avg = np.sum(gap_list) / batch\n                gap_std = np.std(gap_list)\n                return cost_avg, gap_avg, gap_std\n            else:\n                return cost_avg\n\n\nclass TSPNARSolver(TSPSolver):\n    \"\"\"\n    \"\"\"\n    def __init__(self):\n        super(TSPNARSolver, self).__init__()\n\n    def solve(\n        self,\n        batch_size: int=16,\n        sparse_factor: int=-1,\n        encoder: Union[TSPNAREncoder, str] = \"gnn\",\n        encoder_kwargs: dict = {},\n        decoding_type: Union[Any, str] = \"greedy\",\n        decoding_kwargs: dict = {},\n        local_search_type: str = None,\n        ls_kwargs: dict = {},\n        active_search: bool = False,\n        pretrained: bool=True,\n        device='cpu',\n    ):\n        self.sparse = sparse_factor > 0\n        self.active_search = active_search\n        self.decoding_type = decoding_type\n        self.ls_type = local_search_type\n\n        # encoder & gain heatmap\n        if type(encoder) == str:\n            encoder_kwargs.update({\n                \"mode\": \"solve\", \n                \"sparse_factor\": sparse_factor,\n                \"num_nodes\": self.num_nodes\n                }\n            )\n            self.encoder = get_nar_model(task=\"tsp\", name=encoder)(**encoder_kwargs)\n        else:\n            self.encoder = encoder\n        rank_zero_info(f\"Begin encoding, Using {self.encoder}\")\n        if pretrained:\n            rank_zero_info(f\"Loading Weights from Pretrained CheckPoint\")\n            ckpt_path = encoder_kwargs[\"ckpt_path\"] if \"ckpt_path\" in encoder_kwargs.keys() else None\n            self.encoder.load_ckpt(ckpt_path)\n        self.encoder.to(device)\n\n        solve_begin_time = time.time()\n        edge_index = None\n        if self.sparse:\n            points, edge_index = sparse_points(self.points, sparse_factor, device)\n            np_edge_index = edge_index.detach().cpu().numpy()\n        else:\n            points = self.points\n        heatmap = self.encoder.solve(points, edge_index, batch_size, device)\n        solve_end_time = time.time()\n        solve_time = solve_end_time - solve_begin_time\n        rank_zero_info(f\"Model Solve, Using {solve_time}\")\n\n        # decoding\n        decoding_kwargs.update({\"sparse_factor\": sparse_factor})\n        if type(decoding_type) == str:\n            self.decoding_func = get_decoding_func(task=\"tsp\", name=decoding_type)\n        else:\n            self.decoding_func = decoding_type\n        rank_zero_info(f\"Begin Decoding, Using {self.decoding_func.__name__}\")\n        decoded_tours = list()\n        for idx in tqdm(range(self.points.shape[0]), desc='Decoding'):\n            if not self.sparse:\n                adj_mat = np.expand_dims(heatmap[idx], axis=0)\n            else:\n                adj_mat = heatmap[idx]\n            tour = self.decoding_func(\n                adj_mat=adj_mat, \n                np_points=self.points[idx], \n                edge_index_np=np_edge_index[idx] if self.sparse else None,\n                sparse_graph=self.sparse,\n                **decoding_kwargs\n            )\n            decoded_tours.append(tour[0])\n        decoded_tours = np.array(decoded_tours)\n        \n        # local_search\n        ls_tours = None\n        self.local_search_func = get_local_search_func(task=\"tsp\", name=local_search_type)        \n        if self.local_search_func is not None:\n            rank_zero_info(f\"Begin Local Search, Using {self.local_search_func.__name__}\")\n            ls_tours = list()\n            for idx in tqdm(range(self.points.shape[0]), desc='Local Search'):\n                adj_mat = heatmap[idx]\n                if self.sparse:\n                    sparse_adj_mat = SparseTensor(\n                        row=edge_index[idx][0].long(),\n                        col=edge_index[idx][1].long(),\n                        value=torch.tensor(adj_mat).to(device=edge_index.device)\n                    )\n                    adj_mat = sparse_adj_mat.to_dense().unsqueeze(dim=0).cpu().numpy()\n                tour = self.local_search_func(\n                    np_points=self.points[idx],\n                    tours=decoded_tours[idx],\n                    adj_mat=adj_mat,\n                    device=device,\n                    **ls_kwargs\n                )\n                ls_tours.append(tour)\n            ls_tours = np.array(ls_tours)\n\n        tours = decoded_tours if ls_tours is None else ls_tours\n        self.tours = tours\n        return tours\n\n    def __repr__(self):\n        message = f\"encoder={self.encoder}, decoding_type={self.decoding_type}, ls_type={self.ls_type}\"\n        return f\"{self.__class__.__name__}({message})\"",
  "description": "Combined Analysis:\n- [ml4tsp-library/ml4tsp/ar/solver/base.py]: This file implements the core algorithmic pipeline of the ML4TSP framework described in the paper. It specifically handles the inference phase where a learned autoregressive model generates candidate TSP tours, followed by optional local search improvement. The solve() method: 1) batches input city coordinates, 2) uses the trained ML model to generate tours (potentially multiple per instance), 3) selects the best tour via cost evaluation (implicitly minimizing ∑Dᵢⱼ·Xᵢⱼ), and 4) applies local search if configured. This aligns with the paper's unified modular design that combines learning and search components, though the mathematical constraints are enforced implicitly through the model's autoregressive generation rather than explicit constraint programming.\n- [ml4tsp-library/ml4tsp/nar/decoder/mcts.py]: This file implements the core optimization algorithm for TSP using Monte Carlo Tree Search (MCTS) combined with 2-opt local search. The _decode method takes a heatmap (edge probability matrix) and optional point coordinates, then uses MCTS to search for optimal tours. The implementation maps to the paper's methodology by: 1) Using learned edge probabilities (heatmap) as priors for search, 2) Combining tree search (MCTS) with improvement heuristics (2-opt), 3) Implementing time-adaptive search based on problem size, 4) Providing smooth heatmap transformation for better search guidance. The tsp_mcts_decoder function (from ml4co_kit) encapsulates the actual MCTS algorithm that solves the TSP optimization problem using the provided heatmap as guidance.\n- [ml4tsp-library/ml4tsp/nar/local_search/mcts.py]: This file implements the Monte Carlo Tree Search (MCTS) local search component of the ML4TSPBench framework. It directly corresponds to the 'improvement-based search' algorithmic step described in the paper, specifically integrating MCTS with 2-opt operations for tour refinement. The core optimization logic is encapsulated in the _local_search method, which takes an initial tour, point coordinates, and a heatmap (edge probability matrix) to perform MCTS-based search for minimizing tour length. The implementation includes adaptive parameter tuning based on problem size, multiple heatmap smoothing techniques, and integration with external C++ MCTS implementation via ml4co_kit. This represents a key search module in the unified learning-search pipeline for TSP optimization.\n- [ml4tsp-library/ml4tsp/nar/model/diffusion.py]: This file implements the core diffusion-based learning algorithm for the TSP optimization model. It directly maps to the paper's non-autoregressive paradigm and joint probability estimation principle. Key aspects:\n1. The ML4TSPDiffusion class learns to predict edge probabilities (heatmap) representing the binary decision variables X_{i,j} ∈ {0,1}.\n2. The points2adj method computes the distance matrix D_{i,j} used in the objective function.\n3. The guided_categorical_denoise_step incorporates the objective function (tour cost) through gradient-based guidance during denoising.\n4. The categorical posterior sampling implements the diffusion process for binary edge variables.\n5. The inference_process generates heatmaps that are then decoded into tours satisfying TSP constraints.\nThe implementation aligns with the paper's unified framework by combining learning (diffusion model) with search (decoder and local search components).\n- [ml4tsp-library/ml4tsp/nar/solver/narsolver.py]: This file implements the core algorithm steps of the ML4TSP framework for non-autoregressive (NAR) TSP solvers. It directly maps to the paper's unified modular streamline by integrating learning (via ML4TSPNARBaseModel for edge probability estimation) and search (via decoder and optional local search). The solve() method handles batch processing and timing, while _solve() executes the key steps: 1) data preparation and distance matrix computation, 2) heatmap generation (either via learned model or soft dictionary), 3) tour decoding from heatmap, and 4) optional local search improvement. This aligns with the paper's principles of joint probability estimation and online optimization, though the mathematical optimization model (objective and constraints) is implicitly handled through the learned heatmap and decoding process rather than explicit constraint programming.\n- [models/modelzoo/diffusion/tsp_diffusion.py]: This file implements a diffusion-based machine learning approach for solving the Traveling Salesman Problem (TSP) as part of the ML4TSPBench framework. The TSPDiffusion class uses a diffusion model to generate edge probability heatmaps, which are then decoded into valid tours using construction methods (greedy) and optionally refined with local search. The implementation directly addresses the TSP optimization problem by: 1) Learning to predict edge probabilities (adjacency matrix) through diffusion denoising, 2) Using decoding algorithms to construct valid Hamiltonian cycles from the heatmaps, 3) Incorporating search techniques like active search and gradient-based refinement. The mathematical optimization model is implicitly implemented through the edge prediction and tour construction process, where the learned heatmaps represent edge selection probabilities that satisfy TSP constraints through the decoding process.\n- [models/modelzoo/gnn/tsp_gnn.py]: This file implements the core ML4TSPBench framework for TSP using GNNs. The shared_step method executes the complete pipeline: 1) Forward pass through GNN to predict edge probabilities (heatmap), 2) Loss computation for training, 3) During validation/testing: decoding (greedy/beam search/etc.) to construct tours from heatmap, 4) Optional active search (test-time optimization) and local search improvement, 5) Evaluation against ground truth using TSPEvaluator. This aligns with the paper's unified framework combining learning (edge prediction) and search (construction + improvement methods).\n- [search/mcts.py]: This file implements the MCTS-based improvement search component of the ML4TSPBench framework. It directly corresponds to the 'improvement-based search' algorithmic step described in the paper, specifically using Monte Carlo Tree Search (MCTS) guided by learned edge probabilities (heatmap) to refine initial tours. The code accepts problem instances (np_points), initial tours, and a learned adjacency matrix (heatmap), then performs MCTS local search with configurable parameters. The implementation handles batch processing, dimension adjustments, and includes smoothing techniques for the heatmap. It encapsulates the integration of machine learning (through the heatmap) with search (MCTS) to optimize TSP solutions, aligning with the paper's unified framework of combining learning and search methodologies.\n- [search/mcts_solver.py]: This file implements the MCTS (Monte Carlo Tree Search) component of the ML4TSP unified framework. It directly corresponds to the 'search' module in the paper's methodology, specifically implementing improvement-based search through MCTS guided by learned edge probabilities (adj_mat). The code: 1) Takes learned edge heatmaps as input, 2) Optionally applies smoothing techniques, 3) Uses MCTS with configurable depth and temperature parameters to explore solution space, 4) Applies 2-opt local search for refinement, 5) Supports parallel sampling and sparse graph representations. This implements the algorithmic step where learned probabilities guide search to find optimal Hamiltonian cycles, addressing the TSP optimization model through a learning-guided search paradigm.\n- [solvers/solver.py]: This file implements the core optimization logic for the non-autoregressive (NAR) learning-based TSP solver as described in the paper's unified framework (ML4TSPBench). The TSPNARSolver class encapsulates the key algorithm steps: (1) encoding node coordinates into edge probability heatmaps using a neural network (e.g., GNN), (2) decoding the heatmap into tours via construction methods (e.g., greedy, beam search), and (3) optional local search improvement. This directly corresponds to the paper's modular design space integrating learning (edge prediction) and search (decoding + improvement). The solve method orchestrates these components, aligning with the paper's principles of joint probability estimation and online optimization.",
  "dependencies": [
    "search.get_decoding_func",
    ".base.ML4TSPNARLocalSearch",
    "tsplib95",
    "scipy.special",
    "torch.utils.data",
    "search",
    "ml4co_kit.to_numpy",
    ".base.ML4TSPNARDecoder",
    "search.get_local_search_func",
    "..model.base.ML4TSPNARBaseModel",
    "typing.Union",
    "ML4TSPNAREnv",
    "pygmtools",
    "models.utils.diffusion.InferenceSchedule",
    "ml4co_kit.tsp_mcts_local_search",
    "ml4co_kit.iterative_execution",
    "ml4co_kit.tsp_mcts_decoder",
    "multiprocessing.Pool",
    "mcts_smooth.smooth_heatmap_v2",
    "models.modelzoo",
    "time",
    "MCTS_SETTINGS",
    "models.utils.evaluator.TSPEvaluator",
    "torch_sparse",
    "ctypes",
    "ml4co_kit.TSPEvaluator",
    "sklearn.utils.class_weight.compute_class_weight",
    "scipy.sparse",
    "utils.utils.coords_to_distance",
    "ml4co_kit.TSPSolver",
    "torch.nn.functional",
    "InferenceSchedule",
    "typing",
    "search.tsp_greedy",
    "warnings",
    "utils.utils",
    "ml4co_kit.to_tensor",
    ".mcts_smooth.smooth_heatmap_v2",
    "scipy.spatial",
    "pytorch_lightning.utilities",
    "tqdm",
    "ML4TSPNARBaseModel",
    "math",
    "CategoricalDiffusion",
    "torch_geometric.data",
    "get_nodes_num_for_mcts_time_limit",
    "lkh",
    "GNNEncoder",
    "ml4co_kit.sparse_points",
    ".gnn_base.MetaGNN",
    "models.utils.diffusion.get_schedule_fn",
    "mcts_smooth.smooth_heatmap",
    "sklearn.utils.class_weight",
    "MCTS_TIME_LIMIT_DEFAULT",
    "ML4TSPNARDecoder",
    ".mcts_smooth.smooth_heatmap",
    "ml4tsp.ar.model.base.ML4TSPARBaseModel",
    "numpy",
    "ml4co_kit.SOLVER_TYPE",
    "ML4TSPNARLocalSearch",
    "models.utils.active_search.ActiveSearch",
    "models.utils.diffusion.CategoricalDiffusion",
    "torch_geometric.data.Data",
    "ml4co_kit.points_to_distmat",
    "solvers.pyconcorde",
    "smooth_heatmap_v3",
    "smooth_heatmap_v2",
    "ml4co_kit.Timer",
    "torch.nn",
    "torch_sparse.SparseTensor",
    "utils.evaluator",
    ".diffusion_base.MetaDiffusion",
    "torch",
    "scipy.spatial.distance.cdist",
    "c_mcts_solver (C++ extension)",
    "smooth_heatmap"
  ]
}