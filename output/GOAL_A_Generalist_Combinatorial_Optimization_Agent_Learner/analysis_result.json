{
  "paper_id": "GOAL_A_Generalist_Combinatorial_Optimization_Agent_Learner",
  "title": "GOAL: A GENERALIST COMBINATORIAL OPTIMIZATION AGENT LEARNER",
  "abstract": "Machine Learning-based heuristics have recently shown impressive performance in solving a variety of hard combinatorial optimization problems (COPs). However they generally rely on a separate neural model, specialized and trained for each single problem. Any variation of a problem requires adjustment of its model and re-training from scratch. In this paper, we propose GOAL (for Generalist combinatorial Optimization Agent Learner), a generalist model capable of efficiently solving multiple COPs and which can be fine-tuned to solve new COPs. GOAL consists of a single backbone plus light-weight problem-specific adapters for input and output processing. The backbone is based on a new form of mixed-attention blocks which allows to handle problems defined on graphs with arbitrary combinations of node, edge and instance-level features. Additionally, problems which involve heterogeneous types of nodes or edges are handled through a novel multi-type transformer architecture, where the attention blocks are duplicated to attend the meaningful combinations of types while relying on the same shared parameters. We train GOAL on a set of routing, scheduling and classic graph problems and show that it is only slightly inferior to the specialized baselines while being the first multi-task model that solves a wide range of COPs. Finally we showcase the strong transfer learning capacity of GOAL by fine-tuning it on several new problems.",
  "problem_description_natural": "The paper addresses the challenge of solving a wide variety of combinatorial optimization problems (COPs)—including routing (e.g., TSP, CVRP), scheduling (e.g., Job Shop), packing (e.g., Knapsack), and graph problems (e.g., Minimum Vertex Cover)—using a single, unified machine learning model. Traditional neural heuristics require separate models per problem and retraining from scratch for any problem variation. GOAL overcomes this by using a shared backbone with lightweight task-specific input/output adapters, enabling efficient multi-task training and rapid adaptation to new COPs via fine-tuning. The model assumes instances can be represented as graphs (with node, edge, and/or instance-level features) and solutions constructed iteratively by selecting nodes.",
  "problem_type": "combinatorial optimization",
  "datasets": [
    "Generated ER Graphs",
    "Euclidean CVRP Instances",
    "CVRPTW Instances",
    "OP_distance Instances",
    "JSSP Benchmark Instances",
    "KP Random Instances",
    "ATSP Random Instances",
    "UMSP Random Instances",
    "MVC Generated Graphs"
  ],
  "performance_metrics": [
    "Optimality Gap",
    "Computation Time"
  ],
  "lp_model": {
    "objective": "$\\min f(x)$",
    "constraints": [
      "$x \\in X$"
    ],
    "variables": [
      "$x$: a feasible solution from the set $X$ of problem-specific solutions"
    ]
  },
  "raw_latex_model": "$$ \\min_{x \\in X} f(x) $$",
  "algorithm_description": "GOAL is a generalist neural combinatorial optimization model consisting of a single transformer backbone with mixed-attention blocks and lightweight task-specific adapters. It is trained via multi-task imitation learning on expert trajectories (solutions) generated by traditional solvers for a variety of COPs (e.g., ATSP, CVRP, JSSP). The model constructs solutions sequentially by selecting nodes, and can be fine-tuned to new problems with or without supervision."
}