{
  "paper_id": "LVM-Med_Learning_Large-Scale_Self-Supervised_Vision_Models_f",
  "title": "LVM-Med: Learning Large-Scale Self-Supervised Vision Models for Medical Imaging via Second-order Graph Matching",
  "abstract": "Obtaining large pre-trained models that can be fine-tuned to new tasks with limited annotated samples has remained an open challenge for medical imaging data. While pre-trained deep networks on ImageNet and vision-language foundation models trained on web-scale data are prevailing approaches, their effectiveness on medical tasks is limited due to the significant domain shift between natural and medical images. To bridge this gap, we introduce LVM-Med, the first family of deep networks trained on large-scale medical datasets. We have collected approximately 1.3 million medical images from 55 publicly available datasets, covering a large number of organs and modalities such as CT, MRI, X-ray, and Ultrasound. We benchmark several state-of-the-art self-supervised algorithms on this dataset and propose a novel self-supervised contrastive learning algorithm using a graph matching formulation. The proposed approach makes three contributions: (i) it integrates prior pair-wise image similarity metrics based on local and global information; (ii) it captures the structural constraints of feature embeddings through a loss function constructed via a combinatorial graph-matching objective; and (iii) it can be trained efficiently end-to-end using modern gradient-estimation techniques for black-box solvers. We thoroughly evaluate the proposed LVM-Med on 15 downstream medical tasks ranging from segmentation and classification to object detection, and both for the in and out-of-distribution settings. LVM-Med empirically outperforms a number of state-of-the-art supervised, self-supervised, and foundation models.",
  "problem_description_natural": "The optimization problem involves learning robust visual representations for medical images through a self-supervised contrastive learning framework formulated as a second-order graph matching problem. Given a batch of images, each image is augmented twice to produce two views. Feature embeddings from these views are used to construct two attributed graphs where nodes represent augmented images and edges encode relationships among them. The goal is to find a correspondence (matching) between the nodes of the two graphs that aligns augmented views originating from the same source image. This is achieved by defining vertex and edge affinity matrices that incorporate both global (entire image) and local (region-level) similarity measures. The matching is obtained by solving a combinatorial graph-matching objective that maximizes the total affinity under structural consistency constraints. Although the graph-matching problem is discrete and non-differentiable, the authors employ modern gradient estimation techniques for black-box solvers to enable end-to-end training of the entire pipeline, including the image encoder and affinity computation modules.",
  "problem_type": "Graph Matching",
  "datasets": [
    "BraTS2018",
    "MMWHS-CT",
    "MMWHS-MRI",
    "ISIC-2018",
    "JSRT",
    "KvaSir",
    "Drive",
    "BUID",
    "FGADR",
    "Brain Tumor Classification",
    "Multi-site Prostate MRI Segmentation",
    "VinDr",
    "LUNA2016",
    "LiTS2017",
    "MSD (Heart)"
  ],
  "performance_metrics": [
    "Dice score",
    "3D IoU",
    "Accuracy",
    "Average Precision (AP) at IoU=0.5",
    "mAP50"
  ],
  "lp_model": {
    "objective": "$\\min_{\\boldsymbol{v}} - \\sum_{i,a} c^v_{ia} v_{ia} - \\sum_{i,j,a,b} c^e_{ia,jb} v_{ia} v_{jb}$",
    "constraints": [
      "$\\sum_{a} v_{ia} = 1 \\quad \\forall i$",
      "$\\sum_{i} v_{ia} = 1 \\quad \\forall a$",
      "$v_{ia} \\in \\{0,1\\} \\quad \\forall i,a$"
    ],
    "variables": [
      "$v_{ia}$: binary decision variable indicating whether vertex $i$ in graph $G^s$ is matched to vertex $a$ in graph $G^t$"
    ]
  },
  "raw_latex_model": "$$\\begin{aligned}\n\\min_{\\boldsymbol{v}} & \\quad - \\sum_{i=1}^{N} \\sum_{a=1}^{N} c^v_{ia} v_{ia} - \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\sum_{a=1}^{N} \\sum_{b=1}^{N} c^e_{ia,jb} v_{ia} v_{jb} \\\\\n\\text{s.t.} & \\quad \\sum_{a=1}^{N} v_{ia} = 1, \\quad \\forall i = 1,\\dots,N, \\\\\n& \\quad \\sum_{i=1}^{N} v_{ia} = 1, \\quad \\forall a = 1,\\dots,N, \\\\\n& \\quad v_{ia} \\in \\{0,1\\}, \\quad \\forall i,a = 1,\\dots,N.\n\\end{aligned}$$",
  "algorithm_description": "The paper formulates self-supervised contrastive learning as a second-order graph matching (quadratic assignment) problem. To solve this combinatorial problem, they use an efficient heuristic solver based on Lagrange decomposition techniques. For end-to-end training, they employ the Implicit Maximum Likelihood Estimation (IMLE) method to approximate gradients through the black-box solver by perturbing the affinity matrices with Gumbel noise and using a finite-difference approximation."
}