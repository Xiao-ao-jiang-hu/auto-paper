{
  "paper_id": "A_Survey_on_Reinforcement_Learning_for_Combinatorial_Optimiz",
  "title": "A Survey on Reinforcement Learning for Combinatorial Optimization",
  "abstract": "This paper provides a detailed review of reinforcement learning (RL) applied to combinatorial optimization, with a focus on the Traveling Salesperson Problem (TSP) as a canonical example. It traces the historical development from early approaches like Graves and Whinston’s 1970 algorithm—viewed as a prototype of RL—to modern deep reinforcement learning methods. The authors compare classical and contemporary RL techniques, highlighting how advances in machine learning and computing power have enabled more effective approximations of NP-hard problems. The paper argues that deep reinforcement learning offers a flexible and powerful framework for tackling combinatorial optimization by integrating neural networks with traditional RL algorithms.",
  "problem_description_natural": "The paper addresses combinatorial optimization problems, particularly the Traveling Salesperson Problem (TSP), which involves finding the shortest possible route that visits each city exactly once and returns to the origin city. TSP is presented as a special case of the more general Quadratic Assignment Problem (QAP), where the goal is to assign facilities to locations to minimize total assignment cost. Both problems are NP-hard, meaning exact solutions are computationally infeasible for large instances, necessitating approximation methods. The paper explores how reinforcement learning—and especially deep reinforcement learning—can be used to generate high-quality approximate solutions without relying on labeled data.",
  "problem_type": "combinatorial optimization",
  "datasets": [
    "33-city",
    "42-city",
    "57-city",
    "50-city",
    "20-city",
    "100-city"
  ],
  "performance_metrics": [
    "Approximation distance",
    "Optimal Solution",
    "Minimum average distance",
    "Optimality Gap"
  ],
  "lp_model": {
    "objective": "$\\min \\sum_{i=1}^{n} \\sum_{j=1}^{n} c_{ij} x_{ij}$",
    "constraints": [
      "$\\sum_{j=1}^{n} x_{ij} = 1$ for all $i = 1,...,n$",
      "$\\sum_{i=1}^{n} x_{ij} = 1$ for all $j = 1,...,n$",
      "$x_{ij} \\in \\{0,1\\}$ for all $i,j$",
      "Subtour elimination: $\\sum_{i \\in S} \\sum_{j \\notin S} x_{ij} \\geq 1$ for all subsets $S$ of $\\{1,...,n\\}$ with $S \\neq \\emptyset$ and $S \\neq \\{1,...,n\\}$"
    ],
    "variables": [
      "$x_{ij}$: binary decision variable that equals 1 if the edge from city $i$ to city $j$ is included in the tour, and 0 otherwise"
    ]
  },
  "raw_latex_model": "$$\\begin{aligned} \\text{Minimize} & \\quad \\sum_{i=1}^{n} \\sum_{j=1}^{n} c_{ij} x_{ij} \\\\ \\text{Subject to} & \\quad \\sum_{j=1}^{n} x_{ij} = 1, \\quad \\forall i = 1,...,n \\\\ & \\quad \\sum_{i=1}^{n} x_{ij} = 1, \\quad \\forall j = 1,...,n \\\\ & \\quad x_{ij} \\in \\{0,1\\}, \\quad \\forall i,j \\\\ & \\quad \\sum_{i \\in S} \\sum_{j \\notin S} x_{ij} \\geq 1, \\quad \\forall S \\subset \\{1,...,n\\}, S \\neq \\emptyset, S \\neq \\{1,...,n\\} \\end{aligned}$$",
  "algorithm_description": "The paper surveys reinforcement learning algorithms for approximating solutions to the Traveling Salesperson Problem (TSP), including historical methods like Graves and Whinston's Algorithm (1970) that uses statistical properties and the Bellman equation, Ant-Q (1995) based on Q-learning and ant colony optimization, and modern deep RL approaches like REINFORCE (2019) that integrate attention models and policy gradient methods."
}