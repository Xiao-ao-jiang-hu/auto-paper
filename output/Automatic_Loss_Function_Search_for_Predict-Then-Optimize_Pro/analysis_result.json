{
  "paper_id": "Automatic_Loss_Function_Search_for_Predict-Then-Optimize_Pro",
  "title": "AUTOMATIC LOSS FUNCTION SEARCH FOR PREDICT-THEN-OPTIMIZE PROBLEMS WITH STRONG RANKING PROPERTY",
  "abstract": "Combinatorial optimization problems with parameters to be predicted from side information are commonly seen in a variety of problems during the paradigm shifts from reactive decision making to proactive decision making. Due to the misalignment between the continuous prediction results and the discrete decisions in optimization problems, it is hard to achieve a satisfactory prediction result with the ordinary $l_2$ loss in the prediction phase. To properly connect the prediction loss with the optimization goal, in this paper we propose a *total group preorder* (TGP) loss and its differential version called *approximate total group preorder* (ATGP) loss for predict-then-optimize (PTO) problems with strong ranking property. These new losses are provably more robust than the usual $l_2$ loss in a linear regression setting and have great potential to extend to other settings. We also propose an automatic searching algorithm that adapts the ATGP loss to PTO problems with different combinatorial structures. Extensive experiments on the ranking problem, the knapsack problem, and the shortest path problem have demonstrated that our proposed method can achieve a significantly better performance compared to the other methods designed for PTO problems.",
  "problem_description_natural": "The paper addresses predict-then-optimize (PTO) problems where unknown parameters of a combinatorial optimization problem must first be predicted from contextual features before solving the optimization. The key challenge is that standard prediction losses like $l_2$ do not align with the downstream optimization objective because small prediction errors may lead to large decision-quality losses due to the discrete and combinatorial nature of the optimization. The authors focus on a class of PTO problems exhibiting a 'strong ranking property,' meaning the optimal solution is fully determined by the total group preorder (i.e., comparisons of sums of subsets of parameters). Examples include ranking, knapsack (with fixed weights and capacity), and shortest path problems. The goal is to design a differentiable surrogate loss that better reflects the optimization outcome and can be automatically adapted to different problem structures.",
  "problem_type": "combinatorial optimization",
  "datasets": [
    "Irish Single Electricity Market Operator (SEM-O) energy price data",
    "Quandl WIKI SP500 dataset",
    "Twitter ego network (McAuley & Leskovec, 2012)"
  ],
  "performance_metrics": [
    "SPO loss"
  ],
  "lp_model": {
    "objective": "\\maximize_{z} U_c(z)",
    "constraints": [
      "z \\in Z"
    ],
    "variables": [
      "z: decision variable"
    ]
  },
  "raw_latex_model": "\\maximize_{z} U_c(z) \\quad \\text{subject to } z \\in Z",
  "algorithm_description": "The APOC (Automatic Prediction and Optimization Connector) algorithm searches for an appropriate ATGP loss function for predict-then-optimize problems with strong ranking property. The steps are as follows:\n1. Initialize with a gradient-based prediction model f_w, initial loss parameters θ_0, number of search iterations T, number of samples per iteration M, and exploration ratio σ.\n2. For each iteration t from 1 to T:\n   a. For each sample m from 1 to M:\n      i. Sample DoG filter parameters μ^m from a truncated normal distribution N_truncated(θ_{t-1}, σ^2 I).\n      ii. Compute the ATGP loss function ℓ^m parameterized by μ^m.\n      iii. Train the prediction model to minimize ℓ^m on the training set using stochastic gradient descent, obtaining model parameters ŵ.\n      iv. Evaluate the model on the validation set to compute predictions ĉ^{(i)} = f_ŵ(x^{(i)}) for all i in the validation set V.\n      v. Compute the reward R_t^m as the negative total SPO loss on the validation set: R_t^m = -∑_{i∈V} ℓ_SPO(ĉ^{(i)}, c^{(i)}).\n   b. Update the loss parameters θ_t using a policy gradient method (e.g., REINFORCE or PPO2) based on the rewards from all M samples.\n3. Output the final loss parameters θ^* = θ_T and the final prediction model parameters w^* obtained by training the model to minimize the ATGP loss parameterized by θ^* on the training set."
}