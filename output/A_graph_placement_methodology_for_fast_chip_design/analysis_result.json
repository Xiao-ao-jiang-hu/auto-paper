{
  "paper_id": "A_graph_placement_methodology_for_fast_chip_design",
  "title": "A graph placement methodology for fast chip design",
  "abstract": "Chip floorplanning, the task of designing the physical layout of a computer chip, has resisted automation for over five decades despite extensive research. This paper presents a deep reinforcement learning approach that automatically generates manufacturable chip floorplans in under six hours—significantly faster than the months required by human experts—while achieving performance comparable or superior across key metrics such as power, performance, and area. The method formulates floorplanning as a reinforcement learning problem and uses an edge-based graph convolutional neural network to learn transferable representations of chip netlists. Trained on past designs, the agent improves with experience and was used to design Google’s next-generation AI accelerators.",
  "problem_description_natural": "The optimization problem involves placing a chip netlist—comprising macros (e.g., memory blocks) and standard cell clusters (e.g., logic gates)—onto a two-dimensional chip canvas such that key performance metrics (wirelength, power consumption, timing, area) are optimized while satisfying hard constraints on density and routing congestion. The placement must respect physical feasibility and manufacturability. The challenge lies in the enormous combinatorial search space (e.g., factorial in the number of components), non-differentiable objectives like congestion, and the need to generalize across diverse chip architectures and canvas sizes.",
  "problem_type": "combinatorial optimization",
  "datasets": [
    "TPU chip blocks",
    "Ariane RISC-V CPU"
  ],
  "performance_metrics": [
    "Wirelength (m)",
    "Total area (μm²)",
    "Total power (W)",
    "Worst Negative Slack (WNS, ps)",
    "Total Negative Slack (TNS, ns)",
    "Horizontal Congestion (%)",
    "Vertical Congestion (%)"
  ],
  "lp_model": {
    "objective": "$ \\min \\left( \\text{Wirelength}(p,g) + \\lambda \\text{Congestion}(p,g) + \\gamma \\text{Density}(p,g) \\right) $",
    "constraints": [
      "$ \\text{density}(c) \\leq D_{\\text{max}} \\quad \\forall c \\in \\text{grid cells} $",
      "$ \\text{no overlap between macros} $",
      "$ x_i, y_i \\in \\text{grid bounds} \\quad \\forall i \\in \\text{macros} $"
    ],
    "variables": [
      "$ x_i, y_i $: coordinates of the center of macro $i$ on the discretized chip grid",
      "$ \\text{Wirelength}(p,g) = \\sum_{i=1}^{N_{\\text{netlist}}} q(i) \\cdot \\text{HPWL}(i) $, where $\\text{HPWL}(i) = (\\max_{b \\in i} x_b - \\min_{b \\in i} x_b + 1) + (\\max_{b \\in i} y_b - \\min_{b \\in i} y_b + 1) $",
      "$ \\text{Congestion}(p,g) $: proxy congestion based on routing allocations",
      "$ \\text{Density}(p,g) $: density penalty calculated from placed items"
    ]
  },
  "raw_latex_model": "$$ \\begin{aligned} \\min_{p} & \\quad \\text{Wirelength}(p,g) + \\lambda \\text{Congestion}(p,g) + \\gamma \\text{Density}(p,g) \\\\ \\text{s.t.} & \\quad \\text{density}(c) \\leq D_{\\text{max}}, \\quad \\forall c \\in \\text{grid cells} \\\\ & \\quad \\text{no overlap between macros} \\\\ & \\quad x_i, y_i \\in \\text{grid bounds}, \\quad \\forall i \\in \\text{macros} \\end{aligned} $$",
  "algorithm_description": "Deep reinforcement learning approach using an edge-based graph convolutional neural network (Edge-GNN) for state representation and proximal policy optimization (PPO) to train a policy that sequentially places macros on a chip canvas, followed by a force-directed method for standard cell placement."
}