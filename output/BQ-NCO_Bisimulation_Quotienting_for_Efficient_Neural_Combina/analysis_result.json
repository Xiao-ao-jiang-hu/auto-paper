{
  "paper_id": "BQ-NCO_Bisimulation_Quotienting_for_Efficient_Neural_Combina",
  "title": "BQ-NCO: Bisimulation Quotienting for Efficient Neural Combinatorial Optimization",
  "abstract": "Despite the success of neural-based combinatorial optimization methods for end-to-end heuristic learning, out-of-distribution generalization remains a challenge. In this paper, we present a novel formulation of Combinatorial Optimization Problems (COPs) as Markov Decision Processes (MDPs) that effectively leverages common symmetries of COPs to improve out-of-distribution robustness. Starting from a direct MDP formulation of a constructive method, we introduce a generic way to reduce the state space, based on Bisimulation Quotienting (BQ) in MDPs. Then, for COPs with a recursive nature, we specialize the bisimulation and show how the reduced state exploits the symmetries of these problems and facilitates MDP solving. Our approach is principled and we prove that an optimal policy for the proposed BQ-MDP actually solves the associated COPs. We illustrate our approach on five classical problems: the Euclidean and Asymmetric Traveling Salesman, Capacitated Vehicle Routing, Orienteering and Knapsack Problems. Furthermore, for each problem, we introduce a simple attention-based policy network for the BQ-MDPs, which we train by imitation of (near) optimal solutions of small instances from a single distribution. We obtain new state-of-the-art results for the five COPs on both synthetic and realistic benchmarks. Notably, in contrast to most existing neural approaches, our learned policies show excellent generalization performance to much larger instances than seen during training, without any additional search procedure.",
  "problem_description_natural": "The paper addresses a range of classical Combinatorial Optimization Problems (COPs), including the Euclidean and Asymmetric Traveling Salesman Problems (TSP/ATSP), the Capacitated Vehicle Routing Problem (CVRP), the Orienteering Problem (OP), and the Knapsack Problem (KP). These problems involve selecting or sequencing discrete elements (e.g., cities, items, or routes) to minimize cost or maximize reward under constraints such as capacity limits, visitation requirements, or resource budgets. The authors frame the solution process as a sequential decision-making problem using Markov Decision Processes (MDPs), where partial solutions are incrementally constructed. Their key insight is that many COPs exhibit recursive structure and symmetries—meaning different partial solutions can lead to equivalent remaining subproblems—and they exploit this via bisimulation quotienting to define a more compact and generalizable MDP representation.",
  "problem_type": "combinatorial optimization",
  "datasets": [
    "TSPLIB",
    "CVRPLIB",
    "Generated Euclidean TSP instances",
    "Generated Asymmetric TSP instances",
    "Generated CVRP instances",
    "Generated Orienteering Problem instances",
    "Generated Knapsack Problem instances"
  ],
  "performance_metrics": [
    "Optimality Gap",
    "Inference Time"
  ],
  "lp_model": {
    "objective": "$\\min \\sum_{i,j \\in V} d_{ij} x_{ij}$",
    "constraints": [
      "$\\sum_{j \\in V, j \\neq i} x_{ij} = 1$ for all $i \\in V$",
      "$\\sum_{i \\in V, i \\neq j} x_{ij} = 1$ for all $j \\in V$",
      "$\\sum_{i \\in S, j \\in V \\setminus S} x_{ij} \\geq 1$ for all $S \\subset V, S \\neq \\emptyset, S \\neq V$",
      "$x_{ij} \\in \\{0,1\\}$ for all $i,j \\in V, i \\neq j$"
    ],
    "variables": [
      "$x_{ij}$: binary decision variable indicating if edge from node $i$ to $j$ is included in the tour",
      "$d_{ij}$: Euclidean distance between nodes $i$ and $j$, defined as $\\| p_i - p_j \\|$ where $p_i$ are coordinates"
    ]
  },
  "raw_latex_model": "$$\\begin{aligned} \\text{Minimize} & \\quad \\sum_{i,j \\in V} d_{ij} x_{ij} \\\\ \\text{Subject to} & \\quad \\sum_{j \\in V, j \\neq i} x_{ij} = 1 \\quad \\forall i \\in V \\\\ & \\quad \\sum_{i \\in V, i \\neq j} x_{ij} = 1 \\quad \\forall j \\in V \\\\ & \\quad \\sum_{i \\in S, j \\in V \\setminus S} x_{ij} \\geq 1 \\quad \\forall S \\subset V, S \\neq \\emptyset, S \\neq V \\\\ & \\quad x_{ij} \\in \\{0,1\\} \\quad \\forall i,j \\in V, i \\neq j \\end{aligned}$$",
  "algorithm_description": "The paper proposes a bisimulation quotiented Markov Decision Process (BQ-MDP) framework to model combinatorial optimization problems, reducing state space by exploiting symmetries. For solving, a transformer-based policy network is trained by imitation learning from (near) optimal solutions of small instances, achieving generalization to larger instances without additional search."
}