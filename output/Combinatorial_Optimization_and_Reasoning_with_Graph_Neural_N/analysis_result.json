{
  "paper_id": "Combinatorial_Optimization_and_Reasoning_with_Graph_Neural_N",
  "title": "Combinatorial Optimization and Reasoning with Graph Neural Networks",
  "abstract": "Combinatorial optimization is a well-established area in operations research and computer science. Until recently, its methods have focused on solving problem instances in isolation, ignoring that they often stem from related data distributions in practice. However, recent years have seen a surge of interest in using machine learning, especially graph neural networks (GNNs), as a key building block for combinatorial tasks, either directly as solvers or by enhancing exact solvers. The inductive bias of GNNs effectively encodes combinatorial and relational input due to their invariance to permutations and awareness of input sparsity. This paper presents a conceptual review of recent key advancements in this emerging field, aiming at optimization and machine learning researchers.",
  "problem_description_natural": "The paper addresses the challenge of solving combinatorial optimization (CO) problems—such as the Traveling Salesperson Problem (TSP), vehicle routing, scheduling, and chip placement—by leveraging machine learning, particularly graph neural networks (GNNs). These problems involve selecting an optimal subset from a finite set under constraints, typically over graph-structured data. Traditional approaches solve each instance in isolation, but real-world scenarios often involve repeated instances with shared patterns (e.g., daily routing in the same city with varying traffic). The goal is to exploit these patterns using data-driven methods to improve solution speed, quality, or generalization, while handling challenges like permutation invariance, sparsity, scalability, and limited labeled data.",
  "problem_type": "combinatorial optimization",
  "datasets": [
    "TSPLIB",
    "MIPLIB",
    "Generated ER Graphs",
    "GIFT cipher SAT instances",
    "Random SAT instances"
  ],
  "performance_metrics": [
    "Optimality Gap",
    "Solving Time",
    "Number of Branch-and-Bound Nodes",
    "Feasibility Rate",
    "Objective Value"
  ],
  "lp_model": {
    "objective": "$\\min \\sum_{i=1}^{n} \\sum_{j \\neq i, j=1}^{n} w_{ij} x_{ij}$",
    "constraints": [
      "$\\sum_{i=1, i \\neq j}^{n} x_{ij} = 1 \\quad \\text{for } j \\in [n]$",
      "$\\sum_{j=1, j \\neq i}^{n} x_{ij} = 1 \\quad \\text{for } i \\in [n]$",
      "$\\sum_{i \\in Q} \\sum_{j \\notin Q} x_{ij} \\geq 1 \\quad \\forall Q \\subsetneq [n], |Q| \\geq 2$"
    ],
    "variables": [
      "$x_{ij}$: binary decision variable, 1 if the cycle goes from city $i$ to city $j$, 0 otherwise"
    ]
  },
  "raw_latex_model": "$$\\begin{aligned}\n& \\min \\sum_{i=1}^{n} \\sum_{j \\neq i, j=1}^{n} w_{ij} x_{ij} \\\\\n& \\text{subject to } \\sum_{i=1, i \\neq j}^{n} x_{ij} = 1 \\quad \\quad \\quad \\quad \\quad \\quad j \\in [n], \\\\\n& \\quad \\quad \\quad \\quad \\sum_{j=1, j \\neq i}^{n} x_{ij} = 1 \\quad \\quad \\quad \\quad \\quad \\quad i \\in [n], \\\\\n& \\quad \\quad \\quad \\quad \\sum_{i \\in Q} \\sum_{j \\notin Q} x_{ij} \\geq 1 \\quad \\quad \\quad \\forall Q \\subsetneq [n], |Q| \\geq 2.\n\\end{aligned}$$",
  "algorithm_description": "The paper surveys the application of Graph Neural Networks (GNNs) to combinatorial optimization problems, including the Traveling Salesperson Problem (TSP). Various machine learning paradigms are reviewed: supervised learning for direct solution prediction or variable scoring, reinforcement learning for iterative solution construction (e.g., greedy node selection policies), unsupervised learning for constraint satisfaction via differentiable loss functions, and imitation learning for branching decisions in exact solvers. GNNs are often integrated with classical algorithms like branch-and-bound, local search, or constraint programming to enhance primal or dual solution processes."
}