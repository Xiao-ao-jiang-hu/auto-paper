{
  "paper_id": "DeepSAT_An_EDA-Driven_Learning_Framework_for_SAT",
  "title": "On EDA-Driven Learning for SAT Solving",
  "abstract": "We present DeepSAT, a novel end-to-end learning framework for the Boolean satisfiability (SAT) problem. Unlike existing solutions trained on random SAT instances with relatively weak supervision, we propose applying the knowledge of the well-developed electronic design automation (EDA) field for SAT solving. Specifically, we first resort to logic synthesis algorithms to pre-process SAT instances into optimized and-inverter graphs (AIGs). By doing so, the distribution diversity among various SAT instances can be dramatically reduced, which facilitates improving the generalization capability of the learned model. Next, we regard the distribution of SAT solutions being a product of conditional Bernoulli distributions. Based on this observation, we approximate the SAT solving procedure with a conditional generative model, leveraging a novel directed acyclic graph neural network (DAGNN) with two polarity prototypes for conditional SAT modeling. To effectively train the generative model, with the help of logic simulation tools, we obtain the probabilities of nodes in the AIG being logic ‘1’ as rich supervision. We conduct comprehensive experiments on various SAT problems. Our results show that, DeepSAT achieves significant accuracy improvements over state-of-the-art learning-based SAT solutions, especially when generalized to SAT instances that are relatively large or with diverse distributions.",
  "problem_description_natural": "The paper addresses the Boolean satisfiability (SAT) problem, which involves determining whether there exists an assignment of binary values to input variables such that a given Boolean formula evaluates to true (logic ‘1’). The authors aim to develop a deep learning-based solver that generalizes well across diverse SAT instance distributions by leveraging techniques from electronic design automation (EDA), specifically logic synthesis and logic simulation. They reformulate SAT solving as a conditional generative modeling task over the joint Bernoulli distribution of input variables, using rich supervision derived from simulated signal probabilities in optimized circuit representations (AIGs). The goal is to predict satisfying assignments directly through a learned model rather than relying on traditional heuristic search.",
  "problem_type": "combinatorial optimization",
  "datasets": [
    "SR(3-10)",
    "SR(10)",
    "SR(20)",
    "SR(40)",
    "SR(60)",
    "SR(80)",
    "graph k-coloring",
    "vertex k-cover",
    "k-clique-detection",
    "dominating k-set"
  ],
  "performance_metrics": [
    "Problems Solved",
    "Coloring Acc.",
    "Domset Acc.",
    "Clique Acc.",
    "Vertex Acc.",
    "Avg. Acc."
  ],
  "lp_model": {
    "objective": "$\\max 0$",
    "constraints": [
      "$v_i = x_i$ for $i=1,\\ldots,I$",
      "For each AND gate $j$ with inputs $a$ and $b$, $v_j = v_a \\land v_b$",
      "For each NOT gate $j$ with input $a$, $v_j = \\neg v_a$",
      "$v_o = 1$"
    ],
    "variables": [
      "$x_i \\in \\{0,1\\}$: binary decision variable for primary input $i$",
      "$v_j \\in \\{0,1\\}$: value of node $j$ (for internal nodes, defined by constraints)"
    ]
  },
  "raw_latex_model": "$$\\begin{aligned}\\max & \\ 0 \\\\\\text{s.t. } & v_i = x_i, \\quad i=1,\\ldots,I \\\\& v_j = v_a \\land v_b \\quad \\text{for each AND gate } j \\text{ with inputs } a \\text{ and } b \\\\& v_j = \\neg v_a \\quad \\text{for each NOT gate } j \\text{ with input } a \\\\& v_o = 1 \\\\& x_i \\in \\{0,1\\}, \\quad i=1,\\ldots,I\\end{aligned}$$",
  "algorithm_description": "DeepSAT is an end-to-end learning framework that formulates SAT solving as a conditional generative procedure. It uses a directed acyclic graph neural network (DAGNN) with polarity prototypes to approximate conditional probabilities of node states, trained with supervision from logic simulation. Solutions are sampled via an auto-regressive procedure that iteratively assigns values to primary inputs based on predicted probabilities."
}